{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a925ca7e",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5825f6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import inspect\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# pycaffe modules\n",
    "import caffe\n",
    "from caffe import layers as L, params as P\n",
    "\n",
    "# PIL modules\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# PyPlot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4056a4f9",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "# constants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740cd76a",
   "metadata": {},
   "source": [
    "## npy files directory root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3a59f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "NPY_ROOT = f\"./npy_save\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6eec9c",
   "metadata": {},
   "source": [
    "# Input Transform Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c11bfe",
   "metadata": {},
   "source": [
    "## get_size()\n",
    "\n",
    "Return suitable size for detection or recognition model\n",
    "* mask rcnn transforms.py get_size() replica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77bebe1e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_size(pil_image, mode='keep_ratio'):\n",
    "    \"\"\"Return suitable size for detection or recognition model\n",
    "       mask rcnn transforms.py get_size() replica\n",
    "\n",
    "    Args:\n",
    "        pil_image (PIL.Image) : PIL image opened with RGB mode (512x438=WxH)\n",
    "        mode (str) : resize mode\n",
    "            \"horizontal_padding\" | 'keep_ratio'\n",
    "\n",
    "    Returns:\n",
    "        (int, int) : tuple of (width, height) for resizing\n",
    "    \"\"\"\n",
    "    # get size of pil_image\n",
    "    w, h = pil_image.size\n",
    "\n",
    "    # output image width and height initialize\n",
    "    ow, oh = -1, -1\n",
    "\n",
    "    # i) recognition model: 'horizontal_padding'\n",
    "    if (mode == 'horizontal_padding'):\n",
    "        ow, oh = -1, -1\n",
    "        target_width = int(w * (oh / h))\n",
    "        if target_width < oh:\n",
    "            target_width = oh\n",
    "\n",
    "        if target_width > ow:\n",
    "            target_width = ow\n",
    "\n",
    "        ow = target_width\n",
    "\n",
    "    # ii) detection model: 'keep_ratio'\n",
    "    elif (mode == 'keep_ratio'):\n",
    "        min_size = 480\n",
    "        max_size = 640\n",
    "        min_original_size = float(min((w, h)))\n",
    "        max_original_size = float(max((w, h)))\n",
    "\n",
    "        # summary\n",
    "        # take smaller one from height or width, and resize smaller one to 480\n",
    "        # and larger one is resized while keeping ratio\n",
    "\n",
    "        # i) first determine max_size\n",
    "        #   max_size : min_size  = max_original_size : min_original_size  -- (1)\n",
    "        #       ? :  480  =  512 : 438\n",
    "        # from (1) max_size = max_original_size * min_size / min_orignal_size\n",
    "        #                   =  480*512/438 = 531.09 = 561\n",
    "        # max size= 561.095\n",
    "        calc_max_size = max_original_size / min_original_size * min_size\n",
    "        max_size = min(calc_max_size, max_size)\n",
    "\n",
    "        # ii) determine min_size from the determined max_size\n",
    "        #   max_size : min_size  = max_original_size : min_original_size  -- (2)\n",
    "        #      561.095  :  ?  =  512 : 438\n",
    "        # from (2) min_size  =  max_size * min_original_size /  max_original_size\n",
    "        #                    = 561.095 * 438 /512 = 479.99 = round(479.99) = 480\n",
    "        min_size = round(max_size * min_original_size / max_original_size)\n",
    "\n",
    "        # if input image is a vertical image, i.e, height > width\n",
    "        #   ow = min_size, oh = max_size\n",
    "        # if input image is a horizontal image, i.e, width > height\n",
    "        #   ow = max_size, oh = min_size\n",
    "        ow = min_size if w < h else max_size\n",
    "\n",
    "        oh = max_size if w < h else min_size\n",
    "\n",
    "        # oh : 480, ow = 561.095\n",
    "        # int() cause round off\n",
    "        # oh : 480, ow = 561,\n",
    "        # (438, 512)  => (480, 561)   ; keep ratio = 1.168\n",
    "\n",
    "    # return target size with WXH format\n",
    "    return (int(ow), int(oh))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2344ea",
   "metadata": {},
   "source": [
    "## pil_image_resize()\n",
    "\n",
    "Returns resized the PIL image using BILINEAR interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "236e1139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_image_resize(pil_image):\n",
    "    \"\"\"Returns resized the PIL image using BILINEAR interpolation\n",
    "\n",
    "    Args:\n",
    "        pil_image (PIL.Image) : original PIL image to be resized\n",
    "            ex. 512x438 => 561 x 480\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image : resized PIL Image\n",
    "    \"\"\"\n",
    "    # cacl height and width after resize\n",
    "    # size = get_size(pil_image, mode='keep_ratio')\n",
    "    width, height = get_size(pil_image, mode='keep_ratio')\n",
    "\n",
    "    # do resize with BILINEAR interpolaton\n",
    "    # resized_pil_image = Image.resize(size, resample=Image.BILINEAR)\n",
    "    resized_pil_image = pil_image.resize((width, height), resample=Image.BILINEAR)\n",
    "\n",
    "    # WxH = 512x438 RGB ==> WxH = 561x480 RGB\n",
    "    return resized_pil_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10d7a80",
   "metadata": {},
   "source": [
    "## pil_to_ndarray()\n",
    "Returns numpy.ndarray converted from PIL image of RGB mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9979f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_to_ndarray(pil_image):\n",
    "    \"\"\"Returns numpy.ndarray converted from PIL image of RGB mode\n",
    "\n",
    "    Args:\n",
    "    pil_image (PIL.Image):  resized PIL image, 561x480 (WxH), mode=RGB\n",
    "\n",
    "    Returns:\n",
    "        ndarray of float32 : array with shape of CxHxW with pixel value range 0.0 ~ 1.0\n",
    "    \"\"\"\n",
    "    # read PIL image into np.ndarray\n",
    "    image_array = np.array(pil_image)\n",
    "\n",
    "    # pil_image.size : (w, h)\n",
    "    # pil_image.mode : \"RGB\", len(pil_image.mode) =3\n",
    "    w, h = pil_image.size\n",
    "    c = len(pil_image.mode)\n",
    "\n",
    "    # reshape 707840 into HWC (480, 561, 3) format\n",
    "    image_array = image_array.reshape(h, w, c)\n",
    "\n",
    "    # change dimension order from HWC to CHW format\n",
    "    image_array = image_array.transpose(2, 0, 1)\n",
    "\n",
    "    # change pixel value range 0 - 255 to 0.0 ~ 1.0\n",
    "    image_array = np.float32(image_array) / 255.0\n",
    "\n",
    "    return image_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45ffcd9",
   "metadata": {},
   "source": [
    "## normalize()\n",
    "Returns normalized ndarray of BGR ch. order with configuration defined mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69d7a9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image_array):\n",
    "    \"\"\" Returns normalized ndarray of BGR ch. order\n",
    "        with configuration defined mean and std\n",
    "\n",
    "    Args:\n",
    "        image_array (np.ndarray) : array format of resized input image, RGB mode and CHW dimension order\n",
    "\n",
    "    Returns:\n",
    "       ndarray: normalized with configuration defined mean and std\n",
    "           dimension order: CHW, channel order: BGR\n",
    "    \"\"\"\n",
    "    mean = [102.9801, 115.9465, 122.7717]\n",
    "    std = [1.0, 1.0, 1.0]\n",
    "\n",
    "    # change ch. order from RGB to BGR\n",
    "    # https://note.nkmk.me/en/python-opencv-bgr-rgb-cvtcolor/\n",
    "    image_array = image_array[[2, 1, 0], :, :]\n",
    "\n",
    "    # multiply 255 to each pixel value\n",
    "    image_array = image_array * 255\n",
    "\n",
    "    # normalize with mean and std\n",
    "    # since std is [1.0, 1.0, 1.0], just subtract mean\n",
    "    # note that CHW shape with channel order BGR\n",
    "    image_array[0, :, :] = image_array[0, :, :] - mean[0]\n",
    "    image_array[1, :, :] = image_array[1, :, :] - mean[1]\n",
    "    image_array[2, :, :] = image_array[2, :, :] - mean[2]\n",
    "\n",
    "    return image_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3f1515",
   "metadata": {},
   "source": [
    "## zero_padding()\n",
    "\n",
    "Returns batched padded array with new width/height with 32 divisible and pad with zero pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c3b99ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_padding(image_array, size_divisible=32):\n",
    "    \"\"\"Returns batched padded array with new width/height with 32 divisible and pad with zero pixels\n",
    "\n",
    "    Args:\n",
    "        image_array (np.ndarray) : image array of CHW dimension order and RGB channel order\n",
    "            ndarray of shape format (3, H, W), RGB channel order\n",
    "        size_divisible (int, default:32) : which multiple of width and height\n",
    "\n",
    "    Returns:\n",
    "        ndarray of shape [1, 3, H', W']:\n",
    "            batched image array of shape (1, 3, H', W'), H' and W' is multiple of 32\n",
    "            increase region filled with zeros and batch dimension added at axis 0\n",
    "    \"\"\"\n",
    "    # calc size divisible new height and width\n",
    "    c, h, w = image_array.shape\n",
    "\n",
    "    new_h = int(np.ceil(h / size_divisible) * size_divisible)\n",
    "    new_w = int(np.ceil(w / size_divisible) * size_divisible)\n",
    "\n",
    "    # create black image with size divisible\n",
    "    padded_image_array = np.zeros((3, new_h, new_w), dtype=np.float32)\n",
    "\n",
    "    # overlay image_array on padded_image\n",
    "    padded_image_array[:c, :h, :w] = image_array\n",
    "\n",
    "    # add batch dimension into image_array\n",
    "    # (3, H, W) => (1, 3, H, W)\n",
    "    padded_image_array = np.expand_dims(padded_image_array, axis=0)\n",
    "\n",
    "    return padded_image_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864f88ae",
   "metadata": {},
   "source": [
    "## image_preprocess()\n",
    "\n",
    "Returns transformed and zero padded batch array\n",
    "- pil_image_resize()\n",
    "- pil_to_ndarray()\n",
    "- normalize()\n",
    "- zero_padding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1382e09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocess(img_file_path, debug=False):\n",
    "    \"\"\" Returns transformed and zero padded batch array\n",
    "\n",
    "    Args:\n",
    "        img_file_path (string): file path to image file\n",
    "        debug (bool): print debug message or not\n",
    "    Retruns:\n",
    "        ndarray of (1, C, W, H)\n",
    "    \"\"\"\n",
    "    # 1 test image laoding into PIL.Image with RGB mode\n",
    "    img_file = \"../sample_images/detection/1594202471809.jpg\"\n",
    "    pil_img = Image.open(img_file).convert('RGB')\n",
    "    if debug:\n",
    "        print(f\"pil_img.size: {pil_img.size}\")\n",
    "\n",
    "    # 2 resize pil image\n",
    "    resized_pil_img = pil_image_resize(pil_img)\n",
    "    if debug:\n",
    "        print(f\"resized_pil_img.size (WxH): {resized_pil_img.size}\\nresized_pil_img.mode: {resized_pil_img.mode}\")\n",
    "\n",
    "    # 2.3 PIL.Image to np.ndarray conversion\n",
    "    img_array = pil_to_ndarray(resized_pil_img)\n",
    "    if debug:\n",
    "        print(f\"img_array.shape (CxHxW): {img_array.shape}, ch. order in C dimension is RGB\")\n",
    "        print(f\"img_array.dtype: {img_array.dtype}\")\n",
    "\n",
    "    # 2.4 Normalization\n",
    "    # normalization with mean and std defined in configuration\n",
    "    # mean: [102.9801, 115.9465, 122.7717], std: [1.0, 1.0, 1.0]\n",
    "    normalized_img_array = normalize(img_array)\n",
    "    if debug:\n",
    "        print(f\"normalized_img_array.shape (CxHxW): {normalized_img_array.shape}, ch. order in C dimension is GBR\")\n",
    "        print(f\"normalized_img_array.dtype: {normalized_img_array.dtype}\")\n",
    "\n",
    "    # 2.5 Zero Padding\n",
    "    # make zero image of width and height that ar multiple of 32 and\n",
    "    # overlay the normalized_img_array on to zeo image\n",
    "    # add batch dimension\n",
    "    batch_img_array = zero_padding(normalized_img_array, size_divisible=32)\n",
    "    if debug:\n",
    "        print(f\"batch_img_array.shape (NxCxHxW): {batch_img_array.shape}, ch. order in C dimension is GBR\")\n",
    "        print(f\"batch_img_array.dtype: {batch_img_array.dtype}\")\n",
    "\n",
    "    return batch_img_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b82cbb6",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "# Network Spec Build Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298bacc9",
   "metadata": {},
   "source": [
    "## conv_fbn()\n",
    "\n",
    "Build a block for Conv -> FronzeBN\n",
    "\n",
    "Note that PyTorch FrozenBN is implemented using Scale layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8dbd5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_fbn(bottom, nout, in_place_scale=False, **kwargs):\n",
    "\n",
    "    \"\"\" Build a block for Conv -> FronzeBN\n",
    "        Note that PyTorch FrozenBN is implemented using Scale layer\n",
    "\n",
    "    Args:\n",
    "        bottom: input to this conv/bn/scale block\n",
    "        nout : num of oputs in Convolution Layer\n",
    "        in_place: in place operation in scale layer\n",
    "\n",
    "    Returns:\n",
    "       top of conv, fbn\n",
    "    \"\"\"\n",
    "    conv = L.Convolution(bottom, num_output=nout, bias_term=False, **kwargs)\n",
    "\n",
    "    # https://github.com/facebookresearch/maskrcnn-benchmark/blob/master/maskrcnn_benchmark/layers/batch_norm.py\n",
    "    # bn = L.BatchNorm(conv, use_global_stats=True, in_place=True)\n",
    "    # fbn = L.Scale(conv, bias_term=True, in_place=True)\n",
    "    fbn = L.Scale(conv, bias_term=True, in_place=in_place_scale)\n",
    "    return conv, fbn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23d29bc",
   "metadata": {},
   "source": [
    "## resnet_stage_sublayer()\n",
    "\n",
    "Build Basic Resnet Stage layer.\n",
    "\n",
    "Resnet50 consists of following layers (aka stage)\n",
    "* layer 0: conv + fbn + relu + maxpool\n",
    "* layer 1: 3 sublayer 0, 1, 2 with oen down_sample branch\n",
    "* layer 2: 4 sublayer 0, 1, 2, 3 with one down_sample branch\n",
    "* layer 3: 6 sublayer 0, 1, 2, 3, 4, 5 with one down_sample branch\n",
    "* layer 4: 3 sublayer 0, 1, 2 with one down_sample branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "824450cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_stage_sublayer(layer_name, sublayer_num, net_spec, bottom, nout, downsample_branch=False, initial_stride=2,\n",
    "                          in_place_scale=False, in_place_relu=False):\n",
    "    \"\"\"Build Basic Resnet Stage\n",
    "       Resnet50 consits of following layers (aka stage)\n",
    "       stage 0 (stem), stage 1, stage 2, stage 3 and stage 4\n",
    "\n",
    "    Args:\n",
    "       layer_num  : layer number as ? in \"backbone_body_layer?\"\n",
    "       sub_num    : sublayer number as # in \"backbone_body_layer?_#\"\n",
    "       net_spec   : caffe.NetSpec object\n",
    "       bottom     : input to this residual block\n",
    "       nout       : num. of out ch.\n",
    "       downsample :  inclusion of downsample path at beginning of this residula block?\n",
    "                     if BottleNeck architecutre used, set True (default: False)\\\n",
    "\n",
    "       initial_stride: stride used in branch2a and branc2b. note that branch3b stride is always 1.\n",
    "\n",
    "\n",
    "    Overview diagram:\n",
    "             +------> [ *_downsample_0 -- *_downsample_1 ]--------------------+\n",
    "             |                                                                |\n",
    "    bottom --+---------> [ *_conv1 --- *_bn1 --- *_relu1 ] ----+              |\n",
    "             |                                                 |              |\n",
    "             |     +-------------------------------------------+              |\n",
    "             |     |                                                          |\n",
    "             |     +---> [ *_conv2 --- *_bn2 --- *_relu2 ] ----+              |\n",
    "             |                                                 |              | if downsample == True\n",
    "             |     +-------------------------------------------+              |\n",
    "             |     |                                                          V\n",
    "             |     +---> [ *_conv3 --- *_bn3 --------------------------> [ *_res: Eltwise ] ----> *__res_relu :ReLu\n",
    "             |                                                                 ^\n",
    "             |                                                                 |\n",
    "             |                                                                 | if downsample == False\n",
    "             +-----------------------------------------------------------------+\n",
    "    \"\"\"\n",
    "    prefix = f'{layer_name}_{sublayer_num}'\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # input downsampling layer at the begining of every layer[0-4]\n",
    "    # ------------------------------------------------------------------\n",
    "    # In pytorch model,\n",
    "    # backbone.body.laye{layer_num}.{sublayer_num}.downsample_0\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.downsample_1\n",
    "    # ------------------------------------------------------------------\n",
    "    if downsample_branch:\n",
    "        # downsample at first layer in resnet block\n",
    "        downsample_conv = f'{prefix}_downsample_0'\n",
    "        downsample_bn = f'{prefix}_downsample_1'\n",
    "        #downsample_scale = f'{prefix}_downsample_scale'\n",
    "        net_spec[downsample_conv], net_spec[downsample_bn]  = \\\n",
    "            conv_fbn( bottom, 4*nout, in_place_scale=in_place_scale,\n",
    "                      kernel_size=1, stride=initial_stride, pad=0)\n",
    "    else:\n",
    "        initial_stride = 1\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # In pytorch model,\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.conv1\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.bn1\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.relu1\n",
    "    # ------------------------------------------------------------------\n",
    "    conv1 = f'{prefix}_conv1'\n",
    "    bn1 = f'{prefix}_bn1'\n",
    "\n",
    "    net_spec[conv1], net_spec[bn1] = \\\n",
    "        conv_fbn( bottom, nout, in_place_scale=in_place_scale,\n",
    "                  kernel_size=1, stride=initial_stride, pad=0)\n",
    "\n",
    "    relu1 = f'{prefix}_relu1'\n",
    "    net_spec[relu1] = L.ReLU(net_spec[bn1], in_place=in_place_relu)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # In pytorch model,\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.conv2\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.bn2\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.relu2\n",
    "    # ------------------------------------------------------------------\n",
    "    conv2 = f'{prefix}_conv2'\n",
    "    bn2 = f'{prefix}_bn2'\n",
    "\n",
    "    net_spec[conv2], net_spec[bn2] = \\\n",
    "        conv_fbn( net_spec[relu1], nout, in_place_scale=in_place_scale,\n",
    "                  kernel_size=3, stride=1, pad=1)\n",
    "\n",
    "    relu2 = f'{prefix}_relu2'\n",
    "    net_spec[relu2] = L.ReLU(net_spec[bn2], in_place=in_place_relu)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # In pytorch model,\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.conv3\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.bn3\n",
    "    # note that no relu after bn3 !!\n",
    "    # ------------------------------------------------------------------\n",
    "    conv3 = f'{prefix}_conv3'\n",
    "    bn3 = f'{prefix}_bn3'\n",
    "\n",
    "    net_spec[conv3], net_spec[bn3] = \\\n",
    "        conv_fbn( net_spec[relu2], 4 * nout, in_place_scale=in_place_scale,\n",
    "                  kernel_size=1, stride=1, pad=0)\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # skip connection processing\n",
    "    # ---------------------------------------\n",
    "    eltwise = f'{prefix}_eltwise'\n",
    "\n",
    "    if downsample_branch:\n",
    "        net_spec[eltwise] = L.Eltwise(net_spec[downsample_bn], net_spec[bn3])\n",
    "    else:\n",
    "        net_spec[eltwise] = L.Eltwise(bottom, net_spec[bn3])\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # last relu\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.relu\n",
    "    # ---------------------------------------\n",
    "    relu = f'{prefix}_relu'\n",
    "    # n[relu] = L.ReLU(n[eltwise], in_place=True)\n",
    "    net_spec[relu] = L.ReLU(net_spec[eltwise], in_place=in_place_relu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a1e4fd",
   "metadata": {},
   "source": [
    "## cls_tower_loigts()\n",
    "\n",
    "Builds cls_tower_logits in form of [conv => relu]x4 + conv block.\n",
    "\n",
    "**Note**\n",
    "* all conv layer uses kernel:3, stride: 1, pad: 1 with bias_term\n",
    "* `cls_logits` is Convolution with num_output = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d454b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cls_tower_logits(bottom, nout=9, bias_term=True, **kwargs):\n",
    "    '''Builds cls_tower_logits in form of [conv => relu]x4 + conv block.\n",
    "       all conv layer uses kernel:3, stride: 1, pad: 1\n",
    "\n",
    "       Params:\n",
    "          bottom (blob) : input to cls tower logits\n",
    "          nout (uint) : num. of outputs in cls logit (last conv layer)\n",
    "          bias_term (bool) : use bias term or not in conv layer\n",
    "    '''\n",
    "\n",
    "    # cls tower: 4 times repetition of [conv => relu]\n",
    "    conv1 = L.Convolution(bottom, num_output=1024, bias_term=bias_term, **kwargs)\n",
    "    relu1 = L.ReLU(conv1, in_place=True)\n",
    "\n",
    "    conv2 = L.Convolution(relu1, num_output=1024, bias_term=bias_term, **kwargs)\n",
    "    relu2 = L.ReLU(conv2, in_place=True)\n",
    "\n",
    "    conv3 = L.Convolution(relu2, num_output=1024, bias_term=bias_term, **kwargs)\n",
    "    relu3 = L.ReLU(conv3, in_place=True)\n",
    "\n",
    "    conv4 = L.Convolution(relu3, num_output=1024, bias_term=bias_term, **kwargs)\n",
    "    relu4 = L.ReLU(conv4, in_place=True)\n",
    "\n",
    "    # cl_logits with nout=9\n",
    "    cls_logits = L.Convolution(relu4, num_output=nout, **kwargs, bias_term=bias_term)\n",
    "\n",
    "    return conv1, relu1, conv2, relu2, conv3, relu3, conv4, relu4, cls_logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4cc807",
   "metadata": {},
   "source": [
    "## bbox_tower_pred()\n",
    "\n",
    "Builds build a bbox_tower_pred in form of [conv => relu]x4 + conv block.\n",
    "\n",
    "**Note:**\n",
    "* all conv layer uses kernel:3, stride: 1, pad: 1 with bias_term\n",
    "* `bbox_pred` is Convolution with num_output = 36\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6d71942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_tower_pred(bottom, nout=36, bias_term=True, **kwargs):\n",
    "    '''Builds build a bbox_tower_pred in form of [conv => relu]x4 + conv block.\n",
    "       all conv layer uses kernel:3, stride: 1, pad: 1\n",
    "\n",
    "       Params:\n",
    "          bottom (blob) : input to cls tower logits\n",
    "          nout (uint) : num. of outputs in cls logit (last conv layer)\n",
    "          bias_term (bool) : use bias term or not in conv layer\n",
    "    '''\n",
    "    # bbox_tower: 4 times repetition of [conv => relut]\n",
    "    conv1 = L.Convolution(bottom, num_output=1024, bias_term=bias_term, **kwargs)\n",
    "    relu1 = L.ReLU(conv1, in_place=True)\n",
    "\n",
    "    conv2 = L.Convolution(relu1, num_output=1024, bias_term=bias_term, **kwargs)\n",
    "    relu2 = L.ReLU(conv2, in_place=True)\n",
    "\n",
    "    conv3 = L.Convolution(relu2, num_output=1024, bias_term=bias_term, **kwargs)\n",
    "    relu3 = L.ReLU(conv3, in_place=True)\n",
    "\n",
    "    conv4 = L.Convolution(relu3, num_output=1024, bias_term=bias_term, **kwargs)\n",
    "    relu4 = L.ReLU(conv4, in_place=True)\n",
    "\n",
    "    # bbox_pred with nout=36\n",
    "    bbox_pred = L.Convolution(relu4, num_output=nout, bias_term=bias_term, **kwargs)\n",
    "\n",
    "    return conv1, relu1, conv2, relu2, conv3, relu3, conv4, relu4, bbox_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d3f4fd",
   "metadata": {},
   "source": [
    "## detection_network_v2_spec()\n",
    "\n",
    "Build detection v2 network spec\n",
    "* backbone: body (Resnet50) + FPN \n",
    "* RPN with two heads (for cls_tower + cls logits and bbox_tower and bbox_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b13194e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_network_v2_spec(net_spec, bottom, in_place_scale=False, in_place_relu=False):\n",
    "\n",
    "    \"\"\"Build network spec of Backbone (ResNet50 + FPN) and RPN\n",
    "\n",
    "    Args:\n",
    "         n (caffe.NetSpec) : NetSpec instance\n",
    "         bottom (blob) : innput to detection network\n",
    "         in_place_scale: use in_place in caffe Scale layer of fbn implemetation\n",
    "         in_place_relu: use in_place in caffe ReLu layer of fbn implemetation\n",
    "         \n",
    "    Returns:\n",
    "        prototxt object of network spec\n",
    "\n",
    "    \"\"\"\n",
    "        \n",
    "    # ************************************************\n",
    "    # 1. model.backbone\n",
    "    # ************************************************\n",
    "    # backbone := body + fpn\n",
    "    # ************************************************\n",
    "\n",
    "\n",
    "    # =================================================================\n",
    "    # 1.1 model.backbone.body\n",
    "    # body = stem (layer 0) +  layer 1 + layer 2 + layer 3 + layer 4\n",
    "    # =================================================================\n",
    "    \"\"\"\n",
    "    Resnet50 consists of following layers (aka stage)\n",
    "     * layer 0: conv + fbn + relu + maxpool\n",
    "     * layer 1: 3 sublayer 0, 1, 2 with oen down_sample branch\n",
    "     * layer 2: 4 sublayer 0, 1, 2, 3 with one down_sample branch\n",
    "     * layer 3: 6 sublayer 0, 1, 2, 3, 4, 5 with one down_sample branch\n",
    "     * layer 4: 3 sublayer 0, 1, 2 with one down_sample branch\n",
    "    \"\"\"\n",
    "    \n",
    "    # keep list of feature maps in stage order\n",
    "    backbone_body_features = []\n",
    "    \n",
    "    prefix = \"backbone_body\"\n",
    "    # -------------------------------------\n",
    "    # 1.1.0 model.backbone.body.stem (layer0)\n",
    "    # sublayer: conv1,  bn1, relu, maxpool\n",
    "    # -------------------------------------\n",
    "    layer_name = f'{prefix}_stem_'\n",
    "\n",
    "    net_spec[layer_name + 'conv1'], net_spec[layer_name + 'bn1'] = \\\n",
    "        conv_fbn(bottom, 64, in_place_scale=in_place_scale, kernel_size=7, pad=3, stride=2)\n",
    "\n",
    "    net_spec[layer_name + 'relu'] = L.ReLU(net_spec[layer_name + 'bn1'], in_place=in_place_relu)\n",
    "    net_spec[layer_name + 'maxpool'] = L.Pooling(net_spec[layer_name + 'relu'], kernel_size=3, stride=2, pool=P.Pooling.MAX)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.1.1 model.backbone.body.layer1\n",
    "    # sublayer: 0, 1, 2\n",
    "    # -------------------------------------\n",
    "    pre_layer_name = layer_name\n",
    "    layer_name = f'{prefix}_layer1'\n",
    "\n",
    "    resnet_stage_sublayer(layer_name=layer_name, sublayer_num='0', net_spec=net_spec,\n",
    "                          bottom=net_spec[pre_layer_name + 'maxpool'],\n",
    "                          nout=64, downsample_branch=True, initial_stride=1,\n",
    "                          in_place_scale=in_place_scale, in_place_relu=in_place_relu)\n",
    "\n",
    "    resnet_stage_sublayer(layer_name=layer_name, sublayer_num='1', net_spec=net_spec,\n",
    "                          bottom=net_spec[layer_name + '_0_relu'],\n",
    "                          nout=64,  downsample_branch=False, initial_stride=2,\n",
    "                          in_place_scale=in_place_scale, in_place_relu=in_place_relu)\n",
    "\n",
    "    resnet_stage_sublayer(layer_name=layer_name, sublayer_num='2', net_spec=net_spec,\n",
    "                          bottom=net_spec[layer_name + '_1_relu'],\n",
    "                          nout=64, downsample_branch=False, initial_stride=2,\n",
    "                          in_place_scale = in_place_scale, in_place_relu = in_place_relu)\n",
    "\n",
    "    # feature C1\n",
    "    backbone_body_features.append(net_spec[layer_name + '_2_relu'])\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.1.2 model.backbone.body.layer2 (stage 2)\n",
    "    # sublayer: 0, 1, 2, 3\n",
    "    # -------------------------------------\n",
    "    pre_layer_name = layer_name\n",
    "    layer_name = f'{prefix}_layer2'\n",
    "\n",
    "    resnet_stage_sublayer(layer_name=layer_name, sublayer_num='0', net_spec=net_spec,\n",
    "                          bottom=net_spec[pre_layer_name + '_2_relu'],\n",
    "                          nout=128, downsample_branch=True, initial_stride=2,\n",
    "                          in_place_scale = in_place_scale, in_place_relu = in_place_relu)\n",
    "\n",
    "    resnet_stage_sublayer(layer_name=layer_name, sublayer_num='1', net_spec=net_spec,\n",
    "                          bottom=net_spec[layer_name + '_0_relu'],\n",
    "                          nout=128, downsample_branch=False, initial_stride=2,\n",
    "                          in_place_scale = in_place_scale, in_place_relu = in_place_relu)\n",
    "\n",
    "    resnet_stage_sublayer(layer_name=layer_name, sublayer_num='2', net_spec=net_spec,\n",
    "                          bottom=net_spec[layer_name + '_1_relu'],\n",
    "                          nout=128, downsample_branch=False, initial_stride=2,\n",
    "                          in_place_scale = in_place_scale, in_place_relu = in_place_relu)\n",
    "\n",
    "    resnet_stage_sublayer(layer_name=layer_name, sublayer_num='3', net_spec=net_spec,\n",
    "                          bottom=net_spec[layer_name + '_2_relu'],\n",
    "                          nout=128, downsample_branch=False, initial_stride=2,\n",
    "                          in_place_scale = in_place_scale, in_place_relu = in_place_relu)\n",
    "\n",
    "    # feature C2\n",
    "    backbone_body_features.append(net_spec[layer_name + '_3_relu'])\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.1.3 model.backbone.body.layer3 (stage 3)\n",
    "    # sublayer: 0, 1, 2, 3, 4, 5\n",
    "    # -------------------------------------\n",
    "    pre_layer_name = layer_name\n",
    "    layer_name = f'{prefix}_layer3'\n",
    "\n",
    "    resnet_stage_sublayer(layer_name=layer_name, sublayer_num='0', net_spec=net_spec,\n",
    "                          bottom=net_spec[pre_layer_name + '_3_relu'],\n",
    "                          nout=256, downsample_branch=True, initial_stride=2,\n",
    "                          in_place_scale = in_place_scale, in_place_relu = in_place_relu)\n",
    "\n",
    "    resnet_stage_sublayer(layer_name=layer_name, sublayer_num='1', net_spec=net_spec,\n",
    "                          bottom=net_spec[layer_name + '_0_relu'],\n",
    "                          nout=256, downsample_branch=False, initial_stride=2,\n",
    "                          in_place_scale=in_place_scale, in_place_relu=in_place_relu)\n",
    "\n",
    "    resnet_stage_sublayer(layer_name=layer_name, sublayer_num='2', net_spec=net_spec,\n",
    "                          bottom=net_spec[layer_name + '_1_relu'],\n",
    "                          nout=256, downsample_branch=False, initial_stride=2,\n",
    "                          in_place_scale=in_place_scale, in_place_relu=in_place_relu)\n",
    "\n",
    "    resnet_stage_sublayer(layer_name=layer_name, sublayer_num='3', net_spec=net_spec,\n",
    "                          bottom=net_spec[layer_name + '_2_relu'],\n",
    "                          nout=256, downsample_branch=False, initial_stride=2,\n",
    "                          in_place_scale=in_place_scale, in_place_relu=in_place_relu)\n",
    "\n",
    "    resnet_stage_sublayer(layer_name=layer_name, sublayer_num='4', net_spec=net_spec,\n",
    "                          bottom=net_spec[layer_name + '_3_relu'],\n",
    "                          nout=256, downsample_branch=False, initial_stride=2,\n",
    "                          in_place_scale=in_place_scale, in_place_relu=in_place_relu)\n",
    "\n",
    "    resnet_stage_sublayer(layer_name=layer_name, sublayer_num='5', net_spec=net_spec,\n",
    "                          bottom=net_spec[layer_name + '_4_relu'],\n",
    "                          nout=256, downsample_branch=False, initial_stride=2,\n",
    "                          in_place_scale=in_place_scale, in_place_relu=in_place_relu)\n",
    "\n",
    "\n",
    "    # feature C3\n",
    "    backbone_body_features.append(net_spec[layer_name + '_5_relu'])\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.1.4 model.backbone.body.layer4 (stage 4)\n",
    "    # sublayer: 0, 1, 2\n",
    "    # -------------------------------------\n",
    "    pre_layer_name = layer_name\n",
    "    layer_name = f'{prefix}_layer4'\n",
    "\n",
    "    resnet_stage_sublayer(layer_name=layer_name, sublayer_num='0', net_spec=net_spec,\n",
    "                          bottom=net_spec[pre_layer_name + '_5_relu'],\n",
    "                          nout=512, downsample_branch=True, initial_stride=2,\n",
    "                          in_place_scale = in_place_scale, in_place_relu = in_place_relu)\n",
    "\n",
    "    resnet_stage_sublayer(layer_name=layer_name, sublayer_num='1', net_spec=net_spec,\n",
    "                          bottom=net_spec[layer_name + '_0_relu'],\n",
    "                          nout=512, downsample_branch=False, initial_stride=2,\n",
    "                          in_place_scale=in_place_scale, in_place_relu=in_place_relu)\n",
    "\n",
    "    resnet_stage_sublayer(layer_name=layer_name, sublayer_num='2', net_spec=net_spec,\n",
    "                          bottom=net_spec[layer_name + '_1_relu'],\n",
    "                          nout=512, downsample_branch=False, initial_stride=2,\n",
    "                          in_place_scale=in_place_scale, in_place_relu=in_place_relu)\n",
    "\n",
    "    # feature C4\n",
    "    backbone_body_features.append(net_spec[layer_name + '_2_relu'])\n",
    "\n",
    "    C1, C2, C3, C4 = backbone_body_features\n",
    "\n",
    "    # =================================================================\n",
    "    # 1.2 model.backbone.fpn\n",
    "    # =================================================================\n",
    "    backbone_fpn_features = []\n",
    "    prefix = \"backbone_fpn\"\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.1 model.backbone.fpn.fpn_inner4\n",
    "    # -------------------------------------\n",
    "    layer_name = f'{prefix}_fpn_inner4'\n",
    "    last_inner = net_spec[layer_name] = L.Convolution(C4, num_output=1024, kernel_size=1, stride=1)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.2 model.backbone.fpn.fpn_layer4\n",
    "    # -------------------------------------\n",
    "    layer_name = f'{prefix}_fpn_layer4'\n",
    "    net_spec[layer_name] = L.Convolution(last_inner, num_output=1024, kernel_size=3, stride=1, pad=1)\n",
    "\n",
    "    # featuer pyramid feature P4 append\n",
    "    # P4 = conv (conv (C4))\n",
    "    backbone_fpn_features.append(net_spec[layer_name])\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.3 model.backbone.fpn_inner3_upsample\n",
    "    # -------------------------------------\n",
    "    layer_name = f'{prefix}_fpn_inner3_upsample' # inner3__upsample\n",
    "    inner3_upsample = net_spec[layer_name] = \\\n",
    "        L.Deconvolution(last_inner, convolution_param = dict(num_output=1024,\n",
    "                                                             kernel_size=4,\n",
    "                                                             stride=2, pad=1,\n",
    "                                                             weight_filler=dict(type ='bilinear'),\n",
    "                                                             bias_term=False) )\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.4 model.backbone.fpn_inner3_lateral\n",
    "    # -------------------------------------\n",
    "    #layer_name = f'{prefix}_fpn_inner3_lateral'\n",
    "    layer_name = f'{prefix}_fpn_inner3'\n",
    "    inner3_lateral = net_spec[layer_name] = L.Convolution(C3, num_output=1024, kernel_size=1, stride=1)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.5 model.backbone.fpn_inner3_lateral_sum\n",
    "    # -------------------------------------\n",
    "    layer_name = f'{prefix}_fpn_inner3_lateral_sum' # P3\n",
    "    last_inner = net_spec[layer_name] = L.Eltwise(inner3_lateral,  inner3_upsample)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.6 model.backbone.fpn_layer3\n",
    "    # -------------------------------------\n",
    "    layer_name = f'{prefix}_fpn_layer3'\n",
    "    net_spec[layer_name] = L.Convolution(last_inner, num_output=1024, kernel_size=3, stride=1, pad=1)\n",
    "\n",
    "    # feature pyramid P3 insert at idx 0\n",
    "    # P3 = unsample(P4) + conv(conv(C3))\n",
    "    backbone_fpn_features.insert(0, net_spec[layer_name])\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.7 model.backbone.fpn_inner2_upsample\n",
    "    # -------------------------------------\n",
    "    layer_name = f'{prefix}_fpn_inner2_upsample' # inner2__upsample\n",
    "    inner2_upsample = net_spec[layer_name] = \\\n",
    "        L.Deconvolution(last_inner, convolution_param = dict(num_output=1024,\n",
    "                                                             kernel_size=4,\n",
    "                                                             stride=2, pad=1,\n",
    "                                                             weight_filler=dict(type ='bilinear'),\n",
    "                                                             bias_term=False))\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.8 model.backbone.fpn_inner2_lateral\n",
    "    # -------------------------------------\n",
    "    #layer_name = f'{prefix}_fpn_inner2_lateral'\n",
    "    layer_name = f'{prefix}_fpn_inner2'\n",
    "    inner2_lateral = net_spec[layer_name] = L.Convolution(C2, num_output=1024, kernel_size=1, stride=1)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.9 model.backbone.fpn_inner2_lateral_sum\n",
    "    # -------------------------------------\n",
    "    layer_name = f'{prefix}_fpn_inner2_lateral_sum' # P3\n",
    "    last_inner = net_spec[layer_name] = L.Eltwise(inner2_lateral,  inner2_upsample)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.10 model.backbone.fpn_layer2\n",
    "    # -------------------------------------\n",
    "    layer_name = f'{prefix}_fpn_layer2'\n",
    "    net_spec[layer_name] = L.Convolution(last_inner, num_output=1024, kernel_size=3, stride=1, pad=1)\n",
    "\n",
    "    # feature pyramid P2 insert at idx 0\n",
    "    # P2 = unsample(P3) + conv(conv(C2))\n",
    "    backbone_fpn_features.insert(0, net_spec[layer_name])\n",
    "\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.11 model.fpn.top_blocks\n",
    "    # -------------------------------------\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.11.1 model.fpn.top_blocks.p6\n",
    "    # -------------------------------------\n",
    "    prefix = \"backbone_fpn_top_blocks\"\n",
    "    layer_name = f'{prefix}_p6'\n",
    "    net_spec[layer_name] = L.Convolution(C4, num_output=1024, kernel_size=3, stride=2, pad=1)\n",
    "\n",
    "    # feature pyramid P6 append at end\n",
    "    # P6 = (conv(C4)) ?\n",
    "    backbone_fpn_features.append(net_spec[layer_name])\n",
    "\n",
    "    P6_relu = net_spec[layer_name + 'relu'] = L.ReLU(net_spec[layer_name], in_place=True)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.11.2 model.fpn.top_blocks.p7\n",
    "    # -------------------------------------\n",
    "\n",
    "    layer_name = f'{prefix}_p7'\n",
    "    net_spec[layer_name] = L.Convolution(P6_relu, num_output=1024, kernel_size=3, stride=2, pad=1)\n",
    "\n",
    "    # feature pyramid P6 append at end\n",
    "    # P7 = (conv(P6))\n",
    "    backbone_fpn_features.append(net_spec[layer_name])\n",
    "\n",
    "    # fpn_results = [P2, P3, P4, P6, P7]\n",
    "    # P2 shape: (1, 1024, 60, 72)\n",
    "    # P3 shape: (1, 1024, 30, 36)\n",
    "    # P4 shape: (1, 1024, 15, 18)\n",
    "    # P6 shape: (1, 1024,  8,  9)\n",
    "    # P7 shape: (1, 1024,  4,  5)\n",
    "\n",
    "\n",
    "    # ************************************************\n",
    "    # 2 model.rpn\n",
    "    # rpn := head\n",
    "    # head := cls_tower  => cls_logits\n",
    "    #       bbox_tower => bbox_pred\n",
    "    # ************************************************\n",
    "    logits = []\n",
    "    bbox_reg = []\n",
    "    for idx, p_num in enumerate([2,3,4,6,7]):\n",
    "\n",
    "        bottom = backbone_fpn_features[idx]\n",
    "\n",
    "        # cls_tower + cls_logits\n",
    "        #prefix = f\"rpn_head_cls_tower_p{p_num}\"\n",
    "        prefix = f\"rpn_head_cls_tower\"\n",
    "        suffix = f\"for_p{p_num}\"\n",
    "        cls_tower_conv1 = f'{prefix}_0_{suffix}'\n",
    "        cls_tower_relu1 = f'{prefix}_1_{suffix}'\n",
    "        cls_tower_conv2 = f'{prefix}_2_{suffix}'\n",
    "        cls_tower_relu2 = f'{prefix}_3_{suffix}'\n",
    "        cls_tower_conv3 = f'{prefix}_4_{suffix}'\n",
    "        cls_tower_relu3 = f'{prefix}_5_{suffix}'\n",
    "        cls_tower_conv4 = f'{prefix}_6_{suffix}'\n",
    "        cls_tower_relu4 = f'{prefix}_7_{suffix}'\n",
    "        cls_logits = f'rpn_head_cls_logits_{suffix}'\n",
    "\n",
    "        net_spec[cls_tower_conv1], net_spec[cls_tower_relu1], net_spec[cls_tower_conv2], \\\n",
    "        net_spec[cls_tower_relu2], net_spec[cls_tower_conv3], net_spec[cls_tower_relu3], \\\n",
    "        net_spec[cls_tower_conv4], net_spec[cls_tower_relu4], net_spec[cls_logits] = \\\n",
    "            cls_tower_logits(bottom=bottom, nout=9, kernel_size=3, stride=1, pad =1 )\n",
    "\n",
    "        logits.append(net_spec[cls_logits])\n",
    "\n",
    "        # bbox_tower + bbox_pred\n",
    "        #prefix = f\"rpn_head_bbox_tower_p{p_num}\"\n",
    "        prefix = f\"rpn_head_bbox_tower\"\n",
    "        suffix = f\"for_p{p_num}\"\n",
    "        bbox_tower_conv1 = f'{prefix}_0_{suffix}'\n",
    "        bbox_tower_relu1 = f'{prefix}_1_{suffix}'\n",
    "        bbox_tower_conv2 = f'{prefix}_2_{suffix}'\n",
    "        bbox_tower_relu2 = f'{prefix}_3_{suffix}'\n",
    "        bbox_tower_conv3 = f'{prefix}_4_{suffix}'\n",
    "        bbox_tower_relu3 = f'{prefix}_5_{suffix}'\n",
    "        bbox_tower_conv4 = f'{prefix}_6_{suffix}'\n",
    "        bbox_tower_relu4 = f'{prefix}_7_{suffix}'\n",
    "        bbox_pred = f'rpn_head_bbox_pred_{suffix}'\n",
    "\n",
    "        net_spec[bbox_tower_conv1], net_spec[bbox_tower_relu1], net_spec[bbox_tower_conv2], \\\n",
    "        net_spec[bbox_tower_relu2], net_spec[bbox_tower_conv3], net_spec[bbox_tower_relu3], \\\n",
    "        net_spec[bbox_tower_conv4], net_spec[bbox_tower_relu4], net_spec[bbox_pred] = \\\n",
    "            bbox_tower_pred(bottom=bottom, nout=36, kernel_size=3, stride=1, pad=1)\n",
    "\n",
    "        bbox_reg.append(net_spec[bbox_pred])\n",
    "\n",
    "    return net_spec.to_proto()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab633e65",
   "metadata": {},
   "source": [
    "# Network Parameter Loading Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea3f86d",
   "metadata": {},
   "source": [
    "## load_backbone_body_params()\n",
    "\n",
    "Load backbone body (resnet50) parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e36fbe14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_backbone_body_params(network, debug=False):\n",
    "\n",
    "    \"\"\"Load backbone body (resnet50) parameters\n",
    "\n",
    "    Args:\n",
    "        network (caffe.Net): Network instance\n",
    "        debug (bool): print debug message or not\n",
    "\n",
    "    Returns:\n",
    "        network with backbone body paramters filled\n",
    "\n",
    "    \"\"\"\n",
    "    # log file patth: ./load_backbone_body_parms_log.txt\n",
    "    if debug:\n",
    "        my_name = inspect.currentframe().f_code.co_name\n",
    "        log_file_path = f\"./log/{my_name}_log.txt\"\n",
    "        original_std_out = sys.stdout\n",
    "        f = open(log_file_path, 'w')\n",
    "        sys.stdout = f\n",
    "\n",
    "    # assumption:\n",
    "    # backbone body (resnet50) learnable layer parameters npy file name start with 'backbone_body_' prefix\n",
    "    k_list = [k for k in network.params.keys() if k.startswith('backbone_body_') and \"data\" not in k]\n",
    "    total_num_of_params = len(k_list)\n",
    "    num_processing = 1\n",
    "\n",
    "    # learnable layers' weight/bias parameters distinguished by suffix 'weight', 'bias'\n",
    "    suffix = [\"weight\", \"bias\"]\n",
    "    # num_layers = len(network.layer_dict)\n",
    "\n",
    "    for idx, layer_name in enumerate(network.layer_dict):\n",
    "\n",
    "        if layer_name in k_list:\n",
    "            print(f\"\\n-----------------------------\")\n",
    "            # print(f\"layer index: {idx}/{num_layers}\")\n",
    "            print(f\"Processing {num_processing}/{total_num_of_params}\")\n",
    "            print(f\"layer name: '{layer_name}''\")\n",
    "            print(f\"layer type: '{network.layers[idx].type}'\")\n",
    "\n",
    "            params = network.params[layer_name]\n",
    "            print(f\"{len(params)} learnable parameters in '{network.layers[idx].type}' type\")\n",
    "\n",
    "            for i, p in enumerate(params):\n",
    "                # print(f\"\\tparams[{i}]: {p}\")\n",
    "                # print(f\"\\tparams[{i}] CxHxW: {p.channels}x{p.height}x{p.width}\")\n",
    "                print(f\"\\tp[{i}]: {p.data.shape} of {p.data.dtype}\")\n",
    "\n",
    "                param_file_path = f\"{NPY_ROOT}/{layer_name}_{suffix[i]}.npy\"\n",
    "\n",
    "                param_file = Path(param_file_path)\n",
    "                if param_file.exists():\n",
    "                    print(f\"\\tload {param_file_path}\")\n",
    "                    arr = np.load(param_file_path, allow_pickle=True)\n",
    "\n",
    "                    if p.data.shape == arr.shape:\n",
    "                        print(f\"\\tset {layer_name}_{suffix[i]} with arr:shape {arr.shape}, type {arr.dtype}\")\n",
    "\n",
    "                        p.data[...] = arr\n",
    "\n",
    "                        if not (np.allclose(p.data, arr)):\n",
    "                            print(f\"\\t>>>>>> p.data is not euqal to arr\")\n",
    "                            print(f\"\\tp.data: {p.data}\")\n",
    "                            print(f\"\\tarr: {arr}\")\n",
    "\n",
    "                            if debug:\n",
    "                                sys.stdout = original_std_out\n",
    "                                f.close()\n",
    "\n",
    "                            return False\n",
    "                    else:\n",
    "                        print(f\">>>>>> p.data.shape: {p.data.shape} is not equal to arr.shape: {arr.shape}\")\n",
    "                        if debug:\n",
    "                            sys.stdout = original_std_out\n",
    "                            f.close()\n",
    "\n",
    "                        return False\n",
    "                else:\n",
    "                    print(f\">>>>>> {param_file_path} is not exits!!\")\n",
    "                    if debug:\n",
    "                        sys.stdout = original_std_out\n",
    "                        f.close()\n",
    "\n",
    "                    return False\n",
    "                    # END for i, pin in enumerate(params):\n",
    "\n",
    "            num_processing += 1\n",
    "\n",
    "    # END for idx, layer_name in enumerate(network.layer_dict):\n",
    "\n",
    "    print(f\"success!!\")\n",
    "    if debug:\n",
    "        sys.stdout = original_std_out\n",
    "        f.close()\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb2104c",
   "metadata": {},
   "source": [
    "## load_backbone_fpn_params()\n",
    "\n",
    "Load backbone fpn (feature pyramid network) parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f730ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_backbone_fpn_params(network, debug=False):\n",
    "    \"\"\"Load backbone fpn (feature pyramid network) parameters\n",
    "\n",
    "    Args:\n",
    "        network (caffe.Net): Network instance\n",
    "        debug (bool): print debug message or not\n",
    "\n",
    "    Returns:\n",
    "        network with backbone fpn paramters filled\n",
    "\n",
    "    \"\"\"\n",
    "    # log file patth: ./load_backbone_fpn_parms_log.txt\n",
    "    if debug:\n",
    "        # get current function name\n",
    "        # https://stackoverflow.com/questions/5067604/determine-function-name-from-within-that-function-without-using-traceback\n",
    "        # my_name =  inspect.stack()[0][3]\n",
    "        my_name = inspect.currentframe().f_code.co_name\n",
    "        log_file_path = f\".{my_name}_log.txt\"\n",
    "        original_std_out = sys.stdout\n",
    "        f = open(log_file_path, 'w')\n",
    "        sys.stdout = f\n",
    "    else:\n",
    "        sys.stdout = sys.stdout\n",
    "\n",
    "    # assumption:\n",
    "    # backbone fpn learnable layer parameters npy file name start with 'backbone_fpn' prefix\n",
    "    # upsample layer is implmented with Decov layer in caffe, hence no parameter loading\n",
    "    k_list = [k for k in network.params.keys() if k.startswith('backbone_fpn') and \"upsample\" not in k]\n",
    "    total_num_of_params = len(k_list)\n",
    "    num_processing = 1\n",
    "\n",
    "    # learnable layers' weight/bias parameters distinguished by suffix 'weight', 'bias'\n",
    "    suffix = [\"weight\", \"bias\"]\n",
    "    num_layers = len(network.layer_dict)\n",
    "\n",
    "    for idx, layer_name in enumerate(network.layer_dict):\n",
    "\n",
    "        if layer_name in k_list:\n",
    "            print(f\"\\n-----------------------------\")\n",
    "            # print(f\"layer index: {idx}/{num_layers}\")\n",
    "            print(f\"Processing {num_processing}/{total_num_of_params}\")\n",
    "            print(f\"layer name: '{layer_name}''\")\n",
    "            print(f\"layer type: '{network.layers[idx].type}'\")\n",
    "\n",
    "            params = network.params[layer_name]\n",
    "            print(f\"{len(params)} learnable parameters in '{network.layers[idx].type}' type\")\n",
    "\n",
    "            for i, p in enumerate(params):\n",
    "                # print(f\"\\tparams[{i}]: {p}\")\n",
    "                # print(f\"\\tparams[{i}] CxHxW: {p.channels}x{p.height}x{p.width}\")\n",
    "                print(f\"\\tp[{i}]: {p.data.shape} of {p.data.dtype}\")\n",
    "\n",
    "                param_file_path = f\"../npy_save/{layer_name}_{suffix[i]}.npy\"\n",
    "\n",
    "                param_file = Path(param_file_path)\n",
    "                if param_file.exists():\n",
    "                    print(f\"\\tload {param_file_path}\")\n",
    "                    arr = np.load(param_file_path, allow_pickle=True)\n",
    "\n",
    "                    if p.data.shape == arr.shape:\n",
    "                        print(f\"\\tset {layer_name}_{suffix[i]} with arr:shape {arr.shape}, type {arr.dtype}\")\n",
    "\n",
    "                        p.data[...] = arr\n",
    "                        if not (np.allclose(p.data, arr)):\n",
    "                            print(f\"\\t>>>>>> p.data is not euqal to arr\")\n",
    "                            print(f\"\\tp.data: {p.data}\")\n",
    "                            print(f\"\\tarr: {arr}\")\n",
    "\n",
    "                            if debug:\n",
    "                                sys.stdout = original_std_out\n",
    "                                f.close()\n",
    "                            return False\n",
    "\n",
    "                    else:\n",
    "                        print(f\">>>>>> p.data.shape: {p.data.shape} is not equal to arr.shape: {arr.shape}\")\n",
    "                        if debug:\n",
    "                            sys.stdout = original_std_out\n",
    "                            f.close()\n",
    "\n",
    "                        return False\n",
    "                else:\n",
    "                    print(f\">>>>>> {param_file_path} is not exits!!\")\n",
    "                    if debug:\n",
    "                        sys.stdout = original_std_out\n",
    "                        f.close()\n",
    "\n",
    "                    return False\n",
    "                    # END for i, p in enumearte(params)\n",
    "            num_processing += 1\n",
    "\n",
    "    # END for idx, layer_name in enumerate(network.layer_dict):\n",
    "    if debug:\n",
    "        sys.stdout = original_std_out\n",
    "        f.close()\n",
    "\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2190f387",
   "metadata": {},
   "source": [
    "## load_rpn_params()\n",
    "\n",
    "Load rpn (region proposal network) parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf0d66ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rpn_params(network, debug=False):\n",
    "    \"\"\"Load rpn (region proposal network) parameters\n",
    "\n",
    "    Args:\n",
    "        network (caffe.Net): Network instance\n",
    "        debug (bool): print debug message or not\n",
    "\n",
    "    Returns:\n",
    "        network with rpn paramters filled\n",
    "\n",
    "    \"\"\"\n",
    "    # log file patth: ./load_rpn_params_log.txt\n",
    "    if debug:\n",
    "        # get current function name\n",
    "        # https://stackoverflow.com/questions/5067604/determine-function-name-from-within-that-function-without-using-traceback\n",
    "        # my_name =  inspect.stack()[0][3]\n",
    "        my_name = inspect.currentframe().f_code.co_name\n",
    "        log_file_path = f\"./{my_name}_log.txt\"\n",
    "        original_std_out = sys.stdout\n",
    "        f = open(log_file_path, 'w')\n",
    "        sys.stdout = f\n",
    "    else:\n",
    "        sys.stdout = sys.stdout\n",
    "\n",
    "    # assumption:\n",
    "    # backbone rpn learnable layer parameters npy file name start with 'rpn_head' prefix\n",
    "    k_list = [k for k in network.params.keys() if k.startswith('rpn_head')]\n",
    "    total_num_of_params = len(k_list)\n",
    "    num_processing = 1\n",
    "\n",
    "    suffix = [\"weight\", \"bias\"]\n",
    "    # num_layers = len(network.layer_dict)\n",
    "\n",
    "    for idx, layer_name in enumerate(network.layer_dict):\n",
    "\n",
    "        if layer_name in k_list:\n",
    "            print(f\"\\n-----------------------------\")\n",
    "            # print(f\"layer index: {idx}/{num_layers}\")\n",
    "            print(f\"Processing {num_processing}/{total_num_of_params}\")\n",
    "            print(f\"layer name: '{layer_name}''\")\n",
    "            print(f\"layer type: '{network.layers[idx].type}'\")\n",
    "\n",
    "            params = network.params[layer_name]\n",
    "            print(f\"{len(params)} learnable parameters in '{network.layers[idx].type}' type\")\n",
    "\n",
    "            for i, p in enumerate(params):\n",
    "                # print(f\"\\tparams[{i}]: {p}\")\n",
    "                # print(f\"\\tparams[{i}] CxHxW: {p.channels}x{p.height}x{p.width}\")\n",
    "                print(f\"\\tp[{i}]: {p.data.shape} of {p.data.dtype}\")\n",
    "\n",
    "                # note remove '_for_pn' suffix from layer name\n",
    "                param_file_path = f\"../npy_save/{layer_name[:-7]}_{suffix[i]}.npy\"\n",
    "\n",
    "                param_file = Path(param_file_path)\n",
    "                if param_file.exists():\n",
    "                    print(f\"\\tload {param_file_path}\")\n",
    "                    arr = np.load(param_file_path, allow_pickle=True)\n",
    "\n",
    "                    if p.data.shape == arr.shape:\n",
    "                        print(f\"\\tset {layer_name}_{suffix[i]} with arr:shape {arr.shape}, type {arr.dtype}\")\n",
    "\n",
    "                        p.data[...] = arr\n",
    "                        if not (np.allclose(p.data, arr)):\n",
    "                            print(f\"\\t>>>>>> p.data is not euqal to arr\")\n",
    "                            print(f\"\\tp.data: {p.data}\")\n",
    "                            print(f\"\\tarr: {arr}\")\n",
    "\n",
    "                            if debug:\n",
    "                                sys.stdout = original_std_out\n",
    "                                f.close()\n",
    "\n",
    "                            return False\n",
    "                    else:\n",
    "                        print(f\">>>>>> p.data.shape: {p.data.shape} is not equal to arr.shape: {arr.shape}\")\n",
    "                        if debug:\n",
    "                            sys.stdout = original_std_out\n",
    "                            f.close()\n",
    "\n",
    "                        return False\n",
    "                else:\n",
    "                    print(f\">>>>>> {param_file_path} is not exits!!\")\n",
    "                    if debug:\n",
    "                        sys.stdout = original_std_out\n",
    "                        f.close()\n",
    "\n",
    "                    return False\n",
    "                    # END for i, p in enumearte(params)\n",
    "            num_processing += 1\n",
    "\n",
    "\n",
    "    # END for idx, layer_name in enumerate(network.layer_dict):\n",
    "    if debug:\n",
    "        sys.stdout = original_std_out\n",
    "        f.close()\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969c50ae",
   "metadata": {},
   "source": [
    "## load_detection_v2_parameters()\n",
    "\n",
    "load detection v2 network paramters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c36cfde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_detection_v2_parameters(detection_v2_network, debug=False):\n",
    "    \"\"\"load detection v2 network paramters\n",
    "\n",
    "    Args:\n",
    "        nw: caff.Net instance\n",
    "\n",
    "    Returns:\n",
    "        network with backbone body, backbone fpn and rpn paramters filled\n",
    "    \"\"\"\n",
    "    # backbone body (resnet50) paramters loading\n",
    "    if (load_backbone_body_params(network=detection_v2_network, debug=debug)):\n",
    "        print(f\"backbone body parameter loading success.\")\n",
    "    else:\n",
    "        print(f\"backbone body parameter loading failed.\")\n",
    "        return False\n",
    "\n",
    "    # backbone fpn (feature pyramid network) paramters loading\n",
    "    if (load_backbone_fpn_params(network=detection_v2_network, debug=debug)):\n",
    "        print(f\"backbone fpn parameter loading success.\")\n",
    "    else:\n",
    "        print(f\"backbone fpn parameter loading failed.\")\n",
    "        return False\n",
    "\n",
    "    # rpn (region proposal network) paramters loading\n",
    "    if (load_rpn_params(network=detection_v2_network, debug=debug)):\n",
    "        print(f\"rpn parameter loading success.\")\n",
    "    else:\n",
    "        print(f\"rpn parameter loading failed.\")\n",
    "        return False\n",
    "\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf5d2fa",
   "metadata": {},
   "source": [
    "# Network Parameter Saving Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31be598",
   "metadata": {},
   "source": [
    "## save_network_parameters()\n",
    "\n",
    "load network parameters from pytorch model saved npy file and save into caffemodel format file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab3a040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_network_parameters(test_image_file, prototxt_file, caffemodel_file, overwrite=False):\n",
    "    \"\"\"load network parameters from pytorch model saved npy file\n",
    "       and save into caffemodel format file\n",
    "    Args:\n",
    "        test_iamge_file: file path to test input image file\n",
    "        prototxt_file: file path to save .prototxt file\n",
    "        caffemodel_file: file path to save .caffemodel file\n",
    "        overwrite (bool): overwrite existing prototxt and caffemodel file\n",
    "    Returns:\n",
    "        none\n",
    "    \"\"\"\n",
    "\n",
    "    if not overwrite:\n",
    "        # if recreate==False, then check files existence\n",
    "        prototxt_file_path = Path(prototxt_file)\n",
    "        caffemodel_file_path = Path(caffemodel_file)\n",
    "        if prototxt_file_path.exists() and caffemodel_file_path.exists():\n",
    "            # if both files already exist, then return False\n",
    "            print(f\"{prototxt_file} and {caffemodel_file} already exist, hence just return\")\n",
    "            return False\n",
    "\n",
    "    nw_spec = caffe.NetSpec()\n",
    "\n",
    "    # load image file and convert to batch zero padded array\n",
    "    batch_img_array = image_preprocess(test_image_file, debug=True)\n",
    "\n",
    "    # set shape of Data layer input in detection v2 model spec\n",
    "    nw_spec.data = L.DummyData(shape=[dict(dim=list(batch_img_array.shape))])\n",
    "\n",
    "    # prototxt generation of detection v2 model spec\n",
    "    detection_v2_prototxt = detection_network_v2_spec(nw_spec, nw_spec.data)\n",
    "\n",
    "    # saving prototxt spec into .prototxt file\n",
    "    with open(prototxt_file, 'w') as f:\n",
    "        f.write(str(detection_v2_prototxt))\n",
    "    print(f\"{prototxt_file} for detection v2 mode written....\")\n",
    "\n",
    "    # caffe.Net instantiation for loading params from npy files\n",
    "    network = caffe.Net(prototxt_file, caffe.TEST)\n",
    "\n",
    "    # load detection v2 network layers parameters\n",
    "    load_detection_v2_parameters(network, debug=True)\n",
    "\n",
    "    network.save(caffemodel_file)\n",
    "    print(f\"{caffemodel_file} for detection v2 mode written....\")\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adb8772",
   "metadata": {},
   "source": [
    "# Test with input image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03334e12",
   "metadata": {},
   "source": [
    "## test image, prototxt and caffemodel file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b09459de",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_file = \"../sample_images/detection/1594202471809.jpg\"\n",
    "prototxt_file = \"./detection_v2.prototxt\"\n",
    "caffemodel_file = \"./detection_v2.caffemodel\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095b73d6",
   "metadata": {},
   "source": [
    "## save detection v2 network pramaters into caffemodel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ffb814d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./detection_v2.prototxt and ./detection_v2.caffemodel already exist, hence just return\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_network_parameters(test_image_file, prototxt_file, caffemodel_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce488197",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh \"./detection_v2.caffemodel\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ba8f7e",
   "metadata": {},
   "source": [
    "## detection v3 network instantiation with prototxt and caffemodel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caf166d",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_v2_network = caffe.Net(prototxt_file, caffemodel_file, caffe.TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e88d93",
   "metadata": {},
   "source": [
    "## set detection v2 network inference input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6858a7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image file and convert to batch zero padded array\n",
    "batch_img_array = image_preprocess(test_image_file, debug=True)\n",
    "    \n",
    "# set detection v2 network input\n",
    "detection_v2_network.blobs['data'].data[...] = batch_img_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8337d061",
   "metadata": {},
   "source": [
    "## foward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379303a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference for input image\n",
    "outputs = detection_v2_network.forward()\n",
    "\n",
    "print(f\"type(outputs): {type(outputs)}\")\n",
    "for k, v in outputs.items():\n",
    "    print(f\"{k} of shape {v.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c261c9c8",
   "metadata": {},
   "source": [
    "## Correctness Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2df4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_check(network, layer_name, rtol=1e-03, atol=1e-04):\n",
    "    output_file_path =f\"./npy_save/{layer_name}_output.npy\"\n",
    "    output_file = Path(output_file_path)\n",
    "    if output_file.exists():\n",
    "        pytorch_stem_conv1_output = np.load(output_file_path, allow_pickle=True)  \n",
    "        caffe_stem_conv1_output=network.blobs[layer_name].data\n",
    "    return np.allclose(caffe_stem_conv1_output, pytorch_stem_conv1_output, rtol=rtol, atol=atol )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12163b30",
   "metadata": {},
   "source": [
    "### stem_conv1 output check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2593abbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_check(detection_v2_network, \"backbone_body_stem_conv1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda0ae43",
   "metadata": {},
   "source": [
    "### stem_bn1 output check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb17e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_check(detection_v2_network, \"backbone_body_stem_bn1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df5332d",
   "metadata": {},
   "source": [
    "### stem_relu output check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f5f0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_check(detection_v2_network, \"backbone_body_stem_relu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e596f6",
   "metadata": {},
   "source": [
    "### stem_maxpool output check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98f9ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_check(detection_v2_network, \"backbone_body_stem_maxpool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c5dabc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 for PyTorch and caffe",
   "language": "python",
   "name": "lomin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
