DEBUG:root:# ======================
DEBUG:root:# Registered Modules
DEBUG:root:# ======================
DEBUG:root:	// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/resnet.py
DEBUG:root:	// _TRANSFORMATION_MODULES: {'BottleneckWithFixedBatchNorm': <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>}

DEBUG:root:	// _STEM_MODULES : {'BottleneckWithFixedBatchNorm': <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>}

DEBUG:root:
# Networks Stage Specs:
DEBUG:root:	'R-50-C4':
DEBUG:root:	(
DEBUG:root:		StageSpec(index=1, block_count=3, return_features=False)
DEBUG:root:		StageSpec(index=2, block_count=4, return_features=False)
DEBUG:root:		StageSpec(index=3, block_count=6, return_features=True)
DEBUG:root:	)

DEBUG:root:	'R-50-C5':
DEBUG:root:	(
DEBUG:root:		StageSpec(index=1, block_count=3, return_features=False)
DEBUG:root:		StageSpec(index=2, block_count=4, return_features=False)
DEBUG:root:		StageSpec(index=3, block_count=6, return_features=False)
DEBUG:root:		StageSpec(index=4, block_count=3, return_features=True)
DEBUG:root:	)

DEBUG:root:	'R-101-C4':
DEBUG:root:	(
DEBUG:root:		StageSpec(index=1, block_count=3, return_features=False)
DEBUG:root:		StageSpec(index=2, block_count=4, return_features=False)
DEBUG:root:		StageSpec(index=3, block_count=23, return_features=True)
DEBUG:root:	)

DEBUG:root:	'R-101-C5':
DEBUG:root:	(
DEBUG:root:		StageSpec(index=1, block_count=3, return_features=False)
DEBUG:root:		StageSpec(index=2, block_count=4, return_features=False)
DEBUG:root:		StageSpec(index=3, block_count=23, return_features=False)
DEBUG:root:		StageSpec(index=4, block_count=3, return_features=True)
DEBUG:root:	)

DEBUG:root:	'R-50-FPN':
DEBUG:root:	(
DEBUG:root:		StageSpec(index=1, block_count=3, return_features=True)
DEBUG:root:		StageSpec(index=2, block_count=4, return_features=True)
DEBUG:root:		StageSpec(index=3, block_count=6, return_features=True)
DEBUG:root:		StageSpec(index=4, block_count=3, return_features=True)
DEBUG:root:	)

DEBUG:root:	'R-50-FPN-RETINANET':
DEBUG:root:	(
DEBUG:root:		StageSpec(index=1, block_count=3, return_features=True)
DEBUG:root:		StageSpec(index=2, block_count=4, return_features=True)
DEBUG:root:		StageSpec(index=3, block_count=6, return_features=True)
DEBUG:root:		StageSpec(index=4, block_count=3, return_features=True)
DEBUG:root:	)

DEBUG:root:	'R-101-FPN':
DEBUG:root:	(
DEBUG:root:		StageSpec(index=1, block_count=3, return_features=True)
DEBUG:root:		StageSpec(index=2, block_count=4, return_features=True)
DEBUG:root:		StageSpec(index=3, block_count=23, return_features=True)
DEBUG:root:		StageSpec(index=4, block_count=3, return_features=True)
DEBUG:root:	)

DEBUG:root:	'R-101-FPN-RETINANET':
DEBUG:root:	(
DEBUG:root:		StageSpec(index=1, block_count=3, return_features=True)
DEBUG:root:		StageSpec(index=2, block_count=4, return_features=True)
DEBUG:root:		StageSpec(index=3, block_count=23, return_features=True)
DEBUG:root:		StageSpec(index=4, block_count=3, return_features=True)
DEBUG:root:	)

DEBUG:root:	'R-152-FPN':
DEBUG:root:	(
DEBUG:root:		StageSpec(index=1, block_count=3, return_features=True)
DEBUG:root:		StageSpec(index=2, block_count=8, return_features=True)
DEBUG:root:		StageSpec(index=3, block_count=36, return_features=True)
DEBUG:root:		StageSpec(index=4, block_count=3, return_features=True)
DEBUG:root:	)

DEBUG:root:


DEBUG:root:# =======================================
DEBUG:root:# I. Detection Model Build and Init
DEBUG:root:# =======================================
DEBUG:root:DetectionDemo.__init__(self, cfg, weight, is_recognition=False) { // BEGIN
DEBUG:root:	// defined in detection_model_debug.py
DEBUG:root:
	// Params:
DEBUG:root:		// cfg.MODEL.DEVICE: cuda
DEBUG:root:		// weight: ./model/detection/model_det_v2_200924_002_180k.pth
DEBUG:root:		// is_recognition: False

DEBUG:root:	self.model = build_detection_model(self.cfg) // CALL
DEBUG:root:	{

DEBUG:root:GeneralizedRCNN.__init__(self, cfg) { //BEGIN
DEBUG:root:	// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/detector/generalized_rcnn.py

DEBUG:root:		// Params:
DEBUG:root:			// cfg:

DEBUG:root:	super(GeneralizedRCNN, self).__init__()

DEBUG:root:	# ===========================================
DEBUG:root:	# 1.1 Backbone(Resnet50 + FPN) build
DEBUG:root:	# ===========================================
DEBUG:root:	{ // BEGIN of 1.1

DEBUG:root:	self.backbone = build_backbone(cfg) // CALL
DEBUG:root:	{

DEBUG:root:
	build_backbone(cfg) { // BEGIN
DEBUG:root:		// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/backbone.py

DEBUG:root:		// Params:
DEBUG:root:			// cfg:

DEBUG:root:		// cfg.MODEL.BACKBONE.CONV_BODY: R-50-FPN-RETINANET
DEBUG:root:		// registry.BACKBONES[cfg.MODEL.BACKBONE.CONV_BODY]:
DEBUG:root:		// <function build_resnet_fpn_p3p7_backbone at 0x7f3d2d0462f0>

DEBUG:root:		return registry.BACKBONES[cfg.MODEL.BACKBONE.CONV_BODY](cfg)
DEBUG:root:
	build_resnet_fpn_p3p7_backbone(cfg) { // BEGIN
DEBUG:root:	// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/backbone.py

DEBUG:root:		// Params:
DEBUG:root:			// cfg:

DEBUG:root:		# ================================
DEBUG:root:		# 1-1-1 ResNet50 build
DEBUG:root:		# ================================
DEBUG:root:		body = resnet.ResNet(cfg) // CALL
DEBUG:root:		{
DEBUG:root:
	Resnet.__init__(self, cfg) { //BEGIN
DEBUG:root:	// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/resnet.py

DEBUG:root:		// Params:
DEBUG:root:			// cfg:

DEBUG:root:		super(ResNet, self).__init__()

DEBUG:root:		// _STEM_MODULES: {'StemWithFixedBatchNorm': <class 'maskrcnn_benchmark.modeling.backbone.resnet.StemWithFixedBatchNorm'>}

DEBUG:root:		// _cfg.MODEL.RESNETS.STEM_FUNC: StemWithFixedBatchNorm
DEBUG:root:		stem_module = _STEM_MODULES[cfg.MODEL.RESNETS.STEM_FUNC]
DEBUG:root:		// stem_module: <class 'maskrcnn_benchmark.modeling.backbone.resnet.StemWithFixedBatchNorm'>

DEBUG:root:		// cfg.MODEL.BACKBONE.CONV_BODY: R-50-FPN-RETINANET
DEBUG:root:		stage_specs = _STAGE_SPECS[cfg.MODEL.BACKBONE.CONV_BODY=R-50-FPN-RETINANET]
DEBUG:root:		// stage_specs: (StageSpec(index=1, block_count=3, return_features=True), StageSpec(index=2, block_count=4, return_features=True), StageSpec(index=3, block_count=6, return_features=True), StageSpec(index=4, block_count=3, return_features=True))

DEBUG:root:		// _TRANSFORMATION_MODULES: {'BottleneckWithFixedBatchNorm': <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>}
DEBUG:root:		// cfg.MODEL.RESNETS.TRANS_FUNC: BottleneckWithFixedBatchNorm
DEBUG:root:		transformation_module = _TRANSFORMATION_MODULES[cfg.MODEL.RESNETS.TRANS_FUNC=BottleneckWithFixedBatchNorm]
DEBUG:root:		// transformation_module: <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>
DEBUG:root:		self.stem = stem_module(cfg) // CALL
DEBUG:root:		{
DEBUG:root:
	StemWithFixedBatchNorm.__init__() { //BEGIN
DEBUG:root:	// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/resnet.py

DEBUG:root:
	BaseStem.__init__() { //BEGIN
DEBUG:root:	// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/resnet.py

DEBUG:root:
	} // END BaseStem.__init__()
DEBUG:root:
	} // END StemWithFixedBatchNorm.__init__()
DEBUG:root:
		}
DEBUG:root:		self.stem = stem_module(cfg) // RETURNED
DEBUG:root:		// self.stem: StemWithFixedBatchNorm(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): FrozenBatchNorm2d()
)
DEBUG:root:		num_groups = cfg.MODEL.RESNETS.NUM_GROUPS
DEBUG:root:		// num_groups.stem: 1
DEBUG:root:		width_per_group = cfg.MODEL.RESNETS.WIDTH_PER_GROUP
DEBUG:root:		// width_per_group: 64
DEBUG:root:		in_channels = cfg.MODEL.RESNETS.STEM_OUT_CHANNELS
DEBUG:root:		// in_channels: 64
DEBUG:root:		stage2_bottleneck_channels = num_groups * width_per_group
DEBUG:root:		// stage2_bottleneck_channels: 64
DEBUG:root:		stage2_out_channels = cfg.MODEL.RESNETS.RES2_OUT_CHANNELS
DEBUG:root:		stage2_out_channels: 256
DEBUG:root:		self.stages = []
DEBUG:root:		self.return_features = {}
DEBUG:root:		for stage_spec in stage_specs {

DEBUG:root:
			{
DEBUG:root:			# ---------------------------------------------------------------
DEBUG:root:			# iteration 1/4
DEBUG:root:			#  1-th stage_spec: StageSpec(index=1, block_count=3, return_features=True)
DEBUG:root:			# ---------------------------------------------------------------
DEBUG:root:			name = "layer" + str(stage_spec.index)
DEBUG:root:			// name: layer1

DEBUG:root:			stage2_relative_factor = 2 ** (stage_spec.index - 1)
DEBUG:root:			// stage2_relative_factor: 1

DEBUG:root:			bottleneck_channels = stage2_bottleneck_channels * stage2_relative_factor
DEBUG:root:			// bottlenec_channels: 64

DEBUG:root:			out_channels = stage2_out_channels * stage2_relative_factor
DEBUG:root:			// out_channels: 256

DEBUG:root:			stage_with_dcn = cfg.MODEL.RESNETS.STAGE_WITH_DCN[stage_spec.index - 1]
DEBUG:root:			// stage_with_dcn: False

DEBUG:root:			module = _make_stage(
DEBUG:root:				transformation_module = <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>,
DEBUG:root:				in_channels = 64,
DEBUG:root:				bottleneck_channels = 64,
DEBUG:root:				out_channels = 256,
DEBUG:root:				stage_spec.block_count = 3,
DEBUG:root:				num_groups = 1,
DEBUG:root:				cfg.MODEL.RESNETS.STRIDE_IN_1X1 : True,
DEBUG:root:				first_stride=int(stage_spec.index > 1) + 1: 1,
DEBUG:root:				dcn_config={
DEBUG:root:					'stage_with_dcn': False,
DEBUG:root:					'with_modulated_dcn': False,
DEBUG:root:					'deformable_groups': 1,
DEBUG:root:					}
DEBUG:root:				) // CALL
DEBUG:root:				{
DEBUG:root:
	_make_stage() { //BEGIN
DEBUG:root:		// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/resnet.py

DEBUG:root:		// Params:
DEBUG:root:			// transformation_module: <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>
DEBUG:root:			// in_channels: 64
DEBUG:root:			// bottleneck_channels: 64
DEBUG:root:			// out_channels: 256
DEBUG:root:			// block_count: 3
DEBUG:root:			// num_groups: 3
DEBUG:root:			// stride_in_1x1: True
DEBUG:root:			// first_stride: 1
DEBUG:root:			// dilation: 1
DEBUG:root:			// dcn_config: {'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}

DEBUG:root:		blocks = []

DEBUG:root:		stride = first_stride

DEBUG:root:		for _ in range(block_count):  {
DEBUG:root:			{
DEBUG:root:			# --------------
DEBUG:root:			# blocks.append iteration 1/3
DEBUG:root:			# --------------
DEBUG:root:			blocks.append(
DEBUG:root:			    transformation_module(
DEBUG:root:			        in_channels=64,
DEBUG:root:			        bottleneck_channels=64,
DEBUG:root:			        out_channels=256,
DEBUG:root:			        num_groups=1,
DEBUG:root:			        stride_in_1x1=True,
DEBUG:root:			        stride=1,
DEBUG:root:			        dilation=1,
DEBUG:root:			        dcn_config={'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}
DEBUG:root:			   )
DEBUG:root:			)

DEBUG:root:			blocks[-1]:BottleneckWithFixedBatchNorm(
  (downsample): Sequential(
    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): FrozenBatchNorm2d()
  )
  (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): FrozenBatchNorm2d()
  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): FrozenBatchNorm2d()
  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): FrozenBatchNorm2d()
)
DEBUG:root:			stride = 1
DEBUG:root:			in_channels = out_channels
DEBUG:root:
			}
DEBUG:root:			{
DEBUG:root:			# --------------
DEBUG:root:			# blocks.append iteration 2/3
DEBUG:root:			# --------------
DEBUG:root:			blocks.append(
DEBUG:root:			    transformation_module(
DEBUG:root:			        in_channels=256,
DEBUG:root:			        bottleneck_channels=64,
DEBUG:root:			        out_channels=256,
DEBUG:root:			        num_groups=1,
DEBUG:root:			        stride_in_1x1=True,
DEBUG:root:			        stride=1,
DEBUG:root:			        dilation=1,
DEBUG:root:			        dcn_config={'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}
DEBUG:root:			   )
DEBUG:root:			)

DEBUG:root:			blocks[-1]:BottleneckWithFixedBatchNorm(
  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): FrozenBatchNorm2d()
  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): FrozenBatchNorm2d()
  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): FrozenBatchNorm2d()
)
DEBUG:root:			stride = 1
DEBUG:root:			in_channels = out_channels
DEBUG:root:
			}
DEBUG:root:			{
DEBUG:root:			# --------------
DEBUG:root:			# blocks.append iteration 3/3
DEBUG:root:			# --------------
DEBUG:root:			blocks.append(
DEBUG:root:			    transformation_module(
DEBUG:root:			        in_channels=256,
DEBUG:root:			        bottleneck_channels=64,
DEBUG:root:			        out_channels=256,
DEBUG:root:			        num_groups=1,
DEBUG:root:			        stride_in_1x1=True,
DEBUG:root:			        stride=1,
DEBUG:root:			        dilation=1,
DEBUG:root:			        dcn_config={'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}
DEBUG:root:			   )
DEBUG:root:			)

DEBUG:root:			blocks[-1]:BottleneckWithFixedBatchNorm(
  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): FrozenBatchNorm2d()
  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): FrozenBatchNorm2d()
  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): FrozenBatchNorm2d()
)
DEBUG:root:			stride = 1
DEBUG:root:			in_channels = out_channels
DEBUG:root:
			}
DEBUG:root:		}// END for _ in range(block_count):

DEBUG:root:		return nn.Sequential(*blocks)

DEBUG:root:
	} // END _make_stage()
DEBUG:root:				}
DEBUG:root:			module = _make_stage(
DEBUG:root:				transformation_module = <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>,
DEBUG:root:				in_channels = 64,
DEBUG:root:				bottleneck_channels = 64,
DEBUG:root:				out_channels = 256,
DEBUG:root:				stage_spec.block_count = 3,
DEBUG:root:				num_groups = 1,
DEBUG:root:				cfg.MODEL.RESNETS.STRIDE_IN_1X1 : True,
DEBUG:root:				first_stride=int(stage_spec.index > 1) + 1: 1,
DEBUG:root:				dcn_config={
DEBUG:root:					'stage_with_dcn': False,
DEBUG:root:					'with_modulated_dcn': False,
DEBUG:root:					'deformable_groups': 1,
DEBUG:root:					}
DEBUG:root:				) // RETURNED

DEBUG:root:			in_channels = out_channels
DEBUG:root:			// in_channels: 256

DEBUG:root:			self.add_module(name=layer1, module)

DEBUG:root:			self.stages.append(name=layer1)

DEBUG:root:			// name: layer1
DEBUG:root:			// stage_spec.return_features: True
DEBUG:root:			self.return_features[name] = stage_spec.return_features

DEBUG:root:			}  // END of iteration 1/4

DEBUG:root:
			{
DEBUG:root:			# ---------------------------------------------------------------
DEBUG:root:			# iteration 2/4
DEBUG:root:			#  2-th stage_spec: StageSpec(index=2, block_count=4, return_features=True)
DEBUG:root:			# ---------------------------------------------------------------
DEBUG:root:			name = "layer" + str(stage_spec.index)
DEBUG:root:			// name: layer2

DEBUG:root:			stage2_relative_factor = 2 ** (stage_spec.index - 1)
DEBUG:root:			// stage2_relative_factor: 2

DEBUG:root:			bottleneck_channels = stage2_bottleneck_channels * stage2_relative_factor
DEBUG:root:			// bottlenec_channels: 128

DEBUG:root:			out_channels = stage2_out_channels * stage2_relative_factor
DEBUG:root:			// out_channels: 512

DEBUG:root:			stage_with_dcn = cfg.MODEL.RESNETS.STAGE_WITH_DCN[stage_spec.index - 1]
DEBUG:root:			// stage_with_dcn: False

DEBUG:root:			module = _make_stage(
DEBUG:root:				transformation_module = <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>,
DEBUG:root:				in_channels = 256,
DEBUG:root:				bottleneck_channels = 128,
DEBUG:root:				out_channels = 512,
DEBUG:root:				stage_spec.block_count = 4,
DEBUG:root:				num_groups = 1,
DEBUG:root:				cfg.MODEL.RESNETS.STRIDE_IN_1X1 : True,
DEBUG:root:				first_stride=int(stage_spec.index > 1) + 1: 2,
DEBUG:root:				dcn_config={
DEBUG:root:					'stage_with_dcn': False,
DEBUG:root:					'with_modulated_dcn': False,
DEBUG:root:					'deformable_groups': 1,
DEBUG:root:					}
DEBUG:root:				) // CALL
DEBUG:root:				{
DEBUG:root:
	_make_stage() { //BEGIN
DEBUG:root:		// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/resnet.py

DEBUG:root:		// Params:
DEBUG:root:			// transformation_module: <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>
DEBUG:root:			// in_channels: 256
DEBUG:root:			// bottleneck_channels: 128
DEBUG:root:			// out_channels: 512
DEBUG:root:			// block_count: 4
DEBUG:root:			// num_groups: 4
DEBUG:root:			// stride_in_1x1: True
DEBUG:root:			// first_stride: 2
DEBUG:root:			// dilation: 1
DEBUG:root:			// dcn_config: {'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}

DEBUG:root:		blocks = []

DEBUG:root:		stride = first_stride

DEBUG:root:		for _ in range(block_count):  {
DEBUG:root:			{
DEBUG:root:			# --------------
DEBUG:root:			# blocks.append iteration 1/4
DEBUG:root:			# --------------
DEBUG:root:			blocks.append(
DEBUG:root:			    transformation_module(
DEBUG:root:			        in_channels=256,
DEBUG:root:			        bottleneck_channels=128,
DEBUG:root:			        out_channels=512,
DEBUG:root:			        num_groups=1,
DEBUG:root:			        stride_in_1x1=True,
DEBUG:root:			        stride=2,
DEBUG:root:			        dilation=1,
DEBUG:root:			        dcn_config={'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}
DEBUG:root:			   )
DEBUG:root:			)

DEBUG:root:			blocks[-1]:BottleneckWithFixedBatchNorm(
  (downsample): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): FrozenBatchNorm2d()
  )
  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
  (bn1): FrozenBatchNorm2d()
  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): FrozenBatchNorm2d()
  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): FrozenBatchNorm2d()
)
DEBUG:root:			stride = 1
DEBUG:root:			in_channels = out_channels
DEBUG:root:
			}
DEBUG:root:			{
DEBUG:root:			# --------------
DEBUG:root:			# blocks.append iteration 2/4
DEBUG:root:			# --------------
DEBUG:root:			blocks.append(
DEBUG:root:			    transformation_module(
DEBUG:root:			        in_channels=512,
DEBUG:root:			        bottleneck_channels=128,
DEBUG:root:			        out_channels=512,
DEBUG:root:			        num_groups=1,
DEBUG:root:			        stride_in_1x1=True,
DEBUG:root:			        stride=1,
DEBUG:root:			        dilation=1,
DEBUG:root:			        dcn_config={'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}
DEBUG:root:			   )
DEBUG:root:			)

DEBUG:root:			blocks[-1]:BottleneckWithFixedBatchNorm(
  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): FrozenBatchNorm2d()
  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): FrozenBatchNorm2d()
  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): FrozenBatchNorm2d()
)
DEBUG:root:			stride = 1
DEBUG:root:			in_channels = out_channels
DEBUG:root:
			}
DEBUG:root:			{
DEBUG:root:			# --------------
DEBUG:root:			# blocks.append iteration 3/4
DEBUG:root:			# --------------
DEBUG:root:			blocks.append(
DEBUG:root:			    transformation_module(
DEBUG:root:			        in_channels=512,
DEBUG:root:			        bottleneck_channels=128,
DEBUG:root:			        out_channels=512,
DEBUG:root:			        num_groups=1,
DEBUG:root:			        stride_in_1x1=True,
DEBUG:root:			        stride=1,
DEBUG:root:			        dilation=1,
DEBUG:root:			        dcn_config={'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}
DEBUG:root:			   )
DEBUG:root:			)

DEBUG:root:			blocks[-1]:BottleneckWithFixedBatchNorm(
  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): FrozenBatchNorm2d()
  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): FrozenBatchNorm2d()
  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): FrozenBatchNorm2d()
)
DEBUG:root:			stride = 1
DEBUG:root:			in_channels = out_channels
DEBUG:root:
			}
DEBUG:root:			{
DEBUG:root:			# --------------
DEBUG:root:			# blocks.append iteration 4/4
DEBUG:root:			# --------------
DEBUG:root:			blocks.append(
DEBUG:root:			    transformation_module(
DEBUG:root:			        in_channels=512,
DEBUG:root:			        bottleneck_channels=128,
DEBUG:root:			        out_channels=512,
DEBUG:root:			        num_groups=1,
DEBUG:root:			        stride_in_1x1=True,
DEBUG:root:			        stride=1,
DEBUG:root:			        dilation=1,
DEBUG:root:			        dcn_config={'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}
DEBUG:root:			   )
DEBUG:root:			)

DEBUG:root:			blocks[-1]:BottleneckWithFixedBatchNorm(
  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): FrozenBatchNorm2d()
  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): FrozenBatchNorm2d()
  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): FrozenBatchNorm2d()
)
DEBUG:root:			stride = 1
DEBUG:root:			in_channels = out_channels
DEBUG:root:
			}
DEBUG:root:		}// END for _ in range(block_count):

DEBUG:root:		return nn.Sequential(*blocks)

DEBUG:root:
	} // END _make_stage()
DEBUG:root:				}
DEBUG:root:			module = _make_stage(
DEBUG:root:				transformation_module = <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>,
DEBUG:root:				in_channels = 256,
DEBUG:root:				bottleneck_channels = 128,
DEBUG:root:				out_channels = 512,
DEBUG:root:				stage_spec.block_count = 4,
DEBUG:root:				num_groups = 1,
DEBUG:root:				cfg.MODEL.RESNETS.STRIDE_IN_1X1 : True,
DEBUG:root:				first_stride=int(stage_spec.index > 1) + 1: 2,
DEBUG:root:				dcn_config={
DEBUG:root:					'stage_with_dcn': False,
DEBUG:root:					'with_modulated_dcn': False,
DEBUG:root:					'deformable_groups': 1,
DEBUG:root:					}
DEBUG:root:				) // RETURNED

DEBUG:root:			in_channels = out_channels
DEBUG:root:			// in_channels: 512

DEBUG:root:			self.add_module(name=layer2, module)

DEBUG:root:			self.stages.append(name=layer2)

DEBUG:root:			// name: layer2
DEBUG:root:			// stage_spec.return_features: True
DEBUG:root:			self.return_features[name] = stage_spec.return_features

DEBUG:root:			}  // END of iteration 2/4

DEBUG:root:
			{
DEBUG:root:			# ---------------------------------------------------------------
DEBUG:root:			# iteration 3/4
DEBUG:root:			#  3-th stage_spec: StageSpec(index=3, block_count=6, return_features=True)
DEBUG:root:			# ---------------------------------------------------------------
DEBUG:root:			name = "layer" + str(stage_spec.index)
DEBUG:root:			// name: layer3

DEBUG:root:			stage2_relative_factor = 2 ** (stage_spec.index - 1)
DEBUG:root:			// stage2_relative_factor: 4

DEBUG:root:			bottleneck_channels = stage2_bottleneck_channels * stage2_relative_factor
DEBUG:root:			// bottlenec_channels: 256

DEBUG:root:			out_channels = stage2_out_channels * stage2_relative_factor
DEBUG:root:			// out_channels: 1024

DEBUG:root:			stage_with_dcn = cfg.MODEL.RESNETS.STAGE_WITH_DCN[stage_spec.index - 1]
DEBUG:root:			// stage_with_dcn: False

DEBUG:root:			module = _make_stage(
DEBUG:root:				transformation_module = <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>,
DEBUG:root:				in_channels = 512,
DEBUG:root:				bottleneck_channels = 256,
DEBUG:root:				out_channels = 1024,
DEBUG:root:				stage_spec.block_count = 6,
DEBUG:root:				num_groups = 1,
DEBUG:root:				cfg.MODEL.RESNETS.STRIDE_IN_1X1 : True,
DEBUG:root:				first_stride=int(stage_spec.index > 1) + 1: 2,
DEBUG:root:				dcn_config={
DEBUG:root:					'stage_with_dcn': False,
DEBUG:root:					'with_modulated_dcn': False,
DEBUG:root:					'deformable_groups': 1,
DEBUG:root:					}
DEBUG:root:				) // CALL
DEBUG:root:				{
DEBUG:root:
	_make_stage() { //BEGIN
DEBUG:root:		// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/resnet.py

DEBUG:root:		// Params:
DEBUG:root:			// transformation_module: <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>
DEBUG:root:			// in_channels: 512
DEBUG:root:			// bottleneck_channels: 256
DEBUG:root:			// out_channels: 1024
DEBUG:root:			// block_count: 6
DEBUG:root:			// num_groups: 6
DEBUG:root:			// stride_in_1x1: True
DEBUG:root:			// first_stride: 2
DEBUG:root:			// dilation: 1
DEBUG:root:			// dcn_config: {'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}

DEBUG:root:		blocks = []

DEBUG:root:		stride = first_stride

DEBUG:root:		for _ in range(block_count):  {
DEBUG:root:			{
DEBUG:root:			# --------------
DEBUG:root:			# blocks.append iteration 1/6
DEBUG:root:			# --------------
DEBUG:root:			blocks.append(
DEBUG:root:			    transformation_module(
DEBUG:root:			        in_channels=512,
DEBUG:root:			        bottleneck_channels=256,
DEBUG:root:			        out_channels=1024,
DEBUG:root:			        num_groups=1,
DEBUG:root:			        stride_in_1x1=True,
DEBUG:root:			        stride=2,
DEBUG:root:			        dilation=1,
DEBUG:root:			        dcn_config={'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}
DEBUG:root:			   )
DEBUG:root:			)

DEBUG:root:			blocks[-1]:BottleneckWithFixedBatchNorm(
  (downsample): Sequential(
    (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): FrozenBatchNorm2d()
  )
  (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
  (bn1): FrozenBatchNorm2d()
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): FrozenBatchNorm2d()
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): FrozenBatchNorm2d()
)
DEBUG:root:			stride = 1
DEBUG:root:			in_channels = out_channels
DEBUG:root:
			}
DEBUG:root:			{
DEBUG:root:			# --------------
DEBUG:root:			# blocks.append iteration 2/6
DEBUG:root:			# --------------
DEBUG:root:			blocks.append(
DEBUG:root:			    transformation_module(
DEBUG:root:			        in_channels=1024,
DEBUG:root:			        bottleneck_channels=256,
DEBUG:root:			        out_channels=1024,
DEBUG:root:			        num_groups=1,
DEBUG:root:			        stride_in_1x1=True,
DEBUG:root:			        stride=1,
DEBUG:root:			        dilation=1,
DEBUG:root:			        dcn_config={'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}
DEBUG:root:			   )
DEBUG:root:			)

DEBUG:root:			blocks[-1]:BottleneckWithFixedBatchNorm(
  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): FrozenBatchNorm2d()
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): FrozenBatchNorm2d()
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): FrozenBatchNorm2d()
)
DEBUG:root:			stride = 1
DEBUG:root:			in_channels = out_channels
DEBUG:root:
			}
DEBUG:root:			{
DEBUG:root:			# --------------
DEBUG:root:			# blocks.append iteration 3/6
DEBUG:root:			# --------------
DEBUG:root:			blocks.append(
DEBUG:root:			    transformation_module(
DEBUG:root:			        in_channels=1024,
DEBUG:root:			        bottleneck_channels=256,
DEBUG:root:			        out_channels=1024,
DEBUG:root:			        num_groups=1,
DEBUG:root:			        stride_in_1x1=True,
DEBUG:root:			        stride=1,
DEBUG:root:			        dilation=1,
DEBUG:root:			        dcn_config={'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}
DEBUG:root:			   )
DEBUG:root:			)

DEBUG:root:			blocks[-1]:BottleneckWithFixedBatchNorm(
  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): FrozenBatchNorm2d()
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): FrozenBatchNorm2d()
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): FrozenBatchNorm2d()
)
DEBUG:root:			stride = 1
DEBUG:root:			in_channels = out_channels
DEBUG:root:
			}
DEBUG:root:			{
DEBUG:root:			# --------------
DEBUG:root:			# blocks.append iteration 4/6
DEBUG:root:			# --------------
DEBUG:root:			blocks.append(
DEBUG:root:			    transformation_module(
DEBUG:root:			        in_channels=1024,
DEBUG:root:			        bottleneck_channels=256,
DEBUG:root:			        out_channels=1024,
DEBUG:root:			        num_groups=1,
DEBUG:root:			        stride_in_1x1=True,
DEBUG:root:			        stride=1,
DEBUG:root:			        dilation=1,
DEBUG:root:			        dcn_config={'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}
DEBUG:root:			   )
DEBUG:root:			)

DEBUG:root:			blocks[-1]:BottleneckWithFixedBatchNorm(
  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): FrozenBatchNorm2d()
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): FrozenBatchNorm2d()
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): FrozenBatchNorm2d()
)
DEBUG:root:			stride = 1
DEBUG:root:			in_channels = out_channels
DEBUG:root:
			}
DEBUG:root:			{
DEBUG:root:			# --------------
DEBUG:root:			# blocks.append iteration 5/6
DEBUG:root:			# --------------
DEBUG:root:			blocks.append(
DEBUG:root:			    transformation_module(
DEBUG:root:			        in_channels=1024,
DEBUG:root:			        bottleneck_channels=256,
DEBUG:root:			        out_channels=1024,
DEBUG:root:			        num_groups=1,
DEBUG:root:			        stride_in_1x1=True,
DEBUG:root:			        stride=1,
DEBUG:root:			        dilation=1,
DEBUG:root:			        dcn_config={'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}
DEBUG:root:			   )
DEBUG:root:			)

DEBUG:root:			blocks[-1]:BottleneckWithFixedBatchNorm(
  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): FrozenBatchNorm2d()
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): FrozenBatchNorm2d()
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): FrozenBatchNorm2d()
)
DEBUG:root:			stride = 1
DEBUG:root:			in_channels = out_channels
DEBUG:root:
			}
DEBUG:root:			{
DEBUG:root:			# --------------
DEBUG:root:			# blocks.append iteration 6/6
DEBUG:root:			# --------------
DEBUG:root:			blocks.append(
DEBUG:root:			    transformation_module(
DEBUG:root:			        in_channels=1024,
DEBUG:root:			        bottleneck_channels=256,
DEBUG:root:			        out_channels=1024,
DEBUG:root:			        num_groups=1,
DEBUG:root:			        stride_in_1x1=True,
DEBUG:root:			        stride=1,
DEBUG:root:			        dilation=1,
DEBUG:root:			        dcn_config={'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}
DEBUG:root:			   )
DEBUG:root:			)

DEBUG:root:			blocks[-1]:BottleneckWithFixedBatchNorm(
  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): FrozenBatchNorm2d()
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): FrozenBatchNorm2d()
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): FrozenBatchNorm2d()
)
DEBUG:root:			stride = 1
DEBUG:root:			in_channels = out_channels
DEBUG:root:
			}
DEBUG:root:		}// END for _ in range(block_count):

DEBUG:root:		return nn.Sequential(*blocks)

DEBUG:root:
	} // END _make_stage()
DEBUG:root:				}
DEBUG:root:			module = _make_stage(
DEBUG:root:				transformation_module = <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>,
DEBUG:root:				in_channels = 512,
DEBUG:root:				bottleneck_channels = 256,
DEBUG:root:				out_channels = 1024,
DEBUG:root:				stage_spec.block_count = 6,
DEBUG:root:				num_groups = 1,
DEBUG:root:				cfg.MODEL.RESNETS.STRIDE_IN_1X1 : True,
DEBUG:root:				first_stride=int(stage_spec.index > 1) + 1: 2,
DEBUG:root:				dcn_config={
DEBUG:root:					'stage_with_dcn': False,
DEBUG:root:					'with_modulated_dcn': False,
DEBUG:root:					'deformable_groups': 1,
DEBUG:root:					}
DEBUG:root:				) // RETURNED

DEBUG:root:			in_channels = out_channels
DEBUG:root:			// in_channels: 1024

DEBUG:root:			self.add_module(name=layer3, module)

DEBUG:root:			self.stages.append(name=layer3)

DEBUG:root:			// name: layer3
DEBUG:root:			// stage_spec.return_features: True
DEBUG:root:			self.return_features[name] = stage_spec.return_features

DEBUG:root:			}  // END of iteration 3/4

DEBUG:root:
			{
DEBUG:root:			# ---------------------------------------------------------------
DEBUG:root:			# iteration 4/4
DEBUG:root:			#  4-th stage_spec: StageSpec(index=4, block_count=3, return_features=True)
DEBUG:root:			# ---------------------------------------------------------------
DEBUG:root:			name = "layer" + str(stage_spec.index)
DEBUG:root:			// name: layer4

DEBUG:root:			stage2_relative_factor = 2 ** (stage_spec.index - 1)
DEBUG:root:			// stage2_relative_factor: 8

DEBUG:root:			bottleneck_channels = stage2_bottleneck_channels * stage2_relative_factor
DEBUG:root:			// bottlenec_channels: 512

DEBUG:root:			out_channels = stage2_out_channels * stage2_relative_factor
DEBUG:root:			// out_channels: 2048

DEBUG:root:			stage_with_dcn = cfg.MODEL.RESNETS.STAGE_WITH_DCN[stage_spec.index - 1]
DEBUG:root:			// stage_with_dcn: False

DEBUG:root:			module = _make_stage(
DEBUG:root:				transformation_module = <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>,
DEBUG:root:				in_channels = 1024,
DEBUG:root:				bottleneck_channels = 512,
DEBUG:root:				out_channels = 2048,
DEBUG:root:				stage_spec.block_count = 3,
DEBUG:root:				num_groups = 1,
DEBUG:root:				cfg.MODEL.RESNETS.STRIDE_IN_1X1 : True,
DEBUG:root:				first_stride=int(stage_spec.index > 1) + 1: 2,
DEBUG:root:				dcn_config={
DEBUG:root:					'stage_with_dcn': False,
DEBUG:root:					'with_modulated_dcn': False,
DEBUG:root:					'deformable_groups': 1,
DEBUG:root:					}
DEBUG:root:				) // CALL
DEBUG:root:				{
DEBUG:root:
	_make_stage() { //BEGIN
DEBUG:root:		// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/resnet.py

DEBUG:root:		// Params:
DEBUG:root:			// transformation_module: <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>
DEBUG:root:			// in_channels: 1024
DEBUG:root:			// bottleneck_channels: 512
DEBUG:root:			// out_channels: 2048
DEBUG:root:			// block_count: 3
DEBUG:root:			// num_groups: 3
DEBUG:root:			// stride_in_1x1: True
DEBUG:root:			// first_stride: 2
DEBUG:root:			// dilation: 1
DEBUG:root:			// dcn_config: {'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}

DEBUG:root:		blocks = []

DEBUG:root:		stride = first_stride

DEBUG:root:		for _ in range(block_count):  {
DEBUG:root:			{
DEBUG:root:			# --------------
DEBUG:root:			# blocks.append iteration 1/3
DEBUG:root:			# --------------
DEBUG:root:			blocks.append(
DEBUG:root:			    transformation_module(
DEBUG:root:			        in_channels=1024,
DEBUG:root:			        bottleneck_channels=512,
DEBUG:root:			        out_channels=2048,
DEBUG:root:			        num_groups=1,
DEBUG:root:			        stride_in_1x1=True,
DEBUG:root:			        stride=2,
DEBUG:root:			        dilation=1,
DEBUG:root:			        dcn_config={'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}
DEBUG:root:			   )
DEBUG:root:			)

DEBUG:root:			blocks[-1]:BottleneckWithFixedBatchNorm(
  (downsample): Sequential(
    (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): FrozenBatchNorm2d()
  )
  (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
  (bn1): FrozenBatchNorm2d()
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): FrozenBatchNorm2d()
  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): FrozenBatchNorm2d()
)
DEBUG:root:			stride = 1
DEBUG:root:			in_channels = out_channels
DEBUG:root:
			}
DEBUG:root:			{
DEBUG:root:			# --------------
DEBUG:root:			# blocks.append iteration 2/3
DEBUG:root:			# --------------
DEBUG:root:			blocks.append(
DEBUG:root:			    transformation_module(
DEBUG:root:			        in_channels=2048,
DEBUG:root:			        bottleneck_channels=512,
DEBUG:root:			        out_channels=2048,
DEBUG:root:			        num_groups=1,
DEBUG:root:			        stride_in_1x1=True,
DEBUG:root:			        stride=1,
DEBUG:root:			        dilation=1,
DEBUG:root:			        dcn_config={'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}
DEBUG:root:			   )
DEBUG:root:			)

DEBUG:root:			blocks[-1]:BottleneckWithFixedBatchNorm(
  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): FrozenBatchNorm2d()
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): FrozenBatchNorm2d()
  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): FrozenBatchNorm2d()
)
DEBUG:root:			stride = 1
DEBUG:root:			in_channels = out_channels
DEBUG:root:
			}
DEBUG:root:			{
DEBUG:root:			# --------------
DEBUG:root:			# blocks.append iteration 3/3
DEBUG:root:			# --------------
DEBUG:root:			blocks.append(
DEBUG:root:			    transformation_module(
DEBUG:root:			        in_channels=2048,
DEBUG:root:			        bottleneck_channels=512,
DEBUG:root:			        out_channels=2048,
DEBUG:root:			        num_groups=1,
DEBUG:root:			        stride_in_1x1=True,
DEBUG:root:			        stride=1,
DEBUG:root:			        dilation=1,
DEBUG:root:			        dcn_config={'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}
DEBUG:root:			   )
DEBUG:root:			)

DEBUG:root:			blocks[-1]:BottleneckWithFixedBatchNorm(
  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): FrozenBatchNorm2d()
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): FrozenBatchNorm2d()
  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): FrozenBatchNorm2d()
)
DEBUG:root:			stride = 1
DEBUG:root:			in_channels = out_channels
DEBUG:root:
			}
DEBUG:root:		}// END for _ in range(block_count):

DEBUG:root:		return nn.Sequential(*blocks)

DEBUG:root:
	} // END _make_stage()
DEBUG:root:				}
DEBUG:root:			module = _make_stage(
DEBUG:root:				transformation_module = <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>,
DEBUG:root:				in_channels = 1024,
DEBUG:root:				bottleneck_channels = 512,
DEBUG:root:				out_channels = 2048,
DEBUG:root:				stage_spec.block_count = 3,
DEBUG:root:				num_groups = 1,
DEBUG:root:				cfg.MODEL.RESNETS.STRIDE_IN_1X1 : True,
DEBUG:root:				first_stride=int(stage_spec.index > 1) + 1: 2,
DEBUG:root:				dcn_config={
DEBUG:root:					'stage_with_dcn': False,
DEBUG:root:					'with_modulated_dcn': False,
DEBUG:root:					'deformable_groups': 1,
DEBUG:root:					}
DEBUG:root:				) // RETURNED

DEBUG:root:			in_channels = out_channels
DEBUG:root:			// in_channels: 2048

DEBUG:root:			self.add_module(name=layer4, module)

DEBUG:root:			self.stages.append(name=layer4)

DEBUG:root:			// name: layer4
DEBUG:root:			// stage_spec.return_features: True
DEBUG:root:			self.return_features[name] = stage_spec.return_features

DEBUG:root:			}  // END of iteration 4/4

DEBUG:root:} // END for stage_spec in stage_specs:

DEBUG:root:			// cfg.MODEL.BACKBONE.FREEZE_CONV_BODY_AT: 2)
DEBUG:root:			self._freeze_backbone(cfg.MODEL.BACKBONE.FREEZE_CONV_BODY_AT)
DEBUG:root:
	Resnet.__freeze_backbone(self, freeze_at) { // BEGIN
DEBUG:root:	// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/resnet.py

DEBUG:root:		// Params:
DEBUG:root:			// freeze_at: 2
DEBUG:root:	} // END Resnet.__freeze_backbone(self, freeze_at)

DEBUG:root:} // END Resnet.__init__(self, cfg)

DEBUG:root:
		}
DEBUG:root:		body = resnet.ResNet(cfg) // RETURNED



DEBUG:root:		# ================================
DEBUG:root:		# 1-1-2 FPN build
DEBUG:root:		# ================================

DEBUG:root:		# get the channels parameters required by fpn
DEBUG:root:		// cfg.MODEL.RESNETS.RES2_OUT_CHANNELS: 256
DEBUG:root:		in_channels_stage2 = cfg.MODEL.RESNETS.RES2_OUT_CHANNELS
DEBUG:root:		// in_channels_stage2: 256

DEBUG:root:		// cfg.MODEL.RESNETS.BACKBONE_OUT_CHANNELS:1024
DEBUG:root:		out_channels = cfg.MODEL.RESNETS.BACKBONE_OUT_CHANNELS
DEBUG:root:		// out_channels: 1024

DEBUG:root:		// in_channels_stage2: 256
DEBUG:root:		// out_channels: 1024
DEBUG:root:		// cfg.MODEL.RETINANET.USE_C5: True
DEBUG:root:		in_channels_p6p7 = in_channels_stage2 * 8 if cfg.MODEL.RETINANET.USE_C5 else out_channels
DEBUG:root:		// in_channels_p6p7: 2048

DEBUG:root:
		fpn = fpn_module.FPN(
DEBUG:root:				in_channels_list = [0, 512, 1024, 2048],
DEBUG:root:				out_channels = 1024,
DEBUG:root:				conv_block=conv_with_kaiming_uniform( cfg.MODEL.FPN.USE_GN =False, cfg.MODEL.FPN.USE_RELU =False ),
DEBUG:root:				top_blocks=fpn_module.LastLevelP6P7(in_channels_p6p7=2048, out_channels=1024,) // CALL
DEBUG:root:
			conv_with_kaiming_uniform(use_gn=False, use_relut=False) { //BEGIN
DEBUG:root:				// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/make_layers.py
DEBUG:root:			} // END conv_with_kaiming_uniform(use_gn=False, use_relu=False)

DEBUG:root:		# =================================
DEBUG:root:		# 1-1-2-1 FPN.LastLevelP6P7 build
DEBUG:root:		# =================================

DEBUG:root:			LastLevelP6P7.__init__(self, in_channels, out_channels) { //BEGIN
DEBUG:root:				// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/fpn.py

DEBUG:root:				> Param:
DEBUG:root:					>in_channels: 2048
DEBUG:root:					>out_channels: 1024

DEBUG:root:				super(LastLevelP6P7, self).__init__()
DEBUG:root:				self.p6 = nn.Conv2d(in_channels=2048, out_channels=1024, 3, 2, 1)
DEBUG:root:				// self.p6: Conv2d(2048, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))

DEBUG:root:				self.p7 = nn.Conv2d(out_channels=1024, out_channels=1024, 3, 2, 1)
DEBUG:root:				// self.p7: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))

DEBUG:root:				for module in [self.p6, self.p7] {
DEBUG:root:					module=Conv2d(2048, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
DEBUG:root:					nn.init.kaiming_uniform_(module.weight=module.weight, a=1)

DEBUG:root:					nn.init.constant_(module.bias=module.bias, 0)

DEBUG:root:					module=Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
DEBUG:root:					nn.init.kaiming_uniform_(module.weight=module.weight, a=1)

DEBUG:root:					nn.init.constant_(module.bias=module.bias, 0)

DEBUG:root:				} // END for module in [self.p6, self.p7]

DEBUG:root:				self.use_P5 = in_channels == out_channels
DEBUG:root:					// self.use_p5: False

DEBUG:root:				} // END LastLevelP6P7.__init__(self, in_channels, out_channels)


DEBUG:root:		# =================================
DEBUG:root:		# 1-1-2-2 FPN build
DEBUG:root:		# =================================

DEBUG:root:

FPN.__init__ { // BEGIN
DEBUG:root:		// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/fpn.py

DEBUG:root:		// Params
DEBUG:root:			// in_channels_list: [0, 512, 1024, 2048]
DEBUG:root:			// out_channels: 1024
DEBUG:root:			// conv_block: <function conv_with_kaiming_uniform.<locals>.make_conv at 0x7f3d0436ec80>
DEBUG:root:			// top_blocks: LastLevelP6P7(
  (p6): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (p7): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
)

DEBUG:root:		super(FPN, self).__init__()

DEBUG:root:		# create two empty lists
DEBUG:root:		self.inner_blocks = []
DEBUG:root:		self.layer_block = []
DEBUG:root:		for idx, in_channels in enumerate(in_channels_list, 1) {

DEBUG:root:			{
DEBUG:root:				# -----------------------------------------------------
DEBUG:root:				# in_channels:0, iteration 1/4 BEGIN
DEBUG:root:				# -----------------------------------------------------
DEBUG:root:				inner_block = "fpn_inner{}".format(idx)
DEBUG:root:				// inner_block: {inner_block}

DEBUG:root:				layer_block = "fpn_layer{}".format(idx)
DEBUG:root:				// layer_block: {layer_block}

DEBUG:root:				if in_channels ==0, skip

DEBUG:root:			}
			# iteration 1/4 END

DEBUG:root:			{
DEBUG:root:				# -----------------------------------------------------
DEBUG:root:				# in_channels:512, iteration 2/4 BEGIN
DEBUG:root:				# -----------------------------------------------------
DEBUG:root:				inner_block = "fpn_inner{}".format(idx)
DEBUG:root:				// inner_block: {inner_block}

DEBUG:root:				layer_block = "fpn_layer{}".format(idx)
DEBUG:root:				// layer_block: {layer_block}

DEBUG:root:				// inner_block: fpn_inner2
DEBUG:root:				// layer_block: fpn_layer2

DEBUG:root:
				make_conv(in_channels, out_channels, kernel_size, stride=1, dilation=1) { //BEGIN
DEBUG:root:				// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/make_layers.py

DEBUG:root:				// Params:
DEBUG:root:					// in_channels: 512
DEBUG:root:					// out_channels: 1024
DEBUG:root:					// kernel_size: 1
DEBUG:root:					// stride: 1
DEBUG:root:					// dilation: 1

DEBUG:root:				conv = Conv2d(in_channles=512, out_channels=1024, kernel_size=1, stride=1
DEBUG:root:				       padding=0, dilation=1, bias=True, )
DEBUG:root:				// conv: Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))

DEBUG:root:				nn.init.kaiming_uniform_(conv.weight, a=1)

DEBUG:root:				if not use_gn:
DEBUG:root:					nn.init.constant_(conv.bias, 0)

DEBUG:root:				module = [conv,]
DEBUG:root:				// module: [Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))]

DEBUG:root:				conv: Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
DEBUG:root:				return conv

DEBUG:root:				} // END conv_with_kaiming_uniform().make_conv()

DEBUG:root:				inner_block_module = conv_block(in_channels=512, out_channels=1024, 1)
DEBUG:root:				// inner_block_module: Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))

DEBUG:root:
				make_conv(in_channels, out_channels, kernel_size, stride=1, dilation=1) { //BEGIN
DEBUG:root:				// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/make_layers.py

DEBUG:root:				// Params:
DEBUG:root:					// in_channels: 1024
DEBUG:root:					// out_channels: 1024
DEBUG:root:					// kernel_size: 3
DEBUG:root:					// stride: 1
DEBUG:root:					// dilation: 1

DEBUG:root:				conv = Conv2d(in_channles=1024, out_channels=1024, kernel_size=3, stride=1
DEBUG:root:				       padding=1, dilation=1, bias=True, )
DEBUG:root:				// conv: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))

DEBUG:root:				nn.init.kaiming_uniform_(conv.weight, a=1)

DEBUG:root:				if not use_gn:
DEBUG:root:					nn.init.constant_(conv.bias, 0)

DEBUG:root:				module = [conv,]
DEBUG:root:				// module: [Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]

DEBUG:root:				conv: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
DEBUG:root:				return conv

DEBUG:root:				} // END conv_with_kaiming_uniform().make_conv()

DEBUG:root:				layer_block_module = conv_block(out_channels=1024, out_channels=1024, 3,1)
DEBUG:root:				// layer_block_module: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))

DEBUG:root:				self.add_module(inner_block, inner_block_module)

DEBUG:root:				self.add_module(layer_block, layer_block_module)

DEBUG:root:				self.inner_blocks.append(fpn_inner2)

DEBUG:root:				self.layer_blocks.append(fpn_layer2)

DEBUG:root:			}
			# iteration 2/4 END

DEBUG:root:			{
DEBUG:root:				# -----------------------------------------------------
DEBUG:root:				# in_channels:1024, iteration 3/4 BEGIN
DEBUG:root:				# -----------------------------------------------------
DEBUG:root:				inner_block = "fpn_inner{}".format(idx)
DEBUG:root:				// inner_block: {inner_block}

DEBUG:root:				layer_block = "fpn_layer{}".format(idx)
DEBUG:root:				// layer_block: {layer_block}

DEBUG:root:				// inner_block: fpn_inner3
DEBUG:root:				// layer_block: fpn_layer3

DEBUG:root:
				make_conv(in_channels, out_channels, kernel_size, stride=1, dilation=1) { //BEGIN
DEBUG:root:				// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/make_layers.py

DEBUG:root:				// Params:
DEBUG:root:					// in_channels: 1024
DEBUG:root:					// out_channels: 1024
DEBUG:root:					// kernel_size: 1
DEBUG:root:					// stride: 1
DEBUG:root:					// dilation: 1

DEBUG:root:				conv = Conv2d(in_channles=1024, out_channels=1024, kernel_size=1, stride=1
DEBUG:root:				       padding=0, dilation=1, bias=True, )
DEBUG:root:				// conv: Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))

DEBUG:root:				nn.init.kaiming_uniform_(conv.weight, a=1)

DEBUG:root:				if not use_gn:
DEBUG:root:					nn.init.constant_(conv.bias, 0)

DEBUG:root:				module = [conv,]
DEBUG:root:				// module: [Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))]

DEBUG:root:				conv: Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
DEBUG:root:				return conv

DEBUG:root:				} // END conv_with_kaiming_uniform().make_conv()

DEBUG:root:				inner_block_module = conv_block(in_channels=1024, out_channels=1024, 1)
DEBUG:root:				// inner_block_module: Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))

DEBUG:root:
				make_conv(in_channels, out_channels, kernel_size, stride=1, dilation=1) { //BEGIN
DEBUG:root:				// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/make_layers.py

DEBUG:root:				// Params:
DEBUG:root:					// in_channels: 1024
DEBUG:root:					// out_channels: 1024
DEBUG:root:					// kernel_size: 3
DEBUG:root:					// stride: 1
DEBUG:root:					// dilation: 1

DEBUG:root:				conv = Conv2d(in_channles=1024, out_channels=1024, kernel_size=3, stride=1
DEBUG:root:				       padding=1, dilation=1, bias=True, )
DEBUG:root:				// conv: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))

DEBUG:root:				nn.init.kaiming_uniform_(conv.weight, a=1)

DEBUG:root:				if not use_gn:
DEBUG:root:					nn.init.constant_(conv.bias, 0)

DEBUG:root:				module = [conv,]
DEBUG:root:				// module: [Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]

DEBUG:root:				conv: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
DEBUG:root:				return conv

DEBUG:root:				} // END conv_with_kaiming_uniform().make_conv()

DEBUG:root:				layer_block_module = conv_block(out_channels=1024, out_channels=1024, 3,1)
DEBUG:root:				// layer_block_module: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))

DEBUG:root:				self.add_module(inner_block, inner_block_module)

DEBUG:root:				self.add_module(layer_block, layer_block_module)

DEBUG:root:				self.inner_blocks.append(fpn_inner3)

DEBUG:root:				self.layer_blocks.append(fpn_layer3)

DEBUG:root:			}
			# iteration 3/4 END

DEBUG:root:			{
DEBUG:root:				# -----------------------------------------------------
DEBUG:root:				# in_channels:2048, iteration 4/4 BEGIN
DEBUG:root:				# -----------------------------------------------------
DEBUG:root:				inner_block = "fpn_inner{}".format(idx)
DEBUG:root:				// inner_block: {inner_block}

DEBUG:root:				layer_block = "fpn_layer{}".format(idx)
DEBUG:root:				// layer_block: {layer_block}

DEBUG:root:				// inner_block: fpn_inner4
DEBUG:root:				// layer_block: fpn_layer4

DEBUG:root:
				make_conv(in_channels, out_channels, kernel_size, stride=1, dilation=1) { //BEGIN
DEBUG:root:				// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/make_layers.py

DEBUG:root:				// Params:
DEBUG:root:					// in_channels: 2048
DEBUG:root:					// out_channels: 1024
DEBUG:root:					// kernel_size: 1
DEBUG:root:					// stride: 1
DEBUG:root:					// dilation: 1

DEBUG:root:				conv = Conv2d(in_channles=2048, out_channels=1024, kernel_size=1, stride=1
DEBUG:root:				       padding=0, dilation=1, bias=True, )
DEBUG:root:				// conv: Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))

DEBUG:root:				nn.init.kaiming_uniform_(conv.weight, a=1)

DEBUG:root:				if not use_gn:
DEBUG:root:					nn.init.constant_(conv.bias, 0)

DEBUG:root:				module = [conv,]
DEBUG:root:				// module: [Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))]

DEBUG:root:				conv: Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
DEBUG:root:				return conv

DEBUG:root:				} // END conv_with_kaiming_uniform().make_conv()

DEBUG:root:				inner_block_module = conv_block(in_channels=2048, out_channels=1024, 1)
DEBUG:root:				// inner_block_module: Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))

DEBUG:root:
				make_conv(in_channels, out_channels, kernel_size, stride=1, dilation=1) { //BEGIN
DEBUG:root:				// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/make_layers.py

DEBUG:root:				// Params:
DEBUG:root:					// in_channels: 1024
DEBUG:root:					// out_channels: 1024
DEBUG:root:					// kernel_size: 3
DEBUG:root:					// stride: 1
DEBUG:root:					// dilation: 1

DEBUG:root:				conv = Conv2d(in_channles=1024, out_channels=1024, kernel_size=3, stride=1
DEBUG:root:				       padding=1, dilation=1, bias=True, )
DEBUG:root:				// conv: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))

DEBUG:root:				nn.init.kaiming_uniform_(conv.weight, a=1)

DEBUG:root:				if not use_gn:
DEBUG:root:					nn.init.constant_(conv.bias, 0)

DEBUG:root:				module = [conv,]
DEBUG:root:				// module: [Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]

DEBUG:root:				conv: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
DEBUG:root:				return conv

DEBUG:root:				} // END conv_with_kaiming_uniform().make_conv()

DEBUG:root:				layer_block_module = conv_block(out_channels=1024, out_channels=1024, 3,1)
DEBUG:root:				// layer_block_module: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))

DEBUG:root:				self.add_module(inner_block, inner_block_module)

DEBUG:root:				self.add_module(layer_block, layer_block_module)

DEBUG:root:				self.inner_blocks.append(fpn_inner4)

DEBUG:root:				self.layer_blocks.append(fpn_layer4)

DEBUG:root:			}
			# iteration 4/4 END

DEBUG:root:
		} // END for idx, in_channels in enumerate(in_channels_list, 1)
DEBUG:root:		self.top_blocks = top_blocks

DEBUG:root:		// self.inner_blocks: ['fpn_inner2', 'fpn_inner3', 'fpn_inner4']
DEBUG:root:		// self.fpn_inner2: Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
DEBUG:root:		// self.fpn_inner3: Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
DEBUG:root:		// self.fpn_inner4: Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
DEBUG:root:
	// self.layer_blocks: ['fpn_layer2', 'fpn_layer3', 'fpn_layer4']
DEBUG:root:		// self.fpn_layer2: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
DEBUG:root:		// self.fpn_layer3: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
DEBUG:root:		// self.fpn_layer4: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
DEBUG:root:
	// self.top_blocks: LastLevelP6P7(
  (p6): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (p7): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
)
DEBUG:root:
} // END FPN.__init__


DEBUG:root:
		fpn = fpn_module.FPN(
DEBUG:root:
				in_channels_list = [0, 512, 1024, 2048],
DEBUG:root:
				out_channels = 1024,
DEBUG:root:
				conv_block=conv_with_kaiming_uniform( cfg.MODEL.FPN.USE_GN =False, cfg.MODEL.FPN.USE_RELU =False ),
DEBUG:root:
				top_blocks=fpn_module.LastLevelP6P7(in_channels_p6p7=2048, out_channels=1024,) // RETURNED
DEBUG:root:
			// fpn: FPN(
  (fpn_inner2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
  (fpn_layer2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (fpn_inner3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
  (fpn_layer3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (fpn_inner4): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
  (fpn_layer4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (top_blocks): LastLevelP6P7(
    (p6): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (p7): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  )
)


DEBUG:root:		model = nn.Sequential(OrderedDict([("body", body), ("fpn", fpn)]))

DEBUG:root:		model.out_channels = out_channels
DEBUG:root:			// model.out_channels: 1024

DEBUG:root:		return model

DEBUG:root:	} // END build_resnet_fpn_p3p7_backbone(cfg)


DEBUG:root:	} // END build_backbone(cfg)

DEBUG:root:	}
DEBUG:root:	self.backbone = build_backbone(cfg) // RETURNED

DEBUG:root:
	} // END of 1.1 

DEBUG:root:	# ===========================================
DEBUG:root:	# 1.2 RPN (Region Proposal Network) build
DEBUG:root:	# ===========================================
DEBUG:root:	{ // BEGIN of 1.2

DEBUG:root:	// self.backbone.out_channels: 1024
DEBUG:root:	self.rpn = build_rpn(cfg, self.backbone.out_channels) // CALL
DEBUG:root:	build_retinanet(cfg, in_channels) { // BEGIN
DEBUG:root:	// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/retinanet/retinanet.py

DEBUG:root:		// Param:
DEBUG:root:			// cfg:
DEBUG:root:			// in_channels: 1024
DEBUG:root:	return RetinaNetModule(cfg, in_channels) // CALL
DEBUG:root:		RetinaNetModule.__init__(self, cfg, in_channels) { // BEGIN
DEBUG:root:			// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/retinanet/retinanet.py

DEBUG:root:			// Params:
DEBUG:root:				// cfg:
DEBUG:root:				// in_channels: 1024

DEBUG:root:	super(RetinaNetModule, self).__init__()
DEBUG:root:	self.cfg = cfg.clone()
DEBUG:root:	#============================
DEBUG:root:	# 1.2.1 anchor generator build
DEBUG:root:	#============================
DEBUG:root:	anchor_generator = make_anchor_generator_retinanet(cfg) // CALL
	{
DEBUG:root:
		make_anchor_generator_retinanet(config) { // BEGIN
DEBUG:root:			// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py

DEBUG:root:				// Params
DEBUG:root:					// anchor_sizes: (32, 64, 128, 256, 512)
DEBUG:root:					// aspect_ratios: (0.5, 1.0, 2.0)
DEBUG:root:					// anchor_strides: (8, 16, 32, 64, 128)
DEBUG:root:					// straddle_thresh: -1
DEBUG:root:					// octave: 2.0
DEBUG:root:					// scales_per_octave: 3

DEBUG:root:				new_anchor_sizes = []

DEBUG:root:
				for size in anchor_sizes {
DEBUG:root:					{
DEBUG:root:					//------------------------
DEBUG:root:					// size: 32
DEBUG:root:					//------------------------

DEBUG:root:			per_layer_anchor_sizes = []
DEBUG:root:
					for scale_per_octave in range(scales_per_octave=3) { // BEGIN
DEBUG:root:						{
DEBUG:root:						// ------------------------
DEBUG:root:						// scale_per_octave: 0, octave: 2.0
DEBUG:root:						// ------------------------
DEBUG:root:						octave_scale = octave ** (scale_per_octave / float(scales_per_octave))

DEBUG:root:						// octave_scale: 1.0
DEBUG:root:						// size: 32
DEBUG:root:						per_layer_anchor_sizes.append(octave_scale * size)
DEBUG:root:						// per_layer_anchor_sizes[-1]: 32.0

DEBUG:root:						}

DEBUG:root:						{
DEBUG:root:						// ------------------------
DEBUG:root:						// scale_per_octave: 1, octave: 2.0
DEBUG:root:						// ------------------------
DEBUG:root:						octave_scale = octave ** (scale_per_octave / float(scales_per_octave))

DEBUG:root:						// octave_scale: 1.2599210498948732
DEBUG:root:						// size: 32
DEBUG:root:						per_layer_anchor_sizes.append(octave_scale * size)
DEBUG:root:						// per_layer_anchor_sizes[-1]: 40.31747359663594

DEBUG:root:						}

DEBUG:root:						{
DEBUG:root:						// ------------------------
DEBUG:root:						// scale_per_octave: 2, octave: 2.0
DEBUG:root:						// ------------------------
DEBUG:root:						octave_scale = octave ** (scale_per_octave / float(scales_per_octave))

DEBUG:root:						// octave_scale: 1.5874010519681994
DEBUG:root:						// size: 32
DEBUG:root:						per_layer_anchor_sizes.append(octave_scale * size)
DEBUG:root:						// per_layer_anchor_sizes[-1]: 50.79683366298238

DEBUG:root:						}

DEBUG:root:						} // END for scale_per_octave in range(scales_per_octave)

DEBUG:root:					new_anchor_sizes.append(tuple(per_layer_anchor_sizes))
DEBUG:root:					// new_anchor_sizes[-1]: (32.0, 40.31747359663594, 50.79683366298238)
DEBUG:root:					}
DEBUG:root:					{
DEBUG:root:					//------------------------
DEBUG:root:					// size: 64
DEBUG:root:					//------------------------

DEBUG:root:			per_layer_anchor_sizes = []
DEBUG:root:
					for scale_per_octave in range(scales_per_octave=3) { // BEGIN
DEBUG:root:						{
DEBUG:root:						// ------------------------
DEBUG:root:						// scale_per_octave: 0, octave: 2.0
DEBUG:root:						// ------------------------
DEBUG:root:						octave_scale = octave ** (scale_per_octave / float(scales_per_octave))

DEBUG:root:						// octave_scale: 1.0
DEBUG:root:						// size: 64
DEBUG:root:						per_layer_anchor_sizes.append(octave_scale * size)
DEBUG:root:						// per_layer_anchor_sizes[-1]: 64.0

DEBUG:root:						}

DEBUG:root:						{
DEBUG:root:						// ------------------------
DEBUG:root:						// scale_per_octave: 1, octave: 2.0
DEBUG:root:						// ------------------------
DEBUG:root:						octave_scale = octave ** (scale_per_octave / float(scales_per_octave))

DEBUG:root:						// octave_scale: 1.2599210498948732
DEBUG:root:						// size: 64
DEBUG:root:						per_layer_anchor_sizes.append(octave_scale * size)
DEBUG:root:						// per_layer_anchor_sizes[-1]: 80.63494719327188

DEBUG:root:						}

DEBUG:root:						{
DEBUG:root:						// ------------------------
DEBUG:root:						// scale_per_octave: 2, octave: 2.0
DEBUG:root:						// ------------------------
DEBUG:root:						octave_scale = octave ** (scale_per_octave / float(scales_per_octave))

DEBUG:root:						// octave_scale: 1.5874010519681994
DEBUG:root:						// size: 64
DEBUG:root:						per_layer_anchor_sizes.append(octave_scale * size)
DEBUG:root:						// per_layer_anchor_sizes[-1]: 101.59366732596476

DEBUG:root:						}

DEBUG:root:						} // END for scale_per_octave in range(scales_per_octave)

DEBUG:root:					new_anchor_sizes.append(tuple(per_layer_anchor_sizes))
DEBUG:root:					// new_anchor_sizes[-1]: (64.0, 80.63494719327188, 101.59366732596476)
DEBUG:root:					}
DEBUG:root:					{
DEBUG:root:					//------------------------
DEBUG:root:					// size: 128
DEBUG:root:					//------------------------

DEBUG:root:			per_layer_anchor_sizes = []
DEBUG:root:
					for scale_per_octave in range(scales_per_octave=3) { // BEGIN
DEBUG:root:						{
DEBUG:root:						// ------------------------
DEBUG:root:						// scale_per_octave: 0, octave: 2.0
DEBUG:root:						// ------------------------
DEBUG:root:						octave_scale = octave ** (scale_per_octave / float(scales_per_octave))

DEBUG:root:						// octave_scale: 1.0
DEBUG:root:						// size: 128
DEBUG:root:						per_layer_anchor_sizes.append(octave_scale * size)
DEBUG:root:						// per_layer_anchor_sizes[-1]: 128.0

DEBUG:root:						}

DEBUG:root:						{
DEBUG:root:						// ------------------------
DEBUG:root:						// scale_per_octave: 1, octave: 2.0
DEBUG:root:						// ------------------------
DEBUG:root:						octave_scale = octave ** (scale_per_octave / float(scales_per_octave))

DEBUG:root:						// octave_scale: 1.2599210498948732
DEBUG:root:						// size: 128
DEBUG:root:						per_layer_anchor_sizes.append(octave_scale * size)
DEBUG:root:						// per_layer_anchor_sizes[-1]: 161.26989438654377

DEBUG:root:						}

DEBUG:root:						{
DEBUG:root:						// ------------------------
DEBUG:root:						// scale_per_octave: 2, octave: 2.0
DEBUG:root:						// ------------------------
DEBUG:root:						octave_scale = octave ** (scale_per_octave / float(scales_per_octave))

DEBUG:root:						// octave_scale: 1.5874010519681994
DEBUG:root:						// size: 128
DEBUG:root:						per_layer_anchor_sizes.append(octave_scale * size)
DEBUG:root:						// per_layer_anchor_sizes[-1]: 203.18733465192952

DEBUG:root:						}

DEBUG:root:						} // END for scale_per_octave in range(scales_per_octave)

DEBUG:root:					new_anchor_sizes.append(tuple(per_layer_anchor_sizes))
DEBUG:root:					// new_anchor_sizes[-1]: (128.0, 161.26989438654377, 203.18733465192952)
DEBUG:root:					}
DEBUG:root:					{
DEBUG:root:					//------------------------
DEBUG:root:					// size: 256
DEBUG:root:					//------------------------

DEBUG:root:			per_layer_anchor_sizes = []
DEBUG:root:
					for scale_per_octave in range(scales_per_octave=3) { // BEGIN
DEBUG:root:						{
DEBUG:root:						// ------------------------
DEBUG:root:						// scale_per_octave: 0, octave: 2.0
DEBUG:root:						// ------------------------
DEBUG:root:						octave_scale = octave ** (scale_per_octave / float(scales_per_octave))

DEBUG:root:						// octave_scale: 1.0
DEBUG:root:						// size: 256
DEBUG:root:						per_layer_anchor_sizes.append(octave_scale * size)
DEBUG:root:						// per_layer_anchor_sizes[-1]: 256.0

DEBUG:root:						}

DEBUG:root:						{
DEBUG:root:						// ------------------------
DEBUG:root:						// scale_per_octave: 1, octave: 2.0
DEBUG:root:						// ------------------------
DEBUG:root:						octave_scale = octave ** (scale_per_octave / float(scales_per_octave))

DEBUG:root:						// octave_scale: 1.2599210498948732
DEBUG:root:						// size: 256
DEBUG:root:						per_layer_anchor_sizes.append(octave_scale * size)
DEBUG:root:						// per_layer_anchor_sizes[-1]: 322.53978877308754

DEBUG:root:						}

DEBUG:root:						{
DEBUG:root:						// ------------------------
DEBUG:root:						// scale_per_octave: 2, octave: 2.0
DEBUG:root:						// ------------------------
DEBUG:root:						octave_scale = octave ** (scale_per_octave / float(scales_per_octave))

DEBUG:root:						// octave_scale: 1.5874010519681994
DEBUG:root:						// size: 256
DEBUG:root:						per_layer_anchor_sizes.append(octave_scale * size)
DEBUG:root:						// per_layer_anchor_sizes[-1]: 406.37466930385904

DEBUG:root:						}

DEBUG:root:						} // END for scale_per_octave in range(scales_per_octave)

DEBUG:root:					new_anchor_sizes.append(tuple(per_layer_anchor_sizes))
DEBUG:root:					// new_anchor_sizes[-1]: (256.0, 322.53978877308754, 406.37466930385904)
DEBUG:root:					}
DEBUG:root:					{
DEBUG:root:					//------------------------
DEBUG:root:					// size: 512
DEBUG:root:					//------------------------

DEBUG:root:			per_layer_anchor_sizes = []
DEBUG:root:
					for scale_per_octave in range(scales_per_octave=3) { // BEGIN
DEBUG:root:						{
DEBUG:root:						// ------------------------
DEBUG:root:						// scale_per_octave: 0, octave: 2.0
DEBUG:root:						// ------------------------
DEBUG:root:						octave_scale = octave ** (scale_per_octave / float(scales_per_octave))

DEBUG:root:						// octave_scale: 1.0
DEBUG:root:						// size: 512
DEBUG:root:						per_layer_anchor_sizes.append(octave_scale * size)
DEBUG:root:						// per_layer_anchor_sizes[-1]: 512.0

DEBUG:root:						}

DEBUG:root:						{
DEBUG:root:						// ------------------------
DEBUG:root:						// scale_per_octave: 1, octave: 2.0
DEBUG:root:						// ------------------------
DEBUG:root:						octave_scale = octave ** (scale_per_octave / float(scales_per_octave))

DEBUG:root:						// octave_scale: 1.2599210498948732
DEBUG:root:						// size: 512
DEBUG:root:						per_layer_anchor_sizes.append(octave_scale * size)
DEBUG:root:						// per_layer_anchor_sizes[-1]: 645.0795775461751

DEBUG:root:						}

DEBUG:root:						{
DEBUG:root:						// ------------------------
DEBUG:root:						// scale_per_octave: 2, octave: 2.0
DEBUG:root:						// ------------------------
DEBUG:root:						octave_scale = octave ** (scale_per_octave / float(scales_per_octave))

DEBUG:root:						// octave_scale: 1.5874010519681994
DEBUG:root:						// size: 512
DEBUG:root:						per_layer_anchor_sizes.append(octave_scale * size)
DEBUG:root:						// per_layer_anchor_sizes[-1]: 812.7493386077181

DEBUG:root:						}

DEBUG:root:						} // END for scale_per_octave in range(scales_per_octave)

DEBUG:root:					new_anchor_sizes.append(tuple(per_layer_anchor_sizes))
DEBUG:root:					// new_anchor_sizes[-1]: (512.0, 645.0795775461751, 812.7493386077181)
DEBUG:root:					}
DEBUG:root:
				} // END for size in anchor_sizes

DEBUG:root:				new_anchor_sizes:[(32.0, 40.31747359663594, 50.79683366298238), (64.0, 80.63494719327188, 101.59366732596476), (128.0, 161.26989438654377, 203.18733465192952), (256.0, 322.53978877308754, 406.37466930385904), (512.0, 645.0795775461751, 812.7493386077181)]
DEBUG:root:				aspect_ratios:(0.5, 1.0, 2.0)
DEBUG:root:				anchor_strides:(8, 16, 32, 64, 128)
DEBUG:root:				straddle_thresh:-1
DEBUG:root:				anchor_generator = AnchorGenerator( tuple(new_anchor_sizes), aspect_ratios, anchor_strides, straddle_thresh ) { //CALL
DEBUG:root:		AnchorGenerator.__init__(sizes, aspect_ratios, anchor_strides, straddle_thresh) { //BEGIN
DEBUG:root:			// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py

DEBUG:root:			// Params
DEBUG:root:				// sizes: ((32.0, 40.31747359663594, 50.79683366298238), (64.0, 80.63494719327188, 101.59366732596476), (128.0, 161.26989438654377, 203.18733465192952), (256.0, 322.53978877308754, 406.37466930385904), (512.0, 645.0795775461751, 812.7493386077181))
DEBUG:root:				// aspect_ratios: (0.5, 1.0, 2.0)
DEBUG:root:				// anchor_strides: (8, 16, 32, 64, 128)
DEBUG:root:				// straddle_thresh: -1

DEBUG:root:		if len(anchor_strides) == 1: 
DEBUG:root:		else: i.e, len(anchor_strides) !=1
DEBUG:root:			anchor_stride = anchor_strides[0]
DEBUG:root:			len(anchor_strides):5, len(size): 5
DEBUG:root:		else: i.e, len(anchor_strides) == len(sizes)
DEBUG:root:		cell_anchors = [ generate_anchors( anchor_stride,
DEBUG:root:		                 size if isinstance(size, (tuple, list)) else (size,), 
DEBUG:root:		                 aspect_ratios).float()
DEBUG:root:		for anchor_stride, size in zip(anchor_strides, sizes)
DEBUG:root:				generate_anchors(stride, sizes, aspect_ratios) { //BEGIN
DEBUG:root:			//defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:					// Params:
DEBUG:root:						// stride: 8
DEBUG:root:						// sizes: (32.0, 40.31747359663594, 50.79683366298238)
DEBUG:root:						// aspect_ratios: (0.5, 1.0, 2.0)

DEBUG:root:					return _generate_anchors(stride,
DEBUG:root:						     np.array(sizes, dtype=np.float) / stride,
DEBUG:root:						     np.array(aspect_ratios, dtype=np.float),)
DEBUG:root:						_generate_anchors(base_size, scales, aspect_ratios) { //BEGIN
DEBUG:root:						// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py

DEBUG:root:							// Params:
DEBUG:root:								// base_size: 8
DEBUG:root:								// scales: [4.         5.0396842  6.34960421]
DEBUG:root:								// aspect_ratios: [0.5 1.  2. ]

DEBUG:root:						anchor = np.array([1, 1, base_size, base_size], dtype=np.float) - 1
DEBUG:root:						// anchor: [0. 0. 7. 7.]
DEBUG:root:				_ratio_enum(anchor, ratios) { //BEGIN
DEBUG:root:				// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py

DEBUG:root:					// Params:
DEBUG:root:						// anchor: [0. 0. 7. 7.]
DEBUG:root:						// ratios: [0.5 1.  2. ]

DEBUG:root:				_whctrs(anchors) { //BEGIN
DEBUG:root:				// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:					// Param:
DEBUG:root:						// anchor: [0. 0. 7. 7.]

DEBUG:root:						w = anchor[2] - anchor[0] + 1
DEBUG:root:						w: 8.0
DEBUG:root:						h = anchor[3] - anchor[1] + 1
DEBUG:root:						h: 8.0
DEBUG:root:						x_ctr = anchor[0] + 0.5 * (w - 1)
DEBUG:root:						x_ctr: 3.5
DEBUG:root:						y_ctr = anchor[1] + 0.5 * (h - 1)
DEBUG:root:						y_ctr: 3.5
DEBUG:root:						return w, h, x_ctr, y_ctr
DEBUG:root:					} // END _whctrs(anchors)
DEBUG:root:					w, h, x_ctr, y_ctr = _whctrs(anchor)
DEBUG:root:					// w: 8.0, h: 8.0, x_ctr: 3.5, y_ctr: 3.5
DEBUG:root:					size = w * h
DEBUG:root:					// size: 64.0
DEBUG:root:					size_ratios = size / ratios
DEBUG:root:					// size_ratios: [128.  64.  32.]
DEBUG:root:					ws = np.round(np.sqrt(size_ratios))
DEBUG:root:					// ws: [11.  8.  6.]
DEBUG:root:					hs = np.round(ws * ratios)
DEBUG:root:					// hs: [ 6.  8. 12.]
DEBUG:root:			_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN
DEBUG:root:			// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:				// Param:
DEBUG:root:					// ws: [11.  8.  6.]
DEBUG:root:					// hs: [ 6.  8. 12.]
DEBUG:root:					// x_ctr: 3.5
DEBUG:root:					// y_ctr: 3.5

DEBUG:root:				ws = ws[:, np.newaxis]
DEBUG:root:					// ws: [[11.]
 [ 8.]
 [ 6.]]
DEBUG:root:				hs = hs[:, np.newaxis]
DEBUG:root:					// hs: [[ 6.]
 [ 8.]
 [12.]]
DEBUG:root:				anchors = np.hstack(
DEBUG:root:				    (
DEBUG:root:				        x_ctr - 0.5 * (ws - 1),
DEBUG:root:				        y_ctr - 0.5 * (hs - 1),
DEBUG:root:				        x_ctr + 0.5 * (ws - 1),
DEBUG:root:				        y_ctr + 0.5 * (hs - 1),
DEBUG:root:				    )
DEBUG:root:				)
DEBUG:root:				// anchors: [[-1.5  1.   8.5  6. ]
 [ 0.   0.   7.   7. ]
 [ 1.  -2.   6.   9. ]]

DEBUG:root:				return anchors
DEBUG:root:			} // END _mkanchors(ws, hs, x_ctr, y_ctr)
DEBUG:root:					anchors = _mkanchors(ws, hs, x_ctr, y_ctr)
DEBUG:root:					// anchors: [[-1.5  1.   8.5  6. ]
 [ 0.   0.   7.   7. ]
 [ 1.  -2.   6.   9. ]]

DEBUG:root:					return anchors
DEBUG:root:				} // END _ratio_enum(anchor, ratios)
DEBUG:root:						anchors = _ratio_enum(anchor, aspect_ratios)
DEBUG:root:						// anchors: [[-1.5  1.   8.5  6. ]
 [ 0.   0.   7.   7. ]
 [ 1.  -2.   6.   9. ]]
DEBUG:root:						anchors = np.vstack(
DEBUG:root:						[_scale_enum(anchors[i, :], scales) for i in range(anchors.shape[0])]
DEBUG:root:						)
DEBUG:root:					_scale_enum(anchor, scales) { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py

DEBUG:root:					// Param:
DEBUG:root:						// anchor: [-1.5  1.   8.5  6. ]
DEBUG:root:						// scales: [4.         5.0396842  6.34960421]

DEBUG:root:				_whctrs(anchors) { //BEGIN
DEBUG:root:				// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:					// Param:
DEBUG:root:						// anchor: [-1.5  1.   8.5  6. ]

DEBUG:root:						w = anchor[2] - anchor[0] + 1
DEBUG:root:						w: 11.0
DEBUG:root:						h = anchor[3] - anchor[1] + 1
DEBUG:root:						h: 6.0
DEBUG:root:						x_ctr = anchor[0] + 0.5 * (w - 1)
DEBUG:root:						x_ctr: 3.5
DEBUG:root:						y_ctr = anchor[1] + 0.5 * (h - 1)
DEBUG:root:						y_ctr: 3.5
DEBUG:root:						return w, h, x_ctr, y_ctr
DEBUG:root:					} // END _whctrs(anchors)
DEBUG:root:					w, h, x_ctr, y_ctr = _whctrs(anchor)
DEBUG:root:					// w: 11.0, h: 6.0, x_ctr: 3.5, y_ctr: 3.5

DEBUG:root:					ws = w * scales
DEBUG:root:					// ws: [44.         55.4365262  69.84564629]

DEBUG:root:					hs = h * scales
DEBUG:root:					// hs: [24.         30.2381052  38.09762525]

DEBUG:root:					anchors = _mkanchors(ws, hs, x_ctr, y_ctr) { // CALL
DEBUG:root:			_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN
DEBUG:root:			// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:				// Param:
DEBUG:root:					// ws: [44.         55.4365262  69.84564629]
DEBUG:root:					// hs: [24.         30.2381052  38.09762525]
DEBUG:root:					// x_ctr: 3.5
DEBUG:root:					// y_ctr: 3.5

DEBUG:root:				ws = ws[:, np.newaxis]
DEBUG:root:					// ws: [[44.        ]
 [55.4365262 ]
 [69.84564629]]
DEBUG:root:				hs = hs[:, np.newaxis]
DEBUG:root:					// hs: [[24.        ]
 [30.2381052 ]
 [38.09762525]]
DEBUG:root:				anchors = np.hstack(
DEBUG:root:				    (
DEBUG:root:				        x_ctr - 0.5 * (ws - 1),
DEBUG:root:				        y_ctr - 0.5 * (hs - 1),
DEBUG:root:				        x_ctr + 0.5 * (ws - 1),
DEBUG:root:				        y_ctr + 0.5 * (hs - 1),
DEBUG:root:				    )
DEBUG:root:				)
DEBUG:root:				// anchors: [[-18.          -8.          25.          15.        ]
 [-23.7182631  -11.1190526   30.7182631   18.1190526 ]
 [-30.92282314 -15.04881262  37.92282314  22.04881262]]

DEBUG:root:				return anchors
DEBUG:root:			} // END _mkanchors(ws, hs, x_ctr, y_ctr)
DEBUG:root:

DEBUG:root:					}anchors = _mkanchors(ws, hs, x_ctr, y_ctr) // RETURNED
DEBUG:root:					// anchors: [[-18.          -8.          25.          15.        ]
 [-23.7182631  -11.1190526   30.7182631   18.1190526 ]
 [-30.92282314 -15.04881262  37.92282314  22.04881262]]

DEBUG:root:					return anchors: [[-18.          -8.          25.          15.        ]
 [-23.7182631  -11.1190526   30.7182631   18.1190526 ]
 [-30.92282314 -15.04881262  37.92282314  22.04881262]]
DEBUG:root:				} // END _scale_enum(anchor, scales)
DEBUG:root:					_scale_enum(anchor, scales) { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py

DEBUG:root:					// Param:
DEBUG:root:						// anchor: [0. 0. 7. 7.]
DEBUG:root:						// scales: [4.         5.0396842  6.34960421]

DEBUG:root:				_whctrs(anchors) { //BEGIN
DEBUG:root:				// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:					// Param:
DEBUG:root:						// anchor: [0. 0. 7. 7.]

DEBUG:root:						w = anchor[2] - anchor[0] + 1
DEBUG:root:						w: 8.0
DEBUG:root:						h = anchor[3] - anchor[1] + 1
DEBUG:root:						h: 8.0
DEBUG:root:						x_ctr = anchor[0] + 0.5 * (w - 1)
DEBUG:root:						x_ctr: 3.5
DEBUG:root:						y_ctr = anchor[1] + 0.5 * (h - 1)
DEBUG:root:						y_ctr: 3.5
DEBUG:root:						return w, h, x_ctr, y_ctr
DEBUG:root:					} // END _whctrs(anchors)
DEBUG:root:					w, h, x_ctr, y_ctr = _whctrs(anchor)
DEBUG:root:					// w: 8.0, h: 8.0, x_ctr: 3.5, y_ctr: 3.5

DEBUG:root:					ws = w * scales
DEBUG:root:					// ws: [32.         40.3174736  50.79683366]

DEBUG:root:					hs = h * scales
DEBUG:root:					// hs: [32.         40.3174736  50.79683366]

DEBUG:root:					anchors = _mkanchors(ws, hs, x_ctr, y_ctr) { // CALL
DEBUG:root:			_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN
DEBUG:root:			// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:				// Param:
DEBUG:root:					// ws: [32.         40.3174736  50.79683366]
DEBUG:root:					// hs: [32.         40.3174736  50.79683366]
DEBUG:root:					// x_ctr: 3.5
DEBUG:root:					// y_ctr: 3.5

DEBUG:root:				ws = ws[:, np.newaxis]
DEBUG:root:					// ws: [[32.        ]
 [40.3174736 ]
 [50.79683366]]
DEBUG:root:				hs = hs[:, np.newaxis]
DEBUG:root:					// hs: [[32.        ]
 [40.3174736 ]
 [50.79683366]]
DEBUG:root:				anchors = np.hstack(
DEBUG:root:				    (
DEBUG:root:				        x_ctr - 0.5 * (ws - 1),
DEBUG:root:				        y_ctr - 0.5 * (hs - 1),
DEBUG:root:				        x_ctr + 0.5 * (ws - 1),
DEBUG:root:				        y_ctr + 0.5 * (hs - 1),
DEBUG:root:				    )
DEBUG:root:				)
DEBUG:root:				// anchors: [[-12.         -12.          19.          19.        ]
 [-16.1587368  -16.1587368   23.1587368   23.1587368 ]
 [-21.39841683 -21.39841683  28.39841683  28.39841683]]

DEBUG:root:				return anchors
DEBUG:root:			} // END _mkanchors(ws, hs, x_ctr, y_ctr)
DEBUG:root:

DEBUG:root:					}anchors = _mkanchors(ws, hs, x_ctr, y_ctr) // RETURNED
DEBUG:root:					// anchors: [[-12.         -12.          19.          19.        ]
 [-16.1587368  -16.1587368   23.1587368   23.1587368 ]
 [-21.39841683 -21.39841683  28.39841683  28.39841683]]

DEBUG:root:					return anchors: [[-12.         -12.          19.          19.        ]
 [-16.1587368  -16.1587368   23.1587368   23.1587368 ]
 [-21.39841683 -21.39841683  28.39841683  28.39841683]]
DEBUG:root:				} // END _scale_enum(anchor, scales)
DEBUG:root:					_scale_enum(anchor, scales) { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py

DEBUG:root:					// Param:
DEBUG:root:						// anchor: [ 1. -2.  6.  9.]
DEBUG:root:						// scales: [4.         5.0396842  6.34960421]

DEBUG:root:				_whctrs(anchors) { //BEGIN
DEBUG:root:				// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:					// Param:
DEBUG:root:						// anchor: [ 1. -2.  6.  9.]

DEBUG:root:						w = anchor[2] - anchor[0] + 1
DEBUG:root:						w: 6.0
DEBUG:root:						h = anchor[3] - anchor[1] + 1
DEBUG:root:						h: 12.0
DEBUG:root:						x_ctr = anchor[0] + 0.5 * (w - 1)
DEBUG:root:						x_ctr: 3.5
DEBUG:root:						y_ctr = anchor[1] + 0.5 * (h - 1)
DEBUG:root:						y_ctr: 3.5
DEBUG:root:						return w, h, x_ctr, y_ctr
DEBUG:root:					} // END _whctrs(anchors)
DEBUG:root:					w, h, x_ctr, y_ctr = _whctrs(anchor)
DEBUG:root:					// w: 6.0, h: 12.0, x_ctr: 3.5, y_ctr: 3.5

DEBUG:root:					ws = w * scales
DEBUG:root:					// ws: [24.         30.2381052  38.09762525]

DEBUG:root:					hs = h * scales
DEBUG:root:					// hs: [48.         60.47621039 76.19525049]

DEBUG:root:					anchors = _mkanchors(ws, hs, x_ctr, y_ctr) { // CALL
DEBUG:root:			_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN
DEBUG:root:			// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:				// Param:
DEBUG:root:					// ws: [24.         30.2381052  38.09762525]
DEBUG:root:					// hs: [48.         60.47621039 76.19525049]
DEBUG:root:					// x_ctr: 3.5
DEBUG:root:					// y_ctr: 3.5

DEBUG:root:				ws = ws[:, np.newaxis]
DEBUG:root:					// ws: [[24.        ]
 [30.2381052 ]
 [38.09762525]]
DEBUG:root:				hs = hs[:, np.newaxis]
DEBUG:root:					// hs: [[48.        ]
 [60.47621039]
 [76.19525049]]
DEBUG:root:				anchors = np.hstack(
DEBUG:root:				    (
DEBUG:root:				        x_ctr - 0.5 * (ws - 1),
DEBUG:root:				        y_ctr - 0.5 * (hs - 1),
DEBUG:root:				        x_ctr + 0.5 * (ws - 1),
DEBUG:root:				        y_ctr + 0.5 * (hs - 1),
DEBUG:root:				    )
DEBUG:root:				)
DEBUG:root:				// anchors: [[ -8.         -20.          15.          27.        ]
 [-11.1190526  -26.2381052   18.1190526   33.2381052 ]
 [-15.04881262 -34.09762525  22.04881262  41.09762525]]

DEBUG:root:				return anchors
DEBUG:root:			} // END _mkanchors(ws, hs, x_ctr, y_ctr)
DEBUG:root:

DEBUG:root:					}anchors = _mkanchors(ws, hs, x_ctr, y_ctr) // RETURNED
DEBUG:root:					// anchors: [[ -8.         -20.          15.          27.        ]
 [-11.1190526  -26.2381052   18.1190526   33.2381052 ]
 [-15.04881262 -34.09762525  22.04881262  41.09762525]]

DEBUG:root:					return anchors: [[ -8.         -20.          15.          27.        ]
 [-11.1190526  -26.2381052   18.1190526   33.2381052 ]
 [-15.04881262 -34.09762525  22.04881262  41.09762525]]
DEBUG:root:				} // END _scale_enum(anchor, scales)
DEBUG:root:						// anchors: [[-18.          -8.          25.          15.        ]
 [-23.7182631  -11.1190526   30.7182631   18.1190526 ]
 [-30.92282314 -15.04881262  37.92282314  22.04881262]
 [-12.         -12.          19.          19.        ]
 [-16.1587368  -16.1587368   23.1587368   23.1587368 ]
 [-21.39841683 -21.39841683  28.39841683  28.39841683]
 [ -8.         -20.          15.          27.        ]
 [-11.1190526  -26.2381052   18.1190526   33.2381052 ]
 [-15.04881262 -34.09762525  22.04881262  41.09762525]]
DEBUG:root:							return torch.from_numpy(anchors)
DEBUG:root:						} // END _generate_anchors(base_size, scales, apect_ratios) END
DEBUG:root:					} // END generate_anchors(stride, sizes, aspect_ratios)
DEBUG:root:				generate_anchors(stride, sizes, aspect_ratios) { //BEGIN
DEBUG:root:			//defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:					// Params:
DEBUG:root:						// stride: 16
DEBUG:root:						// sizes: (64.0, 80.63494719327188, 101.59366732596476)
DEBUG:root:						// aspect_ratios: (0.5, 1.0, 2.0)

DEBUG:root:					return _generate_anchors(stride,
DEBUG:root:						     np.array(sizes, dtype=np.float) / stride,
DEBUG:root:						     np.array(aspect_ratios, dtype=np.float),)
DEBUG:root:						_generate_anchors(base_size, scales, aspect_ratios) { //BEGIN
DEBUG:root:						// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py

DEBUG:root:							// Params:
DEBUG:root:								// base_size: 16
DEBUG:root:								// scales: [4.         5.0396842  6.34960421]
DEBUG:root:								// aspect_ratios: [0.5 1.  2. ]

DEBUG:root:						anchor = np.array([1, 1, base_size, base_size], dtype=np.float) - 1
DEBUG:root:						// anchor: [ 0.  0. 15. 15.]
DEBUG:root:				_ratio_enum(anchor, ratios) { //BEGIN
DEBUG:root:				// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py

DEBUG:root:					// Params:
DEBUG:root:						// anchor: [ 0.  0. 15. 15.]
DEBUG:root:						// ratios: [0.5 1.  2. ]

DEBUG:root:				_whctrs(anchors) { //BEGIN
DEBUG:root:				// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:					// Param:
DEBUG:root:						// anchor: [ 0.  0. 15. 15.]

DEBUG:root:						w = anchor[2] - anchor[0] + 1
DEBUG:root:						w: 16.0
DEBUG:root:						h = anchor[3] - anchor[1] + 1
DEBUG:root:						h: 16.0
DEBUG:root:						x_ctr = anchor[0] + 0.5 * (w - 1)
DEBUG:root:						x_ctr: 7.5
DEBUG:root:						y_ctr = anchor[1] + 0.5 * (h - 1)
DEBUG:root:						y_ctr: 7.5
DEBUG:root:						return w, h, x_ctr, y_ctr
DEBUG:root:					} // END _whctrs(anchors)
DEBUG:root:					w, h, x_ctr, y_ctr = _whctrs(anchor)
DEBUG:root:					// w: 16.0, h: 16.0, x_ctr: 7.5, y_ctr: 7.5
DEBUG:root:					size = w * h
DEBUG:root:					// size: 256.0
DEBUG:root:					size_ratios = size / ratios
DEBUG:root:					// size_ratios: [512. 256. 128.]
DEBUG:root:					ws = np.round(np.sqrt(size_ratios))
DEBUG:root:					// ws: [23. 16. 11.]
DEBUG:root:					hs = np.round(ws * ratios)
DEBUG:root:					// hs: [12. 16. 22.]
DEBUG:root:			_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN
DEBUG:root:			// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:				// Param:
DEBUG:root:					// ws: [23. 16. 11.]
DEBUG:root:					// hs: [12. 16. 22.]
DEBUG:root:					// x_ctr: 7.5
DEBUG:root:					// y_ctr: 7.5

DEBUG:root:				ws = ws[:, np.newaxis]
DEBUG:root:					// ws: [[23.]
 [16.]
 [11.]]
DEBUG:root:				hs = hs[:, np.newaxis]
DEBUG:root:					// hs: [[12.]
 [16.]
 [22.]]
DEBUG:root:				anchors = np.hstack(
DEBUG:root:				    (
DEBUG:root:				        x_ctr - 0.5 * (ws - 1),
DEBUG:root:				        y_ctr - 0.5 * (hs - 1),
DEBUG:root:				        x_ctr + 0.5 * (ws - 1),
DEBUG:root:				        y_ctr + 0.5 * (hs - 1),
DEBUG:root:				    )
DEBUG:root:				)
DEBUG:root:				// anchors: [[-3.5  2.  18.5 13. ]
 [ 0.   0.  15.  15. ]
 [ 2.5 -3.  12.5 18. ]]

DEBUG:root:				return anchors
DEBUG:root:			} // END _mkanchors(ws, hs, x_ctr, y_ctr)
DEBUG:root:					anchors = _mkanchors(ws, hs, x_ctr, y_ctr)
DEBUG:root:					// anchors: [[-3.5  2.  18.5 13. ]
 [ 0.   0.  15.  15. ]
 [ 2.5 -3.  12.5 18. ]]

DEBUG:root:					return anchors
DEBUG:root:				} // END _ratio_enum(anchor, ratios)
DEBUG:root:						anchors = _ratio_enum(anchor, aspect_ratios)
DEBUG:root:						// anchors: [[-3.5  2.  18.5 13. ]
 [ 0.   0.  15.  15. ]
 [ 2.5 -3.  12.5 18. ]]
DEBUG:root:						anchors = np.vstack(
DEBUG:root:						[_scale_enum(anchors[i, :], scales) for i in range(anchors.shape[0])]
DEBUG:root:						)
DEBUG:root:					_scale_enum(anchor, scales) { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py

DEBUG:root:					// Param:
DEBUG:root:						// anchor: [-3.5  2.  18.5 13. ]
DEBUG:root:						// scales: [4.         5.0396842  6.34960421]

DEBUG:root:				_whctrs(anchors) { //BEGIN
DEBUG:root:				// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:					// Param:
DEBUG:root:						// anchor: [-3.5  2.  18.5 13. ]

DEBUG:root:						w = anchor[2] - anchor[0] + 1
DEBUG:root:						w: 23.0
DEBUG:root:						h = anchor[3] - anchor[1] + 1
DEBUG:root:						h: 12.0
DEBUG:root:						x_ctr = anchor[0] + 0.5 * (w - 1)
DEBUG:root:						x_ctr: 7.5
DEBUG:root:						y_ctr = anchor[1] + 0.5 * (h - 1)
DEBUG:root:						y_ctr: 7.5
DEBUG:root:						return w, h, x_ctr, y_ctr
DEBUG:root:					} // END _whctrs(anchors)
DEBUG:root:					w, h, x_ctr, y_ctr = _whctrs(anchor)
DEBUG:root:					// w: 23.0, h: 12.0, x_ctr: 7.5, y_ctr: 7.5

DEBUG:root:					ws = w * scales
DEBUG:root:					// ws: [ 92.         115.91273659 146.04089678]

DEBUG:root:					hs = h * scales
DEBUG:root:					// hs: [48.         60.47621039 76.19525049]

DEBUG:root:					anchors = _mkanchors(ws, hs, x_ctr, y_ctr) { // CALL
DEBUG:root:			_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN
DEBUG:root:			// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:				// Param:
DEBUG:root:					// ws: [ 92.         115.91273659 146.04089678]
DEBUG:root:					// hs: [48.         60.47621039 76.19525049]
DEBUG:root:					// x_ctr: 7.5
DEBUG:root:					// y_ctr: 7.5

DEBUG:root:				ws = ws[:, np.newaxis]
DEBUG:root:					// ws: [[ 92.        ]
 [115.91273659]
 [146.04089678]]
DEBUG:root:				hs = hs[:, np.newaxis]
DEBUG:root:					// hs: [[48.        ]
 [60.47621039]
 [76.19525049]]
DEBUG:root:				anchors = np.hstack(
DEBUG:root:				    (
DEBUG:root:				        x_ctr - 0.5 * (ws - 1),
DEBUG:root:				        y_ctr - 0.5 * (hs - 1),
DEBUG:root:				        x_ctr + 0.5 * (ws - 1),
DEBUG:root:				        y_ctr + 0.5 * (hs - 1),
DEBUG:root:				    )
DEBUG:root:				)
DEBUG:root:				// anchors: [[-38.         -16.          53.          31.        ]
 [-49.9563683  -22.2381052   64.9563683   37.2381052 ]
 [-65.02044839 -30.09762525  80.02044839  45.09762525]]

DEBUG:root:				return anchors
DEBUG:root:			} // END _mkanchors(ws, hs, x_ctr, y_ctr)
DEBUG:root:

DEBUG:root:					}anchors = _mkanchors(ws, hs, x_ctr, y_ctr) // RETURNED
DEBUG:root:					// anchors: [[-38.         -16.          53.          31.        ]
 [-49.9563683  -22.2381052   64.9563683   37.2381052 ]
 [-65.02044839 -30.09762525  80.02044839  45.09762525]]

DEBUG:root:					return anchors: [[-38.         -16.          53.          31.        ]
 [-49.9563683  -22.2381052   64.9563683   37.2381052 ]
 [-65.02044839 -30.09762525  80.02044839  45.09762525]]
DEBUG:root:				} // END _scale_enum(anchor, scales)
DEBUG:root:					_scale_enum(anchor, scales) { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py

DEBUG:root:					// Param:
DEBUG:root:						// anchor: [ 0.  0. 15. 15.]
DEBUG:root:						// scales: [4.         5.0396842  6.34960421]

DEBUG:root:				_whctrs(anchors) { //BEGIN
DEBUG:root:				// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:					// Param:
DEBUG:root:						// anchor: [ 0.  0. 15. 15.]

DEBUG:root:						w = anchor[2] - anchor[0] + 1
DEBUG:root:						w: 16.0
DEBUG:root:						h = anchor[3] - anchor[1] + 1
DEBUG:root:						h: 16.0
DEBUG:root:						x_ctr = anchor[0] + 0.5 * (w - 1)
DEBUG:root:						x_ctr: 7.5
DEBUG:root:						y_ctr = anchor[1] + 0.5 * (h - 1)
DEBUG:root:						y_ctr: 7.5
DEBUG:root:						return w, h, x_ctr, y_ctr
DEBUG:root:					} // END _whctrs(anchors)
DEBUG:root:					w, h, x_ctr, y_ctr = _whctrs(anchor)
DEBUG:root:					// w: 16.0, h: 16.0, x_ctr: 7.5, y_ctr: 7.5

DEBUG:root:					ws = w * scales
DEBUG:root:					// ws: [ 64.          80.63494719 101.59366733]

DEBUG:root:					hs = h * scales
DEBUG:root:					// hs: [ 64.          80.63494719 101.59366733]

DEBUG:root:					anchors = _mkanchors(ws, hs, x_ctr, y_ctr) { // CALL
DEBUG:root:			_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN
DEBUG:root:			// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:				// Param:
DEBUG:root:					// ws: [ 64.          80.63494719 101.59366733]
DEBUG:root:					// hs: [ 64.          80.63494719 101.59366733]
DEBUG:root:					// x_ctr: 7.5
DEBUG:root:					// y_ctr: 7.5

DEBUG:root:				ws = ws[:, np.newaxis]
DEBUG:root:					// ws: [[ 64.        ]
 [ 80.63494719]
 [101.59366733]]
DEBUG:root:				hs = hs[:, np.newaxis]
DEBUG:root:					// hs: [[ 64.        ]
 [ 80.63494719]
 [101.59366733]]
DEBUG:root:				anchors = np.hstack(
DEBUG:root:				    (
DEBUG:root:				        x_ctr - 0.5 * (ws - 1),
DEBUG:root:				        y_ctr - 0.5 * (hs - 1),
DEBUG:root:				        x_ctr + 0.5 * (ws - 1),
DEBUG:root:				        y_ctr + 0.5 * (hs - 1),
DEBUG:root:				    )
DEBUG:root:				)
DEBUG:root:				// anchors: [[-24.         -24.          39.          39.        ]
 [-32.3174736  -32.3174736   47.3174736   47.3174736 ]
 [-42.79683366 -42.79683366  57.79683366  57.79683366]]

DEBUG:root:				return anchors
DEBUG:root:			} // END _mkanchors(ws, hs, x_ctr, y_ctr)
DEBUG:root:

DEBUG:root:					}anchors = _mkanchors(ws, hs, x_ctr, y_ctr) // RETURNED
DEBUG:root:					// anchors: [[-24.         -24.          39.          39.        ]
 [-32.3174736  -32.3174736   47.3174736   47.3174736 ]
 [-42.79683366 -42.79683366  57.79683366  57.79683366]]

DEBUG:root:					return anchors: [[-24.         -24.          39.          39.        ]
 [-32.3174736  -32.3174736   47.3174736   47.3174736 ]
 [-42.79683366 -42.79683366  57.79683366  57.79683366]]
DEBUG:root:				} // END _scale_enum(anchor, scales)
DEBUG:root:					_scale_enum(anchor, scales) { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py

DEBUG:root:					// Param:
DEBUG:root:						// anchor: [ 2.5 -3.  12.5 18. ]
DEBUG:root:						// scales: [4.         5.0396842  6.34960421]

DEBUG:root:				_whctrs(anchors) { //BEGIN
DEBUG:root:				// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:					// Param:
DEBUG:root:						// anchor: [ 2.5 -3.  12.5 18. ]

DEBUG:root:						w = anchor[2] - anchor[0] + 1
DEBUG:root:						w: 11.0
DEBUG:root:						h = anchor[3] - anchor[1] + 1
DEBUG:root:						h: 22.0
DEBUG:root:						x_ctr = anchor[0] + 0.5 * (w - 1)
DEBUG:root:						x_ctr: 7.5
DEBUG:root:						y_ctr = anchor[1] + 0.5 * (h - 1)
DEBUG:root:						y_ctr: 7.5
DEBUG:root:						return w, h, x_ctr, y_ctr
DEBUG:root:					} // END _whctrs(anchors)
DEBUG:root:					w, h, x_ctr, y_ctr = _whctrs(anchor)
DEBUG:root:					// w: 11.0, h: 22.0, x_ctr: 7.5, y_ctr: 7.5

DEBUG:root:					ws = w * scales
DEBUG:root:					// ws: [44.         55.4365262  69.84564629]

DEBUG:root:					hs = h * scales
DEBUG:root:					// hs: [ 88.         110.87305239 139.69129257]

DEBUG:root:					anchors = _mkanchors(ws, hs, x_ctr, y_ctr) { // CALL
DEBUG:root:			_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN
DEBUG:root:			// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:				// Param:
DEBUG:root:					// ws: [44.         55.4365262  69.84564629]
DEBUG:root:					// hs: [ 88.         110.87305239 139.69129257]
DEBUG:root:					// x_ctr: 7.5
DEBUG:root:					// y_ctr: 7.5

DEBUG:root:				ws = ws[:, np.newaxis]
DEBUG:root:					// ws: [[44.        ]
 [55.4365262 ]
 [69.84564629]]
DEBUG:root:				hs = hs[:, np.newaxis]
DEBUG:root:					// hs: [[ 88.        ]
 [110.87305239]
 [139.69129257]]
DEBUG:root:				anchors = np.hstack(
DEBUG:root:				    (
DEBUG:root:				        x_ctr - 0.5 * (ws - 1),
DEBUG:root:				        y_ctr - 0.5 * (hs - 1),
DEBUG:root:				        x_ctr + 0.5 * (ws - 1),
DEBUG:root:				        y_ctr + 0.5 * (hs - 1),
DEBUG:root:				    )
DEBUG:root:				)
DEBUG:root:				// anchors: [[-14.         -36.          29.          51.        ]
 [-19.7182631  -47.4365262   34.7182631   62.4365262 ]
 [-26.92282314 -61.84564629  41.92282314  76.84564629]]

DEBUG:root:				return anchors
DEBUG:root:			} // END _mkanchors(ws, hs, x_ctr, y_ctr)
DEBUG:root:

DEBUG:root:					}anchors = _mkanchors(ws, hs, x_ctr, y_ctr) // RETURNED
DEBUG:root:					// anchors: [[-14.         -36.          29.          51.        ]
 [-19.7182631  -47.4365262   34.7182631   62.4365262 ]
 [-26.92282314 -61.84564629  41.92282314  76.84564629]]

DEBUG:root:					return anchors: [[-14.         -36.          29.          51.        ]
 [-19.7182631  -47.4365262   34.7182631   62.4365262 ]
 [-26.92282314 -61.84564629  41.92282314  76.84564629]]
DEBUG:root:				} // END _scale_enum(anchor, scales)
DEBUG:root:						// anchors: [[-38.         -16.          53.          31.        ]
 [-49.9563683  -22.2381052   64.9563683   37.2381052 ]
 [-65.02044839 -30.09762525  80.02044839  45.09762525]
 [-24.         -24.          39.          39.        ]
 [-32.3174736  -32.3174736   47.3174736   47.3174736 ]
 [-42.79683366 -42.79683366  57.79683366  57.79683366]
 [-14.         -36.          29.          51.        ]
 [-19.7182631  -47.4365262   34.7182631   62.4365262 ]
 [-26.92282314 -61.84564629  41.92282314  76.84564629]]
DEBUG:root:							return torch.from_numpy(anchors)
DEBUG:root:						} // END _generate_anchors(base_size, scales, apect_ratios) END
DEBUG:root:					} // END generate_anchors(stride, sizes, aspect_ratios)
DEBUG:root:				generate_anchors(stride, sizes, aspect_ratios) { //BEGIN
DEBUG:root:			//defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:					// Params:
DEBUG:root:						// stride: 32
DEBUG:root:						// sizes: (128.0, 161.26989438654377, 203.18733465192952)
DEBUG:root:						// aspect_ratios: (0.5, 1.0, 2.0)

DEBUG:root:					return _generate_anchors(stride,
DEBUG:root:						     np.array(sizes, dtype=np.float) / stride,
DEBUG:root:						     np.array(aspect_ratios, dtype=np.float),)
DEBUG:root:						_generate_anchors(base_size, scales, aspect_ratios) { //BEGIN
DEBUG:root:						// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py

DEBUG:root:							// Params:
DEBUG:root:								// base_size: 32
DEBUG:root:								// scales: [4.         5.0396842  6.34960421]
DEBUG:root:								// aspect_ratios: [0.5 1.  2. ]

DEBUG:root:						anchor = np.array([1, 1, base_size, base_size], dtype=np.float) - 1
DEBUG:root:						// anchor: [ 0.  0. 31. 31.]
DEBUG:root:				_ratio_enum(anchor, ratios) { //BEGIN
DEBUG:root:				// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py

DEBUG:root:					// Params:
DEBUG:root:						// anchor: [ 0.  0. 31. 31.]
DEBUG:root:						// ratios: [0.5 1.  2. ]

DEBUG:root:				_whctrs(anchors) { //BEGIN
DEBUG:root:				// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:					// Param:
DEBUG:root:						// anchor: [ 0.  0. 31. 31.]

DEBUG:root:						w = anchor[2] - anchor[0] + 1
DEBUG:root:						w: 32.0
DEBUG:root:						h = anchor[3] - anchor[1] + 1
DEBUG:root:						h: 32.0
DEBUG:root:						x_ctr = anchor[0] + 0.5 * (w - 1)
DEBUG:root:						x_ctr: 15.5
DEBUG:root:						y_ctr = anchor[1] + 0.5 * (h - 1)
DEBUG:root:						y_ctr: 15.5
DEBUG:root:						return w, h, x_ctr, y_ctr
DEBUG:root:					} // END _whctrs(anchors)
DEBUG:root:					w, h, x_ctr, y_ctr = _whctrs(anchor)
DEBUG:root:					// w: 32.0, h: 32.0, x_ctr: 15.5, y_ctr: 15.5
DEBUG:root:					size = w * h
DEBUG:root:					// size: 1024.0
DEBUG:root:					size_ratios = size / ratios
DEBUG:root:					// size_ratios: [2048. 1024.  512.]
DEBUG:root:					ws = np.round(np.sqrt(size_ratios))
DEBUG:root:					// ws: [45. 32. 23.]
DEBUG:root:					hs = np.round(ws * ratios)
DEBUG:root:					// hs: [22. 32. 46.]
DEBUG:root:			_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN
DEBUG:root:			// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:				// Param:
DEBUG:root:					// ws: [45. 32. 23.]
DEBUG:root:					// hs: [22. 32. 46.]
DEBUG:root:					// x_ctr: 15.5
DEBUG:root:					// y_ctr: 15.5

DEBUG:root:				ws = ws[:, np.newaxis]
DEBUG:root:					// ws: [[45.]
 [32.]
 [23.]]
DEBUG:root:				hs = hs[:, np.newaxis]
DEBUG:root:					// hs: [[22.]
 [32.]
 [46.]]
DEBUG:root:				anchors = np.hstack(
DEBUG:root:				    (
DEBUG:root:				        x_ctr - 0.5 * (ws - 1),
DEBUG:root:				        y_ctr - 0.5 * (hs - 1),
DEBUG:root:				        x_ctr + 0.5 * (ws - 1),
DEBUG:root:				        y_ctr + 0.5 * (hs - 1),
DEBUG:root:				    )
DEBUG:root:				)
DEBUG:root:				// anchors: [[-6.5  5.  37.5 26. ]
 [ 0.   0.  31.  31. ]
 [ 4.5 -7.  26.5 38. ]]

DEBUG:root:				return anchors
DEBUG:root:			} // END _mkanchors(ws, hs, x_ctr, y_ctr)
DEBUG:root:					anchors = _mkanchors(ws, hs, x_ctr, y_ctr)
DEBUG:root:					// anchors: [[-6.5  5.  37.5 26. ]
 [ 0.   0.  31.  31. ]
 [ 4.5 -7.  26.5 38. ]]

DEBUG:root:					return anchors
DEBUG:root:				} // END _ratio_enum(anchor, ratios)
DEBUG:root:						anchors = _ratio_enum(anchor, aspect_ratios)
DEBUG:root:						// anchors: [[-6.5  5.  37.5 26. ]
 [ 0.   0.  31.  31. ]
 [ 4.5 -7.  26.5 38. ]]
DEBUG:root:						anchors = np.vstack(
DEBUG:root:						[_scale_enum(anchors[i, :], scales) for i in range(anchors.shape[0])]
DEBUG:root:						)
DEBUG:root:					_scale_enum(anchor, scales) { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py

DEBUG:root:					// Param:
DEBUG:root:						// anchor: [-6.5  5.  37.5 26. ]
DEBUG:root:						// scales: [4.         5.0396842  6.34960421]

DEBUG:root:				_whctrs(anchors) { //BEGIN
DEBUG:root:				// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:					// Param:
DEBUG:root:						// anchor: [-6.5  5.  37.5 26. ]

DEBUG:root:						w = anchor[2] - anchor[0] + 1
DEBUG:root:						w: 45.0
DEBUG:root:						h = anchor[3] - anchor[1] + 1
DEBUG:root:						h: 22.0
DEBUG:root:						x_ctr = anchor[0] + 0.5 * (w - 1)
DEBUG:root:						x_ctr: 15.5
DEBUG:root:						y_ctr = anchor[1] + 0.5 * (h - 1)
DEBUG:root:						y_ctr: 15.5
DEBUG:root:						return w, h, x_ctr, y_ctr
DEBUG:root:					} // END _whctrs(anchors)
DEBUG:root:					w, h, x_ctr, y_ctr = _whctrs(anchor)
DEBUG:root:					// w: 45.0, h: 22.0, x_ctr: 15.5, y_ctr: 15.5

DEBUG:root:					ws = w * scales
DEBUG:root:					// ws: [180.         226.78578898 285.73218935]

DEBUG:root:					hs = h * scales
DEBUG:root:					// hs: [ 88.         110.87305239 139.69129257]

DEBUG:root:					anchors = _mkanchors(ws, hs, x_ctr, y_ctr) { // CALL
DEBUG:root:			_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN
DEBUG:root:			// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:				// Param:
DEBUG:root:					// ws: [180.         226.78578898 285.73218935]
DEBUG:root:					// hs: [ 88.         110.87305239 139.69129257]
DEBUG:root:					// x_ctr: 15.5
DEBUG:root:					// y_ctr: 15.5

DEBUG:root:				ws = ws[:, np.newaxis]
DEBUG:root:					// ws: [[180.        ]
 [226.78578898]
 [285.73218935]]
DEBUG:root:				hs = hs[:, np.newaxis]
DEBUG:root:					// hs: [[ 88.        ]
 [110.87305239]
 [139.69129257]]
DEBUG:root:				anchors = np.hstack(
DEBUG:root:				    (
DEBUG:root:				        x_ctr - 0.5 * (ws - 1),
DEBUG:root:				        y_ctr - 0.5 * (hs - 1),
DEBUG:root:				        x_ctr + 0.5 * (ws - 1),
DEBUG:root:				        y_ctr + 0.5 * (hs - 1),
DEBUG:root:				    )
DEBUG:root:				)
DEBUG:root:				// anchors: [[ -74.          -28.          105.           59.        ]
 [ -97.39289449  -39.4365262   128.39289449   70.4365262 ]
 [-126.86609468  -53.84564629  157.86609468   84.84564629]]

DEBUG:root:				return anchors
DEBUG:root:			} // END _mkanchors(ws, hs, x_ctr, y_ctr)
DEBUG:root:

DEBUG:root:					}anchors = _mkanchors(ws, hs, x_ctr, y_ctr) // RETURNED
DEBUG:root:					// anchors: [[ -74.          -28.          105.           59.        ]
 [ -97.39289449  -39.4365262   128.39289449   70.4365262 ]
 [-126.86609468  -53.84564629  157.86609468   84.84564629]]

DEBUG:root:					return anchors: [[ -74.          -28.          105.           59.        ]
 [ -97.39289449  -39.4365262   128.39289449   70.4365262 ]
 [-126.86609468  -53.84564629  157.86609468   84.84564629]]
DEBUG:root:				} // END _scale_enum(anchor, scales)
DEBUG:root:					_scale_enum(anchor, scales) { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py

DEBUG:root:					// Param:
DEBUG:root:						// anchor: [ 0.  0. 31. 31.]
DEBUG:root:						// scales: [4.         5.0396842  6.34960421]

DEBUG:root:				_whctrs(anchors) { //BEGIN
DEBUG:root:				// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:					// Param:
DEBUG:root:						// anchor: [ 0.  0. 31. 31.]

DEBUG:root:						w = anchor[2] - anchor[0] + 1
DEBUG:root:						w: 32.0
DEBUG:root:						h = anchor[3] - anchor[1] + 1
DEBUG:root:						h: 32.0
DEBUG:root:						x_ctr = anchor[0] + 0.5 * (w - 1)
DEBUG:root:						x_ctr: 15.5
DEBUG:root:						y_ctr = anchor[1] + 0.5 * (h - 1)
DEBUG:root:						y_ctr: 15.5
DEBUG:root:						return w, h, x_ctr, y_ctr
DEBUG:root:					} // END _whctrs(anchors)
DEBUG:root:					w, h, x_ctr, y_ctr = _whctrs(anchor)
DEBUG:root:					// w: 32.0, h: 32.0, x_ctr: 15.5, y_ctr: 15.5

DEBUG:root:					ws = w * scales
DEBUG:root:					// ws: [128.         161.26989439 203.18733465]

DEBUG:root:					hs = h * scales
DEBUG:root:					// hs: [128.         161.26989439 203.18733465]

DEBUG:root:					anchors = _mkanchors(ws, hs, x_ctr, y_ctr) { // CALL
DEBUG:root:			_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN
DEBUG:root:			// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:				// Param:
DEBUG:root:					// ws: [128.         161.26989439 203.18733465]
DEBUG:root:					// hs: [128.         161.26989439 203.18733465]
DEBUG:root:					// x_ctr: 15.5
DEBUG:root:					// y_ctr: 15.5

DEBUG:root:				ws = ws[:, np.newaxis]
DEBUG:root:					// ws: [[128.        ]
 [161.26989439]
 [203.18733465]]
DEBUG:root:				hs = hs[:, np.newaxis]
DEBUG:root:					// hs: [[128.        ]
 [161.26989439]
 [203.18733465]]
DEBUG:root:				anchors = np.hstack(
DEBUG:root:				    (
DEBUG:root:				        x_ctr - 0.5 * (ws - 1),
DEBUG:root:				        y_ctr - 0.5 * (hs - 1),
DEBUG:root:				        x_ctr + 0.5 * (ws - 1),
DEBUG:root:				        y_ctr + 0.5 * (hs - 1),
DEBUG:root:				    )
DEBUG:root:				)
DEBUG:root:				// anchors: [[-48.         -48.          79.          79.        ]
 [-64.63494719 -64.63494719  95.63494719  95.63494719]
 [-85.59366733 -85.59366733 116.59366733 116.59366733]]

DEBUG:root:				return anchors
DEBUG:root:			} // END _mkanchors(ws, hs, x_ctr, y_ctr)
DEBUG:root:

DEBUG:root:					}anchors = _mkanchors(ws, hs, x_ctr, y_ctr) // RETURNED
DEBUG:root:					// anchors: [[-48.         -48.          79.          79.        ]
 [-64.63494719 -64.63494719  95.63494719  95.63494719]
 [-85.59366733 -85.59366733 116.59366733 116.59366733]]

DEBUG:root:					return anchors: [[-48.         -48.          79.          79.        ]
 [-64.63494719 -64.63494719  95.63494719  95.63494719]
 [-85.59366733 -85.59366733 116.59366733 116.59366733]]
DEBUG:root:				} // END _scale_enum(anchor, scales)
DEBUG:root:					_scale_enum(anchor, scales) { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py

DEBUG:root:					// Param:
DEBUG:root:						// anchor: [ 4.5 -7.  26.5 38. ]
DEBUG:root:						// scales: [4.         5.0396842  6.34960421]

DEBUG:root:				_whctrs(anchors) { //BEGIN
DEBUG:root:				// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:					// Param:
DEBUG:root:						// anchor: [ 4.5 -7.  26.5 38. ]

DEBUG:root:						w = anchor[2] - anchor[0] + 1
DEBUG:root:						w: 23.0
DEBUG:root:						h = anchor[3] - anchor[1] + 1
DEBUG:root:						h: 46.0
DEBUG:root:						x_ctr = anchor[0] + 0.5 * (w - 1)
DEBUG:root:						x_ctr: 15.5
DEBUG:root:						y_ctr = anchor[1] + 0.5 * (h - 1)
DEBUG:root:						y_ctr: 15.5
DEBUG:root:						return w, h, x_ctr, y_ctr
DEBUG:root:					} // END _whctrs(anchors)
DEBUG:root:					w, h, x_ctr, y_ctr = _whctrs(anchor)
DEBUG:root:					// w: 23.0, h: 46.0, x_ctr: 15.5, y_ctr: 15.5

DEBUG:root:					ws = w * scales
DEBUG:root:					// ws: [ 92.         115.91273659 146.04089678]

DEBUG:root:					hs = h * scales
DEBUG:root:					// hs: [184.         231.82547318 292.08179356]

DEBUG:root:					anchors = _mkanchors(ws, hs, x_ctr, y_ctr) { // CALL
DEBUG:root:			_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN
DEBUG:root:			// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:				// Param:
DEBUG:root:					// ws: [ 92.         115.91273659 146.04089678]
DEBUG:root:					// hs: [184.         231.82547318 292.08179356]
DEBUG:root:					// x_ctr: 15.5
DEBUG:root:					// y_ctr: 15.5

DEBUG:root:				ws = ws[:, np.newaxis]
DEBUG:root:					// ws: [[ 92.        ]
 [115.91273659]
 [146.04089678]]
DEBUG:root:				hs = hs[:, np.newaxis]
DEBUG:root:					// hs: [[184.        ]
 [231.82547318]
 [292.08179356]]
DEBUG:root:				anchors = np.hstack(
DEBUG:root:				    (
DEBUG:root:				        x_ctr - 0.5 * (ws - 1),
DEBUG:root:				        y_ctr - 0.5 * (hs - 1),
DEBUG:root:				        x_ctr + 0.5 * (ws - 1),
DEBUG:root:				        y_ctr + 0.5 * (hs - 1),
DEBUG:root:				    )
DEBUG:root:				)
DEBUG:root:				// anchors: [[ -30.          -76.           61.          107.        ]
 [ -41.9563683   -99.91273659   72.9563683   130.91273659]
 [ -57.02044839 -130.04089678   88.02044839  161.04089678]]

DEBUG:root:				return anchors
DEBUG:root:			} // END _mkanchors(ws, hs, x_ctr, y_ctr)
DEBUG:root:

DEBUG:root:					}anchors = _mkanchors(ws, hs, x_ctr, y_ctr) // RETURNED
DEBUG:root:					// anchors: [[ -30.          -76.           61.          107.        ]
 [ -41.9563683   -99.91273659   72.9563683   130.91273659]
 [ -57.02044839 -130.04089678   88.02044839  161.04089678]]

DEBUG:root:					return anchors: [[ -30.          -76.           61.          107.        ]
 [ -41.9563683   -99.91273659   72.9563683   130.91273659]
 [ -57.02044839 -130.04089678   88.02044839  161.04089678]]
DEBUG:root:				} // END _scale_enum(anchor, scales)
DEBUG:root:						// anchors: [[ -74.          -28.          105.           59.        ]
 [ -97.39289449  -39.4365262   128.39289449   70.4365262 ]
 [-126.86609468  -53.84564629  157.86609468   84.84564629]
 [ -48.          -48.           79.           79.        ]
 [ -64.63494719  -64.63494719   95.63494719   95.63494719]
 [ -85.59366733  -85.59366733  116.59366733  116.59366733]
 [ -30.          -76.           61.          107.        ]
 [ -41.9563683   -99.91273659   72.9563683   130.91273659]
 [ -57.02044839 -130.04089678   88.02044839  161.04089678]]
DEBUG:root:							return torch.from_numpy(anchors)
DEBUG:root:						} // END _generate_anchors(base_size, scales, apect_ratios) END
DEBUG:root:					} // END generate_anchors(stride, sizes, aspect_ratios)
DEBUG:root:				generate_anchors(stride, sizes, aspect_ratios) { //BEGIN
DEBUG:root:			//defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:					// Params:
DEBUG:root:						// stride: 64
DEBUG:root:						// sizes: (256.0, 322.53978877308754, 406.37466930385904)
DEBUG:root:						// aspect_ratios: (0.5, 1.0, 2.0)

DEBUG:root:					return _generate_anchors(stride,
DEBUG:root:						     np.array(sizes, dtype=np.float) / stride,
DEBUG:root:						     np.array(aspect_ratios, dtype=np.float),)
DEBUG:root:						_generate_anchors(base_size, scales, aspect_ratios) { //BEGIN
DEBUG:root:						// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py

DEBUG:root:							// Params:
DEBUG:root:								// base_size: 64
DEBUG:root:								// scales: [4.         5.0396842  6.34960421]
DEBUG:root:								// aspect_ratios: [0.5 1.  2. ]

DEBUG:root:						anchor = np.array([1, 1, base_size, base_size], dtype=np.float) - 1
DEBUG:root:						// anchor: [ 0.  0. 63. 63.]
DEBUG:root:				_ratio_enum(anchor, ratios) { //BEGIN
DEBUG:root:				// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py

DEBUG:root:					// Params:
DEBUG:root:						// anchor: [ 0.  0. 63. 63.]
DEBUG:root:						// ratios: [0.5 1.  2. ]

DEBUG:root:				_whctrs(anchors) { //BEGIN
DEBUG:root:				// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:					// Param:
DEBUG:root:						// anchor: [ 0.  0. 63. 63.]

DEBUG:root:						w = anchor[2] - anchor[0] + 1
DEBUG:root:						w: 64.0
DEBUG:root:						h = anchor[3] - anchor[1] + 1
DEBUG:root:						h: 64.0
DEBUG:root:						x_ctr = anchor[0] + 0.5 * (w - 1)
DEBUG:root:						x_ctr: 31.5
DEBUG:root:						y_ctr = anchor[1] + 0.5 * (h - 1)
DEBUG:root:						y_ctr: 31.5
DEBUG:root:						return w, h, x_ctr, y_ctr
DEBUG:root:					} // END _whctrs(anchors)
DEBUG:root:					w, h, x_ctr, y_ctr = _whctrs(anchor)
DEBUG:root:					// w: 64.0, h: 64.0, x_ctr: 31.5, y_ctr: 31.5
DEBUG:root:					size = w * h
DEBUG:root:					// size: 4096.0
DEBUG:root:					size_ratios = size / ratios
DEBUG:root:					// size_ratios: [8192. 4096. 2048.]
DEBUG:root:					ws = np.round(np.sqrt(size_ratios))
DEBUG:root:					// ws: [91. 64. 45.]
DEBUG:root:					hs = np.round(ws * ratios)
DEBUG:root:					// hs: [46. 64. 90.]
DEBUG:root:			_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN
DEBUG:root:			// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:				// Param:
DEBUG:root:					// ws: [91. 64. 45.]
DEBUG:root:					// hs: [46. 64. 90.]
DEBUG:root:					// x_ctr: 31.5
DEBUG:root:					// y_ctr: 31.5

DEBUG:root:				ws = ws[:, np.newaxis]
DEBUG:root:					// ws: [[91.]
 [64.]
 [45.]]
DEBUG:root:				hs = hs[:, np.newaxis]
DEBUG:root:					// hs: [[46.]
 [64.]
 [90.]]
DEBUG:root:				anchors = np.hstack(
DEBUG:root:				    (
DEBUG:root:				        x_ctr - 0.5 * (ws - 1),
DEBUG:root:				        y_ctr - 0.5 * (hs - 1),
DEBUG:root:				        x_ctr + 0.5 * (ws - 1),
DEBUG:root:				        y_ctr + 0.5 * (hs - 1),
DEBUG:root:				    )
DEBUG:root:				)
DEBUG:root:				// anchors: [[-13.5   9.   76.5  54. ]
 [  0.    0.   63.   63. ]
 [  9.5 -13.   53.5  76. ]]

DEBUG:root:				return anchors
DEBUG:root:			} // END _mkanchors(ws, hs, x_ctr, y_ctr)
DEBUG:root:					anchors = _mkanchors(ws, hs, x_ctr, y_ctr)
DEBUG:root:					// anchors: [[-13.5   9.   76.5  54. ]
 [  0.    0.   63.   63. ]
 [  9.5 -13.   53.5  76. ]]

DEBUG:root:					return anchors
DEBUG:root:				} // END _ratio_enum(anchor, ratios)
DEBUG:root:						anchors = _ratio_enum(anchor, aspect_ratios)
DEBUG:root:						// anchors: [[-13.5   9.   76.5  54. ]
 [  0.    0.   63.   63. ]
 [  9.5 -13.   53.5  76. ]]
DEBUG:root:						anchors = np.vstack(
DEBUG:root:						[_scale_enum(anchors[i, :], scales) for i in range(anchors.shape[0])]
DEBUG:root:						)
DEBUG:root:					_scale_enum(anchor, scales) { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py

DEBUG:root:					// Param:
DEBUG:root:						// anchor: [-13.5   9.   76.5  54. ]
DEBUG:root:						// scales: [4.         5.0396842  6.34960421]

DEBUG:root:				_whctrs(anchors) { //BEGIN
DEBUG:root:				// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:					// Param:
DEBUG:root:						// anchor: [-13.5   9.   76.5  54. ]

DEBUG:root:						w = anchor[2] - anchor[0] + 1
DEBUG:root:						w: 91.0
DEBUG:root:						h = anchor[3] - anchor[1] + 1
DEBUG:root:						h: 46.0
DEBUG:root:						x_ctr = anchor[0] + 0.5 * (w - 1)
DEBUG:root:						x_ctr: 31.5
DEBUG:root:						y_ctr = anchor[1] + 0.5 * (h - 1)
DEBUG:root:						y_ctr: 31.5
DEBUG:root:						return w, h, x_ctr, y_ctr
DEBUG:root:					} // END _whctrs(anchors)
DEBUG:root:					w, h, x_ctr, y_ctr = _whctrs(anchor)
DEBUG:root:					// w: 91.0, h: 46.0, x_ctr: 31.5, y_ctr: 31.5

DEBUG:root:					ws = w * scales
DEBUG:root:					// ws: [364.         458.61126216 577.81398292]

DEBUG:root:					hs = h * scales
DEBUG:root:					// hs: [184.         231.82547318 292.08179356]

DEBUG:root:					anchors = _mkanchors(ws, hs, x_ctr, y_ctr) { // CALL
DEBUG:root:			_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN
DEBUG:root:			// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:				// Param:
DEBUG:root:					// ws: [364.         458.61126216 577.81398292]
DEBUG:root:					// hs: [184.         231.82547318 292.08179356]
DEBUG:root:					// x_ctr: 31.5
DEBUG:root:					// y_ctr: 31.5

DEBUG:root:				ws = ws[:, np.newaxis]
DEBUG:root:					// ws: [[364.        ]
 [458.61126216]
 [577.81398292]]
DEBUG:root:				hs = hs[:, np.newaxis]
DEBUG:root:					// hs: [[184.        ]
 [231.82547318]
 [292.08179356]]
DEBUG:root:				anchors = np.hstack(
DEBUG:root:				    (
DEBUG:root:				        x_ctr - 0.5 * (ws - 1),
DEBUG:root:				        y_ctr - 0.5 * (hs - 1),
DEBUG:root:				        x_ctr + 0.5 * (ws - 1),
DEBUG:root:				        y_ctr + 0.5 * (hs - 1),
DEBUG:root:				    )
DEBUG:root:				)
DEBUG:root:				// anchors: [[-150.          -60.          213.          123.        ]
 [-197.30563108  -83.91273659  260.30563108  146.91273659]
 [-256.90699146 -114.04089678  319.90699146  177.04089678]]

DEBUG:root:				return anchors
DEBUG:root:			} // END _mkanchors(ws, hs, x_ctr, y_ctr)
DEBUG:root:

DEBUG:root:					}anchors = _mkanchors(ws, hs, x_ctr, y_ctr) // RETURNED
DEBUG:root:					// anchors: [[-150.          -60.          213.          123.        ]
 [-197.30563108  -83.91273659  260.30563108  146.91273659]
 [-256.90699146 -114.04089678  319.90699146  177.04089678]]

DEBUG:root:					return anchors: [[-150.          -60.          213.          123.        ]
 [-197.30563108  -83.91273659  260.30563108  146.91273659]
 [-256.90699146 -114.04089678  319.90699146  177.04089678]]
DEBUG:root:				} // END _scale_enum(anchor, scales)
DEBUG:root:					_scale_enum(anchor, scales) { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py

DEBUG:root:					// Param:
DEBUG:root:						// anchor: [ 0.  0. 63. 63.]
DEBUG:root:						// scales: [4.         5.0396842  6.34960421]

DEBUG:root:				_whctrs(anchors) { //BEGIN
DEBUG:root:				// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:					// Param:
DEBUG:root:						// anchor: [ 0.  0. 63. 63.]

DEBUG:root:						w = anchor[2] - anchor[0] + 1
DEBUG:root:						w: 64.0
DEBUG:root:						h = anchor[3] - anchor[1] + 1
DEBUG:root:						h: 64.0
DEBUG:root:						x_ctr = anchor[0] + 0.5 * (w - 1)
DEBUG:root:						x_ctr: 31.5
DEBUG:root:						y_ctr = anchor[1] + 0.5 * (h - 1)
DEBUG:root:						y_ctr: 31.5
DEBUG:root:						return w, h, x_ctr, y_ctr
DEBUG:root:					} // END _whctrs(anchors)
DEBUG:root:					w, h, x_ctr, y_ctr = _whctrs(anchor)
DEBUG:root:					// w: 64.0, h: 64.0, x_ctr: 31.5, y_ctr: 31.5

DEBUG:root:					ws = w * scales
DEBUG:root:					// ws: [256.         322.53978877 406.3746693 ]

DEBUG:root:					hs = h * scales
DEBUG:root:					// hs: [256.         322.53978877 406.3746693 ]

DEBUG:root:					anchors = _mkanchors(ws, hs, x_ctr, y_ctr) { // CALL
DEBUG:root:			_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN
DEBUG:root:			// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:				// Param:
DEBUG:root:					// ws: [256.         322.53978877 406.3746693 ]
DEBUG:root:					// hs: [256.         322.53978877 406.3746693 ]
DEBUG:root:					// x_ctr: 31.5
DEBUG:root:					// y_ctr: 31.5

DEBUG:root:				ws = ws[:, np.newaxis]
DEBUG:root:					// ws: [[256.        ]
 [322.53978877]
 [406.3746693 ]]
DEBUG:root:				hs = hs[:, np.newaxis]
DEBUG:root:					// hs: [[256.        ]
 [322.53978877]
 [406.3746693 ]]
DEBUG:root:				anchors = np.hstack(
DEBUG:root:				    (
DEBUG:root:				        x_ctr - 0.5 * (ws - 1),
DEBUG:root:				        y_ctr - 0.5 * (hs - 1),
DEBUG:root:				        x_ctr + 0.5 * (ws - 1),
DEBUG:root:				        y_ctr + 0.5 * (hs - 1),
DEBUG:root:				    )
DEBUG:root:				)
DEBUG:root:				// anchors: [[ -96.          -96.          159.          159.        ]
 [-129.26989439 -129.26989439  192.26989439  192.26989439]
 [-171.18733465 -171.18733465  234.18733465  234.18733465]]

DEBUG:root:				return anchors
DEBUG:root:			} // END _mkanchors(ws, hs, x_ctr, y_ctr)
DEBUG:root:

DEBUG:root:					}anchors = _mkanchors(ws, hs, x_ctr, y_ctr) // RETURNED
DEBUG:root:					// anchors: [[ -96.          -96.          159.          159.        ]
 [-129.26989439 -129.26989439  192.26989439  192.26989439]
 [-171.18733465 -171.18733465  234.18733465  234.18733465]]

DEBUG:root:					return anchors: [[ -96.          -96.          159.          159.        ]
 [-129.26989439 -129.26989439  192.26989439  192.26989439]
 [-171.18733465 -171.18733465  234.18733465  234.18733465]]
DEBUG:root:				} // END _scale_enum(anchor, scales)
DEBUG:root:					_scale_enum(anchor, scales) { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py

DEBUG:root:					// Param:
DEBUG:root:						// anchor: [  9.5 -13.   53.5  76. ]
DEBUG:root:						// scales: [4.         5.0396842  6.34960421]

DEBUG:root:				_whctrs(anchors) { //BEGIN
DEBUG:root:				// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:					// Param:
DEBUG:root:						// anchor: [  9.5 -13.   53.5  76. ]

DEBUG:root:						w = anchor[2] - anchor[0] + 1
DEBUG:root:						w: 45.0
DEBUG:root:						h = anchor[3] - anchor[1] + 1
DEBUG:root:						h: 90.0
DEBUG:root:						x_ctr = anchor[0] + 0.5 * (w - 1)
DEBUG:root:						x_ctr: 31.5
DEBUG:root:						y_ctr = anchor[1] + 0.5 * (h - 1)
DEBUG:root:						y_ctr: 31.5
DEBUG:root:						return w, h, x_ctr, y_ctr
DEBUG:root:					} // END _whctrs(anchors)
DEBUG:root:					w, h, x_ctr, y_ctr = _whctrs(anchor)
DEBUG:root:					// w: 45.0, h: 90.0, x_ctr: 31.5, y_ctr: 31.5

DEBUG:root:					ws = w * scales
DEBUG:root:					// ws: [180.         226.78578898 285.73218935]

DEBUG:root:					hs = h * scales
DEBUG:root:					// hs: [360.         453.57157796 571.46437871]

DEBUG:root:					anchors = _mkanchors(ws, hs, x_ctr, y_ctr) { // CALL
DEBUG:root:			_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN
DEBUG:root:			// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:				// Param:
DEBUG:root:					// ws: [180.         226.78578898 285.73218935]
DEBUG:root:					// hs: [360.         453.57157796 571.46437871]
DEBUG:root:					// x_ctr: 31.5
DEBUG:root:					// y_ctr: 31.5

DEBUG:root:				ws = ws[:, np.newaxis]
DEBUG:root:					// ws: [[180.        ]
 [226.78578898]
 [285.73218935]]
DEBUG:root:				hs = hs[:, np.newaxis]
DEBUG:root:					// hs: [[360.        ]
 [453.57157796]
 [571.46437871]]
DEBUG:root:				anchors = np.hstack(
DEBUG:root:				    (
DEBUG:root:				        x_ctr - 0.5 * (ws - 1),
DEBUG:root:				        y_ctr - 0.5 * (hs - 1),
DEBUG:root:				        x_ctr + 0.5 * (ws - 1),
DEBUG:root:				        y_ctr + 0.5 * (hs - 1),
DEBUG:root:				    )
DEBUG:root:				)
DEBUG:root:				// anchors: [[ -58.         -148.          121.          211.        ]
 [ -81.39289449 -194.78578898  144.39289449  257.78578898]
 [-110.86609468 -253.73218935  173.86609468  316.73218935]]

DEBUG:root:				return anchors
DEBUG:root:			} // END _mkanchors(ws, hs, x_ctr, y_ctr)
DEBUG:root:

DEBUG:root:					}anchors = _mkanchors(ws, hs, x_ctr, y_ctr) // RETURNED
DEBUG:root:					// anchors: [[ -58.         -148.          121.          211.        ]
 [ -81.39289449 -194.78578898  144.39289449  257.78578898]
 [-110.86609468 -253.73218935  173.86609468  316.73218935]]

DEBUG:root:					return anchors: [[ -58.         -148.          121.          211.        ]
 [ -81.39289449 -194.78578898  144.39289449  257.78578898]
 [-110.86609468 -253.73218935  173.86609468  316.73218935]]
DEBUG:root:				} // END _scale_enum(anchor, scales)
DEBUG:root:						// anchors: [[-150.          -60.          213.          123.        ]
 [-197.30563108  -83.91273659  260.30563108  146.91273659]
 [-256.90699146 -114.04089678  319.90699146  177.04089678]
 [ -96.          -96.          159.          159.        ]
 [-129.26989439 -129.26989439  192.26989439  192.26989439]
 [-171.18733465 -171.18733465  234.18733465  234.18733465]
 [ -58.         -148.          121.          211.        ]
 [ -81.39289449 -194.78578898  144.39289449  257.78578898]
 [-110.86609468 -253.73218935  173.86609468  316.73218935]]
DEBUG:root:							return torch.from_numpy(anchors)
DEBUG:root:						} // END _generate_anchors(base_size, scales, apect_ratios) END
DEBUG:root:					} // END generate_anchors(stride, sizes, aspect_ratios)
DEBUG:root:				generate_anchors(stride, sizes, aspect_ratios) { //BEGIN
DEBUG:root:			//defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:					// Params:
DEBUG:root:						// stride: 128
DEBUG:root:						// sizes: (512.0, 645.0795775461751, 812.7493386077181)
DEBUG:root:						// aspect_ratios: (0.5, 1.0, 2.0)

DEBUG:root:					return _generate_anchors(stride,
DEBUG:root:						     np.array(sizes, dtype=np.float) / stride,
DEBUG:root:						     np.array(aspect_ratios, dtype=np.float),)
DEBUG:root:						_generate_anchors(base_size, scales, aspect_ratios) { //BEGIN
DEBUG:root:						// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py

DEBUG:root:							// Params:
DEBUG:root:								// base_size: 128
DEBUG:root:								// scales: [4.         5.0396842  6.34960421]
DEBUG:root:								// aspect_ratios: [0.5 1.  2. ]

DEBUG:root:						anchor = np.array([1, 1, base_size, base_size], dtype=np.float) - 1
DEBUG:root:						// anchor: [  0.   0. 127. 127.]
DEBUG:root:				_ratio_enum(anchor, ratios) { //BEGIN
DEBUG:root:				// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py

DEBUG:root:					// Params:
DEBUG:root:						// anchor: [  0.   0. 127. 127.]
DEBUG:root:						// ratios: [0.5 1.  2. ]

DEBUG:root:				_whctrs(anchors) { //BEGIN
DEBUG:root:				// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:					// Param:
DEBUG:root:						// anchor: [  0.   0. 127. 127.]

DEBUG:root:						w = anchor[2] - anchor[0] + 1
DEBUG:root:						w: 128.0
DEBUG:root:						h = anchor[3] - anchor[1] + 1
DEBUG:root:						h: 128.0
DEBUG:root:						x_ctr = anchor[0] + 0.5 * (w - 1)
DEBUG:root:						x_ctr: 63.5
DEBUG:root:						y_ctr = anchor[1] + 0.5 * (h - 1)
DEBUG:root:						y_ctr: 63.5
DEBUG:root:						return w, h, x_ctr, y_ctr
DEBUG:root:					} // END _whctrs(anchors)
DEBUG:root:					w, h, x_ctr, y_ctr = _whctrs(anchor)
DEBUG:root:					// w: 128.0, h: 128.0, x_ctr: 63.5, y_ctr: 63.5
DEBUG:root:					size = w * h
DEBUG:root:					// size: 16384.0
DEBUG:root:					size_ratios = size / ratios
DEBUG:root:					// size_ratios: [32768. 16384.  8192.]
DEBUG:root:					ws = np.round(np.sqrt(size_ratios))
DEBUG:root:					// ws: [181. 128.  91.]
DEBUG:root:					hs = np.round(ws * ratios)
DEBUG:root:					// hs: [ 90. 128. 182.]
DEBUG:root:			_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN
DEBUG:root:			// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:				// Param:
DEBUG:root:					// ws: [181. 128.  91.]
DEBUG:root:					// hs: [ 90. 128. 182.]
DEBUG:root:					// x_ctr: 63.5
DEBUG:root:					// y_ctr: 63.5

DEBUG:root:				ws = ws[:, np.newaxis]
DEBUG:root:					// ws: [[181.]
 [128.]
 [ 91.]]
DEBUG:root:				hs = hs[:, np.newaxis]
DEBUG:root:					// hs: [[ 90.]
 [128.]
 [182.]]
DEBUG:root:				anchors = np.hstack(
DEBUG:root:				    (
DEBUG:root:				        x_ctr - 0.5 * (ws - 1),
DEBUG:root:				        y_ctr - 0.5 * (hs - 1),
DEBUG:root:				        x_ctr + 0.5 * (ws - 1),
DEBUG:root:				        y_ctr + 0.5 * (hs - 1),
DEBUG:root:				    )
DEBUG:root:				)
DEBUG:root:				// anchors: [[-26.5  19.  153.5 108. ]
 [  0.    0.  127.  127. ]
 [ 18.5 -27.  108.5 154. ]]

DEBUG:root:				return anchors
DEBUG:root:			} // END _mkanchors(ws, hs, x_ctr, y_ctr)
DEBUG:root:					anchors = _mkanchors(ws, hs, x_ctr, y_ctr)
DEBUG:root:					// anchors: [[-26.5  19.  153.5 108. ]
 [  0.    0.  127.  127. ]
 [ 18.5 -27.  108.5 154. ]]

DEBUG:root:					return anchors
DEBUG:root:				} // END _ratio_enum(anchor, ratios)
DEBUG:root:						anchors = _ratio_enum(anchor, aspect_ratios)
DEBUG:root:						// anchors: [[-26.5  19.  153.5 108. ]
 [  0.    0.  127.  127. ]
 [ 18.5 -27.  108.5 154. ]]
DEBUG:root:						anchors = np.vstack(
DEBUG:root:						[_scale_enum(anchors[i, :], scales) for i in range(anchors.shape[0])]
DEBUG:root:						)
DEBUG:root:					_scale_enum(anchor, scales) { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py

DEBUG:root:					// Param:
DEBUG:root:						// anchor: [-26.5  19.  153.5 108. ]
DEBUG:root:						// scales: [4.         5.0396842  6.34960421]

DEBUG:root:				_whctrs(anchors) { //BEGIN
DEBUG:root:				// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:					// Param:
DEBUG:root:						// anchor: [-26.5  19.  153.5 108. ]

DEBUG:root:						w = anchor[2] - anchor[0] + 1
DEBUG:root:						w: 181.0
DEBUG:root:						h = anchor[3] - anchor[1] + 1
DEBUG:root:						h: 90.0
DEBUG:root:						x_ctr = anchor[0] + 0.5 * (w - 1)
DEBUG:root:						x_ctr: 63.5
DEBUG:root:						y_ctr = anchor[1] + 0.5 * (h - 1)
DEBUG:root:						y_ctr: 63.5
DEBUG:root:						return w, h, x_ctr, y_ctr
DEBUG:root:					} // END _whctrs(anchors)
DEBUG:root:					w, h, x_ctr, y_ctr = _whctrs(anchor)
DEBUG:root:					// w: 181.0, h: 90.0, x_ctr: 63.5, y_ctr: 63.5

DEBUG:root:					ws = w * scales
DEBUG:root:					// ws: [ 724.          912.18284012 1149.27836162]

DEBUG:root:					hs = h * scales
DEBUG:root:					// hs: [360.         453.57157796 571.46437871]

DEBUG:root:					anchors = _mkanchors(ws, hs, x_ctr, y_ctr) { // CALL
DEBUG:root:			_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN
DEBUG:root:			// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:				// Param:
DEBUG:root:					// ws: [ 724.          912.18284012 1149.27836162]
DEBUG:root:					// hs: [360.         453.57157796 571.46437871]
DEBUG:root:					// x_ctr: 63.5
DEBUG:root:					// y_ctr: 63.5

DEBUG:root:				ws = ws[:, np.newaxis]
DEBUG:root:					// ws: [[ 724.        ]
 [ 912.18284012]
 [1149.27836162]]
DEBUG:root:				hs = hs[:, np.newaxis]
DEBUG:root:					// hs: [[360.        ]
 [453.57157796]
 [571.46437871]]
DEBUG:root:				anchors = np.hstack(
DEBUG:root:				    (
DEBUG:root:				        x_ctr - 0.5 * (ws - 1),
DEBUG:root:				        y_ctr - 0.5 * (hs - 1),
DEBUG:root:				        x_ctr + 0.5 * (ws - 1),
DEBUG:root:				        y_ctr + 0.5 * (hs - 1),
DEBUG:root:				    )
DEBUG:root:				)
DEBUG:root:				// anchors: [[-298.         -116.          425.          243.        ]
 [-392.09142006 -162.78578898  519.09142006  289.78578898]
 [-510.63918081 -221.73218935  637.63918081  348.73218935]]

DEBUG:root:				return anchors
DEBUG:root:			} // END _mkanchors(ws, hs, x_ctr, y_ctr)
DEBUG:root:

DEBUG:root:					}anchors = _mkanchors(ws, hs, x_ctr, y_ctr) // RETURNED
DEBUG:root:					// anchors: [[-298.         -116.          425.          243.        ]
 [-392.09142006 -162.78578898  519.09142006  289.78578898]
 [-510.63918081 -221.73218935  637.63918081  348.73218935]]

DEBUG:root:					return anchors: [[-298.         -116.          425.          243.        ]
 [-392.09142006 -162.78578898  519.09142006  289.78578898]
 [-510.63918081 -221.73218935  637.63918081  348.73218935]]
DEBUG:root:				} // END _scale_enum(anchor, scales)
DEBUG:root:					_scale_enum(anchor, scales) { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py

DEBUG:root:					// Param:
DEBUG:root:						// anchor: [  0.   0. 127. 127.]
DEBUG:root:						// scales: [4.         5.0396842  6.34960421]

DEBUG:root:				_whctrs(anchors) { //BEGIN
DEBUG:root:				// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:					// Param:
DEBUG:root:						// anchor: [  0.   0. 127. 127.]

DEBUG:root:						w = anchor[2] - anchor[0] + 1
DEBUG:root:						w: 128.0
DEBUG:root:						h = anchor[3] - anchor[1] + 1
DEBUG:root:						h: 128.0
DEBUG:root:						x_ctr = anchor[0] + 0.5 * (w - 1)
DEBUG:root:						x_ctr: 63.5
DEBUG:root:						y_ctr = anchor[1] + 0.5 * (h - 1)
DEBUG:root:						y_ctr: 63.5
DEBUG:root:						return w, h, x_ctr, y_ctr
DEBUG:root:					} // END _whctrs(anchors)
DEBUG:root:					w, h, x_ctr, y_ctr = _whctrs(anchor)
DEBUG:root:					// w: 128.0, h: 128.0, x_ctr: 63.5, y_ctr: 63.5

DEBUG:root:					ws = w * scales
DEBUG:root:					// ws: [512.         645.07957755 812.74933861]

DEBUG:root:					hs = h * scales
DEBUG:root:					// hs: [512.         645.07957755 812.74933861]

DEBUG:root:					anchors = _mkanchors(ws, hs, x_ctr, y_ctr) { // CALL
DEBUG:root:			_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN
DEBUG:root:			// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:				// Param:
DEBUG:root:					// ws: [512.         645.07957755 812.74933861]
DEBUG:root:					// hs: [512.         645.07957755 812.74933861]
DEBUG:root:					// x_ctr: 63.5
DEBUG:root:					// y_ctr: 63.5

DEBUG:root:				ws = ws[:, np.newaxis]
DEBUG:root:					// ws: [[512.        ]
 [645.07957755]
 [812.74933861]]
DEBUG:root:				hs = hs[:, np.newaxis]
DEBUG:root:					// hs: [[512.        ]
 [645.07957755]
 [812.74933861]]
DEBUG:root:				anchors = np.hstack(
DEBUG:root:				    (
DEBUG:root:				        x_ctr - 0.5 * (ws - 1),
DEBUG:root:				        y_ctr - 0.5 * (hs - 1),
DEBUG:root:				        x_ctr + 0.5 * (ws - 1),
DEBUG:root:				        y_ctr + 0.5 * (hs - 1),
DEBUG:root:				    )
DEBUG:root:				)
DEBUG:root:				// anchors: [[-192.         -192.          319.          319.        ]
 [-258.53978877 -258.53978877  385.53978877  385.53978877]
 [-342.3746693  -342.3746693   469.3746693   469.3746693 ]]

DEBUG:root:				return anchors
DEBUG:root:			} // END _mkanchors(ws, hs, x_ctr, y_ctr)
DEBUG:root:

DEBUG:root:					}anchors = _mkanchors(ws, hs, x_ctr, y_ctr) // RETURNED
DEBUG:root:					// anchors: [[-192.         -192.          319.          319.        ]
 [-258.53978877 -258.53978877  385.53978877  385.53978877]
 [-342.3746693  -342.3746693   469.3746693   469.3746693 ]]

DEBUG:root:					return anchors: [[-192.         -192.          319.          319.        ]
 [-258.53978877 -258.53978877  385.53978877  385.53978877]
 [-342.3746693  -342.3746693   469.3746693   469.3746693 ]]
DEBUG:root:				} // END _scale_enum(anchor, scales)
DEBUG:root:					_scale_enum(anchor, scales) { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py

DEBUG:root:					// Param:
DEBUG:root:						// anchor: [ 18.5 -27.  108.5 154. ]
DEBUG:root:						// scales: [4.         5.0396842  6.34960421]

DEBUG:root:				_whctrs(anchors) { //BEGIN
DEBUG:root:				// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:					// Param:
DEBUG:root:						// anchor: [ 18.5 -27.  108.5 154. ]

DEBUG:root:						w = anchor[2] - anchor[0] + 1
DEBUG:root:						w: 91.0
DEBUG:root:						h = anchor[3] - anchor[1] + 1
DEBUG:root:						h: 182.0
DEBUG:root:						x_ctr = anchor[0] + 0.5 * (w - 1)
DEBUG:root:						x_ctr: 63.5
DEBUG:root:						y_ctr = anchor[1] + 0.5 * (h - 1)
DEBUG:root:						y_ctr: 63.5
DEBUG:root:						return w, h, x_ctr, y_ctr
DEBUG:root:					} // END _whctrs(anchors)
DEBUG:root:					w, h, x_ctr, y_ctr = _whctrs(anchor)
DEBUG:root:					// w: 91.0, h: 182.0, x_ctr: 63.5, y_ctr: 63.5

DEBUG:root:					ws = w * scales
DEBUG:root:					// ws: [364.         458.61126216 577.81398292]

DEBUG:root:					hs = h * scales
DEBUG:root:					// hs: [ 728.          917.22252432 1155.62796583]

DEBUG:root:					anchors = _mkanchors(ws, hs, x_ctr, y_ctr) { // CALL
DEBUG:root:			_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN
DEBUG:root:			// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:				// Param:
DEBUG:root:					// ws: [364.         458.61126216 577.81398292]
DEBUG:root:					// hs: [ 728.          917.22252432 1155.62796583]
DEBUG:root:					// x_ctr: 63.5
DEBUG:root:					// y_ctr: 63.5

DEBUG:root:				ws = ws[:, np.newaxis]
DEBUG:root:					// ws: [[364.        ]
 [458.61126216]
 [577.81398292]]
DEBUG:root:				hs = hs[:, np.newaxis]
DEBUG:root:					// hs: [[ 728.        ]
 [ 917.22252432]
 [1155.62796583]]
DEBUG:root:				anchors = np.hstack(
DEBUG:root:				    (
DEBUG:root:				        x_ctr - 0.5 * (ws - 1),
DEBUG:root:				        y_ctr - 0.5 * (hs - 1),
DEBUG:root:				        x_ctr + 0.5 * (ws - 1),
DEBUG:root:				        y_ctr + 0.5 * (hs - 1),
DEBUG:root:				    )
DEBUG:root:				)
DEBUG:root:				// anchors: [[-118.         -300.          245.          427.        ]
 [-165.30563108 -394.61126216  292.30563108  521.61126216]
 [-224.90699146 -513.81398292  351.90699146  640.81398292]]

DEBUG:root:				return anchors
DEBUG:root:			} // END _mkanchors(ws, hs, x_ctr, y_ctr)
DEBUG:root:

DEBUG:root:					}anchors = _mkanchors(ws, hs, x_ctr, y_ctr) // RETURNED
DEBUG:root:					// anchors: [[-118.         -300.          245.          427.        ]
 [-165.30563108 -394.61126216  292.30563108  521.61126216]
 [-224.90699146 -513.81398292  351.90699146  640.81398292]]

DEBUG:root:					return anchors: [[-118.         -300.          245.          427.        ]
 [-165.30563108 -394.61126216  292.30563108  521.61126216]
 [-224.90699146 -513.81398292  351.90699146  640.81398292]]
DEBUG:root:				} // END _scale_enum(anchor, scales)
DEBUG:root:						// anchors: [[-298.         -116.          425.          243.        ]
 [-392.09142006 -162.78578898  519.09142006  289.78578898]
 [-510.63918081 -221.73218935  637.63918081  348.73218935]
 [-192.         -192.          319.          319.        ]
 [-258.53978877 -258.53978877  385.53978877  385.53978877]
 [-342.3746693  -342.3746693   469.3746693   469.3746693 ]
 [-118.         -300.          245.          427.        ]
 [-165.30563108 -394.61126216  292.30563108  521.61126216]
 [-224.90699146 -513.81398292  351.90699146  640.81398292]]
DEBUG:root:							return torch.from_numpy(anchors)
DEBUG:root:						} // END _generate_anchors(base_size, scales, apect_ratios) END
DEBUG:root:					} // END generate_anchors(stride, sizes, aspect_ratios)
DEBUG:root:			len(cell_anchors): 5
DEBUG:root:			cell_anchors[i].shape: torch.Size([9, 4])
DEBUG:root:			cell_anchors[i].shape: torch.Size([9, 4])
DEBUG:root:			cell_anchors[i].shape: torch.Size([9, 4])
DEBUG:root:			cell_anchors[i].shape: torch.Size([9, 4])
DEBUG:root:			cell_anchors[i].shape: torch.Size([9, 4])
DEBUG:root:	self.strides = anchor_strides
DEBUG:root:	// self.strides: (8, 16, 32, 64, 128)
DEBUG:root:	self.cell_anchors = BufferList(cell_anchors) // CALL
DEBUG:root:BufferList.__init__(slef, buffers=None) { // BEGIN
DEBUG:root:	// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:	Params
DEBUG:root:		len(buffers): 5
DEBUG:root:	super(BufferList, self).__init__()
DEBUG:root:if buffers is not None:
DEBUG:root:BufferList.extend(self, buffers) { // BEGIN
DEBUG:root:	// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
DEBUG:root:		Params
DEBUG:root:		len(buffers): 5

DEBUG:root:	offset = len(self)
DEBUG:root:	// offset: 0

DEBUG:root:	for i, buffer in enumerate(buffers) { // BEGIN
DEBUG:root:	t{ // BEGIN iteration 0
DEBUG:root:	#--------------------
DEBUG:root:buffer.shape: torch.Size([9, 4])
DEBUG:root:	#--------------------
DEBUG:root:self.register_buffer(str(offset + i), buffer)
DEBUG:root:		} // END iteration 0 
DEBUG:root:	t{ // BEGIN iteration 1
DEBUG:root:	#--------------------
DEBUG:root:buffer.shape: torch.Size([9, 4])
DEBUG:root:	#--------------------
DEBUG:root:self.register_buffer(str(offset + i), buffer)
DEBUG:root:		} // END iteration 1 
DEBUG:root:	t{ // BEGIN iteration 2
DEBUG:root:	#--------------------
DEBUG:root:buffer.shape: torch.Size([9, 4])
DEBUG:root:	#--------------------
DEBUG:root:self.register_buffer(str(offset + i), buffer)
DEBUG:root:		} // END iteration 2 
DEBUG:root:	t{ // BEGIN iteration 3
DEBUG:root:	#--------------------
DEBUG:root:buffer.shape: torch.Size([9, 4])
DEBUG:root:	#--------------------
DEBUG:root:self.register_buffer(str(offset + i), buffer)
DEBUG:root:		} // END iteration 3 
DEBUG:root:	t{ // BEGIN iteration 4
DEBUG:root:	#--------------------
DEBUG:root:buffer.shape: torch.Size([9, 4])
DEBUG:root:	#--------------------
DEBUG:root:self.register_buffer(str(offset + i), buffer)
DEBUG:root:		} // END iteration 4 
DEBUG:root:	} // END for i, buffer in enumerate(buffers)

DEBUG:root:	self: BufferList()
DEBUG:root:	return self
DEBUG:root:} // END BufferList.extend(self, buffers)
DEBUG:root:self.extend(buffers)
DEBUG:root:	len(buffers): 5
DEBUG:root:} // END BufferList.__init__(slef, buffers=None)
DEBUG:root:	self.cell_anchors = BufferList(cell_anchors) // RETURNED
DEBUG:root:	// self.cell_anchors: BufferList()
DEBUG:root:	self.straddle_thresh = straddle_thresh
DEBUG:root:	// self.straddle_thresh: -1
DEBUG:root:		} // END AnchorGenerator.__init__(sizes, aspect_ratios, anchor_strides, straddle_thresh)
DEBUG:root:				}
DEBUG:root:				anchor_generator = AnchorGenerator( tuple(new_anchor_sizes), aspect_ratios, anchor_strides, straddle_thresh ) // RETURNED
DEBUG:root:				// anchor_generator = AnchorGenerator(
  (cell_anchors): BufferList()
)

DEBUG:root:
		return anchor_generator
DEBUG:root:		} // make_anchor_generator_retinanet(config) END

DEBUG:root:	}
	anchor_generator = make_anchor_generator_retinanet(cfg) // RETURNED

DEBUG:root:	// anchor_generator: AnchorGenerator(
  (cell_anchors): BufferList()
)
DEBUG:root:	#============================
DEBUG:root:	# 1.2.2 RPN head build 
DEBUG:root:	#============================
DEBUG:root:	head = RetinaNetHead(cfg, in_channels=1024) // CALL
	{
DEBUG:root:

			RetinaNetHead.__init__(cfg, in_channels) { //BEGIN
DEBUG:root:				// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/retinanet/retinanet.py

DEBUG:root:				// Params:
DEBUG:root:					// cfg:
DEBUG:root:					//in_channles: 1024

DEBUG:root:				num_classes = cfg.MODEL.RETINANET.NUM_CLASSES - 1
DEBUG:root:				// num_classes: 1
DEBUG:root:				// cfg.MODEL.RETINANET.ASPECT_RATIOS: (0.5, 1.0, 2.0)
DEBUG:root:				// cfg.MODEL.RETINANET.SCALES_PER_OCTAVE: 3
DEBUG:root:				num_anchors = len(cfg.MODEL.RETINANET.ASPECT_RATIOS) \
DEBUG:root:				                * cfg.MODEL.RETINANET.SCALES_PER_OCTAVE
DEBUG:root:				// num_anchors: 9
DEBUG:root:

} // END RetinaNetHead._init__(cfg, in_channels)
DEBUG:root:	}
	head = RetinaNetHead(cfg, in_channels=1024) // RETURNED
DEBUG:root:	// head: RetinaNetHead(
  (cls_tower): Sequential(
    (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU()
    (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (5): ReLU()
    (6): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU()
  )
  (bbox_tower): Sequential(
    (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU()
    (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (5): ReLU()
    (6): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU()
  )
  (cls_logits): Conv2d(1024, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (bbox_pred): Conv2d(1024, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)
DEBUG:root:	#============================
DEBUG:root:	# 1.2.3 RPN box_coder build
DEBUG:root:	#============================
DEBUG:root:	box_coder = BoxCoder(weights=(10., 10., 5., 5.)) // CALL
	{
DEBUG:root:		BoxCoder.__init__(self, weights, bbox_xfrom_clip)__ { // BEGIN
DEBUG:root:			// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/box_coder.py
DEBUG:root:			// Params:
DEBUG:root:				weights: (10.0, 10.0, 5.0, 5.0)
DEBUG:root:				bbox_xform_clip: 4.135166556742356
DEBUG:root:				self.weights = weights
DEBUG:root:				self.bbox_xform_clip = bbox_xform_clip

DEBUG:root:		} // END BoxCoder.__init__(self, weights, bbox_xfrom_clip)__

DEBUG:root:	}
	box_coder = BoxCoder(weights=(10., 10., 5., 5.)) // RETURNED
DEBUG:root:	// box_coder: <maskrcnn_benchmark.modeling.box_coder.BoxCoder object at 0x7f3ce49bc588>
DEBUG:root:	#============================
DEBUG:root:	# 1.2.4 RPN box_selector_test build
DEBUG:root:	#============================
DEBUG:root:	box_selector_test = make_retinanet_postprocessor(cfg, box_coder) // CALL
	{
DEBUG:root:make_retinanet_postprocessor() { //BEGIN
DEBUG:root:	// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/retinanet/inference.py

DEBUG:root:	// Params:
DEBUG:root:		> config:
DEBUG:root:		> rpn_box_coder:

DEBUG:root:RPNPostProcessor.__init__() { //BEGIN
DEBUG:root:	// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/inference.py
DEBUG:root:} // END RPNPostProcessor.__init__()
DEBUG:root:RetinaNetPostProcessor.__init__() { //BEGIN
DEBUG:root:	// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/retinanet/inference.py

DEBUG:root:	// Params:
DEBUG:root:		> pre_nms_top_n: 1000
DEBUG:root:		> post_nms_top_n: 1000
DEBUG:root:		> nms_thresh: 0.4
DEBUG:root:		> min_size: 0
DEBUG:root:		> box_coder: <maskrcnn_benchmark.modeling.box_coder.BoxCoder object at 0x7f3ce49bc588>
DEBUG:root:		> fpn_post_nms_top_n: 100
DEBUG:root:	self.pre_nms_thresh = pre_nms_thresh
DEBUG:root:	self.pre_nms_top_n = pre_nms_top_n
DEBUG:root:	self.nms_thresh = nms_thresh
DEBUG:root:	self.fpn_post_nms_top_n = fpn_post_nms_top_n
DEBUG:root:	self.min_size = min_size
DEBUG:root:	self.num_classes = num_classes
DEBUG:root:	self.box_coder = box_coder

DEBUG:root:}// END RetinaNetPostProcessor.__init__()
DEBUG:root:} // END make_retinanet_postprocessor()
DEBUG:root:	}
	box_selector_test = make_retinanet_postprocessor(cfg, box_coder) // RETURNED
DEBUG:root:	// box_selector_test: RetinaNetPostProcessor()
DEBUG:root:	self.anchor_generator = anchor_generator
DEBUG:root:	self.head = head
DEBUG:root:	self.box_selector_test = box_selector_test
DEBUG:root:

} // RetinaNetModule.__init__(self, cfg, in_channels) END
DEBUG:root:	} // END build_retinanet(cfg, in_channels)
DEBUG:root:	self.rpn = build_rpn(cfg, self.backbone.out_channels) // RETURNED


DEBUG:root:	// self.rpn: RetinaNetModule(
  (anchor_generator): AnchorGenerator(
    (cell_anchors): BufferList()
  )
  (head): RetinaNetHead(
    (cls_tower): Sequential(
      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU()
      (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU()
      (6): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU()
    )
    (bbox_tower): Sequential(
      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU()
      (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU()
      (6): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU()
    )
    (cls_logits): Conv2d(1024, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (bbox_pred): Conv2d(1024, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (box_selector_test): RetinaNetPostProcessor()
)
DEBUG:root:
	} // END of 1.2

DEBUG:root:} // END GeneralizedRCNN.__init__(self, cfg)
DEBUG:root:	}
DEBUG:root:
	self.model = build_detection_model(self.cfg) // RETURNED
DEBUG:root:	// self.model: GeneralizedRCNN(
  (backbone): Sequential(
    (body): ResNet(
      (stem): StemWithFixedBatchNorm(
        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
        (bn1): FrozenBatchNorm2d()
      )
      (layer1): Sequential(
        (0): BottleneckWithFixedBatchNorm(
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): FrozenBatchNorm2d()
          )
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (1): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (2): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
      )
      (layer2): Sequential(
        (0): BottleneckWithFixedBatchNorm(
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): FrozenBatchNorm2d()
          )
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (1): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (2): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (3): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
      )
      (layer3): Sequential(
        (0): BottleneckWithFixedBatchNorm(
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): FrozenBatchNorm2d()
          )
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (1): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (2): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (3): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (4): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (5): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
      )
      (layer4): Sequential(
        (0): BottleneckWithFixedBatchNorm(
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): FrozenBatchNorm2d()
          )
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (1): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (2): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
      )
    )
    (fpn): FPN(
      (fpn_inner2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
      (fpn_layer2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (fpn_inner3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
      (fpn_layer3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (fpn_inner4): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
      (fpn_layer4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (top_blocks): LastLevelP6P7(
        (p6): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (p7): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      )
    )
  )
  (rpn): RetinaNetModule(
    (anchor_generator): AnchorGenerator(
      (cell_anchors): BufferList()
    )
    (head): RetinaNetHead(
      (cls_tower): Sequential(
        (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
        (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): ReLU()
        (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): ReLU()
        (6): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): ReLU()
      )
      (bbox_tower): Sequential(
        (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
        (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): ReLU()
        (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): ReLU()
        (6): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): ReLU()
      )
      (cls_logits): Conv2d(1024, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bbox_pred): Conv2d(1024, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (box_selector_test): RetinaNetPostProcessor()
  )
)


DEBUG:root:	# -----------------------------------------
DEBUG:root:	# 1.3 set to evaluation mode for interference
DEBUG:root:	# -----------------------------------------
DEBUG:root:	self.model.eval()

DEBUG:root:	// in detection_model_debug.py
DEBUG:root:	# -----------------------------------------
DEBUG:root:	# 1.4 Load Weight
DEBUG:root:	# -----------------------------------------
DEBUG:root:	checkpointer = DetectronCheckpointer(cfg, self.model, save_dir='/dev/null') // CALL
DEBUG:root:	checkpointer = DetectronCheckpointer(cfg, self.model, save_dir='/dev/null') // RETURNED
DEBUG:root:	_ = checkpointer.load(weight){// CALL
INFO:maskrcnn_benchmark.utils.checkpoint:Loading checkpoint from ./model/detection/model_det_v2_200924_002_180k.pth
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.bn1.bias                  loaded from backbone.body.layer1.0.bn1.bias                  of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.bn1.running_mean          loaded from backbone.body.layer1.0.bn1.running_mean          of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.bn1.running_var           loaded from backbone.body.layer1.0.bn1.running_var           of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.bn1.weight                loaded from backbone.body.layer1.0.bn1.weight                of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.bn2.bias                  loaded from backbone.body.layer1.0.bn2.bias                  of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.bn2.running_mean          loaded from backbone.body.layer1.0.bn2.running_mean          of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.bn2.running_var           loaded from backbone.body.layer1.0.bn2.running_var           of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.bn2.weight                loaded from backbone.body.layer1.0.bn2.weight                of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.bn3.bias                  loaded from backbone.body.layer1.0.bn3.bias                  of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.bn3.running_mean          loaded from backbone.body.layer1.0.bn3.running_mean          of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.bn3.running_var           loaded from backbone.body.layer1.0.bn3.running_var           of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.bn3.weight                loaded from backbone.body.layer1.0.bn3.weight                of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.conv1.weight              loaded from backbone.body.layer1.0.conv1.weight              of shape (64, 64, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.conv2.weight              loaded from backbone.body.layer1.0.conv2.weight              of shape (64, 64, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.conv3.weight              loaded from backbone.body.layer1.0.conv3.weight              of shape (256, 64, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.downsample.0.weight       loaded from backbone.body.layer1.0.downsample.0.weight       of shape (256, 64, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.downsample.1.bias         loaded from backbone.body.layer1.0.downsample.1.bias         of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.downsample.1.running_mean loaded from backbone.body.layer1.0.downsample.1.running_mean of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.downsample.1.running_var  loaded from backbone.body.layer1.0.downsample.1.running_var  of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.downsample.1.weight       loaded from backbone.body.layer1.0.downsample.1.weight       of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.bn1.bias                  loaded from backbone.body.layer1.1.bn1.bias                  of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.bn1.running_mean          loaded from backbone.body.layer1.1.bn1.running_mean          of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.bn1.running_var           loaded from backbone.body.layer1.1.bn1.running_var           of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.bn1.weight                loaded from backbone.body.layer1.1.bn1.weight                of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.bn2.bias                  loaded from backbone.body.layer1.1.bn2.bias                  of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.bn2.running_mean          loaded from backbone.body.layer1.1.bn2.running_mean          of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.bn2.running_var           loaded from backbone.body.layer1.1.bn2.running_var           of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.bn2.weight                loaded from backbone.body.layer1.1.bn2.weight                of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.bn3.bias                  loaded from backbone.body.layer1.1.bn3.bias                  of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.bn3.running_mean          loaded from backbone.body.layer1.1.bn3.running_mean          of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.bn3.running_var           loaded from backbone.body.layer1.1.bn3.running_var           of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.bn3.weight                loaded from backbone.body.layer1.1.bn3.weight                of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.conv1.weight              loaded from backbone.body.layer1.1.conv1.weight              of shape (64, 256, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.conv2.weight              loaded from backbone.body.layer1.1.conv2.weight              of shape (64, 64, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.conv3.weight              loaded from backbone.body.layer1.1.conv3.weight              of shape (256, 64, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.bn1.bias                  loaded from backbone.body.layer1.2.bn1.bias                  of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.bn1.running_mean          loaded from backbone.body.layer1.2.bn1.running_mean          of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.bn1.running_var           loaded from backbone.body.layer1.2.bn1.running_var           of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.bn1.weight                loaded from backbone.body.layer1.2.bn1.weight                of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.bn2.bias                  loaded from backbone.body.layer1.2.bn2.bias                  of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.bn2.running_mean          loaded from backbone.body.layer1.2.bn2.running_mean          of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.bn2.running_var           loaded from backbone.body.layer1.2.bn2.running_var           of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.bn2.weight                loaded from backbone.body.layer1.2.bn2.weight                of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.bn3.bias                  loaded from backbone.body.layer1.2.bn3.bias                  of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.bn3.running_mean          loaded from backbone.body.layer1.2.bn3.running_mean          of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.bn3.running_var           loaded from backbone.body.layer1.2.bn3.running_var           of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.bn3.weight                loaded from backbone.body.layer1.2.bn3.weight                of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.conv1.weight              loaded from backbone.body.layer1.2.conv1.weight              of shape (64, 256, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.conv2.weight              loaded from backbone.body.layer1.2.conv2.weight              of shape (64, 64, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.conv3.weight              loaded from backbone.body.layer1.2.conv3.weight              of shape (256, 64, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.bn1.bias                  loaded from backbone.body.layer2.0.bn1.bias                  of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.bn1.running_mean          loaded from backbone.body.layer2.0.bn1.running_mean          of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.bn1.running_var           loaded from backbone.body.layer2.0.bn1.running_var           of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.bn1.weight                loaded from backbone.body.layer2.0.bn1.weight                of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.bn2.bias                  loaded from backbone.body.layer2.0.bn2.bias                  of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.bn2.running_mean          loaded from backbone.body.layer2.0.bn2.running_mean          of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.bn2.running_var           loaded from backbone.body.layer2.0.bn2.running_var           of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.bn2.weight                loaded from backbone.body.layer2.0.bn2.weight                of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.bn3.bias                  loaded from backbone.body.layer2.0.bn3.bias                  of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.bn3.running_mean          loaded from backbone.body.layer2.0.bn3.running_mean          of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.bn3.running_var           loaded from backbone.body.layer2.0.bn3.running_var           of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.bn3.weight                loaded from backbone.body.layer2.0.bn3.weight                of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.conv1.weight              loaded from backbone.body.layer2.0.conv1.weight              of shape (128, 256, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.conv2.weight              loaded from backbone.body.layer2.0.conv2.weight              of shape (128, 128, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.conv3.weight              loaded from backbone.body.layer2.0.conv3.weight              of shape (512, 128, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.downsample.0.weight       loaded from backbone.body.layer2.0.downsample.0.weight       of shape (512, 256, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.downsample.1.bias         loaded from backbone.body.layer2.0.downsample.1.bias         of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.downsample.1.running_mean loaded from backbone.body.layer2.0.downsample.1.running_mean of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.downsample.1.running_var  loaded from backbone.body.layer2.0.downsample.1.running_var  of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.downsample.1.weight       loaded from backbone.body.layer2.0.downsample.1.weight       of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.bn1.bias                  loaded from backbone.body.layer2.1.bn1.bias                  of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.bn1.running_mean          loaded from backbone.body.layer2.1.bn1.running_mean          of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.bn1.running_var           loaded from backbone.body.layer2.1.bn1.running_var           of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.bn1.weight                loaded from backbone.body.layer2.1.bn1.weight                of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.bn2.bias                  loaded from backbone.body.layer2.1.bn2.bias                  of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.bn2.running_mean          loaded from backbone.body.layer2.1.bn2.running_mean          of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.bn2.running_var           loaded from backbone.body.layer2.1.bn2.running_var           of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.bn2.weight                loaded from backbone.body.layer2.1.bn2.weight                of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.bn3.bias                  loaded from backbone.body.layer2.1.bn3.bias                  of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.bn3.running_mean          loaded from backbone.body.layer2.1.bn3.running_mean          of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.bn3.running_var           loaded from backbone.body.layer2.1.bn3.running_var           of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.bn3.weight                loaded from backbone.body.layer2.1.bn3.weight                of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.conv1.weight              loaded from backbone.body.layer2.1.conv1.weight              of shape (128, 512, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.conv2.weight              loaded from backbone.body.layer2.1.conv2.weight              of shape (128, 128, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.conv3.weight              loaded from backbone.body.layer2.1.conv3.weight              of shape (512, 128, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.bn1.bias                  loaded from backbone.body.layer2.2.bn1.bias                  of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.bn1.running_mean          loaded from backbone.body.layer2.2.bn1.running_mean          of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.bn1.running_var           loaded from backbone.body.layer2.2.bn1.running_var           of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.bn1.weight                loaded from backbone.body.layer2.2.bn1.weight                of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.bn2.bias                  loaded from backbone.body.layer2.2.bn2.bias                  of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.bn2.running_mean          loaded from backbone.body.layer2.2.bn2.running_mean          of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.bn2.running_var           loaded from backbone.body.layer2.2.bn2.running_var           of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.bn2.weight                loaded from backbone.body.layer2.2.bn2.weight                of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.bn3.bias                  loaded from backbone.body.layer2.2.bn3.bias                  of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.bn3.running_mean          loaded from backbone.body.layer2.2.bn3.running_mean          of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.bn3.running_var           loaded from backbone.body.layer2.2.bn3.running_var           of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.bn3.weight                loaded from backbone.body.layer2.2.bn3.weight                of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.conv1.weight              loaded from backbone.body.layer2.2.conv1.weight              of shape (128, 512, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.conv2.weight              loaded from backbone.body.layer2.2.conv2.weight              of shape (128, 128, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.conv3.weight              loaded from backbone.body.layer2.2.conv3.weight              of shape (512, 128, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.bn1.bias                  loaded from backbone.body.layer2.3.bn1.bias                  of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.bn1.running_mean          loaded from backbone.body.layer2.3.bn1.running_mean          of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.bn1.running_var           loaded from backbone.body.layer2.3.bn1.running_var           of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.bn1.weight                loaded from backbone.body.layer2.3.bn1.weight                of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.bn2.bias                  loaded from backbone.body.layer2.3.bn2.bias                  of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.bn2.running_mean          loaded from backbone.body.layer2.3.bn2.running_mean          of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.bn2.running_var           loaded from backbone.body.layer2.3.bn2.running_var           of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.bn2.weight                loaded from backbone.body.layer2.3.bn2.weight                of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.bn3.bias                  loaded from backbone.body.layer2.3.bn3.bias                  of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.bn3.running_mean          loaded from backbone.body.layer2.3.bn3.running_mean          of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.bn3.running_var           loaded from backbone.body.layer2.3.bn3.running_var           of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.bn3.weight                loaded from backbone.body.layer2.3.bn3.weight                of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.conv1.weight              loaded from backbone.body.layer2.3.conv1.weight              of shape (128, 512, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.conv2.weight              loaded from backbone.body.layer2.3.conv2.weight              of shape (128, 128, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.conv3.weight              loaded from backbone.body.layer2.3.conv3.weight              of shape (512, 128, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.bn1.bias                  loaded from backbone.body.layer3.0.bn1.bias                  of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.bn1.running_mean          loaded from backbone.body.layer3.0.bn1.running_mean          of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.bn1.running_var           loaded from backbone.body.layer3.0.bn1.running_var           of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.bn1.weight                loaded from backbone.body.layer3.0.bn1.weight                of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.bn2.bias                  loaded from backbone.body.layer3.0.bn2.bias                  of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.bn2.running_mean          loaded from backbone.body.layer3.0.bn2.running_mean          of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.bn2.running_var           loaded from backbone.body.layer3.0.bn2.running_var           of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.bn2.weight                loaded from backbone.body.layer3.0.bn2.weight                of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.bn3.bias                  loaded from backbone.body.layer3.0.bn3.bias                  of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.bn3.running_mean          loaded from backbone.body.layer3.0.bn3.running_mean          of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.bn3.running_var           loaded from backbone.body.layer3.0.bn3.running_var           of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.bn3.weight                loaded from backbone.body.layer3.0.bn3.weight                of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.conv1.weight              loaded from backbone.body.layer3.0.conv1.weight              of shape (256, 512, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.conv2.weight              loaded from backbone.body.layer3.0.conv2.weight              of shape (256, 256, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.conv3.weight              loaded from backbone.body.layer3.0.conv3.weight              of shape (1024, 256, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.downsample.0.weight       loaded from backbone.body.layer3.0.downsample.0.weight       of shape (1024, 512, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.downsample.1.bias         loaded from backbone.body.layer3.0.downsample.1.bias         of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.downsample.1.running_mean loaded from backbone.body.layer3.0.downsample.1.running_mean of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.downsample.1.running_var  loaded from backbone.body.layer3.0.downsample.1.running_var  of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.downsample.1.weight       loaded from backbone.body.layer3.0.downsample.1.weight       of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.bn1.bias                  loaded from backbone.body.layer3.1.bn1.bias                  of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.bn1.running_mean          loaded from backbone.body.layer3.1.bn1.running_mean          of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.bn1.running_var           loaded from backbone.body.layer3.1.bn1.running_var           of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.bn1.weight                loaded from backbone.body.layer3.1.bn1.weight                of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.bn2.bias                  loaded from backbone.body.layer3.1.bn2.bias                  of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.bn2.running_mean          loaded from backbone.body.layer3.1.bn2.running_mean          of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.bn2.running_var           loaded from backbone.body.layer3.1.bn2.running_var           of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.bn2.weight                loaded from backbone.body.layer3.1.bn2.weight                of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.bn3.bias                  loaded from backbone.body.layer3.1.bn3.bias                  of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.bn3.running_mean          loaded from backbone.body.layer3.1.bn3.running_mean          of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.bn3.running_var           loaded from backbone.body.layer3.1.bn3.running_var           of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.bn3.weight                loaded from backbone.body.layer3.1.bn3.weight                of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.conv1.weight              loaded from backbone.body.layer3.1.conv1.weight              of shape (256, 1024, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.conv2.weight              loaded from backbone.body.layer3.1.conv2.weight              of shape (256, 256, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.conv3.weight              loaded from backbone.body.layer3.1.conv3.weight              of shape (1024, 256, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.bn1.bias                  loaded from backbone.body.layer3.2.bn1.bias                  of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.bn1.running_mean          loaded from backbone.body.layer3.2.bn1.running_mean          of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.bn1.running_var           loaded from backbone.body.layer3.2.bn1.running_var           of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.bn1.weight                loaded from backbone.body.layer3.2.bn1.weight                of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.bn2.bias                  loaded from backbone.body.layer3.2.bn2.bias                  of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.bn2.running_mean          loaded from backbone.body.layer3.2.bn2.running_mean          of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.bn2.running_var           loaded from backbone.body.layer3.2.bn2.running_var           of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.bn2.weight                loaded from backbone.body.layer3.2.bn2.weight                of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.bn3.bias                  loaded from backbone.body.layer3.2.bn3.bias                  of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.bn3.running_mean          loaded from backbone.body.layer3.2.bn3.running_mean          of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.bn3.running_var           loaded from backbone.body.layer3.2.bn3.running_var           of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.bn3.weight                loaded from backbone.body.layer3.2.bn3.weight                of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.conv1.weight              loaded from backbone.body.layer3.2.conv1.weight              of shape (256, 1024, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.conv2.weight              loaded from backbone.body.layer3.2.conv2.weight              of shape (256, 256, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.conv3.weight              loaded from backbone.body.layer3.2.conv3.weight              of shape (1024, 256, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.bn1.bias                  loaded from backbone.body.layer3.3.bn1.bias                  of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.bn1.running_mean          loaded from backbone.body.layer3.3.bn1.running_mean          of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.bn1.running_var           loaded from backbone.body.layer3.3.bn1.running_var           of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.bn1.weight                loaded from backbone.body.layer3.3.bn1.weight                of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.bn2.bias                  loaded from backbone.body.layer3.3.bn2.bias                  of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.bn2.running_mean          loaded from backbone.body.layer3.3.bn2.running_mean          of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.bn2.running_var           loaded from backbone.body.layer3.3.bn2.running_var           of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.bn2.weight                loaded from backbone.body.layer3.3.bn2.weight                of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.bn3.bias                  loaded from backbone.body.layer3.3.bn3.bias                  of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.bn3.running_mean          loaded from backbone.body.layer3.3.bn3.running_mean          of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.bn3.running_var           loaded from backbone.body.layer3.3.bn3.running_var           of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.bn3.weight                loaded from backbone.body.layer3.3.bn3.weight                of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.conv1.weight              loaded from backbone.body.layer3.3.conv1.weight              of shape (256, 1024, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.conv2.weight              loaded from backbone.body.layer3.3.conv2.weight              of shape (256, 256, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.conv3.weight              loaded from backbone.body.layer3.3.conv3.weight              of shape (1024, 256, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.bn1.bias                  loaded from backbone.body.layer3.4.bn1.bias                  of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.bn1.running_mean          loaded from backbone.body.layer3.4.bn1.running_mean          of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.bn1.running_var           loaded from backbone.body.layer3.4.bn1.running_var           of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.bn1.weight                loaded from backbone.body.layer3.4.bn1.weight                of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.bn2.bias                  loaded from backbone.body.layer3.4.bn2.bias                  of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.bn2.running_mean          loaded from backbone.body.layer3.4.bn2.running_mean          of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.bn2.running_var           loaded from backbone.body.layer3.4.bn2.running_var           of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.bn2.weight                loaded from backbone.body.layer3.4.bn2.weight                of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.bn3.bias                  loaded from backbone.body.layer3.4.bn3.bias                  of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.bn3.running_mean          loaded from backbone.body.layer3.4.bn3.running_mean          of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.bn3.running_var           loaded from backbone.body.layer3.4.bn3.running_var           of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.bn3.weight                loaded from backbone.body.layer3.4.bn3.weight                of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.conv1.weight              loaded from backbone.body.layer3.4.conv1.weight              of shape (256, 1024, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.conv2.weight              loaded from backbone.body.layer3.4.conv2.weight              of shape (256, 256, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.conv3.weight              loaded from backbone.body.layer3.4.conv3.weight              of shape (1024, 256, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.bn1.bias                  loaded from backbone.body.layer3.5.bn1.bias                  of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.bn1.running_mean          loaded from backbone.body.layer3.5.bn1.running_mean          of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.bn1.running_var           loaded from backbone.body.layer3.5.bn1.running_var           of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.bn1.weight                loaded from backbone.body.layer3.5.bn1.weight                of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.bn2.bias                  loaded from backbone.body.layer3.5.bn2.bias                  of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.bn2.running_mean          loaded from backbone.body.layer3.5.bn2.running_mean          of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.bn2.running_var           loaded from backbone.body.layer3.5.bn2.running_var           of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.bn2.weight                loaded from backbone.body.layer3.5.bn2.weight                of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.bn3.bias                  loaded from backbone.body.layer3.5.bn3.bias                  of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.bn3.running_mean          loaded from backbone.body.layer3.5.bn3.running_mean          of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.bn3.running_var           loaded from backbone.body.layer3.5.bn3.running_var           of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.bn3.weight                loaded from backbone.body.layer3.5.bn3.weight                of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.conv1.weight              loaded from backbone.body.layer3.5.conv1.weight              of shape (256, 1024, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.conv2.weight              loaded from backbone.body.layer3.5.conv2.weight              of shape (256, 256, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.conv3.weight              loaded from backbone.body.layer3.5.conv3.weight              of shape (1024, 256, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.bn1.bias                  loaded from backbone.body.layer4.0.bn1.bias                  of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.bn1.running_mean          loaded from backbone.body.layer4.0.bn1.running_mean          of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.bn1.running_var           loaded from backbone.body.layer4.0.bn1.running_var           of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.bn1.weight                loaded from backbone.body.layer4.0.bn1.weight                of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.bn2.bias                  loaded from backbone.body.layer4.0.bn2.bias                  of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.bn2.running_mean          loaded from backbone.body.layer4.0.bn2.running_mean          of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.bn2.running_var           loaded from backbone.body.layer4.0.bn2.running_var           of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.bn2.weight                loaded from backbone.body.layer4.0.bn2.weight                of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.bn3.bias                  loaded from backbone.body.layer4.0.bn3.bias                  of shape (2048,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.bn3.running_mean          loaded from backbone.body.layer4.0.bn3.running_mean          of shape (2048,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.bn3.running_var           loaded from backbone.body.layer4.0.bn3.running_var           of shape (2048,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.bn3.weight                loaded from backbone.body.layer4.0.bn3.weight                of shape (2048,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.conv1.weight              loaded from backbone.body.layer4.0.conv1.weight              of shape (512, 1024, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.conv2.weight              loaded from backbone.body.layer4.0.conv2.weight              of shape (512, 512, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.conv3.weight              loaded from backbone.body.layer4.0.conv3.weight              of shape (2048, 512, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.downsample.0.weight       loaded from backbone.body.layer4.0.downsample.0.weight       of shape (2048, 1024, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.downsample.1.bias         loaded from backbone.body.layer4.0.downsample.1.bias         of shape (2048,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.downsample.1.running_mean loaded from backbone.body.layer4.0.downsample.1.running_mean of shape (2048,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.downsample.1.running_var  loaded from backbone.body.layer4.0.downsample.1.running_var  of shape (2048,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.downsample.1.weight       loaded from backbone.body.layer4.0.downsample.1.weight       of shape (2048,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.bn1.bias                  loaded from backbone.body.layer4.1.bn1.bias                  of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.bn1.running_mean          loaded from backbone.body.layer4.1.bn1.running_mean          of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.bn1.running_var           loaded from backbone.body.layer4.1.bn1.running_var           of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.bn1.weight                loaded from backbone.body.layer4.1.bn1.weight                of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.bn2.bias                  loaded from backbone.body.layer4.1.bn2.bias                  of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.bn2.running_mean          loaded from backbone.body.layer4.1.bn2.running_mean          of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.bn2.running_var           loaded from backbone.body.layer4.1.bn2.running_var           of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.bn2.weight                loaded from backbone.body.layer4.1.bn2.weight                of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.bn3.bias                  loaded from backbone.body.layer4.1.bn3.bias                  of shape (2048,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.bn3.running_mean          loaded from backbone.body.layer4.1.bn3.running_mean          of shape (2048,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.bn3.running_var           loaded from backbone.body.layer4.1.bn3.running_var           of shape (2048,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.bn3.weight                loaded from backbone.body.layer4.1.bn3.weight                of shape (2048,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.conv1.weight              loaded from backbone.body.layer4.1.conv1.weight              of shape (512, 2048, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.conv2.weight              loaded from backbone.body.layer4.1.conv2.weight              of shape (512, 512, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.conv3.weight              loaded from backbone.body.layer4.1.conv3.weight              of shape (2048, 512, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.bn1.bias                  loaded from backbone.body.layer4.2.bn1.bias                  of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.bn1.running_mean          loaded from backbone.body.layer4.2.bn1.running_mean          of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.bn1.running_var           loaded from backbone.body.layer4.2.bn1.running_var           of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.bn1.weight                loaded from backbone.body.layer4.2.bn1.weight                of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.bn2.bias                  loaded from backbone.body.layer4.2.bn2.bias                  of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.bn2.running_mean          loaded from backbone.body.layer4.2.bn2.running_mean          of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.bn2.running_var           loaded from backbone.body.layer4.2.bn2.running_var           of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.bn2.weight                loaded from backbone.body.layer4.2.bn2.weight                of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.bn3.bias                  loaded from backbone.body.layer4.2.bn3.bias                  of shape (2048,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.bn3.running_mean          loaded from backbone.body.layer4.2.bn3.running_mean          of shape (2048,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.bn3.running_var           loaded from backbone.body.layer4.2.bn3.running_var           of shape (2048,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.bn3.weight                loaded from backbone.body.layer4.2.bn3.weight                of shape (2048,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.conv1.weight              loaded from backbone.body.layer4.2.conv1.weight              of shape (512, 2048, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.conv2.weight              loaded from backbone.body.layer4.2.conv2.weight              of shape (512, 512, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.conv3.weight              loaded from backbone.body.layer4.2.conv3.weight              of shape (2048, 512, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.stem.bn1.bias                      loaded from backbone.body.stem.bn1.bias                      of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.stem.bn1.running_mean              loaded from backbone.body.stem.bn1.running_mean              of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.stem.bn1.running_var               loaded from backbone.body.stem.bn1.running_var               of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.stem.bn1.weight                    loaded from backbone.body.stem.bn1.weight                    of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.stem.conv1.weight                  loaded from backbone.body.stem.conv1.weight                  of shape (64, 3, 7, 7)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.fpn_inner2.bias                     loaded from backbone.fpn.fpn_inner2.bias                     of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.fpn_inner2.weight                   loaded from backbone.fpn.fpn_inner2.weight                   of shape (1024, 512, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.fpn_inner3.bias                     loaded from backbone.fpn.fpn_inner3.bias                     of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.fpn_inner3.weight                   loaded from backbone.fpn.fpn_inner3.weight                   of shape (1024, 1024, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.fpn_inner4.bias                     loaded from backbone.fpn.fpn_inner4.bias                     of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.fpn_inner4.weight                   loaded from backbone.fpn.fpn_inner4.weight                   of shape (1024, 2048, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.fpn_layer2.bias                     loaded from backbone.fpn.fpn_layer2.bias                     of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.fpn_layer2.weight                   loaded from backbone.fpn.fpn_layer2.weight                   of shape (1024, 1024, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.fpn_layer3.bias                     loaded from backbone.fpn.fpn_layer3.bias                     of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.fpn_layer3.weight                   loaded from backbone.fpn.fpn_layer3.weight                   of shape (1024, 1024, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.fpn_layer4.bias                     loaded from backbone.fpn.fpn_layer4.bias                     of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.fpn_layer4.weight                   loaded from backbone.fpn.fpn_layer4.weight                   of shape (1024, 1024, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.top_blocks.p6.bias                  loaded from backbone.fpn.top_blocks.p6.bias                  of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.top_blocks.p6.weight                loaded from backbone.fpn.top_blocks.p6.weight                of shape (1024, 2048, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.top_blocks.p7.bias                  loaded from backbone.fpn.top_blocks.p7.bias                  of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.top_blocks.p7.weight                loaded from backbone.fpn.top_blocks.p7.weight                of shape (1024, 1024, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.anchor_generator.cell_anchors.0              loaded from rpn.anchor_generator.cell_anchors.0              of shape (9, 4)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.anchor_generator.cell_anchors.1              loaded from rpn.anchor_generator.cell_anchors.1              of shape (9, 4)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.anchor_generator.cell_anchors.2              loaded from rpn.anchor_generator.cell_anchors.2              of shape (9, 4)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.anchor_generator.cell_anchors.3              loaded from rpn.anchor_generator.cell_anchors.3              of shape (9, 4)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.anchor_generator.cell_anchors.4              loaded from rpn.anchor_generator.cell_anchors.4              of shape (9, 4)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.bbox_pred.bias                          loaded from rpn.head.bbox_pred.bias                          of shape (36,)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.bbox_pred.weight                        loaded from rpn.head.bbox_pred.weight                        of shape (36, 1024, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.bbox_tower.0.bias                       loaded from rpn.head.bbox_tower.0.bias                       of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.bbox_tower.0.weight                     loaded from rpn.head.bbox_tower.0.weight                     of shape (1024, 1024, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.bbox_tower.2.bias                       loaded from rpn.head.bbox_tower.2.bias                       of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.bbox_tower.2.weight                     loaded from rpn.head.bbox_tower.2.weight                     of shape (1024, 1024, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.bbox_tower.4.bias                       loaded from rpn.head.bbox_tower.4.bias                       of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.bbox_tower.4.weight                     loaded from rpn.head.bbox_tower.4.weight                     of shape (1024, 1024, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.bbox_tower.6.bias                       loaded from rpn.head.bbox_tower.6.bias                       of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.bbox_tower.6.weight                     loaded from rpn.head.bbox_tower.6.weight                     of shape (1024, 1024, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.cls_logits.bias                         loaded from rpn.head.cls_logits.bias                         of shape (9,)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.cls_logits.weight                       loaded from rpn.head.cls_logits.weight                       of shape (9, 1024, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.cls_tower.0.bias                        loaded from rpn.head.cls_tower.0.bias                        of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.cls_tower.0.weight                      loaded from rpn.head.cls_tower.0.weight                      of shape (1024, 1024, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.cls_tower.2.bias                        loaded from rpn.head.cls_tower.2.bias                        of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.cls_tower.2.weight                      loaded from rpn.head.cls_tower.2.weight                      of shape (1024, 1024, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.cls_tower.4.bias                        loaded from rpn.head.cls_tower.4.bias                        of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.cls_tower.4.weight                      loaded from rpn.head.cls_tower.4.weight                      of shape (1024, 1024, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.cls_tower.6.bias                        loaded from rpn.head.cls_tower.6.bias                        of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.cls_tower.6.weight                      loaded from rpn.head.cls_tower.6.weight                      of shape (1024, 1024, 3, 3)
DEBUG:root:	} _ = checkpointer.load(weight) // RETURNED
DEBUG:root:	# -----------------------------------------
DEBUG:root:	# 1.5 Build Transfroms
DEBUG:root:	# -----------------------------------------
DEBUG:root:	self.transforms = build_transforms(self.cfg, self.is_recognition) // CALL
DEBUG:root:
		Compose.__init__(self, transforms { // BEGIN
DEBUG:root:			// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/data/transforms/transforms.py
DEBUG:root:
			// Params:
DEBUG:root:				transforms: [<maskrcnn_benchmark.data.transforms.transforms.Resize object at 0x7f3ce49e0080>, <maskrcnn_benchmark.data.transforms.transforms.ToTensor object at 0x7f3ce49e0128>, <maskrcnn_benchmark.data.transforms.transforms.Normalize object at 0x7f3ce49e00b8>]
DEBUG:root:
			self.transforms = transforms
DEBUG:root:			// self.transforms: [<maskrcnn_benchmark.data.transforms.transforms.Resize object at 0x7f3ce49e0080>, <maskrcnn_benchmark.data.transforms.transforms.ToTensor object at 0x7f3ce49e0128>, <maskrcnn_benchmark.data.transforms.transforms.Normalize object at 0x7f3ce49e00b8>]
DEBUG:root:
		Compose.__init__(self, transforms } // END
DEBUG:root:	self.transforms = build_transforms(self.cfg, self.is_recognition) // RETURNED
DEBUG:root:	// self.cfg.TEST.SCORE_THRESHOLD:0.3
DEBUG:root:	self.score_thresh = self.cfg.TEST.SCORE_THRESHOLD
DEBUG:root:} // END DetectionDemo.__init__



DEBUG:root:# =======================================
DEBUG:root:# II. Model Forward with test image
DEBUG:root:# =======================================


DEBUG:root:compute_prediction(self, image) { // BEGIN
DEBUG:root:	// defined in detection_model_debug.py

DEBUG:root:
	// Params:
DEBUG:root:		> image.width: 512
DEBUG:root:		> image.height: 438

DEBUG:root:	# ==================================
DEBUG:root:	# 2-1 Transformer to input image
DEBUG:root:	# ==================================
DEBUG:root:	image_tensor = self.transforms(image) // CALL
	{
DEBUG:root:
		Compose.__call__(self, image) { // BEGIN
DEBUG:root:			// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/data/transforms/transforms.py
DEBUG:root:
			// Params:
DEBUG:root:				type(image): <class 'PIL.Image.Image'>
DEBUG:root:				image.height: 438
DEBUG:root:				image.width: 512
DEBUG:root:
			for t in self.transforms:
DEBUG:root:				image = <maskrcnn_benchmark.data.transforms.transforms.Resize object at 0x7f3ce49e0080>(image)
DEBUG:root:				type(image): <class 'PIL.Image.Image'>
DEBUG:root:				image.height: 480
DEBUG:root:				image.width: 561
DEBUG:root:				image = <maskrcnn_benchmark.data.transforms.transforms.ToTensor object at 0x7f3ce49e0128>(image)
DEBUG:root:				type(image): <class 'torch.Tensor'>
DEBUG:root:				image.size(): torch.Size([3, 480, 561])
DEBUG:root:				image = <maskrcnn_benchmark.data.transforms.transforms.Normalize object at 0x7f3ce49e00b8>(image)
DEBUG:root:				type(image): <class 'torch.Tensor'>
DEBUG:root:				image.size(): torch.Size([3, 480, 561])
DEBUG:root:
			return image
DEBUG:root:
		} // END Compose.__call__()
DEBUG:root:
	} image_tensor = self.transforms(image) // RETURNED
DEBUG:root:	// image_tensor.shape: torch.Size([3, 480, 561])

DEBUG:root:	# ==================================
DEBUG:root:	# 2-2 Zero padding and Batched Input
DEBUG:root:	# ==================================
DEBUG:root:
	// padding images for 32 divisible size on width and height
DEBUG:root:	// self.cfg.DATALOADER.SIZE_DIVISIBILITY: 32
DEBUG:root:	// self.device: cuda
DEBUG:root:	image_list = to_image_list(image_tensor, self.cfg.DATALOADER.SIZE_DIVISIBILITY).to(self.device) // CALL
	{
DEBUG:root:
	to_image_list(tensors, size_divisible=0) { // BEGIN
DEBUG:root:		// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/structures/image_list.py

DEBUG:root:		// Params:
DEBUG:root:			> type(tensors): <class 'torch.Tensor'>
DEBUG:root:			> size_divisible: 32

DEBUG:root:		if isinstance(tensors, torch.Tensor) and size_divisible > 0:
DEBUG:root:			tensors = [tensors]
DEBUG:root:			// len(tensors]: 1
DEBUG:root:			// tensors[0].shape: torch.Size([3, 480, 561])

DEBUG:root:		elif isinstance(tensors, (tuple, list)):
DEBUG:root:			max_size = tuple(max(s) for s in zip(*[img.shape for img in tensors]))
DEBUG:root:			// max_size: (3, 480, 561)

DEBUG:root:			if size_divisible > 0:
DEBUG:root:				import math

DEBUG:root:				stride = size_divisible
DEBUG:root:				// stride: 32

DEBUG:root:				max_size = list(max_size)
DEBUG:root:				// max_size: [3, 480, 561]

DEBUG:root:				max_size[1] = int(math.ceil(max_size[1] / stride) * stride)
DEBUG:root:				// max_size[1]: 480

DEBUG:root:				max_size[2] = int(math.ceil(max_size[2] / stride) * stride)
DEBUG:root:				// max_size[2]: 576

DEBUG:root:				max_size = tuple(max_size)
DEBUG:root:				max_size: (3, 480, 576)

DEBUG:root:			batch_shape = (len(tensors),) + max_size
DEBUG:root:			batch_shape: (1, 3, 480, 576)

DEBUG:root:			# make batch_imgs by adding axis with all pixel values is zero
DEBUG:root:			batched_imgs = tensors[0].new(*batch_shape).zero_()
DEBUG:root:			batched_imgs.shape: torch.Size([1, 3, 480, 576])

DEBUG:root:			# overlay tensors on batch_imgs (pad)img
DEBUG:root:			for img, pad_img in zip(tensors, batched_imgs):
DEBUG:root:				pad_img[: img.shape[0], : img.shape[1], : img.shape[2]].copy_(img)

DEBUG:root:			image_sizes = [im.shape[-2:] for im in tensors]
DEBUG:root:			// image_sizes: [torch.Size([480, 561])]

DEBUG:root:			// type(batched_imgs): <class 'torch.Tensor'>

DEBUG:root:			// batched_imgs.shape: torch.Size([1, 3, 480, 576])
DEBUG:root:			// image_sizes: [torch.Size([480, 561])]

DEBUG:root:			return ImageList(batched_imgs, image_sizes) // CALL
DEBUG:root:
	ImageList.__init__(self, tensors, image_sizes) { // BEGIN
DEBUG:root:		// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/structures/image_list.py

DEBUG:root:		// Params:
DEBUG:root:			> tensors.shape: torch.Size([1, 3, 480, 576])
DEBUG:root:			> image_sizes: [torch.Size([480, 561])]

DEBUG:root:		self.tensors = tensors
DEBUG:root:		self.image_sizes = image_sizes
DEBUG:root:	} // END ImageList.__init__(self, tensors, image_sizes)

DEBUG:root:
	ImageList.to(self, *args, **kwargs) { // BEGIN
DEBUG:root:		// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/structures/image_list.py

DEBUG:root:		// Params:
DEBUG:root:			args: (device(type='cuda'),)
DEBUG:root:			kwargs: {}

DEBUG:root:		cast_tensor = self.tensors.to(*args, **kwargs)
DEBUG:root:		// cast_tensor: cast_tensor
DEBUG:root:	} // END ImageList.to(self, *args, **kwargs)

DEBUG:root:
	ImageList.__init__(self, tensors, image_sizes) { // BEGIN
DEBUG:root:		// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/structures/image_list.py

DEBUG:root:		// Params:
DEBUG:root:			> tensors.shape: torch.Size([1, 3, 480, 576])
DEBUG:root:			> image_sizes: [torch.Size([480, 561])]

DEBUG:root:		self.tensors = tensors
DEBUG:root:		self.image_sizes = image_sizes
DEBUG:root:	} // END ImageList.__init__(self, tensors, image_sizes)

DEBUG:root:
	} // END to_image_list(tensors, size_divisible=0)

DEBUG:root:	image_list = to_image_list(image_tensor, self.cfg.DATALOADER.SIZE_DIVISIBILITY).to(self.device) // RETURNED
DEBUG:root:	// image_list.image_sizes: [torch.Size([480, 561])]
DEBUG:root:	// image_list.tensors.shape: torch.Size([1, 3, 480, 576])
DEBUG:root:


DEBUG:root:	# ==============================
DEBUG:root:	# 2-3 Inference with input image
DEBUG:root:	# ==============================
DEBUG:root:	with torch.no_grad():
DEBUG:root:		pred = self.model(image_list) // CALL
DEBUG:root:

	GeneralizedRCNN.forward(self, images, targets=None) { //BEGIN
DEBUG:root:	// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/detector/generalized_rcnn.py

DEBUG:root:		// Params:
DEBUG:root:			> images:
DEBUG:root:			> type(images): <class 'maskrcnn_benchmark.structures.image_list.ImageList'>
DEBUG:root:			> targets: None

DEBUG:root:	if self.training: False
DEBUG:root:	images = to_image_list(images) // CALL
	{
DEBUG:root:
	to_image_list(tensors, size_divisible=0) { // BEGIN
DEBUG:root:		// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/structures/image_list.py

DEBUG:root:		// Params:
DEBUG:root:			> type(tensors): <class 'maskrcnn_benchmark.structures.image_list.ImageList'>
DEBUG:root:			> size_divisible: 0

DEBUG:root:		if isinstance(tensors, ImageList):
DEBUG:root:			return tensors

DEBUG:root:
	} // END to_image_list(tensors, size_divisible=0)
DEBUG:root:
	}
	images = to_image_list(images) // RETURNED

DEBUG:root:	images.image_sizes: [torch.Size([480, 561])]
DEBUG:root:	images.tensors.shape: torch.Size([1, 3, 480, 576])
DEBUG:root:	# ===========================================
DEBUG:root:	# 2-3-1 Backbone Forward
DEBUG:root:	# ===========================================
DEBUG:root:	model.backbone.forward(images.tensors) // CALL
	{
DEBUG:root:


DEBUG:root:		# =================================
DEBUG:root:		# 2-3-1-1 ResNet Forward
DEBUG:root:		# =================================

DEBUG:root:	Resnet.forward(self, x) { //BEGIN
DEBUG:root:		// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/resnet.py

DEBUG:root:		Param
DEBUG:root:			x.shape=torch.Size([1, 3, 480, 576])

DEBUG:root:		# =================================
DEBUG:root:		# 2-3-1-1-1 stem (layer0) forward
DEBUG:root:		# =================================


DEBUG:root:		x = self.stem(x) { // CALL

DEBUG:root:
	BaseStem.forward(self, x) { //BEGIN
DEBUG:root:		// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/resnet.py

DEBUG:root:		// Params:
DEBUG:root:			> x.shape: torch.Size([1, 3, 480, 576])

DEBUG:root:		x = self.conv1(x)
DEBUG:root:		// self.conv1: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
DEBUG:root:		// x.shape: torch.Size([1, 64, 240, 288])

DEBUG:root:		stem conv1 output of shape (1, 64, 240, 288) saved into ./npy_save/backbone_body_stem_conv1_output.npy.npy


DEBUG:root:		x = self.bn1(x)
DEBUG:root:		// self.bn1: FrozenBatchNorm2d()
DEBUG:root:		// x.shape: torch.Size([1, 64, 240, 288])

DEBUG:root:		stem bn1 output of shape (1, 64, 240, 288) saved into ./npy_save/backbone_body_stem_bn1_output.npy.npy


DEBUG:root:		x = F.relu_(x)
DEBUG:root:		// x.shape: torch.Size([1, 64, 240, 288])

DEBUG:root:		stem relu output of shape (1, 64, 240, 288) saved into ./npy_save/backbone_body_stem_relu_output.npy.npy


DEBUG:root:		x = F.max_pool2d(x, kernel_size=3, stride=2, ceil_mode=True)
DEBUG:root:		// x.shape: torch.Size([1, 64, 120, 144])

DEBUG:root:		stem maxpool output of shape (1, 64, 120, 144) saved into ./npy_save/backbone_body_stem_maxpool_output.npy.npy


DEBUG:root:	return x

DEBUG:root:
	} // END BaseStem.forward()
DEBUG:root:
		}
DEBUG:root:
		x = self.stem(x) // RETURNED
DEBUG:root:		// x.shape: torch.Size([1, 64, 120, 144])

DEBUG:root:		stem output of shape (1, 64, 120, 144) saved into ./npy_save/stem_output.npy


DEBUG:root:		for stage_name in self.stages:
		{
DEBUG:root:			# =================================
DEBUG:root:			# 2-3-1-1-1 forward
DEBUG:root:			# =================================
DEBUG:root:			{ // BEGIN of iteration for 1 for layer1

DEBUG:root:			x = getattr(self, stage_name)(x) { // CALL

DEBUG:root:
	Bottleneck.__forward__(self.x) { //BEGIN
DEBUG:root:		// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/resnet.py

DEBUG:root:		Params:
DEBUG:root:			x.shape : torch.Size([1, 64, 120, 144])

DEBUG:root:			self : BottleneckWithFixedBatchNorm(
  (downsample): Sequential(
    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): FrozenBatchNorm2d()
  )
  (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): FrozenBatchNorm2d()
  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): FrozenBatchNorm2d()
  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): FrozenBatchNorm2d()
)

DEBUG:root:		// # Identity connection, directly make the residual equal to x
DEBUG:root:		identity = x

DEBUG:root:		// # conv1, bn1, relu (in place relu)
DEBUG:root:		// self.conv1: Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
DEBUG:root:		// self.bn1: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv1(x)
DEBUG:root:		// out.shape: torch.Size([1, 64, 120, 144])

DEBUG:root:		out = self.bn1(out)
DEBUG:root:		// out.shape: torch.Size([1, 64, 120, 144])

DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 64, 120, 144])


DEBUG:root:		// # conv2, bn2, relu (in place relu)
DEBUG:root:		// self.conv2: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
DEBUG:root:		// self.bn2: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv2(x)
DEBUG:root:		// out.shape: torch.Size([1, 64, 120, 144])

DEBUG:root:		out = self.bn2(out)
DEBUG:root:		// out.shape: torch.Size([1, 64, 120, 144])

DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 64, 120, 144])


DEBUG:root:		// # conv3, bn3, not relu here
DEBUG:root:		// self.conv3: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
DEBUG:root:		// self.bn3: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv3(x)
DEBUG:root:		// out.shape: torch.Size([1, 256, 120, 144])

DEBUG:root:		out = self.bn3(out)
DEBUG:root:		// out.shape: torch.Size([1, 256, 120, 144])


DEBUG:root:		// # If the number of input and output channels are different,
DEBUG:root:		// # they need to be mapped to make them the same.
DEBUG:root:		// self.downsample: Sequential(
  (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (1): FrozenBatchNorm2d()
)
DEBUG:root:		if self.downsample is not None:
DEBUG:root:			identity = self.downsample(x)
DEBUG:root:			// identity.shape: torch.Size([1, 256, 120, 144])

DEBUG:root:		out += identity   # H = F + x in paper
DEBUG:root:		// out.shape: torch.Size([1, 256, 120, 144])


DEBUG:root:		// # the third (final) relu ( in place relu)
DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 256, 120, 144])

DEBUG:root:		return out

DEBUG:root:
	} // END Bottelneck.__forward__()
DEBUG:root:
	Bottleneck.__forward__(self.x) { //BEGIN
DEBUG:root:		// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/resnet.py

DEBUG:root:		Params:
DEBUG:root:			x.shape : torch.Size([1, 256, 120, 144])

DEBUG:root:			self : BottleneckWithFixedBatchNorm(
  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): FrozenBatchNorm2d()
  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): FrozenBatchNorm2d()
  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): FrozenBatchNorm2d()
)

DEBUG:root:		// # Identity connection, directly make the residual equal to x
DEBUG:root:		identity = x

DEBUG:root:		// # conv1, bn1, relu (in place relu)
DEBUG:root:		// self.conv1: Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
DEBUG:root:		// self.bn1: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv1(x)
DEBUG:root:		// out.shape: torch.Size([1, 64, 120, 144])

DEBUG:root:		out = self.bn1(out)
DEBUG:root:		// out.shape: torch.Size([1, 64, 120, 144])

DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 64, 120, 144])


DEBUG:root:		// # conv2, bn2, relu (in place relu)
DEBUG:root:		// self.conv2: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
DEBUG:root:		// self.bn2: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv2(x)
DEBUG:root:		// out.shape: torch.Size([1, 64, 120, 144])

DEBUG:root:		out = self.bn2(out)
DEBUG:root:		// out.shape: torch.Size([1, 64, 120, 144])

DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 64, 120, 144])


DEBUG:root:		// # conv3, bn3, not relu here
DEBUG:root:		// self.conv3: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
DEBUG:root:		// self.bn3: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv3(x)
DEBUG:root:		// out.shape: torch.Size([1, 256, 120, 144])

DEBUG:root:		out = self.bn3(out)
DEBUG:root:		// out.shape: torch.Size([1, 256, 120, 144])


DEBUG:root:		// # If the number of input and output channels are different,
DEBUG:root:		// # they need to be mapped to make them the same.
DEBUG:root:		// self.downsample: None
DEBUG:root:		out += identity   # H = F + x in paper
DEBUG:root:		// out.shape: torch.Size([1, 256, 120, 144])


DEBUG:root:		// # the third (final) relu ( in place relu)
DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 256, 120, 144])

DEBUG:root:		return out

DEBUG:root:
	} // END Bottelneck.__forward__()
DEBUG:root:
	Bottleneck.__forward__(self.x) { //BEGIN
DEBUG:root:		// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/resnet.py

DEBUG:root:		Params:
DEBUG:root:			x.shape : torch.Size([1, 256, 120, 144])

DEBUG:root:			self : BottleneckWithFixedBatchNorm(
  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): FrozenBatchNorm2d()
  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): FrozenBatchNorm2d()
  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): FrozenBatchNorm2d()
)

DEBUG:root:		// # Identity connection, directly make the residual equal to x
DEBUG:root:		identity = x

DEBUG:root:		// # conv1, bn1, relu (in place relu)
DEBUG:root:		// self.conv1: Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
DEBUG:root:		// self.bn1: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv1(x)
DEBUG:root:		// out.shape: torch.Size([1, 64, 120, 144])

DEBUG:root:		out = self.bn1(out)
DEBUG:root:		// out.shape: torch.Size([1, 64, 120, 144])

DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 64, 120, 144])


DEBUG:root:		// # conv2, bn2, relu (in place relu)
DEBUG:root:		// self.conv2: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
DEBUG:root:		// self.bn2: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv2(x)
DEBUG:root:		// out.shape: torch.Size([1, 64, 120, 144])

DEBUG:root:		out = self.bn2(out)
DEBUG:root:		// out.shape: torch.Size([1, 64, 120, 144])

DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 64, 120, 144])


DEBUG:root:		// # conv3, bn3, not relu here
DEBUG:root:		// self.conv3: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
DEBUG:root:		// self.bn3: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv3(x)
DEBUG:root:		// out.shape: torch.Size([1, 256, 120, 144])

DEBUG:root:		out = self.bn3(out)
DEBUG:root:		// out.shape: torch.Size([1, 256, 120, 144])


DEBUG:root:		// # If the number of input and output channels are different,
DEBUG:root:		// # they need to be mapped to make them the same.
DEBUG:root:		// self.downsample: None
DEBUG:root:		out += identity   # H = F + x in paper
DEBUG:root:		// out.shape: torch.Size([1, 256, 120, 144])


DEBUG:root:		// # the third (final) relu ( in place relu)
DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 256, 120, 144])

DEBUG:root:		return out

DEBUG:root:
	} // END Bottelneck.__forward__()
DEBUG:root:
			} // x = getattr(self, stage_name)(x) RETURNED

DEBUG:root:				// output shape of layer1: torch.Size([1, 256, 120, 144])

DEBUG:root:			# Save all the calculation results of stage 1 ~ 4 (that is, the feature map) in the form of a list
DEBUG:root:			if self.return_features[stage_name]:
DEBUG:root:				outputs.append(x)
DEBUG:root:				// stage_name: layer1
DEBUG:root:				// x.shape: torch.Size([1, 256, 120, 144])

DEBUG:root:				#layer1 output of shape (1, 256, 120, 144) saved into ./npy_save/C1.npy


DEBUG:root:			} // END of iteration for layer1

DEBUG:root:			# =================================
DEBUG:root:			# 2-3-1-1-2 forward
DEBUG:root:			# =================================
DEBUG:root:			{ // BEGIN of iteration for 2 for layer2

DEBUG:root:			x = getattr(self, stage_name)(x) { // CALL

DEBUG:root:
	Bottleneck.__forward__(self.x) { //BEGIN
DEBUG:root:		// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/resnet.py

DEBUG:root:		Params:
DEBUG:root:			x.shape : torch.Size([1, 256, 120, 144])

DEBUG:root:			self : BottleneckWithFixedBatchNorm(
  (downsample): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): FrozenBatchNorm2d()
  )
  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
  (bn1): FrozenBatchNorm2d()
  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): FrozenBatchNorm2d()
  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): FrozenBatchNorm2d()
)

DEBUG:root:		// # Identity connection, directly make the residual equal to x
DEBUG:root:		identity = x

DEBUG:root:		// # conv1, bn1, relu (in place relu)
DEBUG:root:		// self.conv1: Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
DEBUG:root:		// self.bn1: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv1(x)
DEBUG:root:		// out.shape: torch.Size([1, 128, 60, 72])

DEBUG:root:		out = self.bn1(out)
DEBUG:root:		// out.shape: torch.Size([1, 128, 60, 72])

DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 128, 60, 72])


DEBUG:root:		// # conv2, bn2, relu (in place relu)
DEBUG:root:		// self.conv2: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
DEBUG:root:		// self.bn2: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv2(x)
DEBUG:root:		// out.shape: torch.Size([1, 128, 60, 72])

DEBUG:root:		out = self.bn2(out)
DEBUG:root:		// out.shape: torch.Size([1, 128, 60, 72])

DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 128, 60, 72])


DEBUG:root:		// # conv3, bn3, not relu here
DEBUG:root:		// self.conv3: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
DEBUG:root:		// self.bn3: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv3(x)
DEBUG:root:		// out.shape: torch.Size([1, 512, 60, 72])

DEBUG:root:		out = self.bn3(out)
DEBUG:root:		// out.shape: torch.Size([1, 512, 60, 72])


DEBUG:root:		// # If the number of input and output channels are different,
DEBUG:root:		// # they need to be mapped to make them the same.
DEBUG:root:		// self.downsample: Sequential(
  (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
  (1): FrozenBatchNorm2d()
)
DEBUG:root:		if self.downsample is not None:
DEBUG:root:			identity = self.downsample(x)
DEBUG:root:			// identity.shape: torch.Size([1, 512, 60, 72])

DEBUG:root:		out += identity   # H = F + x in paper
DEBUG:root:		// out.shape: torch.Size([1, 512, 60, 72])


DEBUG:root:		// # the third (final) relu ( in place relu)
DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 512, 60, 72])

DEBUG:root:		return out

DEBUG:root:
	} // END Bottelneck.__forward__()
DEBUG:root:
	Bottleneck.__forward__(self.x) { //BEGIN
DEBUG:root:		// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/resnet.py

DEBUG:root:		Params:
DEBUG:root:			x.shape : torch.Size([1, 512, 60, 72])

DEBUG:root:			self : BottleneckWithFixedBatchNorm(
  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): FrozenBatchNorm2d()
  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): FrozenBatchNorm2d()
  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): FrozenBatchNorm2d()
)

DEBUG:root:		// # Identity connection, directly make the residual equal to x
DEBUG:root:		identity = x

DEBUG:root:		// # conv1, bn1, relu (in place relu)
DEBUG:root:		// self.conv1: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
DEBUG:root:		// self.bn1: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv1(x)
DEBUG:root:		// out.shape: torch.Size([1, 128, 60, 72])

DEBUG:root:		out = self.bn1(out)
DEBUG:root:		// out.shape: torch.Size([1, 128, 60, 72])

DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 128, 60, 72])


DEBUG:root:		// # conv2, bn2, relu (in place relu)
DEBUG:root:		// self.conv2: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
DEBUG:root:		// self.bn2: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv2(x)
DEBUG:root:		// out.shape: torch.Size([1, 128, 60, 72])

DEBUG:root:		out = self.bn2(out)
DEBUG:root:		// out.shape: torch.Size([1, 128, 60, 72])

DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 128, 60, 72])


DEBUG:root:		// # conv3, bn3, not relu here
DEBUG:root:		// self.conv3: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
DEBUG:root:		// self.bn3: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv3(x)
DEBUG:root:		// out.shape: torch.Size([1, 512, 60, 72])

DEBUG:root:		out = self.bn3(out)
DEBUG:root:		// out.shape: torch.Size([1, 512, 60, 72])


DEBUG:root:		// # If the number of input and output channels are different,
DEBUG:root:		// # they need to be mapped to make them the same.
DEBUG:root:		// self.downsample: None
DEBUG:root:		out += identity   # H = F + x in paper
DEBUG:root:		// out.shape: torch.Size([1, 512, 60, 72])


DEBUG:root:		// # the third (final) relu ( in place relu)
DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 512, 60, 72])

DEBUG:root:		return out

DEBUG:root:
	} // END Bottelneck.__forward__()
DEBUG:root:
	Bottleneck.__forward__(self.x) { //BEGIN
DEBUG:root:		// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/resnet.py

DEBUG:root:		Params:
DEBUG:root:			x.shape : torch.Size([1, 512, 60, 72])

DEBUG:root:			self : BottleneckWithFixedBatchNorm(
  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): FrozenBatchNorm2d()
  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): FrozenBatchNorm2d()
  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): FrozenBatchNorm2d()
)

DEBUG:root:		// # Identity connection, directly make the residual equal to x
DEBUG:root:		identity = x

DEBUG:root:		// # conv1, bn1, relu (in place relu)
DEBUG:root:		// self.conv1: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
DEBUG:root:		// self.bn1: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv1(x)
DEBUG:root:		// out.shape: torch.Size([1, 128, 60, 72])

DEBUG:root:		out = self.bn1(out)
DEBUG:root:		// out.shape: torch.Size([1, 128, 60, 72])

DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 128, 60, 72])


DEBUG:root:		// # conv2, bn2, relu (in place relu)
DEBUG:root:		// self.conv2: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
DEBUG:root:		// self.bn2: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv2(x)
DEBUG:root:		// out.shape: torch.Size([1, 128, 60, 72])

DEBUG:root:		out = self.bn2(out)
DEBUG:root:		// out.shape: torch.Size([1, 128, 60, 72])

DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 128, 60, 72])


DEBUG:root:		// # conv3, bn3, not relu here
DEBUG:root:		// self.conv3: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
DEBUG:root:		// self.bn3: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv3(x)
DEBUG:root:		// out.shape: torch.Size([1, 512, 60, 72])

DEBUG:root:		out = self.bn3(out)
DEBUG:root:		// out.shape: torch.Size([1, 512, 60, 72])


DEBUG:root:		// # If the number of input and output channels are different,
DEBUG:root:		// # they need to be mapped to make them the same.
DEBUG:root:		// self.downsample: None
DEBUG:root:		out += identity   # H = F + x in paper
DEBUG:root:		// out.shape: torch.Size([1, 512, 60, 72])


DEBUG:root:		// # the third (final) relu ( in place relu)
DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 512, 60, 72])

DEBUG:root:		return out

DEBUG:root:
	} // END Bottelneck.__forward__()
DEBUG:root:
	Bottleneck.__forward__(self.x) { //BEGIN
DEBUG:root:		// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/resnet.py

DEBUG:root:		Params:
DEBUG:root:			x.shape : torch.Size([1, 512, 60, 72])

DEBUG:root:			self : BottleneckWithFixedBatchNorm(
  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): FrozenBatchNorm2d()
  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): FrozenBatchNorm2d()
  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): FrozenBatchNorm2d()
)

DEBUG:root:		// # Identity connection, directly make the residual equal to x
DEBUG:root:		identity = x

DEBUG:root:		// # conv1, bn1, relu (in place relu)
DEBUG:root:		// self.conv1: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
DEBUG:root:		// self.bn1: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv1(x)
DEBUG:root:		// out.shape: torch.Size([1, 128, 60, 72])

DEBUG:root:		out = self.bn1(out)
DEBUG:root:		// out.shape: torch.Size([1, 128, 60, 72])

DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 128, 60, 72])


DEBUG:root:		// # conv2, bn2, relu (in place relu)
DEBUG:root:		// self.conv2: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
DEBUG:root:		// self.bn2: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv2(x)
DEBUG:root:		// out.shape: torch.Size([1, 128, 60, 72])

DEBUG:root:		out = self.bn2(out)
DEBUG:root:		// out.shape: torch.Size([1, 128, 60, 72])

DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 128, 60, 72])


DEBUG:root:		// # conv3, bn3, not relu here
DEBUG:root:		// self.conv3: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
DEBUG:root:		// self.bn3: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv3(x)
DEBUG:root:		// out.shape: torch.Size([1, 512, 60, 72])

DEBUG:root:		out = self.bn3(out)
DEBUG:root:		// out.shape: torch.Size([1, 512, 60, 72])


DEBUG:root:		// # If the number of input and output channels are different,
DEBUG:root:		// # they need to be mapped to make them the same.
DEBUG:root:		// self.downsample: None
DEBUG:root:		out += identity   # H = F + x in paper
DEBUG:root:		// out.shape: torch.Size([1, 512, 60, 72])


DEBUG:root:		// # the third (final) relu ( in place relu)
DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 512, 60, 72])

DEBUG:root:		return out

DEBUG:root:
	} // END Bottelneck.__forward__()
DEBUG:root:
			} // x = getattr(self, stage_name)(x) RETURNED

DEBUG:root:				// output shape of layer2: torch.Size([1, 512, 60, 72])

DEBUG:root:			# Save all the calculation results of stage 1 ~ 4 (that is, the feature map) in the form of a list
DEBUG:root:			if self.return_features[stage_name]:
DEBUG:root:				outputs.append(x)
DEBUG:root:				// stage_name: layer2
DEBUG:root:				// x.shape: torch.Size([1, 512, 60, 72])

DEBUG:root:				#layer2 output of shape (1, 512, 60, 72) saved into ./npy_save/C2.npy


DEBUG:root:			} // END of iteration for layer2

DEBUG:root:			# =================================
DEBUG:root:			# 2-3-1-1-3 forward
DEBUG:root:			# =================================
DEBUG:root:			{ // BEGIN of iteration for 3 for layer3

DEBUG:root:			x = getattr(self, stage_name)(x) { // CALL

DEBUG:root:
	Bottleneck.__forward__(self.x) { //BEGIN
DEBUG:root:		// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/resnet.py

DEBUG:root:		Params:
DEBUG:root:			x.shape : torch.Size([1, 512, 60, 72])

DEBUG:root:			self : BottleneckWithFixedBatchNorm(
  (downsample): Sequential(
    (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): FrozenBatchNorm2d()
  )
  (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
  (bn1): FrozenBatchNorm2d()
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): FrozenBatchNorm2d()
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): FrozenBatchNorm2d()
)

DEBUG:root:		// # Identity connection, directly make the residual equal to x
DEBUG:root:		identity = x

DEBUG:root:		// # conv1, bn1, relu (in place relu)
DEBUG:root:		// self.conv1: Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
DEBUG:root:		// self.bn1: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv1(x)
DEBUG:root:		// out.shape: torch.Size([1, 256, 30, 36])

DEBUG:root:		out = self.bn1(out)
DEBUG:root:		// out.shape: torch.Size([1, 256, 30, 36])

DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 256, 30, 36])


DEBUG:root:		// # conv2, bn2, relu (in place relu)
DEBUG:root:		// self.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
DEBUG:root:		// self.bn2: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv2(x)
DEBUG:root:		// out.shape: torch.Size([1, 256, 30, 36])

DEBUG:root:		out = self.bn2(out)
DEBUG:root:		// out.shape: torch.Size([1, 256, 30, 36])

DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 256, 30, 36])


DEBUG:root:		// # conv3, bn3, not relu here
DEBUG:root:		// self.conv3: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
DEBUG:root:		// self.bn3: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv3(x)
DEBUG:root:		// out.shape: torch.Size([1, 1024, 30, 36])

DEBUG:root:		out = self.bn3(out)
DEBUG:root:		// out.shape: torch.Size([1, 1024, 30, 36])


DEBUG:root:		// # If the number of input and output channels are different,
DEBUG:root:		// # they need to be mapped to make them the same.
DEBUG:root:		// self.downsample: Sequential(
  (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
  (1): FrozenBatchNorm2d()
)
DEBUG:root:		if self.downsample is not None:
DEBUG:root:			identity = self.downsample(x)
DEBUG:root:			// identity.shape: torch.Size([1, 1024, 30, 36])

DEBUG:root:		out += identity   # H = F + x in paper
DEBUG:root:		// out.shape: torch.Size([1, 1024, 30, 36])


DEBUG:root:		// # the third (final) relu ( in place relu)
DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 1024, 30, 36])

DEBUG:root:		return out

DEBUG:root:
	} // END Bottelneck.__forward__()
DEBUG:root:
	Bottleneck.__forward__(self.x) { //BEGIN
DEBUG:root:		// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/resnet.py

DEBUG:root:		Params:
DEBUG:root:			x.shape : torch.Size([1, 1024, 30, 36])

DEBUG:root:			self : BottleneckWithFixedBatchNorm(
  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): FrozenBatchNorm2d()
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): FrozenBatchNorm2d()
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): FrozenBatchNorm2d()
)

DEBUG:root:		// # Identity connection, directly make the residual equal to x
DEBUG:root:		identity = x

DEBUG:root:		// # conv1, bn1, relu (in place relu)
DEBUG:root:		// self.conv1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
DEBUG:root:		// self.bn1: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv1(x)
DEBUG:root:		// out.shape: torch.Size([1, 256, 30, 36])

DEBUG:root:		out = self.bn1(out)
DEBUG:root:		// out.shape: torch.Size([1, 256, 30, 36])

DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 256, 30, 36])


DEBUG:root:		// # conv2, bn2, relu (in place relu)
DEBUG:root:		// self.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
DEBUG:root:		// self.bn2: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv2(x)
DEBUG:root:		// out.shape: torch.Size([1, 256, 30, 36])

DEBUG:root:		out = self.bn2(out)
DEBUG:root:		// out.shape: torch.Size([1, 256, 30, 36])

DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 256, 30, 36])


DEBUG:root:		// # conv3, bn3, not relu here
DEBUG:root:		// self.conv3: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
DEBUG:root:		// self.bn3: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv3(x)
DEBUG:root:		// out.shape: torch.Size([1, 1024, 30, 36])

DEBUG:root:		out = self.bn3(out)
DEBUG:root:		// out.shape: torch.Size([1, 1024, 30, 36])


DEBUG:root:		// # If the number of input and output channels are different,
DEBUG:root:		// # they need to be mapped to make them the same.
DEBUG:root:		// self.downsample: None
DEBUG:root:		out += identity   # H = F + x in paper
DEBUG:root:		// out.shape: torch.Size([1, 1024, 30, 36])


DEBUG:root:		// # the third (final) relu ( in place relu)
DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 1024, 30, 36])

DEBUG:root:		return out

DEBUG:root:
	} // END Bottelneck.__forward__()
DEBUG:root:
	Bottleneck.__forward__(self.x) { //BEGIN
DEBUG:root:		// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/resnet.py

DEBUG:root:		Params:
DEBUG:root:			x.shape : torch.Size([1, 1024, 30, 36])

DEBUG:root:			self : BottleneckWithFixedBatchNorm(
  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): FrozenBatchNorm2d()
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): FrozenBatchNorm2d()
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): FrozenBatchNorm2d()
)

DEBUG:root:		// # Identity connection, directly make the residual equal to x
DEBUG:root:		identity = x

DEBUG:root:		// # conv1, bn1, relu (in place relu)
DEBUG:root:		// self.conv1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
DEBUG:root:		// self.bn1: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv1(x)
DEBUG:root:		// out.shape: torch.Size([1, 256, 30, 36])

DEBUG:root:		out = self.bn1(out)
DEBUG:root:		// out.shape: torch.Size([1, 256, 30, 36])

DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 256, 30, 36])


DEBUG:root:		// # conv2, bn2, relu (in place relu)
DEBUG:root:		// self.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
DEBUG:root:		// self.bn2: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv2(x)
DEBUG:root:		// out.shape: torch.Size([1, 256, 30, 36])

DEBUG:root:		out = self.bn2(out)
DEBUG:root:		// out.shape: torch.Size([1, 256, 30, 36])

DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 256, 30, 36])


DEBUG:root:		// # conv3, bn3, not relu here
DEBUG:root:		// self.conv3: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
DEBUG:root:		// self.bn3: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv3(x)
DEBUG:root:		// out.shape: torch.Size([1, 1024, 30, 36])

DEBUG:root:		out = self.bn3(out)
DEBUG:root:		// out.shape: torch.Size([1, 1024, 30, 36])


DEBUG:root:		// # If the number of input and output channels are different,
DEBUG:root:		// # they need to be mapped to make them the same.
DEBUG:root:		// self.downsample: None
DEBUG:root:		out += identity   # H = F + x in paper
DEBUG:root:		// out.shape: torch.Size([1, 1024, 30, 36])


DEBUG:root:		// # the third (final) relu ( in place relu)
DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 1024, 30, 36])

DEBUG:root:		return out

DEBUG:root:
	} // END Bottelneck.__forward__()
DEBUG:root:
	Bottleneck.__forward__(self.x) { //BEGIN
DEBUG:root:		// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/resnet.py

DEBUG:root:		Params:
DEBUG:root:			x.shape : torch.Size([1, 1024, 30, 36])

DEBUG:root:			self : BottleneckWithFixedBatchNorm(
  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): FrozenBatchNorm2d()
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): FrozenBatchNorm2d()
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): FrozenBatchNorm2d()
)

DEBUG:root:		// # Identity connection, directly make the residual equal to x
DEBUG:root:		identity = x

DEBUG:root:		// # conv1, bn1, relu (in place relu)
DEBUG:root:		// self.conv1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
DEBUG:root:		// self.bn1: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv1(x)
DEBUG:root:		// out.shape: torch.Size([1, 256, 30, 36])

DEBUG:root:		out = self.bn1(out)
DEBUG:root:		// out.shape: torch.Size([1, 256, 30, 36])

DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 256, 30, 36])


DEBUG:root:		// # conv2, bn2, relu (in place relu)
DEBUG:root:		// self.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
DEBUG:root:		// self.bn2: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv2(x)
DEBUG:root:		// out.shape: torch.Size([1, 256, 30, 36])

DEBUG:root:		out = self.bn2(out)
DEBUG:root:		// out.shape: torch.Size([1, 256, 30, 36])

DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 256, 30, 36])


DEBUG:root:		// # conv3, bn3, not relu here
DEBUG:root:		// self.conv3: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
DEBUG:root:		// self.bn3: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv3(x)
DEBUG:root:		// out.shape: torch.Size([1, 1024, 30, 36])

DEBUG:root:		out = self.bn3(out)
DEBUG:root:		// out.shape: torch.Size([1, 1024, 30, 36])


DEBUG:root:		// # If the number of input and output channels are different,
DEBUG:root:		// # they need to be mapped to make them the same.
DEBUG:root:		// self.downsample: None
DEBUG:root:		out += identity   # H = F + x in paper
DEBUG:root:		// out.shape: torch.Size([1, 1024, 30, 36])


DEBUG:root:		// # the third (final) relu ( in place relu)
DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 1024, 30, 36])

DEBUG:root:		return out

DEBUG:root:
	} // END Bottelneck.__forward__()
DEBUG:root:
	Bottleneck.__forward__(self.x) { //BEGIN
DEBUG:root:		// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/resnet.py

DEBUG:root:		Params:
DEBUG:root:			x.shape : torch.Size([1, 1024, 30, 36])

DEBUG:root:			self : BottleneckWithFixedBatchNorm(
  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): FrozenBatchNorm2d()
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): FrozenBatchNorm2d()
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): FrozenBatchNorm2d()
)

DEBUG:root:		// # Identity connection, directly make the residual equal to x
DEBUG:root:		identity = x

DEBUG:root:		// # conv1, bn1, relu (in place relu)
DEBUG:root:		// self.conv1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
DEBUG:root:		// self.bn1: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv1(x)
DEBUG:root:		// out.shape: torch.Size([1, 256, 30, 36])

DEBUG:root:		out = self.bn1(out)
DEBUG:root:		// out.shape: torch.Size([1, 256, 30, 36])

DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 256, 30, 36])


DEBUG:root:		// # conv2, bn2, relu (in place relu)
DEBUG:root:		// self.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
DEBUG:root:		// self.bn2: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv2(x)
DEBUG:root:		// out.shape: torch.Size([1, 256, 30, 36])

DEBUG:root:		out = self.bn2(out)
DEBUG:root:		// out.shape: torch.Size([1, 256, 30, 36])

DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 256, 30, 36])


DEBUG:root:		// # conv3, bn3, not relu here
DEBUG:root:		// self.conv3: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
DEBUG:root:		// self.bn3: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv3(x)
DEBUG:root:		// out.shape: torch.Size([1, 1024, 30, 36])

DEBUG:root:		out = self.bn3(out)
DEBUG:root:		// out.shape: torch.Size([1, 1024, 30, 36])


DEBUG:root:		// # If the number of input and output channels are different,
DEBUG:root:		// # they need to be mapped to make them the same.
DEBUG:root:		// self.downsample: None
DEBUG:root:		out += identity   # H = F + x in paper
DEBUG:root:		// out.shape: torch.Size([1, 1024, 30, 36])


DEBUG:root:		// # the third (final) relu ( in place relu)
DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 1024, 30, 36])

DEBUG:root:		return out

DEBUG:root:
	} // END Bottelneck.__forward__()
DEBUG:root:
	Bottleneck.__forward__(self.x) { //BEGIN
DEBUG:root:		// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/resnet.py

DEBUG:root:		Params:
DEBUG:root:			x.shape : torch.Size([1, 1024, 30, 36])

DEBUG:root:			self : BottleneckWithFixedBatchNorm(
  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): FrozenBatchNorm2d()
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): FrozenBatchNorm2d()
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): FrozenBatchNorm2d()
)

DEBUG:root:		// # Identity connection, directly make the residual equal to x
DEBUG:root:		identity = x

DEBUG:root:		// # conv1, bn1, relu (in place relu)
DEBUG:root:		// self.conv1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
DEBUG:root:		// self.bn1: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv1(x)
DEBUG:root:		// out.shape: torch.Size([1, 256, 30, 36])

DEBUG:root:		out = self.bn1(out)
DEBUG:root:		// out.shape: torch.Size([1, 256, 30, 36])

DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 256, 30, 36])


DEBUG:root:		// # conv2, bn2, relu (in place relu)
DEBUG:root:		// self.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
DEBUG:root:		// self.bn2: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv2(x)
DEBUG:root:		// out.shape: torch.Size([1, 256, 30, 36])

DEBUG:root:		out = self.bn2(out)
DEBUG:root:		// out.shape: torch.Size([1, 256, 30, 36])

DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 256, 30, 36])


DEBUG:root:		// # conv3, bn3, not relu here
DEBUG:root:		// self.conv3: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
DEBUG:root:		// self.bn3: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv3(x)
DEBUG:root:		// out.shape: torch.Size([1, 1024, 30, 36])

DEBUG:root:		out = self.bn3(out)
DEBUG:root:		// out.shape: torch.Size([1, 1024, 30, 36])


DEBUG:root:		// # If the number of input and output channels are different,
DEBUG:root:		// # they need to be mapped to make them the same.
DEBUG:root:		// self.downsample: None
DEBUG:root:		out += identity   # H = F + x in paper
DEBUG:root:		// out.shape: torch.Size([1, 1024, 30, 36])


DEBUG:root:		// # the third (final) relu ( in place relu)
DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 1024, 30, 36])

DEBUG:root:		return out

DEBUG:root:
	} // END Bottelneck.__forward__()
DEBUG:root:
			} // x = getattr(self, stage_name)(x) RETURNED

DEBUG:root:				// output shape of layer3: torch.Size([1, 1024, 30, 36])

DEBUG:root:			# Save all the calculation results of stage 1 ~ 4 (that is, the feature map) in the form of a list
DEBUG:root:			if self.return_features[stage_name]:
DEBUG:root:				outputs.append(x)
DEBUG:root:				// stage_name: layer3
DEBUG:root:				// x.shape: torch.Size([1, 1024, 30, 36])

DEBUG:root:				#layer3 output of shape (1, 1024, 30, 36) saved into ./npy_save/C3.npy


DEBUG:root:			} // END of iteration for layer3

DEBUG:root:			# =================================
DEBUG:root:			# 2-3-1-1-4 forward
DEBUG:root:			# =================================
DEBUG:root:			{ // BEGIN of iteration for 4 for layer4

DEBUG:root:			x = getattr(self, stage_name)(x) { // CALL

DEBUG:root:
	Bottleneck.__forward__(self.x) { //BEGIN
DEBUG:root:		// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/resnet.py

DEBUG:root:		Params:
DEBUG:root:			x.shape : torch.Size([1, 1024, 30, 36])

DEBUG:root:			self : BottleneckWithFixedBatchNorm(
  (downsample): Sequential(
    (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): FrozenBatchNorm2d()
  )
  (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
  (bn1): FrozenBatchNorm2d()
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): FrozenBatchNorm2d()
  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): FrozenBatchNorm2d()
)

DEBUG:root:		// # Identity connection, directly make the residual equal to x
DEBUG:root:		identity = x

DEBUG:root:		// # conv1, bn1, relu (in place relu)
DEBUG:root:		// self.conv1: Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
DEBUG:root:		// self.bn1: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv1(x)
DEBUG:root:		// out.shape: torch.Size([1, 512, 15, 18])

DEBUG:root:		out = self.bn1(out)
DEBUG:root:		// out.shape: torch.Size([1, 512, 15, 18])

DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 512, 15, 18])


DEBUG:root:		// # conv2, bn2, relu (in place relu)
DEBUG:root:		// self.conv2: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
DEBUG:root:		// self.bn2: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv2(x)
DEBUG:root:		// out.shape: torch.Size([1, 512, 15, 18])

DEBUG:root:		out = self.bn2(out)
DEBUG:root:		// out.shape: torch.Size([1, 512, 15, 18])

DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 512, 15, 18])


DEBUG:root:		// # conv3, bn3, not relu here
DEBUG:root:		// self.conv3: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
DEBUG:root:		// self.bn3: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv3(x)
DEBUG:root:		// out.shape: torch.Size([1, 2048, 15, 18])

DEBUG:root:		out = self.bn3(out)
DEBUG:root:		// out.shape: torch.Size([1, 2048, 15, 18])


DEBUG:root:		// # If the number of input and output channels are different,
DEBUG:root:		// # they need to be mapped to make them the same.
DEBUG:root:		// self.downsample: Sequential(
  (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
  (1): FrozenBatchNorm2d()
)
DEBUG:root:		if self.downsample is not None:
DEBUG:root:			identity = self.downsample(x)
DEBUG:root:			// identity.shape: torch.Size([1, 2048, 15, 18])

DEBUG:root:		out += identity   # H = F + x in paper
DEBUG:root:		// out.shape: torch.Size([1, 2048, 15, 18])


DEBUG:root:		// # the third (final) relu ( in place relu)
DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 2048, 15, 18])

DEBUG:root:		return out

DEBUG:root:
	} // END Bottelneck.__forward__()
DEBUG:root:
	Bottleneck.__forward__(self.x) { //BEGIN
DEBUG:root:		// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/resnet.py

DEBUG:root:		Params:
DEBUG:root:			x.shape : torch.Size([1, 2048, 15, 18])

DEBUG:root:			self : BottleneckWithFixedBatchNorm(
  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): FrozenBatchNorm2d()
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): FrozenBatchNorm2d()
  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): FrozenBatchNorm2d()
)

DEBUG:root:		// # Identity connection, directly make the residual equal to x
DEBUG:root:		identity = x

DEBUG:root:		// # conv1, bn1, relu (in place relu)
DEBUG:root:		// self.conv1: Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
DEBUG:root:		// self.bn1: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv1(x)
DEBUG:root:		// out.shape: torch.Size([1, 512, 15, 18])

DEBUG:root:		out = self.bn1(out)
DEBUG:root:		// out.shape: torch.Size([1, 512, 15, 18])

DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 512, 15, 18])


DEBUG:root:		// # conv2, bn2, relu (in place relu)
DEBUG:root:		// self.conv2: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
DEBUG:root:		// self.bn2: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv2(x)
DEBUG:root:		// out.shape: torch.Size([1, 512, 15, 18])

DEBUG:root:		out = self.bn2(out)
DEBUG:root:		// out.shape: torch.Size([1, 512, 15, 18])

DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 512, 15, 18])


DEBUG:root:		// # conv3, bn3, not relu here
DEBUG:root:		// self.conv3: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
DEBUG:root:		// self.bn3: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv3(x)
DEBUG:root:		// out.shape: torch.Size([1, 2048, 15, 18])

DEBUG:root:		out = self.bn3(out)
DEBUG:root:		// out.shape: torch.Size([1, 2048, 15, 18])


DEBUG:root:		// # If the number of input and output channels are different,
DEBUG:root:		// # they need to be mapped to make them the same.
DEBUG:root:		// self.downsample: None
DEBUG:root:		out += identity   # H = F + x in paper
DEBUG:root:		// out.shape: torch.Size([1, 2048, 15, 18])


DEBUG:root:		// # the third (final) relu ( in place relu)
DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 2048, 15, 18])

DEBUG:root:		return out

DEBUG:root:
	} // END Bottelneck.__forward__()
DEBUG:root:
	Bottleneck.__forward__(self.x) { //BEGIN
DEBUG:root:		// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/resnet.py

DEBUG:root:		Params:
DEBUG:root:			x.shape : torch.Size([1, 2048, 15, 18])

DEBUG:root:			self : BottleneckWithFixedBatchNorm(
  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): FrozenBatchNorm2d()
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): FrozenBatchNorm2d()
  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): FrozenBatchNorm2d()
)

DEBUG:root:		// # Identity connection, directly make the residual equal to x
DEBUG:root:		identity = x

DEBUG:root:		// # conv1, bn1, relu (in place relu)
DEBUG:root:		// self.conv1: Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
DEBUG:root:		// self.bn1: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv1(x)
DEBUG:root:		// out.shape: torch.Size([1, 512, 15, 18])

DEBUG:root:		out = self.bn1(out)
DEBUG:root:		// out.shape: torch.Size([1, 512, 15, 18])

DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 512, 15, 18])


DEBUG:root:		// # conv2, bn2, relu (in place relu)
DEBUG:root:		// self.conv2: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
DEBUG:root:		// self.bn2: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv2(x)
DEBUG:root:		// out.shape: torch.Size([1, 512, 15, 18])

DEBUG:root:		out = self.bn2(out)
DEBUG:root:		// out.shape: torch.Size([1, 512, 15, 18])

DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 512, 15, 18])


DEBUG:root:		// # conv3, bn3, not relu here
DEBUG:root:		// self.conv3: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
DEBUG:root:		// self.bn3: FrozenBatchNorm2d()

DEBUG:root:		out = self.conv3(x)
DEBUG:root:		// out.shape: torch.Size([1, 2048, 15, 18])

DEBUG:root:		out = self.bn3(out)
DEBUG:root:		// out.shape: torch.Size([1, 2048, 15, 18])


DEBUG:root:		// # If the number of input and output channels are different,
DEBUG:root:		// # they need to be mapped to make them the same.
DEBUG:root:		// self.downsample: None
DEBUG:root:		out += identity   # H = F + x in paper
DEBUG:root:		// out.shape: torch.Size([1, 2048, 15, 18])


DEBUG:root:		// # the third (final) relu ( in place relu)
DEBUG:root:		out = F.relu_(out)
DEBUG:root:		// out.shape: torch.Size([1, 2048, 15, 18])

DEBUG:root:		return out

DEBUG:root:
	} // END Bottelneck.__forward__()
DEBUG:root:
			} // x = getattr(self, stage_name)(x) RETURNED

DEBUG:root:				// output shape of layer4: torch.Size([1, 2048, 15, 18])

DEBUG:root:			# Save all the calculation results of stage 1 ~ 4 (that is, the feature map) in the form of a list
DEBUG:root:			if self.return_features[stage_name]:
DEBUG:root:				outputs.append(x)
DEBUG:root:				// stage_name: layer4
DEBUG:root:				// x.shape: torch.Size([1, 2048, 15, 18])

DEBUG:root:				#layer4 output of shape (1, 2048, 15, 18) saved into ./npy_save/C4.npy


DEBUG:root:			} // END of iteration for layer4

DEBUG:root:
		} // END for stage_name in self.stages

DEBUG:root:			# -------------------------------
DEBUG:root:			# return value (outputs) info
DEBUG:root:			# fed into FPN.forward()
DEBUG:root:			# -------------------------------
DEBUG:root:			output of layer1 is C1 of shape: torch.Size([1, 256, 120, 144])
DEBUG:root:			output of layer2 is C2 of shape: torch.Size([1, 512, 60, 72])
DEBUG:root:			output of layer3 is C3 of shape: torch.Size([1, 1024, 30, 36])
DEBUG:root:			output of layer4 is C4 of shape: torch.Size([1, 2048, 15, 18])
DEBUG:root:
		return outputs
DEBUG:root:
	} // END Resnet.forward(self, x)
DEBUG:root:


DEBUG:root:		# =================================
DEBUG:root:		# 2-3-1-2 FPN Forward
DEBUG:root:		# =================================
DEBUG:root:
	FPN.forward(self,x) { // BEGIN
DEBUG:root:	// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/fpn.py

DEBUG:root:		// Param: x  = [C1, C2, C3, C4], return of Resnet.forward()
DEBUG:root:			// C[1] of shape : torch.Size([1, 256, 120, 144])
DEBUG:root:			// C[2] of shape : torch.Size([1, 512, 60, 72])
DEBUG:root:			// C[3] of shape : torch.Size([1, 1024, 30, 36])
DEBUG:root:			// C[4] of shape : torch.Size([1, 2048, 15, 18])
DEBUG:root:

DEBUG:root:			# ===========================================================================
DEBUG:root:			# FPN block info
DEBUG:root:			# self.inner_blocks: ['fpn_inner2', 'fpn_inner3', 'fpn_inner4'])
DEBUG:root:			# self.layer_blocks: ['fpn_layer2', 'fpn_layer3', 'fpn_layer4'])
DEBUG:root:			# ===========================================================================

DEBUG:root:			# last_inner = fpn_inner4(C4)

DEBUG:root:			# self.innerblocks[-1]:fpn_inner4
DEBUG:root:			# getattr(self, self.innerblocks[-1]):Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
DEBUG:root:			// x[-1].shape = torch.Size([1, 2048, 15, 18])

DEBUG:root:			last_inner = getattr(self, self.inner_blocks[-1])(x[-1])
DEBUG:root:			// last_inner.shape:torch.Size([1, 1024, 15, 18])

DEBUG:root:			# fpn_inner4 output of shape (1, 1024, 15, 18) saved into ./npy_save/fpn_inner4_output.npy


DEBUG:root:			results = []
DEBUG:root:			# self.layer_blocks[-1]: fpn_layer4
DEBUG:root:			# getattr(self, self.layer_blocks[-1]): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
DEBUG:root:			// last_inner.shape: torch.Size([1, 1024, 15, 18])]

DEBUG:root:
		results.append(self.layer_blocks[-1](last_inner))
DEBUG:root:			# results.append() : P4
DEBUG:root:		// results[-1].shape: torch.Size([1, 1024, 15, 18]) <=== P4

DEBUG:root:			# fpn_layer4 output (P4) of shape (1, 1024, 15, 18) saved into ./npy_save/fpn_layer4_output.npy


DEBUG:root:			for feature, inner_block, layer_block in zip(
DEBUG:root:				[(x[:-1][::-1], self.inner_blocks[:-1][::-1], self.layer_blocks[:-1][::-1]): {

DEBUG:root:				{ // BEGIN iteratrion for calc P3

DEBUG:root:				# ====================================
DEBUG:root:				# for calc P3
DEBUG:root:				# feature.shape: torch.Size([1, 1024, 30, 36])
DEBUG:root:				# inner_block: fpn_inner3 ==> Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
DEBUG:root:				# layer_block: fpn_layer3 ==> Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
DEBUG:root:				# last_inner.shape: torch.Size([1, 1024, 15, 18])
DEBUG:root:				# ====================================

DEBUG:root:				eltwise_suffix = inner_block[-1]
DEBUG:root:				// eltwise_suffix: 3
DEBUG:root:				# --------------------------------------------------
DEBUG:root:				# for calc P3
DEBUG:root:				# 1. Upsample : replace with Decovolution in caffe
DEBUG:root:				# layer name in caffe: fpn_inner3_upsample = Deconvolution(last_inner)
DEBUG:root:				# --------------------------------------------------
DEBUG:root:				// last_inner.shape: torch.Size([1, 1024, 15, 18])
DEBUG:root:				inner_top_down = F.interpolate(last_inner, scale_factor=2, mode='nearest')
DEBUG:root:				// inner_top_down.shape : torch.Size([1, 1024, 30, 36])

DEBUG:root:				# inner_top_down of shape (1, 1024, 30, 36) saved into ./npy_save/inner_top_down_for_fpn_inner3.npy


DEBUG:root:				--------------------------------------------------
DEBUG:root:				# for calc P3
DEBUG:root:				# 2. inner_lateral = Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))(feature)
DEBUG:root:				# layer name in caffe: fpn_inner3_lateral=Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))(feature)
DEBUG:root:				# --------------------------------------------------
DEBUG:root:				// inner_block: fpn_inner3 ==> Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
DEBUG:root:				// feature.shape: torch.Size([1, 1024, 30, 36])
DEBUG:root:				inner_lateral = getattr(self, inner_block)(feature)
DEBUG:root:				// inner_lateral.shape: torch.Size([1, 1024, 30, 36])

DEBUG:root:				# fpn_inner3 output of shape (1, 1024, 30, 36) saved into ./npy_save/fpn_inner3_output.npy


DEBUG:root:				# --------------------------------------------------
DEBUG:root:				# for calc P3
DEBUG:root:				# 3. Elementwise Addition: replaced with eltwise in caffe
DEBUG:root:				# layer in caffe: eltwise_3 = eltwise(fpn_inner3_lateral, fpn_inner3_upsample )
DEBUG:root:				# --------------------------------------------------
DEBUG:root:				// inner_lateral.shape: torch.Size([1, 1024, 30, 36])
DEBUG:root:				// inner_top_down.shape: torch.Size([1, 1024, 30, 36])
DEBUG:root:				last_inner = inner_lateral + inner_top_down
DEBUG:root:				// last_inner.shape : torch.Size([1, 1024, 30, 36])
DEBUG:root:				# superimposing result of fpn_inner3 output plus inner topdown of shape (1, 1024, 30, 36) saved into ./npy_save/fpn_inner3_ouptut_plus_inner_topdown.npy


DEBUG:root:				# --------------------------------------------------
DEBUG:root:				# for calc P3
DEBUG:root:				# 4. results.insert(0, Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))(last_inner)
DEBUG:root:				# layer in caffe: fpn_layer3 = Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))(eltwise_3)
DEBUG:root:				# --------------------------------------------------
DEBUG:root:				// layer_block: fpn_layer3 ==> Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
DEBUG:root:				// input: last_inner.shape = torch.Size([1, 1024, 30, 36])
DEBUG:root:				results.insert(0, getattr(self, layer_block)(last_inner))
DEBUG:root:				// results[0].shape: torch.Size([1, 1024, 30, 36])

DEBUG:root:				# fpn_layer3 output (P3) of shape (1, 1024, 30, 36) saved into ./npy_save/fpn_layer3_ouptut.npy


DEBUG:root:				# --------------------------------------------------
DEBUG:root:				# results after iteration 0
DEBUG:root:				# --------------------------------------------------
DEBUG:root:				# results[0] of shape: torch.Size([1, 1024, 30, 36])
DEBUG:root:				# results[1] of shape: torch.Size([1, 1024, 15, 18])
DEBUG:root:				#--------------------------------------------------

DEBUG:root:				} // END iteratrion for calc P3

DEBUG:root:				{ // BEGIN iteratrion for calc P2

DEBUG:root:				# ====================================
DEBUG:root:				# for calc P2
DEBUG:root:				# feature.shape: torch.Size([1, 512, 60, 72])
DEBUG:root:				# inner_block: fpn_inner2 ==> Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
DEBUG:root:				# layer_block: fpn_layer2 ==> Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
DEBUG:root:				# last_inner.shape: torch.Size([1, 1024, 30, 36])
DEBUG:root:				# ====================================

DEBUG:root:				eltwise_suffix = inner_block[-1]
DEBUG:root:				// eltwise_suffix: 2
DEBUG:root:				# --------------------------------------------------
DEBUG:root:				# for calc P2
DEBUG:root:				# 1. Upsample : replace with Decovolution in caffe
DEBUG:root:				# layer name in caffe: fpn_inner2_upsample = Deconvolution(last_inner)
DEBUG:root:				# --------------------------------------------------
DEBUG:root:				// last_inner.shape: torch.Size([1, 1024, 30, 36])
DEBUG:root:				inner_top_down = F.interpolate(last_inner, scale_factor=2, mode='nearest')
DEBUG:root:				// inner_top_down.shape : torch.Size([1, 1024, 60, 72])

DEBUG:root:				# inner_top_down of shape (1, 1024, 60, 72) saved into ./npy_save/inner_top_down_for_fpn_inner2.npy


DEBUG:root:				--------------------------------------------------
DEBUG:root:				# for calc P2
DEBUG:root:				# 2. inner_lateral = Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))(feature)
DEBUG:root:				# layer name in caffe: fpn_inner2_lateral=Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))(feature)
DEBUG:root:				# --------------------------------------------------
DEBUG:root:				// inner_block: fpn_inner2 ==> Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
DEBUG:root:				// feature.shape: torch.Size([1, 512, 60, 72])
DEBUG:root:				inner_lateral = getattr(self, inner_block)(feature)
DEBUG:root:				// inner_lateral.shape: torch.Size([1, 1024, 60, 72])

DEBUG:root:				# fpn_inner2 output of shape (1, 1024, 60, 72) saved into ./npy_save/fpn_inner2_output.npy


DEBUG:root:				# --------------------------------------------------
DEBUG:root:				# for calc P2
DEBUG:root:				# 3. Elementwise Addition: replaced with eltwise in caffe
DEBUG:root:				# layer in caffe: eltwise_2 = eltwise(fpn_inner2_lateral, fpn_inner2_upsample )
DEBUG:root:				# --------------------------------------------------
DEBUG:root:				// inner_lateral.shape: torch.Size([1, 1024, 60, 72])
DEBUG:root:				// inner_top_down.shape: torch.Size([1, 1024, 60, 72])
DEBUG:root:				last_inner = inner_lateral + inner_top_down
DEBUG:root:				// last_inner.shape : torch.Size([1, 1024, 60, 72])
DEBUG:root:				# superimposing result of fpn_inner2 output plus inner topdown of shape (1, 1024, 60, 72) saved into ./npy_save/fpn_inner2_ouptut_plus_inner_topdown.npy


DEBUG:root:				# --------------------------------------------------
DEBUG:root:				# for calc P2
DEBUG:root:				# 4. results.insert(0, Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))(last_inner)
DEBUG:root:				# layer in caffe: fpn_layer2 = Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))(eltwise_2)
DEBUG:root:				# --------------------------------------------------
DEBUG:root:				// layer_block: fpn_layer2 ==> Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
DEBUG:root:				// input: last_inner.shape = torch.Size([1, 1024, 60, 72])
DEBUG:root:				results.insert(0, getattr(self, layer_block)(last_inner))
DEBUG:root:				// results[0].shape: torch.Size([1, 1024, 60, 72])

DEBUG:root:				# fpn_layer2 output (P2) of shape (1, 1024, 60, 72) saved into ./npy_save/fpn_layer2_ouptut.npy


DEBUG:root:				# --------------------------------------------------
DEBUG:root:				# results after iteration 1
DEBUG:root:				# --------------------------------------------------
DEBUG:root:				# results[0] of shape: torch.Size([1, 1024, 60, 72])
DEBUG:root:				# results[1] of shape: torch.Size([1, 1024, 30, 36])
DEBUG:root:				# results[2] of shape: torch.Size([1, 1024, 15, 18])
DEBUG:root:				#--------------------------------------------------

DEBUG:root:				} // END iteratrion for calc P2

DEBUG:root:			} // for loop END

DEBUG:root:			# --------------------------------------------------
DEBUG:root:			# results after for loop
DEBUG:root:			# --------------------------------------------------
DEBUG:root:				# results[0] AKA P2 of shape: torch.Size([1, 1024, 60, 72])
DEBUG:root:				# results[1] AKA P3 of shape: torch.Size([1, 1024, 30, 36])
DEBUG:root:				# results[2] AKA P4 of shape: torch.Size([1, 1024, 15, 18])
DEBUG:root:

DEBUG:root:
			if isinstance(self.top_blocks, LastLevelP6P7):
DEBUG:root:				// self.top_blocks: LastLevelP6P7(
  (p6): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (p7): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
)
DEBUG:root:				// len(x): 4
DEBUG:root:					// x[0].shape : torch.Size([1, 256, 120, 144]) ==> C1
DEBUG:root:					// x[1].shape : torch.Size([1, 512, 60, 72]) ==> C2
DEBUG:root:					// x[2].shape : torch.Size([1, 1024, 30, 36]) ==> C3
DEBUG:root:					// x[3].shape : torch.Size([1, 2048, 15, 18]) ==> C4
DEBUG:root:					//x[-1] AKA C4 of shape : torch.Size([1, 2048, 15, 18])


DEBUG:root:				// len(results): 3
DEBUG:root:					// results[0].shape : torch.Size([1, 1024, 60, 72]) ==> P2
DEBUG:root:					// results[1].shape : torch.Size([1, 1024, 30, 36]) ==> P3
DEBUG:root:					// results[2].shape : torch.Size([1, 1024, 15, 18]) ==> P4
DEBUG:root:
				// results[-1] AKA P4 of shape: torch.Size([1, 1024, 15, 18])


DEBUG:root:				last_result = self.top_blocks(x[-1]==>C4, results[-1]==>P4) { // CALL
DEBUG:root:		# =================================
DEBUG:root:		# 2-3-1-3 FPN.LastLevelP6P7 Forward
DEBUG:root:		# =================================

DEBUG:root:
			LastLevelP6P7.forward(self, c5, p5) { // BEGIN
DEBUG:root:			// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/fpn.py

DEBUG:root:				//Param:
DEBUG:root:					//c5.shape: torch.Size([1, 2048, 15, 18])
DEBUG:root:					//p5.shape: torch.Size([1, 1024, 15, 18])

DEBUG:root:				// self.use_P5: False
DEBUG:root:				x = p5 if self.use_P5 else c5
DEBUG:root:				x=c5

DEBUG:root:				// x.shape = torch.Size([1, 2048, 15, 18])

DEBUG:root:				// self.p6: Conv2d(2048, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
DEBUG:root:				// x.shape: torch.Size([1, 2048, 15, 18])
DEBUG:root:				p6 = self.p6(x)
DEBUG:root:				// p6.shape: torch.Size([1, 1024, 8, 9])

DEBUG:root:				# LastLevelP6P7::forward(), P6 of shape (1, 1024, 8, 9) saved into ./npy_save/P6.npy


DEBUG:root:				// self.p7: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
DEBUG:root:				p7 = self.p7(F.relu(p6))
DEBUG:root:				// p7.shape: torch.Size([1, 1024, 4, 5])

DEBUG:root:			# LastLevelP6P7::forward(), P7 of shape (1, 1024, 4, 5) saved into ./npy_save/P7.npy


DEBUG:root:				# ------------------
DEBUG:root:				# return value (P6, P7) info
DEBUG:root:				# which is appended into FPN results
DEBUG:root:				# ------------------
DEBUG:root:				P6 of shape torch.Size([1, 1024, 8, 9])
DEBUG:root:				P7 of shape torch.Size([1, 1024, 4, 5])

DEBUG:root:				returns [p6, p7]

DEBUG:root:			} // END LastLevelP6P7.forward(self, c5, p5)


DEBUG:root:				}
DEBUG:root:				last_result = self.top_blocks(x[-1]==>C4, results[-1]==>P4) // RETURNED

DEBUG:root:				// len(last_results):2
DEBUG:root:				//last_results[0] AKA P6shape : torch.Size([1, 1024, 8, 9])
DEBUG:root:				//last_results[1] AKA P7shape : torch.Size([1, 1024, 4, 5])
DEBUG:root:
				results.extend(last_results)
DEBUG:root:				// len(results): 5
DEBUG:root:					results[0].shape : torch.Size([1, 1024, 60, 72])
DEBUG:root:					results[1].shape : torch.Size([1, 1024, 30, 36])
DEBUG:root:					results[2].shape : torch.Size([1, 1024, 15, 18])
DEBUG:root:					results[3].shape : torch.Size([1, 1024, 8, 9])
DEBUG:root:					results[4].shape : torch.Size([1, 1024, 4, 5])
DEBUG:root:


DEBUG:root:
			#-----------------------------------
DEBUG:root:			# return value tuple(results: P2, P3, P4, P6, P7) info
DEBUG:root:			# which fed into RPN.forward()
DEBUG:root:			#-----------------------------------
DEBUG:root:			results[0] = P2 of shape: torch.Size([1, 1024, 60, 72])
DEBUG:root:			results[1] = P3 of shape: torch.Size([1, 1024, 30, 36])
DEBUG:root:			results[2] = P4 of shape: torch.Size([1, 1024, 15, 18])
DEBUG:root:			results[3] = P6 of shape: torch.Size([1, 1024, 8, 9])
DEBUG:root:			results[4] = P7 of shape: torch.Size([1, 1024, 4, 5])
DEBUG:root:
	return tuple(results)

DEBUG:root:

	} // END FPN.forward(self,x)
DEBUG:root:
	} model.backbone.forward(images.tensors) // RETURNED
DEBUG:root:

	# ===========================================
DEBUG:root:	# 2-3-2 RPN Forward
DEBUG:root:	# ===========================================

DEBUG:root:	proposals, proposal_losses = self.rpn(images, features, targets) // CALL
	{
DEBUG:root:		RetinaNetModule.forward(self, images, features, targets=None) { // BEGIN
DEBUG:root:			// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/retinanet/retinanet.py

DEBUG:root:			// Params:
DEBUG:root:				// type(images): <class 'maskrcnn_benchmark.structures.image_list.ImageList'>
DEBUG:root:				// len(images.image_sizes): 1
DEBUG:root:				// len(images.tensors): 1
DEBUG:root:				// len(features)): 5
DEBUG:root:				// target: None

DEBUG:root:				# images info
DEBUG:root:				// images.image_sizes[0]: torch.Size([480, 561]) # transformed image size (H, W)
DEBUG:root:				// images.tensors[0].shape: torch.Size([3, 480, 576]) # zero-padded batch image size (C, H, W)
DEBUG:root:
				# features info
DEBUG:root:				// feature[0].shape: torch.Size([1, 1024, 60, 72]) <== P2 after FPN
DEBUG:root:				// feature[1].shape: torch.Size([1, 1024, 30, 36]) <== P3 after FPN
DEBUG:root:				// feature[2].shape: torch.Size([1, 1024, 15, 18]) <== P4 after FPN
DEBUG:root:				// feature[3].shape: torch.Size([1, 1024, 8, 9]) <== P6 after FPN
DEBUG:root:				// feature[4].shape: torch.Size([1, 1024, 4, 5]) <== P7 after FPN
DEBUG:root:

DEBUG:root:		# ===========================================
DEBUG:root:		# 2-3-2-1 RPN.Head forward
DEBUG:root:		# ===========================================

DEBUG:root:		// type(self.head): <class 'maskrcnn_benchmark.modeling.rpn.retinanet.retinanet.RetinaNetHead'>
DEBUG:root:		box_cls, box_regression = self.head(features) // CALL
{
DEBUG:root:

	RetinaNetHead.forward(self, x) { // BEGIN
DEBUG:root:	// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/retinanet/retinanet.py

DEBUG:root:		// Param:
DEBUG:root:			// self: RetinaNetHead(
  (cls_tower): Sequential(
    (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU()
    (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (5): ReLU()
    (6): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU()
  )
  (bbox_tower): Sequential(
    (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU()
    (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (5): ReLU()
    (6): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU()
  )
  (cls_logits): Conv2d(1024, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (bbox_pred): Conv2d(1024, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)
DEBUG:root:			// len(x)): 5 # x is features retruned fron FPN forward
DEBUG:root:
				# features info
DEBUG:root:				// feature[0].shape: torch.Size([1, 1024, 60, 72]) <== P2 after FPN
DEBUG:root:				// feature[1].shape: torch.Size([1, 1024, 30, 36]) <== P3 after FPN
DEBUG:root:				// feature[2].shape: torch.Size([1, 1024, 15, 18]) <== P4 after FPN
DEBUG:root:				// feature[3].shape: torch.Size([1, 1024, 8, 9]) <== P6 after FPN
DEBUG:root:				// feature[4].shape: torch.Size([1, 1024, 4, 5]) <== P7 after FPN
DEBUG:root:

DEBUG:root:		logits = []
DEBUG:root:		bbox_reg = []

DEBUG:root:		#=========================================
DEBUG:root:		# for every P (total 5) from FPN,
DEBUG:root:		# - apply cls_tower and cls_logits
DEBUG:root:		# - apply bbox_tower and bbox_pred
DEBUG:root:		# hence 5 set of identical cls_tower, cls_logits, bbox_tower and bbox_pred
DEBUG:root:		# should be prepared because caffe don't have sub-net iteration structure
DEBUG:root:		#=========================================
DEBUG:root:		for idx, feature in enumerate(x) {
DEBUG:root:			{
DEBUG:root:			# BEGIN iteration: 1/5

DEBUG:root:			// ===================================
DEBUG:root:			// feature P2 of shape: torch.Size([1, 1024, 60, 72])
DEBUG:root:			// ===================================
DEBUG:root:			# 2-3-2-1-1. append cls_logits(cls_tower(feature))
DEBUG:root:			logits.append(self.cls_logits(self.cls_tower(feature)))
DEBUG:root:			logits.append(self.cls_logits(self.cls_tower(feature)))
DEBUG:root:				// feature.shape: torch.Size([1, 1024, 60, 72])
DEBUG:root:				// self.cls_tower: Sequential(
  (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (3): ReLU()
  (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (5): ReLU()
  (6): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (7): ReLU()
)
DEBUG:root:				// self.cls_logits: Conv2d(1024, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
DEBUG:root:				// logits[-1].shape: torch.Size([1, 9, 60, 72])
DEBUG:root:				// len(logits): 1

DEBUG:root:			# 2-3-2-1-2. append bbox_pred(bbox_tower(feature))
DEBUG:root:			bbox_reg.append(self.bbox_pred(self.bbox_tower(feature)))
DEBUG:root:				// feature.shape: torch.Size([1, 1024, 60, 72])
DEBUG:root:				// self.bbox_tower: Sequential(
  (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (3): ReLU()
  (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (5): ReLU()
  (6): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (7): ReLU()
)
DEBUG:root:				// self.bbox_pred: Conv2d(1024, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
DEBUG:root:				// bbox_reg[-1].shape: torch.Size([1, 36, 60, 72])
DEBUG:root:				// len(bbox_reg): 1

DEBUG:root:			} // END iteration: 1/5

DEBUG:root:			{
DEBUG:root:			# BEGIN iteration: 2/5

DEBUG:root:			// ===================================
DEBUG:root:			// feature P3 of shape: torch.Size([1, 1024, 30, 36])
DEBUG:root:			// ===================================
DEBUG:root:			# 2-3-2-1-1. append cls_logits(cls_tower(feature))
DEBUG:root:			logits.append(self.cls_logits(self.cls_tower(feature)))
DEBUG:root:			logits.append(self.cls_logits(self.cls_tower(feature)))
DEBUG:root:				// feature.shape: torch.Size([1, 1024, 30, 36])
DEBUG:root:				// self.cls_tower: Sequential(
  (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (3): ReLU()
  (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (5): ReLU()
  (6): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (7): ReLU()
)
DEBUG:root:				// self.cls_logits: Conv2d(1024, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
DEBUG:root:				// logits[-1].shape: torch.Size([1, 9, 30, 36])
DEBUG:root:				// len(logits): 2

DEBUG:root:			# 2-3-2-1-2. append bbox_pred(bbox_tower(feature))
DEBUG:root:			bbox_reg.append(self.bbox_pred(self.bbox_tower(feature)))
DEBUG:root:				// feature.shape: torch.Size([1, 1024, 30, 36])
DEBUG:root:				// self.bbox_tower: Sequential(
  (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (3): ReLU()
  (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (5): ReLU()
  (6): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (7): ReLU()
)
DEBUG:root:				// self.bbox_pred: Conv2d(1024, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
DEBUG:root:				// bbox_reg[-1].shape: torch.Size([1, 36, 30, 36])
DEBUG:root:				// len(bbox_reg): 2

DEBUG:root:			} // END iteration: 2/5

DEBUG:root:			{
DEBUG:root:			# BEGIN iteration: 3/5

DEBUG:root:			// ===================================
DEBUG:root:			// feature P4 of shape: torch.Size([1, 1024, 15, 18])
DEBUG:root:			// ===================================
DEBUG:root:			# 2-3-2-1-1. append cls_logits(cls_tower(feature))
DEBUG:root:			logits.append(self.cls_logits(self.cls_tower(feature)))
DEBUG:root:			logits.append(self.cls_logits(self.cls_tower(feature)))
DEBUG:root:				// feature.shape: torch.Size([1, 1024, 15, 18])
DEBUG:root:				// self.cls_tower: Sequential(
  (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (3): ReLU()
  (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (5): ReLU()
  (6): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (7): ReLU()
)
DEBUG:root:				// self.cls_logits: Conv2d(1024, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
DEBUG:root:				// logits[-1].shape: torch.Size([1, 9, 15, 18])
DEBUG:root:				// len(logits): 3

DEBUG:root:			# 2-3-2-1-2. append bbox_pred(bbox_tower(feature))
DEBUG:root:			bbox_reg.append(self.bbox_pred(self.bbox_tower(feature)))
DEBUG:root:				// feature.shape: torch.Size([1, 1024, 15, 18])
DEBUG:root:				// self.bbox_tower: Sequential(
  (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (3): ReLU()
  (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (5): ReLU()
  (6): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (7): ReLU()
)
DEBUG:root:				// self.bbox_pred: Conv2d(1024, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
DEBUG:root:				// bbox_reg[-1].shape: torch.Size([1, 36, 15, 18])
DEBUG:root:				// len(bbox_reg): 3

DEBUG:root:			} // END iteration: 3/5

DEBUG:root:			{
DEBUG:root:			# BEGIN iteration: 4/5

DEBUG:root:			// ===================================
DEBUG:root:			// feature p6 of shape: torch.Size([1, 1024, 8, 9])
DEBUG:root:			// ===================================
DEBUG:root:			# 2-3-2-1-1. append cls_logits(cls_tower(feature))
DEBUG:root:			logits.append(self.cls_logits(self.cls_tower(feature)))
DEBUG:root:			logits.append(self.cls_logits(self.cls_tower(feature)))
DEBUG:root:				// feature.shape: torch.Size([1, 1024, 8, 9])
DEBUG:root:				// self.cls_tower: Sequential(
  (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (3): ReLU()
  (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (5): ReLU()
  (6): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (7): ReLU()
)
DEBUG:root:				// self.cls_logits: Conv2d(1024, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
DEBUG:root:				// logits[-1].shape: torch.Size([1, 9, 8, 9])
DEBUG:root:				// len(logits): 4

DEBUG:root:			# 2-3-2-1-2. append bbox_pred(bbox_tower(feature))
DEBUG:root:			bbox_reg.append(self.bbox_pred(self.bbox_tower(feature)))
DEBUG:root:				// feature.shape: torch.Size([1, 1024, 8, 9])
DEBUG:root:				// self.bbox_tower: Sequential(
  (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (3): ReLU()
  (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (5): ReLU()
  (6): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (7): ReLU()
)
DEBUG:root:				// self.bbox_pred: Conv2d(1024, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
DEBUG:root:				// bbox_reg[-1].shape: torch.Size([1, 36, 8, 9])
DEBUG:root:				// len(bbox_reg): 4

DEBUG:root:			} // END iteration: 4/5

DEBUG:root:			{
DEBUG:root:			# BEGIN iteration: 5/5

DEBUG:root:			// ===================================
DEBUG:root:			// feature p7 of shape: torch.Size([1, 1024, 4, 5])
DEBUG:root:			// ===================================
DEBUG:root:			# 2-3-2-1-1. append cls_logits(cls_tower(feature))
DEBUG:root:			logits.append(self.cls_logits(self.cls_tower(feature)))
DEBUG:root:			logits.append(self.cls_logits(self.cls_tower(feature)))
DEBUG:root:				// feature.shape: torch.Size([1, 1024, 4, 5])
DEBUG:root:				// self.cls_tower: Sequential(
  (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (3): ReLU()
  (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (5): ReLU()
  (6): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (7): ReLU()
)
DEBUG:root:				// self.cls_logits: Conv2d(1024, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
DEBUG:root:				// logits[-1].shape: torch.Size([1, 9, 4, 5])
DEBUG:root:				// len(logits): 5

DEBUG:root:			# 2-3-2-1-2. append bbox_pred(bbox_tower(feature))
DEBUG:root:			bbox_reg.append(self.bbox_pred(self.bbox_tower(feature)))
DEBUG:root:				// feature.shape: torch.Size([1, 1024, 4, 5])
DEBUG:root:				// self.bbox_tower: Sequential(
  (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (3): ReLU()
  (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (5): ReLU()
  (6): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (7): ReLU()
)
DEBUG:root:				// self.bbox_pred: Conv2d(1024, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
DEBUG:root:				// bbox_reg[-1].shape: torch.Size([1, 36, 4, 5])
DEBUG:root:				// len(bbox_reg): 5

DEBUG:root:			} // END iteration: 5/5

DEBUG:root:

		}// END for idx, feature n enumerate(x)

DEBUG:root:		// ==== logits ====
DEBUG:root:		// logits[0].shape: torch.Size([1, 9, 60, 72])
DEBUG:root:		// logits[1].shape: torch.Size([1, 9, 30, 36])
DEBUG:root:		// logits[2].shape: torch.Size([1, 9, 15, 18])
DEBUG:root:		// logits[3].shape: torch.Size([1, 9, 8, 9])
DEBUG:root:		// logits[4].shape: torch.Size([1, 9, 4, 5])
DEBUG:root:
		// ==== bbox_reg ====
DEBUG:root:		// bbox_reg[0].shape: torch.Size([1, 36, 60, 72])
DEBUG:root:		// bbox_reg[1].shape: torch.Size([1, 36, 30, 36])
DEBUG:root:		// bbox_reg[2].shape: torch.Size([1, 36, 15, 18])
DEBUG:root:		// bbox_reg[3].shape: torch.Size([1, 36, 8, 9])
DEBUG:root:		// bbox_reg[4].shape: torch.Size([1, 36, 4, 5])
DEBUG:root:
return logits, bbox_reg
DEBUG:root:	} // END RetinaNetHead.forward(self, x)
DEBUG:root:
		}
box_cls, box_regression = self.head(features) // RETURNED
DEBUG:root:		// len(box_cls): 5
DEBUG:root:			// box_cls[0].shape: torch.Size([1, 9, 60, 72])
DEBUG:root:			// box_cls[1].shape: torch.Size([1, 9, 30, 36])
DEBUG:root:			// box_cls[2].shape: torch.Size([1, 9, 15, 18])
DEBUG:root:			// box_cls[3].shape: torch.Size([1, 9, 8, 9])
DEBUG:root:			// box_cls[4].shape: torch.Size([1, 9, 4, 5])
DEBUG:root:		// len(box_regression): 5
DEBUG:root:			// box_regression[0].shape: torch.Size([1, 36, 60, 72])
DEBUG:root:			// box_regression[1].shape: torch.Size([1, 36, 30, 36])
DEBUG:root:			// box_regression[2].shape: torch.Size([1, 36, 15, 18])
DEBUG:root:			// box_regression[3].shape: torch.Size([1, 36, 8, 9])
DEBUG:root:			// box_regression[4].shape: torch.Size([1, 36, 4, 5])
DEBUG:root:


DEBUG:root:		# ===========================================
DEBUG:root:		# 2-3-2-2 RPN.anchor_generator forward
DEBUG:root:		# ===========================================

DEBUG:root:		// self.anchor_generator: AnchorGenerator(
  (cell_anchors): BufferList()
)
DEBUG:root:		anchors = self.anchor_generator(images, features) // CALL {
DEBUG:root:
	AnchorGenerator.forward(image_list, feature_maps) { //BEGIN
DEBUG:root:		// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py

DEBUG:root:		// Params:
DEBUG:root:			> image_list:
DEBUG:root:				> len(image_list.image_sizes): 1
DEBUG:root:				> image_list.image_sizes[0]: torch.Size([480, 561])
DEBUG:root:				> len(image_list.tensors): 1
DEBUG:root:				> image_list.tensors[0].shape: torch.Size([3, 480, 576])
DEBUG:root:			>feature_maps:
DEBUG:root:				feature_maps[0].shape: torch.Size([1, 1024, 60, 72]) <== P2
DEBUG:root:				feature_maps[1].shape: torch.Size([1, 1024, 30, 36]) <== P3
DEBUG:root:				feature_maps[2].shape: torch.Size([1, 1024, 15, 18]) <== P4
DEBUG:root:				feature_maps[3].shape: torch.Size([1, 1024, 8, 9]) <== P6
DEBUG:root:				feature_maps[4].shape: torch.Size([1, 1024, 4, 5]) <== P7
DEBUG:root:

DEBUG:root:		grid_sizes = [feature_map.shape[-2:] for feature_map in feature_maps]
DEBUG:root:		// grid_sizes: [torch.Size([60, 72]), torch.Size([30, 36]), torch.Size([15, 18]), torch.Size([8, 9]), torch.Size([4, 5])]

DEBUG:root:
		# -------------------------------------------------------------
DEBUG:root:		# 2-3-2-2-1
DEBUG:root:		# anchors_over_all_feature_maps = self.grid_anchors(grid_sizes)
DEBUG:root:		# -------------------------------------------------------------
DEBUG:root:		anchors_over_all_feature_maps = self.grid_anchors(grid_sizes) // CALL
{
DEBUG:root:		AnchorGenerator.grid_anchors(grid_sizes) { // BEGIN
DEBUG:root:			// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py

DEBUG:root:				Param:
DEBUG:root:				grid_sizes: [torch.Size([60, 72]), torch.Size([30, 36]), torch.Size([15, 18]), torch.Size([8, 9]), torch.Size([4, 5])]

DEBUG:root:			anchors = []
DEBUG:root:			// self.strides:(8, 16, 32, 64, 128)

DEBUG:root:			// self.cell_anchors[0].shape:torch.Size([9, 4])
DEBUG:root:			// self.cell_anchors[1].shape:torch.Size([9, 4])
DEBUG:root:			// self.cell_anchors[2].shape:torch.Size([9, 4])
DEBUG:root:			// self.cell_anchors[3].shape:torch.Size([9, 4])
DEBUG:root:			// self.cell_anchors[4].shape:torch.Size([9, 4])
DEBUG:root:
			for size, stride, base_anchors in zip( grid_sizes, self.strides, self.cell_anchors ):
			{
DEBUG:root:				{
DEBUG:root:				# BEGIN iteration: 1/5

DEBUG:root:				#------------------------------------
DEBUG:root:				# size: torch.Size([60, 72]) from grid_sizes
DEBUG:root:				# size: 8 from self.strides
DEBUG:root:				# base_anchors.shape: torch.Size([9, 4]) from self.cell_anchors
DEBUG:root:				#------------------------------------
DEBUG:root:				grid_height, grid_width = size
DEBUG:root:				// grid_height: 60
DEBUG:root:				// grid_width: 72

DEBUG:root:				device = base_anchors.device
DEBUG:root:				// device: cuda:0

DEBUG:root:				shifts_x = torch.arange(
DEBUG:root:				    0, grid_width * stride, step=stride, dtype=torch.float32, device=device)
DEBUG:root:				// shifts_x: tensor([  0.,   8.,  16.,  24.,  32.,  40.,  48.,  56.,  64.,  72.,  80.,  88.,
         96., 104., 112., 120., 128., 136., 144., 152., 160., 168., 176., 184.,
        192., 200., 208., 216., 224., 232., 240., 248., 256., 264., 272., 280.,
        288., 296., 304., 312., 320., 328., 336., 344., 352., 360., 368., 376.,
        384., 392., 400., 408., 416., 424., 432., 440., 448., 456., 464., 472.,
        480., 488., 496., 504., 512., 520., 528., 536., 544., 552., 560., 568.])

DEBUG:root:				shifts_y = torch.arange(
DEBUG:root:				    0, grid_height * stride, step=stride, dtype=torch.float32, device=device)
DEBUG:root:				// shifts_y: tensor([  0.,   8.,  16.,  24.,  32.,  40.,  48.,  56.,  64.,  72.,  80.,  88.,
         96., 104., 112., 120., 128., 136., 144., 152., 160., 168., 176., 184.,
        192., 200., 208., 216., 224., 232., 240., 248., 256., 264., 272., 280.,
        288., 296., 304., 312., 320., 328., 336., 344., 352., 360., 368., 376.,
        384., 392., 400., 408., 416., 424., 432., 440., 448., 456., 464., 472.])

DEBUG:root:				shift_y, shift_x = torch.meshgrid(shifts_y, shifts_x)
DEBUG:root:				\ shift_y.shape: torch.Size([60, 72]), shift_x.shape: torch.Size([60, 72])

DEBUG:root:				shift_x = shift_x.reshape(-1)
DEBUG:root:				// shifts_x.shape: torch.Size([72])

DEBUG:root:				shift_y = shift_y.reshape(-1)
DEBUG:root:				// shifts_y.shape: torch.Size([60])

DEBUG:root:				shifts = torch.stack((shift_x, shift_y, shift_x, shift_y), dim=1)
DEBUG:root:				// shifts.shape: torch.Size([4320, 4])
DEBUG:root:				anchors.append(
DEBUG:root:				    (shifts.view(-1, 1, 4) + base_anchors.view(1, -1, 4)).reshape(-1, 4) )
DEBUG:root:				// anchors[-1].shape: torch.Size([38880, 4])
DEBUG:root:				} END iteration: 1/5

DEBUG:root:				{
DEBUG:root:				# BEGIN iteration: 2/5

DEBUG:root:				#------------------------------------
DEBUG:root:				# size: torch.Size([30, 36]) from grid_sizes
DEBUG:root:				# size: 16 from self.strides
DEBUG:root:				# base_anchors.shape: torch.Size([9, 4]) from self.cell_anchors
DEBUG:root:				#------------------------------------
DEBUG:root:				grid_height, grid_width = size
DEBUG:root:				// grid_height: 30
DEBUG:root:				// grid_width: 36

DEBUG:root:				device = base_anchors.device
DEBUG:root:				// device: cuda:0

DEBUG:root:				shifts_x = torch.arange(
DEBUG:root:				    0, grid_width * stride, step=stride, dtype=torch.float32, device=device)
DEBUG:root:				// shifts_x: tensor([  0.,  16.,  32.,  48.,  64.,  80.,  96., 112., 128., 144., 160., 176.,
        192., 208., 224., 240., 256., 272., 288., 304., 320., 336., 352., 368.,
        384., 400., 416., 432., 448., 464., 480., 496., 512., 528., 544., 560.])

DEBUG:root:				shifts_y = torch.arange(
DEBUG:root:				    0, grid_height * stride, step=stride, dtype=torch.float32, device=device)
DEBUG:root:				// shifts_y: tensor([  0.,  16.,  32.,  48.,  64.,  80.,  96., 112., 128., 144., 160., 176.,
        192., 208., 224., 240., 256., 272., 288., 304., 320., 336., 352., 368.,
        384., 400., 416., 432., 448., 464.])

DEBUG:root:				shift_y, shift_x = torch.meshgrid(shifts_y, shifts_x)
DEBUG:root:				\ shift_y.shape: torch.Size([30, 36]), shift_x.shape: torch.Size([30, 36])

DEBUG:root:				shift_x = shift_x.reshape(-1)
DEBUG:root:				// shifts_x.shape: torch.Size([36])

DEBUG:root:				shift_y = shift_y.reshape(-1)
DEBUG:root:				// shifts_y.shape: torch.Size([30])

DEBUG:root:				shifts = torch.stack((shift_x, shift_y, shift_x, shift_y), dim=1)
DEBUG:root:				// shifts.shape: torch.Size([1080, 4])
DEBUG:root:				anchors.append(
DEBUG:root:				    (shifts.view(-1, 1, 4) + base_anchors.view(1, -1, 4)).reshape(-1, 4) )
DEBUG:root:				// anchors[-1].shape: torch.Size([9720, 4])
DEBUG:root:				} END iteration: 2/5

DEBUG:root:				{
DEBUG:root:				# BEGIN iteration: 3/5

DEBUG:root:				#------------------------------------
DEBUG:root:				# size: torch.Size([15, 18]) from grid_sizes
DEBUG:root:				# size: 32 from self.strides
DEBUG:root:				# base_anchors.shape: torch.Size([9, 4]) from self.cell_anchors
DEBUG:root:				#------------------------------------
DEBUG:root:				grid_height, grid_width = size
DEBUG:root:				// grid_height: 15
DEBUG:root:				// grid_width: 18

DEBUG:root:				device = base_anchors.device
DEBUG:root:				// device: cuda:0

DEBUG:root:				shifts_x = torch.arange(
DEBUG:root:				    0, grid_width * stride, step=stride, dtype=torch.float32, device=device)
DEBUG:root:				// shifts_x: tensor([  0.,  32.,  64.,  96., 128., 160., 192., 224., 256., 288., 320., 352.,
        384., 416., 448., 480., 512., 544.])

DEBUG:root:				shifts_y = torch.arange(
DEBUG:root:				    0, grid_height * stride, step=stride, dtype=torch.float32, device=device)
DEBUG:root:				// shifts_y: tensor([  0.,  32.,  64.,  96., 128., 160., 192., 224., 256., 288., 320., 352.,
        384., 416., 448.])

DEBUG:root:				shift_y, shift_x = torch.meshgrid(shifts_y, shifts_x)
DEBUG:root:				\ shift_y.shape: torch.Size([15, 18]), shift_x.shape: torch.Size([15, 18])

DEBUG:root:				shift_x = shift_x.reshape(-1)
DEBUG:root:				// shifts_x.shape: torch.Size([18])

DEBUG:root:				shift_y = shift_y.reshape(-1)
DEBUG:root:				// shifts_y.shape: torch.Size([15])

DEBUG:root:				shifts = torch.stack((shift_x, shift_y, shift_x, shift_y), dim=1)
DEBUG:root:				// shifts.shape: torch.Size([270, 4])
DEBUG:root:				anchors.append(
DEBUG:root:				    (shifts.view(-1, 1, 4) + base_anchors.view(1, -1, 4)).reshape(-1, 4) )
DEBUG:root:				// anchors[-1].shape: torch.Size([2430, 4])
DEBUG:root:				} END iteration: 3/5

DEBUG:root:				{
DEBUG:root:				# BEGIN iteration: 4/5

DEBUG:root:				#------------------------------------
DEBUG:root:				# size: torch.Size([8, 9]) from grid_sizes
DEBUG:root:				# size: 64 from self.strides
DEBUG:root:				# base_anchors.shape: torch.Size([9, 4]) from self.cell_anchors
DEBUG:root:				#------------------------------------
DEBUG:root:				grid_height, grid_width = size
DEBUG:root:				// grid_height: 8
DEBUG:root:				// grid_width: 9

DEBUG:root:				device = base_anchors.device
DEBUG:root:				// device: cuda:0

DEBUG:root:				shifts_x = torch.arange(
DEBUG:root:				    0, grid_width * stride, step=stride, dtype=torch.float32, device=device)
DEBUG:root:				// shifts_x: tensor([  0.,  64., 128., 192., 256., 320., 384., 448., 512.])

DEBUG:root:				shifts_y = torch.arange(
DEBUG:root:				    0, grid_height * stride, step=stride, dtype=torch.float32, device=device)
DEBUG:root:				// shifts_y: tensor([  0.,  64., 128., 192., 256., 320., 384., 448.])

DEBUG:root:				shift_y, shift_x = torch.meshgrid(shifts_y, shifts_x)
DEBUG:root:				\ shift_y.shape: torch.Size([8, 9]), shift_x.shape: torch.Size([8, 9])

DEBUG:root:				shift_x = shift_x.reshape(-1)
DEBUG:root:				// shifts_x.shape: torch.Size([9])

DEBUG:root:				shift_y = shift_y.reshape(-1)
DEBUG:root:				// shifts_y.shape: torch.Size([8])

DEBUG:root:				shifts = torch.stack((shift_x, shift_y, shift_x, shift_y), dim=1)
DEBUG:root:				// shifts.shape: torch.Size([72, 4])
DEBUG:root:				anchors.append(
DEBUG:root:				    (shifts.view(-1, 1, 4) + base_anchors.view(1, -1, 4)).reshape(-1, 4) )
DEBUG:root:				// anchors[-1].shape: torch.Size([648, 4])
DEBUG:root:				} END iteration: 4/5

DEBUG:root:				{
DEBUG:root:				# BEGIN iteration: 5/5

DEBUG:root:				#------------------------------------
DEBUG:root:				# size: torch.Size([4, 5]) from grid_sizes
DEBUG:root:				# size: 128 from self.strides
DEBUG:root:				# base_anchors.shape: torch.Size([9, 4]) from self.cell_anchors
DEBUG:root:				#------------------------------------
DEBUG:root:				grid_height, grid_width = size
DEBUG:root:				// grid_height: 4
DEBUG:root:				// grid_width: 5

DEBUG:root:				device = base_anchors.device
DEBUG:root:				// device: cuda:0

DEBUG:root:				shifts_x = torch.arange(
DEBUG:root:				    0, grid_width * stride, step=stride, dtype=torch.float32, device=device)
DEBUG:root:				// shifts_x: tensor([  0., 128., 256., 384., 512.])

DEBUG:root:				shifts_y = torch.arange(
DEBUG:root:				    0, grid_height * stride, step=stride, dtype=torch.float32, device=device)
DEBUG:root:				// shifts_y: tensor([  0., 128., 256., 384.])

DEBUG:root:				shift_y, shift_x = torch.meshgrid(shifts_y, shifts_x)
DEBUG:root:				\ shift_y.shape: torch.Size([4, 5]), shift_x.shape: torch.Size([4, 5])

DEBUG:root:				shift_x = shift_x.reshape(-1)
DEBUG:root:				// shifts_x.shape: torch.Size([5])

DEBUG:root:				shift_y = shift_y.reshape(-1)
DEBUG:root:				// shifts_y.shape: torch.Size([4])

DEBUG:root:				shifts = torch.stack((shift_x, shift_y, shift_x, shift_y), dim=1)
DEBUG:root:				// shifts.shape: torch.Size([20, 4])
DEBUG:root:				anchors.append(
DEBUG:root:				    (shifts.view(-1, 1, 4) + base_anchors.view(1, -1, 4)).reshape(-1, 4) )
DEBUG:root:				// anchors[-1].shape: torch.Size([180, 4])
DEBUG:root:				} END iteration: 5/5

DEBUG:root:			} // END for size, stride, base_anchors in zip( grid_sizes, self.strides, self.cell_anchors )

DEBUG:root:			// len(anchors): 5
DEBUG:root:			// anchors[i].shape: torch.Size([38880, 4])
DEBUG:root:			// anchors[i].shape: torch.Size([9720, 4])
DEBUG:root:			// anchors[i].shape: torch.Size([2430, 4])
DEBUG:root:			// anchors[i].shape: torch.Size([648, 4])
DEBUG:root:			// anchors[i].shape: torch.Size([180, 4])
DEBUG:root:
		return anchors
DEBUG:root:		} // END AnchorGenerator.grid_anchors(grid_sizes)

DEBUG:root:

DEBUG:root:		}
		anchors_over_all_feature_maps = self.grid_anchors(grid_sizes) // RETURNED
DEBUG:root:		// len(anchors_over_all_feature_maps): 5

DEBUG:root:anchors = []
DEBUG:root:

		# -------------------------------------------------------------
DEBUG:root:		# 2-3-2-2-2
DEBUG:root:		# loop over anchors_per_feature_map 
DEBUG:root:		# -------------------------------------------------------------
DEBUG:root:		// len(imge_list.image_sizes): 1
DEBUG:root:		for i, (image_height, image_width) in enumerate(image_list.image_sizes) {

DEBUG:root:			{
DEBUG:root:			# BEGIN iteration i: 1

DEBUG:root:			# image_height:480
DEBUG:root:			# image_width:561
DEBUG:root:			anchors_in_image = []

DEBUG:root:			# len(anchors_over_all_feature_maps): 5
DEBUG:root:			for j, anchors_per_feature_map in enumerate(anchors_over_all_feature_maps): {

DEBUG:root:				{
DEBUG:root:				# BEGIN iteration: j: 1/5

DEBUG:root:				# anchors_per_feature_map.shape: torch.Size([38880, 4])
DEBUG:root:				# image_width: 561
DEBUG:root:				# image_height: 480

DEBUG:root:				# -----------------------------------------
DEBUG:root:				# 2-3-2-2-2-1 boxlist = BoxList( anchors_per_feature_map, (image_width, image_height), mode="xyxy")
DEBUG:root:				# i: 1, j: 1/5
DEBUG:root:				# -----------------------------------------
DEBUG:root:				boxlist = BoxList( anchors_per_feature_map, (image_width, image_height), mode="xyxy" ) // CALL
		{
DEBUG:root:				BoxList.__init__(self, bbox, image_size, mode='xyxy') { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/structures/bounding_box.py

DEBUG:root:					// Params:
DEBUG:root:						// type(bbox):<class 'torch.Tensor'>
DEBUG:root:						// bbox.shape:torch.Size([38880, 4])
DEBUG:root:						// image_size: (561, 480)

DEBUG:root:					// isinstance(bbox, torch.Tensor): True
DEBUG:root:					device = bbox.device if isinstance(bbox, torch.Tensor) else torch.device("cpu")
DEBUG:root:					// device: cuda:0

DEBUG:root:					bbox = torch.as_tensor(bbox, dtype=torch.float32, device=device)
DEBUG:root:					// bbox.shape: torch.Size([38880, 4])

DEBUG:root:					// bbox.ndimension(): 2
DEBUG:root:					// bbox.size(-1): 4

DEBUG:root:					self.bbox = bbox
DEBUG:root:					self.size = image_size  # (image_width, image_height)
DEBUG:root:					self.mode = mode
DEBUG:root:					self.extra_fields = {}
DEBUG:root:				} // END BoxList.__init__(self, bbox, image_size, mode='xyxy')
DEBUG:root:

DEBUG:root:				} boxlist = BoxList( anchors_per_feature_map, (image_width, image_height), mode="xyxy" ) // RETURNED
DEBUG:root:				// boxlist:
			BoxList(num_boxes=38880, image_width=561, image_height=480, mode=xyxy)

DEBUG:root:				# -----------------------------------------
DEBUG:root:				# 2-3-2-2-2-2 self.add_visibility_to(boxlist)
DEBUG:root:				# i: 1, j: 1/5
DEBUG:root:				# -----------------------------------------
DEBUG:root:				self.add_visibility_to(boxlist) // CALL
		{
DEBUG:root:				AnchorGenerator.add_visibitity_to(boxlist) { // BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py

DEBUG:root:					// Params

DEBUG:root:					// type(boxlist): <class 'maskrcnn_benchmark.structures.bounding_box.BoxList'>
DEBUG:root:					// boxlist.size: (561, 480)
DEBUG:root:					// boxlist.bbox.shape: torch.Size([38880, 4])

DEBUG:root:					image_width, image_height = boxlist.size
DEBUG:root:					// image_width: 561
DEBUG:root:					// image_height: 480

DEBUG:root:					anchors = boxlist.bbox
DEBUG:root:					// anchors.shape: torch.Size([38880, 4])

DEBUG:root:					// self.straddle_thresh: -1
DEBUG:root:					else: ie. self.straddle_thresh < 0
DEBUG:root:						device = anchors.device
DEBUG:root:						inds_inside = torch.ones(anchors.shape[0], dtype=torch.bool, device=device)

DEBUG:root:					// inds_inside.shape torch.Size([38880])
DEBUG:root:					boxlist.add_field("visibility", inds_inside)

DEBUG:root:				} // END AnchorGenerator.add_visibitity_to(boxlist)

DEBUG:root:

DEBUG:root:				} self.add_visibility_to(boxlist) // RETURNED
DEBUG:root:				// boxlist:BoxList(num_boxes=38880, image_width=561, image_height=480, mode=xyxy)

DEBUG:root:				# -----------------------------------------
DEBUG:root:				# 2-3-2-2-2-3 anchors_in_image.append(boxlist)
DEBUG:root:				# i: 1, j: 1/5
DEBUG:root:				# -----------------------------------------
DEBUG:root:				anchors_in_image.append(boxlist)

DEBUG:root:				} // END iteration: j = 1/5

DEBUG:root:				{
DEBUG:root:				# BEGIN iteration: j: 2/5

DEBUG:root:				# anchors_per_feature_map.shape: torch.Size([9720, 4])
DEBUG:root:				# image_width: 561
DEBUG:root:				# image_height: 480

DEBUG:root:				# -----------------------------------------
DEBUG:root:				# 2-3-2-2-2-1 boxlist = BoxList( anchors_per_feature_map, (image_width, image_height), mode="xyxy")
DEBUG:root:				# i: 1, j: 2/5
DEBUG:root:				# -----------------------------------------
DEBUG:root:				boxlist = BoxList( anchors_per_feature_map, (image_width, image_height), mode="xyxy" ) // CALL
		{
DEBUG:root:				BoxList.__init__(self, bbox, image_size, mode='xyxy') { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/structures/bounding_box.py

DEBUG:root:					// Params:
DEBUG:root:						// type(bbox):<class 'torch.Tensor'>
DEBUG:root:						// bbox.shape:torch.Size([9720, 4])
DEBUG:root:						// image_size: (561, 480)

DEBUG:root:					// isinstance(bbox, torch.Tensor): True
DEBUG:root:					device = bbox.device if isinstance(bbox, torch.Tensor) else torch.device("cpu")
DEBUG:root:					// device: cuda:0

DEBUG:root:					bbox = torch.as_tensor(bbox, dtype=torch.float32, device=device)
DEBUG:root:					// bbox.shape: torch.Size([9720, 4])

DEBUG:root:					// bbox.ndimension(): 2
DEBUG:root:					// bbox.size(-1): 4

DEBUG:root:					self.bbox = bbox
DEBUG:root:					self.size = image_size  # (image_width, image_height)
DEBUG:root:					self.mode = mode
DEBUG:root:					self.extra_fields = {}
DEBUG:root:				} // END BoxList.__init__(self, bbox, image_size, mode='xyxy')
DEBUG:root:

DEBUG:root:				} boxlist = BoxList( anchors_per_feature_map, (image_width, image_height), mode="xyxy" ) // RETURNED
DEBUG:root:				// boxlist:
			BoxList(num_boxes=9720, image_width=561, image_height=480, mode=xyxy)

DEBUG:root:				# -----------------------------------------
DEBUG:root:				# 2-3-2-2-2-2 self.add_visibility_to(boxlist)
DEBUG:root:				# i: 1, j: 2/5
DEBUG:root:				# -----------------------------------------
DEBUG:root:				self.add_visibility_to(boxlist) // CALL
		{
DEBUG:root:				AnchorGenerator.add_visibitity_to(boxlist) { // BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py

DEBUG:root:					// Params

DEBUG:root:					// type(boxlist): <class 'maskrcnn_benchmark.structures.bounding_box.BoxList'>
DEBUG:root:					// boxlist.size: (561, 480)
DEBUG:root:					// boxlist.bbox.shape: torch.Size([9720, 4])

DEBUG:root:					image_width, image_height = boxlist.size
DEBUG:root:					// image_width: 561
DEBUG:root:					// image_height: 480

DEBUG:root:					anchors = boxlist.bbox
DEBUG:root:					// anchors.shape: torch.Size([9720, 4])

DEBUG:root:					// self.straddle_thresh: -1
DEBUG:root:					else: ie. self.straddle_thresh < 0
DEBUG:root:						device = anchors.device
DEBUG:root:						inds_inside = torch.ones(anchors.shape[0], dtype=torch.bool, device=device)

DEBUG:root:					// inds_inside.shape torch.Size([9720])
DEBUG:root:					boxlist.add_field("visibility", inds_inside)

DEBUG:root:				} // END AnchorGenerator.add_visibitity_to(boxlist)

DEBUG:root:

DEBUG:root:				} self.add_visibility_to(boxlist) // RETURNED
DEBUG:root:				// boxlist:BoxList(num_boxes=9720, image_width=561, image_height=480, mode=xyxy)

DEBUG:root:				# -----------------------------------------
DEBUG:root:				# 2-3-2-2-2-3 anchors_in_image.append(boxlist)
DEBUG:root:				# i: 1, j: 2/5
DEBUG:root:				# -----------------------------------------
DEBUG:root:				anchors_in_image.append(boxlist)

DEBUG:root:				} // END iteration: j = 2/5

DEBUG:root:				{
DEBUG:root:				# BEGIN iteration: j: 3/5

DEBUG:root:				# anchors_per_feature_map.shape: torch.Size([2430, 4])
DEBUG:root:				# image_width: 561
DEBUG:root:				# image_height: 480

DEBUG:root:				# -----------------------------------------
DEBUG:root:				# 2-3-2-2-2-1 boxlist = BoxList( anchors_per_feature_map, (image_width, image_height), mode="xyxy")
DEBUG:root:				# i: 1, j: 3/5
DEBUG:root:				# -----------------------------------------
DEBUG:root:				boxlist = BoxList( anchors_per_feature_map, (image_width, image_height), mode="xyxy" ) // CALL
		{
DEBUG:root:				BoxList.__init__(self, bbox, image_size, mode='xyxy') { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/structures/bounding_box.py

DEBUG:root:					// Params:
DEBUG:root:						// type(bbox):<class 'torch.Tensor'>
DEBUG:root:						// bbox.shape:torch.Size([2430, 4])
DEBUG:root:						// image_size: (561, 480)

DEBUG:root:					// isinstance(bbox, torch.Tensor): True
DEBUG:root:					device = bbox.device if isinstance(bbox, torch.Tensor) else torch.device("cpu")
DEBUG:root:					// device: cuda:0

DEBUG:root:					bbox = torch.as_tensor(bbox, dtype=torch.float32, device=device)
DEBUG:root:					// bbox.shape: torch.Size([2430, 4])

DEBUG:root:					// bbox.ndimension(): 2
DEBUG:root:					// bbox.size(-1): 4

DEBUG:root:					self.bbox = bbox
DEBUG:root:					self.size = image_size  # (image_width, image_height)
DEBUG:root:					self.mode = mode
DEBUG:root:					self.extra_fields = {}
DEBUG:root:				} // END BoxList.__init__(self, bbox, image_size, mode='xyxy')
DEBUG:root:

DEBUG:root:				} boxlist = BoxList( anchors_per_feature_map, (image_width, image_height), mode="xyxy" ) // RETURNED
DEBUG:root:				// boxlist:
			BoxList(num_boxes=2430, image_width=561, image_height=480, mode=xyxy)

DEBUG:root:				# -----------------------------------------
DEBUG:root:				# 2-3-2-2-2-2 self.add_visibility_to(boxlist)
DEBUG:root:				# i: 1, j: 3/5
DEBUG:root:				# -----------------------------------------
DEBUG:root:				self.add_visibility_to(boxlist) // CALL
		{
DEBUG:root:				AnchorGenerator.add_visibitity_to(boxlist) { // BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py

DEBUG:root:					// Params

DEBUG:root:					// type(boxlist): <class 'maskrcnn_benchmark.structures.bounding_box.BoxList'>
DEBUG:root:					// boxlist.size: (561, 480)
DEBUG:root:					// boxlist.bbox.shape: torch.Size([2430, 4])

DEBUG:root:					image_width, image_height = boxlist.size
DEBUG:root:					// image_width: 561
DEBUG:root:					// image_height: 480

DEBUG:root:					anchors = boxlist.bbox
DEBUG:root:					// anchors.shape: torch.Size([2430, 4])

DEBUG:root:					// self.straddle_thresh: -1
DEBUG:root:					else: ie. self.straddle_thresh < 0
DEBUG:root:						device = anchors.device
DEBUG:root:						inds_inside = torch.ones(anchors.shape[0], dtype=torch.bool, device=device)

DEBUG:root:					// inds_inside.shape torch.Size([2430])
DEBUG:root:					boxlist.add_field("visibility", inds_inside)

DEBUG:root:				} // END AnchorGenerator.add_visibitity_to(boxlist)

DEBUG:root:

DEBUG:root:				} self.add_visibility_to(boxlist) // RETURNED
DEBUG:root:				// boxlist:BoxList(num_boxes=2430, image_width=561, image_height=480, mode=xyxy)

DEBUG:root:				# -----------------------------------------
DEBUG:root:				# 2-3-2-2-2-3 anchors_in_image.append(boxlist)
DEBUG:root:				# i: 1, j: 3/5
DEBUG:root:				# -----------------------------------------
DEBUG:root:				anchors_in_image.append(boxlist)

DEBUG:root:				} // END iteration: j = 3/5

DEBUG:root:				{
DEBUG:root:				# BEGIN iteration: j: 4/5

DEBUG:root:				# anchors_per_feature_map.shape: torch.Size([648, 4])
DEBUG:root:				# image_width: 561
DEBUG:root:				# image_height: 480

DEBUG:root:				# -----------------------------------------
DEBUG:root:				# 2-3-2-2-2-1 boxlist = BoxList( anchors_per_feature_map, (image_width, image_height), mode="xyxy")
DEBUG:root:				# i: 1, j: 4/5
DEBUG:root:				# -----------------------------------------
DEBUG:root:				boxlist = BoxList( anchors_per_feature_map, (image_width, image_height), mode="xyxy" ) // CALL
		{
DEBUG:root:				BoxList.__init__(self, bbox, image_size, mode='xyxy') { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/structures/bounding_box.py

DEBUG:root:					// Params:
DEBUG:root:						// type(bbox):<class 'torch.Tensor'>
DEBUG:root:						// bbox.shape:torch.Size([648, 4])
DEBUG:root:						// image_size: (561, 480)

DEBUG:root:					// isinstance(bbox, torch.Tensor): True
DEBUG:root:					device = bbox.device if isinstance(bbox, torch.Tensor) else torch.device("cpu")
DEBUG:root:					// device: cuda:0

DEBUG:root:					bbox = torch.as_tensor(bbox, dtype=torch.float32, device=device)
DEBUG:root:					// bbox.shape: torch.Size([648, 4])

DEBUG:root:					// bbox.ndimension(): 2
DEBUG:root:					// bbox.size(-1): 4

DEBUG:root:					self.bbox = bbox
DEBUG:root:					self.size = image_size  # (image_width, image_height)
DEBUG:root:					self.mode = mode
DEBUG:root:					self.extra_fields = {}
DEBUG:root:				} // END BoxList.__init__(self, bbox, image_size, mode='xyxy')
DEBUG:root:

DEBUG:root:				} boxlist = BoxList( anchors_per_feature_map, (image_width, image_height), mode="xyxy" ) // RETURNED
DEBUG:root:				// boxlist:
			BoxList(num_boxes=648, image_width=561, image_height=480, mode=xyxy)

DEBUG:root:				# -----------------------------------------
DEBUG:root:				# 2-3-2-2-2-2 self.add_visibility_to(boxlist)
DEBUG:root:				# i: 1, j: 4/5
DEBUG:root:				# -----------------------------------------
DEBUG:root:				self.add_visibility_to(boxlist) // CALL
		{
DEBUG:root:				AnchorGenerator.add_visibitity_to(boxlist) { // BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py

DEBUG:root:					// Params

DEBUG:root:					// type(boxlist): <class 'maskrcnn_benchmark.structures.bounding_box.BoxList'>
DEBUG:root:					// boxlist.size: (561, 480)
DEBUG:root:					// boxlist.bbox.shape: torch.Size([648, 4])

DEBUG:root:					image_width, image_height = boxlist.size
DEBUG:root:					// image_width: 561
DEBUG:root:					// image_height: 480

DEBUG:root:					anchors = boxlist.bbox
DEBUG:root:					// anchors.shape: torch.Size([648, 4])

DEBUG:root:					// self.straddle_thresh: -1
DEBUG:root:					else: ie. self.straddle_thresh < 0
DEBUG:root:						device = anchors.device
DEBUG:root:						inds_inside = torch.ones(anchors.shape[0], dtype=torch.bool, device=device)

DEBUG:root:					// inds_inside.shape torch.Size([648])
DEBUG:root:					boxlist.add_field("visibility", inds_inside)

DEBUG:root:				} // END AnchorGenerator.add_visibitity_to(boxlist)

DEBUG:root:

DEBUG:root:				} self.add_visibility_to(boxlist) // RETURNED
DEBUG:root:				// boxlist:BoxList(num_boxes=648, image_width=561, image_height=480, mode=xyxy)

DEBUG:root:				# -----------------------------------------
DEBUG:root:				# 2-3-2-2-2-3 anchors_in_image.append(boxlist)
DEBUG:root:				# i: 1, j: 4/5
DEBUG:root:				# -----------------------------------------
DEBUG:root:				anchors_in_image.append(boxlist)

DEBUG:root:				} // END iteration: j = 4/5

DEBUG:root:				{
DEBUG:root:				# BEGIN iteration: j: 5/5

DEBUG:root:				# anchors_per_feature_map.shape: torch.Size([180, 4])
DEBUG:root:				# image_width: 561
DEBUG:root:				# image_height: 480

DEBUG:root:				# -----------------------------------------
DEBUG:root:				# 2-3-2-2-2-1 boxlist = BoxList( anchors_per_feature_map, (image_width, image_height), mode="xyxy")
DEBUG:root:				# i: 1, j: 5/5
DEBUG:root:				# -----------------------------------------
DEBUG:root:				boxlist = BoxList( anchors_per_feature_map, (image_width, image_height), mode="xyxy" ) // CALL
		{
DEBUG:root:				BoxList.__init__(self, bbox, image_size, mode='xyxy') { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/structures/bounding_box.py

DEBUG:root:					// Params:
DEBUG:root:						// type(bbox):<class 'torch.Tensor'>
DEBUG:root:						// bbox.shape:torch.Size([180, 4])
DEBUG:root:						// image_size: (561, 480)

DEBUG:root:					// isinstance(bbox, torch.Tensor): True
DEBUG:root:					device = bbox.device if isinstance(bbox, torch.Tensor) else torch.device("cpu")
DEBUG:root:					// device: cuda:0

DEBUG:root:					bbox = torch.as_tensor(bbox, dtype=torch.float32, device=device)
DEBUG:root:					// bbox.shape: torch.Size([180, 4])

DEBUG:root:					// bbox.ndimension(): 2
DEBUG:root:					// bbox.size(-1): 4

DEBUG:root:					self.bbox = bbox
DEBUG:root:					self.size = image_size  # (image_width, image_height)
DEBUG:root:					self.mode = mode
DEBUG:root:					self.extra_fields = {}
DEBUG:root:				} // END BoxList.__init__(self, bbox, image_size, mode='xyxy')
DEBUG:root:

DEBUG:root:				} boxlist = BoxList( anchors_per_feature_map, (image_width, image_height), mode="xyxy" ) // RETURNED
DEBUG:root:				// boxlist:
			BoxList(num_boxes=180, image_width=561, image_height=480, mode=xyxy)

DEBUG:root:				# -----------------------------------------
DEBUG:root:				# 2-3-2-2-2-2 self.add_visibility_to(boxlist)
DEBUG:root:				# i: 1, j: 5/5
DEBUG:root:				# -----------------------------------------
DEBUG:root:				self.add_visibility_to(boxlist) // CALL
		{
DEBUG:root:				AnchorGenerator.add_visibitity_to(boxlist) { // BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py

DEBUG:root:					// Params

DEBUG:root:					// type(boxlist): <class 'maskrcnn_benchmark.structures.bounding_box.BoxList'>
DEBUG:root:					// boxlist.size: (561, 480)
DEBUG:root:					// boxlist.bbox.shape: torch.Size([180, 4])

DEBUG:root:					image_width, image_height = boxlist.size
DEBUG:root:					// image_width: 561
DEBUG:root:					// image_height: 480

DEBUG:root:					anchors = boxlist.bbox
DEBUG:root:					// anchors.shape: torch.Size([180, 4])

DEBUG:root:					// self.straddle_thresh: -1
DEBUG:root:					else: ie. self.straddle_thresh < 0
DEBUG:root:						device = anchors.device
DEBUG:root:						inds_inside = torch.ones(anchors.shape[0], dtype=torch.bool, device=device)

DEBUG:root:					// inds_inside.shape torch.Size([180])
DEBUG:root:					boxlist.add_field("visibility", inds_inside)

DEBUG:root:				} // END AnchorGenerator.add_visibitity_to(boxlist)

DEBUG:root:

DEBUG:root:				} self.add_visibility_to(boxlist) // RETURNED
DEBUG:root:				// boxlist:BoxList(num_boxes=180, image_width=561, image_height=480, mode=xyxy)

DEBUG:root:				# -----------------------------------------
DEBUG:root:				# 2-3-2-2-2-3 anchors_in_image.append(boxlist)
DEBUG:root:				# i: 1, j: 5/5
DEBUG:root:				# -----------------------------------------
DEBUG:root:				anchors_in_image.append(boxlist)

DEBUG:root:				} // END iteration: j = 5/5

DEBUG:root:		} // END for j, anchors_per_feature_map in enumerate(anchors_over_all_feature_maps)

DEBUG:root:		// anchors_in_image:[BoxList(num_boxes=38880, image_width=561, image_height=480, mode=xyxy), BoxList(num_boxes=9720, image_width=561, image_height=480, mode=xyxy), BoxList(num_boxes=2430, image_width=561, image_height=480, mode=xyxy), BoxList(num_boxes=648, image_width=561, image_height=480, mode=xyxy), BoxList(num_boxes=180, image_width=561, image_height=480, mode=xyxy)]
DEBUG:root:		// len(anchors_in_image):5

DEBUG:root:		# -----------------------------------------
DEBUG:root:		# 2-3-2-2-3 anchors.append(anchors_in_image)
DEBUG:root:		# -----------------------------------------
DEBUG:root:		anchors.append(anchors_in_image)

DEBUG:root:} # END iteration i: 1

DEBUG:root:} // END for i, (image_height, image_width) in enumerate(image_list.image_sizes)

DEBUG:root:		# return value (anchors) info
DEBUG:root:		// len(anchors):1
DEBUG:root:		// len(anchors[0]):5
DEBUG:root:		// anchors[0][0]: BoxList(num_boxes=38880, image_width=561, image_height=480, mode=xyxy)
DEBUG:root:		// anchors[0][1]: BoxList(num_boxes=9720, image_width=561, image_height=480, mode=xyxy)
DEBUG:root:		// anchors[0][2]: BoxList(num_boxes=2430, image_width=561, image_height=480, mode=xyxy)
DEBUG:root:		// anchors[0][3]: BoxList(num_boxes=648, image_width=561, image_height=480, mode=xyxy)
DEBUG:root:		// anchors[0][4]: BoxList(num_boxes=180, image_width=561, image_height=480, mode=xyxy)
DEBUG:root:
return anchors

DEBUG:root:	} // END AnchorGenerator.forward(image_list, feature_maps)
DEBUG:root:		}
anchors = self.anchor_generator(images, features) // RETURNED
DEBUG:root:		// anchors: list of list of BoxList
DEBUG:root:		// len(anchors):1
DEBUG:root:		// len(anchors[0]):5
DEBUG:root:		// anchors[0][0]: BoxList(num_boxes=38880, image_width=561, image_height=480, mode=xyxy)
DEBUG:root:		// anchors[0][1]: BoxList(num_boxes=9720, image_width=561, image_height=480, mode=xyxy)
DEBUG:root:		// anchors[0][2]: BoxList(num_boxes=2430, image_width=561, image_height=480, mode=xyxy)
DEBUG:root:		// anchors[0][3]: BoxList(num_boxes=648, image_width=561, image_height=480, mode=xyxy)
DEBUG:root:		// anchors[0][4]: BoxList(num_boxes=180, image_width=561, image_height=480, mode=xyxy)
DEBUG:root:

		# ===========================================
DEBUG:root:		# 2-3-2-3 RPN._forward_test
DEBUG:root:		# ===========================================

DEBUG:root:		if self.training: False
DEBUG:root:			# call paramers info
DEBUG:root:			# anchors:
DEBUG:root:			#    from self.anchor_generator(self, x)  # 2-3-2-2
DEBUG:root:			# box_cls, box_regression:
DEBUG:root:			#     return value RetinaNetHead.forward(self, x)
DEBUG:root:			#     called by box_cls, box_regression = self.head(features)  # 2-3-2-1
DEBUG:root:			return self._forward_test(anchors, box_cls, box_regression) // CALL
DEBUG:root:

RetinaNetModule._forward_test(self, anchors, box_cls, box_regression) { // BEGIN
DEBUG:root:	// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/retinanet/retinanet.py

DEBUG:root:	// Params:
DEBUG:root:		// len(anchors): 1
DEBUG:root:		// anchors: [[BoxList(num_boxes=38880, image_width=561, image_height=480, mode=xyxy), BoxList(num_boxes=9720, image_width=561, image_height=480, mode=xyxy), BoxList(num_boxes=2430, image_width=561, image_height=480, mode=xyxy), BoxList(num_boxes=648, image_width=561, image_height=480, mode=xyxy), BoxList(num_boxes=180, image_width=561, image_height=480, mode=xyxy)]]
DEBUG:root:		// len(box_cls): 5 from RetinaNetHead (RPN.Head cls_towers and cls_logit)
DEBUG:root:		// len(box_regression): 5 from RetinaNetHead (RPN.Head bbox_towers and bbox_pred
DEBUG:root:	// self.box_selector_test: RetinaNetPostProcessor()
DEBUG:root:	boxes = self.box_selector_test(anchors=>anchors, box_cls=>objectness, box_regression=>box_regression) // CALL
{
DEBUG:root:		RPNPostProcessor.forward(self. anchors, objectness, box_regression, targets=None) { // BEGIN
DEBUG:root:				// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/inference.py

DEBUG:root:				// Params:
DEBUG:root:					// len(anchors): 1
DEBUG:root:					// anchors: [[BoxList(num_boxes=38880, image_width=561, image_height=480, mode=xyxy), BoxList(num_boxes=9720, image_width=561, image_height=480, mode=xyxy), BoxList(num_boxes=2430, image_width=561, image_height=480, mode=xyxy), BoxList(num_boxes=648, image_width=561, image_height=480, mode=xyxy), BoxList(num_boxes=180, image_width=561, image_height=480, mode=xyxy)]]
DEBUG:root:
					// len(objectness): 5 aka box_cls
DEBUG:root:					//objectness[0].shape): torch.Size([1, 9, 60, 72])
DEBUG:root:					//objectness[1].shape): torch.Size([1, 9, 30, 36])
DEBUG:root:					//objectness[2].shape): torch.Size([1, 9, 15, 18])
DEBUG:root:					//objectness[3].shape): torch.Size([1, 9, 8, 9])
DEBUG:root:					//objectness[4].shape): torch.Size([1, 9, 4, 5])
DEBUG:root:
					// len(box_regression): : 5
DEBUG:root:					//box_regression[0].shape): torch.Size([1, 36, 60, 72])
DEBUG:root:					//box_regression[1].shape): torch.Size([1, 36, 30, 36])
DEBUG:root:					//box_regression[2].shape): torch.Size([1, 36, 15, 18])
DEBUG:root:					//box_regression[3].shape): torch.Size([1, 36, 8, 9])
DEBUG:root:					//box_regression[4].shape): torch.Size([1, 36, 4, 5])
DEBUG:root:					// target: None

DEBUG:root:				sampled_boxes = []
DEBUG:root:				num_levels = len(objectness)
DEBUG:root:				// num_levels: 5

DEBUG:root:				anchors = list(zip(*anchors))

DEBUG:root:				for a, o, b in zip(anchors, objectness, box_regression) {
DEBUG:root:					# 2-3-2-3-1 loop over single_feature_map
DEBUG:root:					{
DEBUG:root:					# BEGIN for a, o, b in zip()  iteration: 1/5
DEBUG:root:					# a: (BoxList(num_boxes=38880, image_width=561, image_height=480, mode=xyxy),)
DEBUG:root:					# o.shape: torch.Size([1, 9, 60, 72])
DEBUG:root:					# b.shape: torch.Size([1, 36, 60, 72])

DEBUG:root:					# 2-3-2-3-2 self.forward_for_single_feature_map
DEBUG:root:					// self.forward_for_single_feature_map: <bound method RetinaNetPostProcessor.forward_for_single_feature_map of RetinaNetPostProcessor()>
DEBUG:root:					sampled_boxes.append(self.forward_for_single_feature_map(a, o, b)) { // CALL
DEBUG:root:RetinaNetPostProcessor.forward_for_single_feature_map() { //BEGIN
DEBUG:root:	// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/retinanet/inference.py

DEBUG:root:	// Params:
DEBUG:root:		> anchors: list[BoxList]
DEBUG:root:		> box_cls: tensor of size N, A*C, H, W)
DEBUG:root:		> box_regression: tensor of size N, A*4, H, W)

DEBUG:root:	device = box_cls.device
DEBUG:root:	// device: cuda:0

DEBUG:root:	N, _, H, W = box_cls.shape
DEBUG:root:	// N:1, H:60, W:72

DEBUG:root:	A = box_regression.size(1) // 4
DEBUG:root:	// A : 9

DEBUG:root:	C = box_cls.size(1) // A
DEBUG:root:	// C: 1

DEBUG:root:	# put 'box_cls' in the same format as anchors
DEBUG:root:	box_cls = permute_and_flatten(box_cls, N, A, C, H, W)
DEBUG:root:	// box_cls.shape: torch.Size([1, 38880, 1])

DEBUG:root:	box_cls = box_cls.sigmoid()
DEBUG:root:	// box_cls.shape: torch.Size([1, 38880, 1])

DEBUG:root:	# put 'box_cls' in the same format as anchors
DEBUG:root:	box_regression = permute_and_flatten(box_regression, N, A, 4, H, W)
DEBUG:root:	// box_regression.shape: torch.Size([1, 38880, 4])

DEBUG:root:	box_regression = box_regression.reshape(N, -1, 4)
DEBUG:root:	// box_regression.shape: torch.Size([1, 38880, 4])

DEBUG:root:	num_anchors = A * H * W
DEBUG:root:	// num_anchors: 38880

DEBUG:root:	candidate_inds = box_cls > self.pre_nms_thresh
DEBUG:root:	// candidate_inds.shape: torch.Size([1, 38880, 1])

DEBUG:root:	pre_nms_top_n = candidate_inds.view(N, -1).sum(1)
DEBUG:root:	// pre_nms_top_n: tensor([846], device='cuda:0')

DEBUG:root:	pre_nms_top_n = pre_nms_top_n.clamp(max=self.pre_nms_top_n)
DEBUG:root:	// pre_nms_top_n: tensor([846], device='cuda:0')

DEBUG:root:	results = []

DEBUG:root:	// box_cls.shape: torch.Size([1, 38880, 1])
DEBUG:root:	// box_regression.shape: torch.Size([1, 38880, 4])
DEBUG:root:	// pre_nmns_top_n: tensor([846], device='cuda:0')
DEBUG:root:	// candidate.inds.shape: torch.Size([1, 38880, 1])
DEBUG:root:	// anchors: (BoxList(num_boxes=38880, image_width=561, image_height=480, mode=xyxy),)
DEBUG:root:	for per_box_cls, per_box_regression, ... in zip():
	{
DEBUG:root:		# ====================================
DEBUG:root:		# per_box_cls.shape: torch.Size([38880, 1])
DEBUG:root:		# type(per_box_cls): <class 'torch.Tensor'>
DEBUG:root:		# per_box_regression.shape: torch.Size([38880, 4])
DEBUG:root:		# per_pre_nms_top_n: 846
DEBUG:root:		# per_candidate_inds.shape: torch.Size([38880, 1])
DEBUG:root:		# per_anchors: BoxList(num_boxes=38880, image_width=561, image_height=480, mode=xyxy)
DEBUG:root:		# ====================================

DEBUG:root:		per_box_cls = per_box_cls[per_candidate_inds]
DEBUG:root:		per_box_cls, top_k_indices =per_box_cls.topk(per_pre_nms_top_n, sorted=False)
DEBUG:root:		// per_box_cls: tensor([0.0525, 0.0671, 0.0605, 0.0640, 0.0576, 0.0511, 0.0646, 0.0710, 0.0697,
        0.0780, 0.0729, 0.0788, 0.0554, 0.2644, 0.5827, 0.6507, 0.3548, 0.0631,
        0.7982, 0.9220, 0.8728, 0.4563, 0.0580, 0.0658, 0.0501, 0.1347, 0.0775,
        0.2188, 0.9680, 0.9187, 0.2132, 0.9878, 0.9746, 0.1192, 0.9866, 0.9923,
        0.0683, 0.9880, 0.9950, 0.0760, 0.9933, 0.9932, 0.0689, 0.9652, 0.8826,
        0.0982, 0.2175, 0.1037, 0.2071, 0.9702, 0.9362, 0.1863, 0.9931, 0.9928,
        0.3014, 0.9912, 0.9915, 0.3307, 0.9914, 0.9810, 0.3070, 0.9897, 0.9293,
        0.1402, 0.8738, 0.5121, 0.1115, 0.4244, 0.1670, 0.9395, 0.1118, 0.9905,
        0.0791, 0.9947, 0.1040, 0.9833, 0.4269, 0.2445, 0.9088, 0.9796, 0.9683,
        0.6671, 0.0743, 0.0528, 0.0691, 0.0861, 0.1465, 0.7331, 0.9395, 0.9441,
        0.9960, 0.0812, 0.9570, 0.9934, 0.1511, 0.8636, 0.9343, 0.0585, 0.0840,
        0.1730, 0.0659, 0.0712, 0.0637, 0.1197, 0.7345, 0.5576, 0.1911, 0.9715,
        0.9440, 0.2291, 0.9878, 0.9909, 0.0565, 0.2711, 0.9823, 0.9836, 0.0852,
        0.3366, 0.9822, 0.9338, 0.0752, 0.0559, 0.4401, 0.3168, 0.0649, 0.0671,
        0.0577, 0.0542, 0.5411, 0.4351, 0.0505, 0.0524, 0.0509, 0.0557, 0.0598,
        0.0585, 0.0581, 0.0631, 0.0699, 0.0567, 0.0701, 0.0774, 0.0745, 0.0683,
        0.0542, 0.0617, 0.0602, 0.0591, 0.0612, 0.0588, 0.0592, 0.0623, 0.0667,
        0.0715, 0.1684, 0.2506, 0.2817, 0.9501, 0.1057, 0.9904, 0.0601, 0.9911,
        0.9857, 0.0625, 0.9605, 0.4239, 0.0840, 0.0549, 0.1025, 0.0599, 0.4675,
        0.0549, 0.1873, 0.2515, 0.0554, 0.1107, 0.0789, 0.0601, 0.2474, 0.1044,
        0.1737, 0.1653, 0.0691, 0.1387, 0.0951, 0.0532, 0.1848, 0.2585, 0.1136,
        0.1026, 0.0548, 0.1002, 0.2817, 0.2120, 0.0658, 0.0690, 0.2197, 0.1728,
        0.0564, 0.0878, 0.0826, 0.0556, 0.0712, 0.0563, 0.1040, 0.1781, 0.0574,
        0.2342, 0.3577, 0.1687, 0.4522, 0.0667, 0.3420, 0.3736, 0.0507, 0.0648,
        0.1714, 0.2625, 0.1210, 0.0971, 0.2152, 0.2207, 0.1904, 0.0591, 0.0592,
        0.1740, 0.1007, 0.3053, 0.2952, 0.1324, 0.1371, 0.0653, 0.7696, 0.0912,
        0.0508, 0.1355, 0.2287, 0.9357, 0.7510, 0.1160, 0.9894, 0.9931, 0.9860,
        0.9983, 0.9862, 0.9971, 0.9816, 0.9957, 0.9732, 0.9903, 0.7367, 0.8833,
        0.3081, 0.1082, 0.4716, 0.1069, 0.5946, 0.5667, 0.3393, 0.1606, 0.0646,
        0.1712, 0.2921, 0.0734, 0.1073, 0.1466, 0.1133, 0.1622, 0.1296, 0.0725,
        0.0540, 0.3029, 0.2092, 0.0608, 0.0976, 0.2335, 0.2607, 0.1165, 0.0738,
        0.1753, 0.2184, 0.1163, 0.1260, 0.1083, 0.0553, 0.0626, 0.0843, 0.0751,
        0.0807, 0.1338, 0.1643, 0.0984, 0.0706, 0.1398, 0.2550, 0.2228, 0.0647,
        0.1302, 0.2762, 0.0663, 0.1555, 0.1552, 0.2108, 0.2288, 0.0550, 0.0914,
        0.0753, 0.3962, 0.1830, 0.5560, 0.0629, 0.1753, 0.1075, 0.2729, 0.5291,
        0.1032, 0.3015, 0.3638, 0.2380, 0.0743, 0.8967, 0.2270, 0.3029, 0.7195,
        0.8813, 0.2541, 0.0733, 0.0851, 0.1680, 0.1717, 0.1037, 0.0515, 0.0567,
        0.0884, 0.0569, 0.1025, 0.0826, 0.0801, 0.0973, 0.1141, 0.0690, 0.0576,
        0.1516, 0.6650, 0.1603, 0.9360, 0.1477, 0.9753, 0.1483, 0.9866, 0.2083,
        0.9797, 0.0543, 0.6144, 0.0616, 0.0743, 0.1722, 0.1479, 0.0893, 0.2436,
        0.4986, 0.2365, 0.0769, 0.2223, 0.4614, 0.6524, 0.1154, 0.1615, 0.3931,
        0.5912, 0.1079, 0.0550, 0.4048, 0.6449, 0.5174, 0.7077, 0.0847, 0.5711,
        0.6941, 0.2182, 0.6273, 0.4000, 0.1615, 0.2567, 0.0732, 0.0687, 0.0685,
        0.0740, 0.0645, 0.0737, 0.0945, 0.3806, 0.1012, 0.7201, 0.7844, 0.7144,
        0.9419, 0.8001, 0.9769, 0.8626, 0.9886, 0.8338, 0.9807, 0.3063, 0.7048,
        0.0743, 0.0583, 0.2664, 0.1544, 0.0520, 0.1605, 0.4675, 0.0985, 0.4775,
        0.0521, 0.0973, 0.5178, 0.1696, 0.5753, 0.2192, 0.5532, 0.0675, 0.2691,
        0.2437, 0.1041, 0.1128, 0.0614, 0.0784, 0.0584, 0.0730, 0.0508, 0.0506,
        0.0663, 0.0887, 0.0604, 0.0727, 0.1056, 0.0634, 0.0807, 0.0709, 0.1877,
        0.2683, 0.5802, 0.9570, 0.4470, 0.9454, 0.3415, 0.8503, 0.2534, 0.8694,
        0.1516, 0.6883, 0.1882, 0.0837, 0.0947, 0.0594, 0.0580, 0.0566, 0.0761,
        0.0510, 0.5935, 0.7547, 0.0641, 0.7375, 0.1987, 0.8951, 0.8817, 0.0796,
        0.8533, 0.9076, 0.0875, 0.7543, 0.8670, 0.1736, 0.7245, 0.5472, 0.0570,
        0.0659, 0.0635, 0.0735, 0.0574, 0.6732, 0.6817, 0.7305, 0.9541, 0.7105,
        0.9536, 0.7512, 0.7807, 0.1138, 0.1469, 0.0691, 0.0887, 0.0585, 0.0780,
        0.3833, 0.3179, 0.0678, 0.8244, 0.9609, 0.6770, 0.9481, 0.5921, 0.8102,
        0.5483, 0.7711, 0.3758, 0.4779, 0.1216, 0.1309, 0.0869, 0.0849, 0.6431,
        0.7226, 0.7148, 0.0871, 0.7500, 0.7782, 0.0834, 0.7655, 0.7540, 0.0727,
        0.6618, 0.7896, 0.1350, 0.7547, 0.3443, 0.1069, 0.0699, 0.0839, 0.4381,
        0.2962, 0.5513, 0.9759, 0.8558, 0.4252, 0.9815, 0.9733, 0.4334, 0.9783,
        0.9715, 0.5791, 0.9827, 0.8646, 0.2291, 0.8002, 0.3781, 0.0807, 0.1247,
        0.3866, 0.5190, 0.0941, 0.0576, 0.0557, 0.0543, 0.0600, 0.0582, 0.0581,
        0.0678, 0.0934, 0.1191, 0.1215, 0.1139, 0.1015, 0.0890, 0.0867, 0.0800,
        0.0666, 0.0569, 0.0508, 0.0565, 0.0531, 0.0978, 0.4612, 0.8258, 0.8943,
        0.7104, 0.1287, 0.2944, 0.0632, 0.3256, 0.9151, 0.1285, 0.1069, 0.0874,
        0.3543, 0.0682, 0.1201, 0.0843, 0.3797, 0.0705, 0.3311, 0.5034, 0.1166,
        0.1403, 0.1215, 0.2363, 0.0632, 0.0848, 0.0572, 0.0802, 0.0527, 0.0635,
        0.0605, 0.0722, 0.1053, 0.0516, 0.3983, 0.0586, 0.4100, 0.1160, 0.0578,
        0.0603, 0.0936, 0.4171, 0.3575, 0.0717, 0.8031, 0.3322, 0.9509, 0.9248,
        0.9901, 0.9947, 0.9956, 0.9982, 0.9974, 0.9988, 0.0634, 0.9982, 0.9981,
        0.9475, 0.8383, 0.4642, 0.1062, 0.0760, 0.9630, 0.8168, 0.3221, 0.9690,
        0.9719, 0.1127, 0.2696, 0.1156, 0.9382, 0.8308, 0.0690, 0.1678, 0.3222,
        0.0622, 0.2460, 0.0688, 0.7396, 0.3508, 0.5114, 0.0652, 0.8581, 0.7854,
        0.2646, 0.1452, 0.6610, 0.5281, 0.0661, 0.2217, 0.4417, 0.2808, 0.0517,
        0.1125, 0.1724, 0.1410, 0.1485, 0.1618, 0.0525, 0.1823, 0.1411, 0.0629,
        0.4462, 0.1222, 0.4472, 0.0777, 0.1340, 0.0902, 0.0591, 0.0893, 0.1061,
        0.4120, 0.3368, 0.3375, 0.8613, 0.9634, 0.9820, 0.9167, 0.1226, 0.0912,
        0.5207, 0.7041, 0.8215, 0.6630, 0.0576, 0.8241, 0.9907, 0.9888, 0.8039,
        0.4324, 0.3585, 0.8967, 0.9329, 0.9709, 0.9868, 0.9713, 0.9874, 0.9838,
        0.9916, 0.9901, 0.9886, 0.8146, 0.7445, 0.0691, 0.1570, 0.9619, 0.8381,
        0.3242, 0.9995, 0.9978, 0.2541, 0.9996, 0.9997, 0.2702, 0.9996, 0.9996,
        0.4038, 0.9995, 0.9959, 0.1377, 0.9736, 0.8081, 0.3473, 0.7629, 0.8611,
        0.8939, 0.6380, 0.0518, 0.0632, 0.1284, 0.9762, 0.0544, 0.9984, 0.9985,
        0.0619, 0.9645, 0.0855, 0.0504, 0.2692, 0.5224, 0.6710, 0.4968, 0.2071,
        0.0568, 0.8586, 0.9598, 0.0728, 0.9737, 0.0693, 0.6823, 0.0968, 0.5487,
        0.5408, 0.3741, 0.5868, 0.0731, 0.1498, 0.2669, 0.1180, 0.0535, 0.0841,
        0.0552, 0.3495, 0.0993, 0.0575, 0.8086, 0.6675, 0.1051, 0.9314, 0.8294,
        0.1181, 0.9310, 0.8676, 0.1159, 0.9071, 0.8767, 0.1156, 0.8860, 0.8296,
        0.0590, 0.5761, 0.3401, 0.0687, 0.0544, 0.1475, 0.2296, 0.9428, 0.6594,
        0.3169, 0.9704, 0.9181, 0.2131, 0.9605, 0.9728, 0.3037, 0.9846, 0.9800,
        0.3587, 0.9879, 0.8962, 0.1884, 0.8087, 0.3302, 0.0563, 0.0619, 0.9411,
        0.4633, 0.5494, 0.9825, 0.8870, 0.8657, 0.4589, 0.9685, 0.8173, 0.8359,
        0.0901, 0.4903, 0.1344, 0.0850, 0.3752, 0.5718, 0.5143, 0.2328, 0.6084,
        0.8725, 0.8943, 0.3605, 0.0644, 0.0912, 0.5094, 0.0520, 0.1083, 0.0501])
DEBUG:root:		// top_k_indices: tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,
        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,
        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,
        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,
        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,
        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,
        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,
        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,
        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,
        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,
        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,
        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,
        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,
        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,
        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,
        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,
        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,
        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,
        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,
        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,
        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,
        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,
        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,
        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,
        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,
        504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 515, 516, 517, 518,
        519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532,
        533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546,
        547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560,
        561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574,
        575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588,
        589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602,
        603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616,
        617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630,
        631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644,
        645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658,
        659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672,
        673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686,
        687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700,
        701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714,
        715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728,
        729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742,
        743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756,
        757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770,
        771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784,
        785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798,
        799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812,
        813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826,
        827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840,
        841, 842, 843, 844, 845, 514])

DEBUG:root:		per_candidate_nonzeros = \
DEBUG:root:		   per_candidate_inds.nonzero()[top_k_indices, :]
DEBUG:root:		// per_candidate_inds.shape: torch.Size([38880, 1])

DEBUG:root:		per_box_loc = per_candidate_nonzeros[:, 0]
DEBUG:root:		// per_box_loc.shape: torch.Size([846])

DEBUG:root:		per_class = per_candidate_nonzeros[:, 1]
DEBUG:root:		// per_class.shape: torch.Size([846])

DEBUG:root:		per_class += 1

DEBUG:root:		detections = self.box_coder.decode( ) { // CALL
DEBUG:root:		BoxCoder.decode(self, rel_codes, boxes) { // BEGIN
DEBUG:root:			// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/box_coder.py
DEBUG:root:			// Params:
DEBUG:root:				rel_codes.shape: torch.Size([846, 4])
DEBUG:root:				boxes.shape: torch.Size([846, 4])

DEBUG:root:			boxes = boxes.to(rel_codes.dtype)
DEBUG:root:			// boxes.shape: torch.Size([846, 4])

DEBUG:root:			TO_REMOVE = 1  # TODO remove

DEBUG:root:			widths = boxes[:, 2] - boxes[:, 0] + TO_REMOVE
DEBUG:root:			// widths.shape: torch.Size([846])

DEBUG:root:			heights = boxes[:, 3] - boxes[:, 1] + TO_REMOVE
DEBUG:root:			// heights.shape: torch.Size([846])

DEBUG:root:			ctr_x = boxes[:, 0] + 0.5 * widths
DEBUG:root:			// ctr_x.shape: torch.Size([846])

DEBUG:root:			ctr_y = boxes[:, 1] + 0.5 * heights
DEBUG:root:			// ctr_y.shape: torch.Size([846])


DEBUG:root:			wx, wy, ww, wh = self.weights
DEBUG:root:			// wx: 10.0, wy: 10.0, ww: 5.0, wh: 5.0

DEBUG:root:			dx = rel_codes[:, 0::4] / wx
DEBUG:root:			// dx.shape: torch.Size([846, 1])

DEBUG:root:			dy = rel_codes[:, 1::4] / wy
DEBUG:root:			// dy.shape: torch.Size([846, 1])

DEBUG:root:			dw = rel_codes[:, 2::4] / ww
DEBUG:root:			// dw.shape: torch.Size([846, 1])

DEBUG:root:			dh = rel_codes[:, 3::4] / wh
DEBUG:root:			// dh.shape: torch.Size([846, 1])


DEBUG:root:			# Prevent sending too large values into torch.exp()
DEBUG:root:			dw = torch.clamp(dw, max=self.bbox_xform_clip)
DEBUG:root:			// dw.shape: torch.Size([846, 1])

DEBUG:root:			dh = torch.clamp(dh, max=self.bbox_xform_clip)
DEBUG:root:			// dh.shape: torch.Size([846, 1])

DEBUG:root:			pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]
DEBUG:root:			// pred_ctr_x.shape: torch.Size([846, 1])

DEBUG:root:			pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]
DEBUG:root:			// pred_ctr_y.shape: torch.Size([846, 1])

DEBUG:root:			pred_w = torch.exp(dw) * widths[:, None]
DEBUG:root:			// pred_w.shape: torch.Size([846, 1])

DEBUG:root:			pred_h = torch.exp(dh) * heights[:, None]
DEBUG:root:			// pred_h.shape: torch.Size([846, 1])


DEBUG:root:			pred_boxes = torch.zeros_like(rel_codes)
DEBUG:root:			// pred_boxes.shape: torch.Size([846, 4])


DEBUG:root:			# x1
DEBUG:root:			pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w

DEBUG:root:			# y1
DEBUG:root:			pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h

DEBUG:root:			# x2 (note: '- 1' is correct; don't be fooled by the asymmetry)
DEBUG:root:			pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w - 1

DEBUG:root:			# y2 (note: '- 1' is correct; don't be fooled by the asymmetry)
DEBUG:root:			pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h - 1


DEBUG:root:			pred_boxes.shape: torch.Size([846, 4])

DEBUG:root:			return pred_boxes

DEBUG:root:		} // END BoxCoder.decode(self, rel_codes, boxes)

DEBUG:root:		} detections = self.box_coder.decode( ) // RETURNED

DEBUG:root:		// type(detections): <class 'torch.Tensor'>
DEBUG:root:		// detections: tensor([[ 81.3227,  25.2027, 130.9270,  61.1659],
        [ 78.7558,  20.3871, 137.0195,  64.6538],
        [ 78.1413,  20.5882, 134.2587,  64.9149],
        [ 79.8649,  19.2144, 136.5249,  66.5698],
        [ 78.3723,  19.2699, 136.2249,  68.6461],
        [ 80.2245,  16.3150, 132.9056,  74.3874],
        [ 80.9453,  26.2738, 138.6343,  71.3957],
        [ 78.9160,  25.7190, 135.7653,  72.2400],
        [ 77.0438,  20.6403, 133.0709,  78.6479],
        [ 81.2455,  24.2860, 139.0143,  73.0214],
        [ 78.2585,  24.5806, 137.2208,  74.3959],
        [ 77.7947,  22.4819, 134.9774,  79.8749],
        [ 83.6639,  23.7961, 141.3301,  74.5757],
        [187.6071,  46.7782, 275.3052,  74.8030],
        [188.0774,  47.4488, 275.6566,  73.7729],
        [187.9682,  47.7004, 277.1918,  73.3938],
        [189.3133,  47.4474, 276.9146,  72.6341],
        [282.6693,  45.1217, 361.9620,  72.0494],
        [284.3165,  47.0951, 368.2970,  73.0911],
        [284.6274,  47.4062, 370.0563,  72.7284],
        [283.7743,  46.7126, 370.7960,  72.5756],
        [283.7312,  46.5117, 371.1086,  72.4880],
        [ 76.0762,  28.9394, 135.5404,  87.2807],
        [ 78.0249,  30.2331, 137.0025,  88.1207],
        [185.0452,  46.2679, 241.7013,  75.8322],
        [186.6016,  47.0293, 261.4979,  75.9420],
        [186.0378,  45.7159, 267.7762,  77.1951],
        [187.9713,  47.8467, 262.6849,  74.7285],
        [187.0740,  47.1408, 278.0413,  75.1207],
        [187.0219,  46.6973, 276.1434,  75.6406],
        [188.3389,  48.1909, 273.8558,  73.9912],
        [187.3519,  48.1553, 276.0275,  74.5788],
        [186.9629,  48.0591, 276.6030,  74.9192],
        [189.3094,  48.3438, 273.8003,  73.2577],
        [187.1818,  48.2639, 276.4908,  74.1537],
        [187.1996,  48.1840, 276.9112,  74.3033],
        [190.6541,  48.5245, 274.5927,  73.0348],
        [187.5330,  48.1971, 276.9821,  74.3182],
        [187.4712,  48.3434, 276.9974,  74.3436],
        [192.5742,  48.2905, 274.9859,  72.3490],
        [188.2964,  48.3320, 276.4489,  73.4035],
        [188.5768,  48.3417, 276.5476,  73.5901],
        [195.0285,  48.2539, 275.5810,  72.4376],
        [187.0268,  47.9457, 276.3680,  73.3163],
        [187.5325,  47.3471, 276.7407,  74.0867],
        [195.3167,  47.5226, 276.5245,  73.7942],
        [283.6366,  47.0830, 355.0704,  73.8759],
        [282.6351,  46.0869, 357.3394,  74.6740],
        [283.7550,  47.6245, 353.7667,  73.1347],
        [284.0605,  46.9125, 371.2044,  73.3778],
        [283.3621,  46.4628, 370.3092,  73.6794],
        [285.0220,  47.7414, 364.7283,  72.9688],
        [283.8060,  47.5957, 370.7070,  73.3398],
        [284.0679,  47.8397, 370.6190,  73.2178],
        [285.6507,  48.1315, 367.4690,  72.4107],
        [282.8689,  47.7622, 372.2303,  72.9843],
        [283.1281,  47.9168, 372.0030,  72.9120],
        [286.3204,  48.1817, 369.3982,  72.2445],
        [282.7086,  47.4647, 371.6978,  73.0539],
        [283.1121,  47.5603, 371.1495,  72.8507],
        [289.2236,  47.8909, 369.1430,  72.4381],
        [283.2614,  47.6337, 371.2444,  73.1172],
        [283.5765,  47.5163, 370.7206,  73.0246],
        [295.4057,  47.6403, 369.2364,  72.2164],
        [286.7992,  47.3451, 370.9734,  73.4068],
        [285.1273,  46.7208, 370.9041,  74.2940],
        [187.3661,  48.8557, 265.3018,  76.0866],
        [186.1410,  47.5541, 274.3205,  76.8059],
        [186.9352,  48.8592, 274.5491,  75.1492],
        [186.4345,  48.0052, 276.9619,  75.0641],
        [187.6077,  48.9666, 275.8602,  74.5803],
        [186.8242,  48.2773, 277.2164,  74.0125],
        [187.9821,  49.0697, 275.8226,  74.8262],
        [187.1331,  48.7249, 276.6153,  74.2259],
        [189.1347,  48.9705, 275.7886,  73.6513],
        [188.0416,  48.4533, 275.8383,  73.1799],
        [188.0319,  48.5192, 276.6142,  74.2008],
        [283.2762,  47.4928, 364.2360,  74.6629],
        [283.4026,  47.6535, 370.1758,  73.2801],
        [283.1202,  47.7416, 371.5120,  72.8645],
        [283.8270,  47.8329, 370.7866,  72.9731],
        [284.4718,  47.4070, 371.3185,  73.1054],
        [379.5544,  49.9194, 458.6581,  89.1182],
        [383.2102,  49.5666, 464.9809,  87.6207],
        [378.1382,  55.2102, 458.8818,  99.6518],
        [236.0175,  82.1428, 311.9262, 110.0256],
        [235.9205,  81.9465, 319.2196, 111.6214],
        [237.8743,  82.9564, 316.6280, 110.0355],
        [237.4141,  83.2478, 318.2462, 111.1835],
        [238.9911,  83.3825, 317.7345, 110.3848],
        [238.0541,  83.6444, 317.7761, 110.9694],
        [239.0485,  81.6651, 316.4407, 112.6878],
        [240.5882,  83.6375, 316.6654, 110.0829],
        [239.9045,  83.7649, 317.0263, 110.5890],
        [241.1096,  82.1098, 315.9056, 112.0076],
        [241.7921,  83.9641, 316.7795, 109.6886],
        [240.1248,  83.7402, 317.8716, 110.3130],
        [250.0966,  83.2365, 314.1880, 109.8375],
        [241.5439,  82.0113, 317.2461, 111.7605],
        [243.8703,  82.7028, 319.5254, 110.4267],
        [361.5274,  72.2187, 433.0860, 117.3568],
        [365.7807,  69.2473, 438.0043, 117.0156],
        [369.7455,  67.0938, 445.7863, 116.1040],
        [237.2079,  83.3949, 301.4229, 110.3121],
        [235.4482,  82.5139, 319.9034, 111.5356],
        [235.5332,  82.2840, 321.5025, 112.3561],
        [238.5736,  84.0163, 313.7429, 110.5081],
        [237.0193,  83.4379, 318.8055, 111.0724],
        [237.1021,  83.5089, 317.6365, 111.1191],
        [240.3914,  84.3390, 315.8295, 110.5780],
        [237.6076,  83.5188, 317.5515, 110.9697],
        [237.1888,  83.6461, 317.7266, 110.9417],
        [238.0902,  81.5880, 316.1656, 113.1964],
        [241.8466,  84.6035, 314.8817, 109.9997],
        [239.7246,  83.9383, 316.6358, 110.4613],
        [239.3410,  83.9174, 316.8478, 110.4687],
        [240.4063,  81.8217, 315.4970, 112.4200],
        [240.4890,  84.4380, 315.8267, 109.7989],
        [238.2051,  84.3114, 316.8370, 110.1745],
        [238.6501,  84.0132, 317.3819, 110.4146],
        [244.6829,  83.2795, 314.3640, 110.9187],
        [264.1404,  84.7910, 314.5359, 109.7360],
        [242.8690,  84.0020, 316.9330, 110.6510],
        [240.0665,  83.6116, 317.5822, 111.5540],
        [357.3587,  76.2131, 431.6918, 120.7236],
        [362.9623,  74.9904, 438.6342, 120.4561],
        [368.4743,  74.5482, 446.9228, 119.6918],
        [235.9620,  83.7273, 316.5164, 112.5651],
        [236.5312,  83.3851, 317.2319, 111.1185],
        [237.9848,  83.6134, 317.6257, 111.0076],
        [145.6772,  56.5803, 272.2485,  98.9507],
        [133.5671,  59.1614, 277.3323, 105.5100],
        [126.3017,  60.4945, 284.0126, 110.0409],
        [186.0351,  69.4723, 321.5512,  97.3031],
        [174.8972,  56.7799, 299.7015,  81.9466],
        [164.2604,  39.6296, 281.0283,  63.6691],
        [156.9411,  22.2588, 262.2635,  45.7267],
        [150.6332,  12.6749, 237.8534,  35.1618],
        [135.0940,  12.2032, 214.3578,  35.7650],
        [169.0780,  60.5613, 316.6466, 106.0871],
        [148.7215,  57.8962, 319.7340, 108.3448],
        [130.6814,  56.9840, 328.2486, 111.9919],
        [126.5060,  57.6126, 341.1669, 117.4672],
        [138.5264,  59.4794, 355.6622, 123.0738],
        [165.9132,  63.5138, 368.4856, 128.9355],
        [205.7784,  79.6955, 407.1278, 141.4455],
        [198.5980,  77.6903, 418.4143, 139.9814],
        [218.2558,  89.8854, 368.1521, 119.0596],
        [202.1083,  83.7358, 338.6246, 108.4430],
        [190.7664,  71.1998, 314.9216,  94.1881],
        [178.2978,  49.7765, 288.6395,  72.4091],
        [172.3019,  24.8793, 265.1483,  47.2351],
        [169.3408,   8.8708, 237.9437,  30.8456],
        [158.1660,   8.4013, 215.7298,  31.0059],
        [ 82.9306, 164.5450, 167.4999, 188.5387],
        [ 82.5281, 163.7338, 175.2298, 190.1506],
        [ 83.7853, 165.2911, 173.4380, 188.3172],
        [ 83.1093, 165.0478, 176.8596, 189.5064],
        [ 83.9986, 164.9900, 176.1992, 188.2424],
        [ 82.4959, 164.9900, 180.4236, 189.8811],
        [ 84.3651, 164.5595, 177.9711, 187.9177],
        [ 82.5422, 164.9108, 180.6918, 189.5731],
        [ 82.2769, 164.6211, 182.7206, 190.0773],
        [ 88.3984, 164.8783, 180.7156, 188.5456],
        [ 84.2930, 165.0544, 182.0442, 189.9212],
        [ 83.3558, 163.1398, 183.9089, 190.5128],
        [159.0812, 164.8029, 184.6678, 191.0392],
        [260.9110, 167.4916, 284.0807, 185.8487],
        [260.3864, 166.2241, 294.4323, 185.9639],
        [258.8919, 164.9249, 304.4512, 186.8196],
        [262.3769, 168.2294, 289.1635, 186.5106],
        [259.2453, 165.1485, 294.1042, 187.6309],
        [262.8301, 167.1157, 303.7541, 186.9768],
        [262.0222, 166.7188, 310.2607, 187.2723],
        [260.2598, 165.2285, 316.2167, 188.2068],
        [265.3542, 168.6503, 293.8438, 187.2635],
        [262.6102, 166.4528, 305.3072, 188.3000],
        [263.4685, 166.5000, 314.1793, 186.8252],
        [263.3335, 167.1812, 316.4588, 186.8749],
        [263.1112, 165.8352, 330.4671, 187.4824],
        [264.9511, 166.4173, 329.9863, 186.7005],
        [262.9075, 166.3138, 341.1378, 187.7013],
        [295.8540, 166.0184, 333.9372, 185.9576],
        [279.9633, 166.5844, 337.5875, 186.0275],
        [270.0443, 166.0610, 350.3355, 187.2914],
        [295.8763, 166.5739, 323.8717, 187.5160],
        [295.5420, 167.0397, 336.3933, 186.8661],
        [294.9286, 167.3560, 339.6224, 186.7082],
        [281.0418, 165.6443, 352.7191, 187.3571],
        [297.1013, 166.5797, 334.8089, 187.2299],
        [295.4320, 168.0353, 334.9027, 188.1201],
        [296.9832, 166.3599, 340.1258, 186.5563],
        [296.2929, 166.8461, 346.8376, 186.8970],
        [293.2815, 166.0016, 355.3913, 187.6755],
        [303.9546, 167.4379, 336.3278, 187.0424],
        [301.6358, 166.2058, 351.6780, 186.2271],
        [296.4447, 166.6609, 354.5121, 186.7400],
        [295.7032, 166.0534, 359.4389, 187.7118],
        [318.0140, 165.3605, 359.3471, 186.0685],
        [297.4963, 166.2414, 361.5288, 186.5907],
        [291.0337, 165.5631, 374.9442, 187.5924],
        [332.0075, 165.9064, 356.9412, 186.5938],
        [286.9700, 164.8439, 397.6599, 188.0234],
        [337.6266, 165.3470, 360.2023, 187.2004],
        [338.6188, 166.0165, 395.9579, 187.2598],
        [314.0200, 165.3444, 403.2854, 188.2360],
        [339.6983, 165.0189, 397.7981, 187.1521],
        [339.8108, 165.9655, 403.8960, 187.5301],
        [339.1043, 165.9939, 405.8217, 187.8884],
        [343.5888, 165.8504, 405.9510, 187.2154],
        [341.5381, 165.8143, 406.6821, 187.4368],
        [356.9250, 165.4619, 406.2704, 187.0060],
        [350.7237, 165.4714, 406.4987, 187.1284],
        [345.7033, 165.0409, 407.4378, 187.5882],
        [362.8166, 165.4992, 402.2785, 186.9831],
        [356.6580, 164.8573, 405.7570, 187.7362],
        [357.8713, 165.5745, 407.3897, 187.6078],
        [356.7579, 165.9165, 407.5820, 187.4326],
        [351.9998, 164.6269, 409.1523, 188.0132],
        [363.4666, 165.0552, 406.6054, 187.2763],
        [358.9303, 165.3073, 407.5850, 187.9999],
        [384.1858, 165.3748, 408.3076, 187.4307],
        [417.0226, 167.9930, 439.7854, 185.9958],
        [417.1901, 166.1685, 464.7184, 186.4860],
        [416.9952, 166.3777, 471.1334, 187.1481],
        [420.4024, 168.3879, 446.0908, 186.4944],
        [417.2995, 167.0365, 470.5327, 186.6503],
        [417.4489, 167.4544, 470.7736, 186.9178],
        [426.2415, 166.5031, 470.7651, 186.2909],
        [420.0580, 166.8160, 470.9672, 186.8627],
        [440.7964, 167.4875, 468.6185, 186.4284],
        [423.7425, 165.7759, 470.8945, 187.8302],
        [449.3864, 167.3077, 472.2330, 186.6139],
        [447.4071, 164.6501, 471.9772, 187.9331],
        [ 83.4707, 165.1059, 144.9277, 189.7613],
        [ 82.4496, 164.4373, 161.5552, 191.3667],
        [ 81.4911, 165.3280, 159.1577, 189.6298],
        [ 82.0402, 165.1459, 177.7531, 190.9210],
        [ 82.0671, 164.0763, 182.2155, 192.0893],
        [ 83.6752, 166.1112, 164.3564, 189.6097],
        [ 83.0745, 165.2735, 180.0360, 190.0199],
        [ 83.3206, 165.0195, 177.7660, 190.0131],
        [ 82.9272, 165.2404, 179.8849, 189.9876],
        [ 82.3102, 165.0672, 180.9667, 190.2034],
        [ 82.4374, 165.2739, 181.1236, 190.1241],
        [ 82.2741, 165.1275, 181.1275, 190.1407],
        [ 82.1947, 165.3093, 182.1914, 190.5890],
        [ 82.1061, 165.0425, 182.1853, 190.5813],
        [ 84.0123, 165.4867, 181.1895, 190.0902],
        [ 80.7503, 165.1010, 182.2058, 190.3641],
        [ 82.4553, 164.7943, 181.6571, 190.8225],
        [ 80.0649, 164.0043, 182.8884, 191.4262],
        [260.6541, 167.9518, 288.1821, 187.9562],
        [261.7666, 168.0142, 284.2726, 187.0939],
        [261.5524, 168.4140, 290.0732, 187.3577],
        [261.1324, 167.2625, 301.2831, 188.9721],
        [262.1909, 168.3461, 288.1512, 186.7824],
        [263.2371, 168.3210, 299.0535, 186.9743],
        [262.8023, 167.5820, 306.7506, 187.3835],
        [263.9539, 168.0300, 291.9542, 186.7259],
        [262.0305, 166.9741, 302.6565, 188.5836],
        [264.5806, 167.7691, 309.4279, 187.1126],
        [264.3050, 167.3738, 315.0716, 186.5090],
        [264.0370, 166.3149, 333.0617, 188.1195],
        [274.0863, 167.1898, 318.8101, 187.4495],
        [266.1479, 167.1207, 328.1703, 186.9471],
        [264.3774, 166.6746, 340.3842, 188.0478],
        [297.1012, 167.3299, 334.1167, 186.7121],
        [281.1294, 167.2455, 335.8861, 186.5453],
        [271.1304, 166.3972, 350.9921, 187.5919],
        [295.2808, 165.7633, 324.7177, 187.1231],
        [297.1048, 166.6959, 335.8196, 186.5701],
        [296.4024, 167.2732, 338.3278, 186.2484],
        [280.6812, 166.1165, 355.4030, 188.0958],
        [296.0125, 165.7199, 335.6075, 187.0194],
        [298.1042, 166.4041, 338.5432, 186.5113],
        [297.6511, 166.5434, 346.5111, 186.1333],
        [292.1706, 165.8157, 354.7409, 187.4504],
        [302.8368, 165.8270, 335.9444, 186.2963],
        [303.0208, 166.0603, 352.5954, 186.2556],
        [297.4047, 166.1776, 355.2773, 186.1295],
        [294.1501, 165.5344, 360.6114, 187.4355],
        [319.4413, 166.1570, 358.0396, 186.4772],
        [300.5715, 166.1632, 359.6042, 186.5468],
        [289.3831, 165.4844, 380.8234, 188.2863],
        [330.4196, 164.8191, 356.7196, 186.2306],
        [336.5905, 166.4090, 362.3932, 187.3636],
        [323.9998, 165.8899, 378.1863, 187.9501],
        [338.4418, 165.2403, 360.3327, 187.3339],
        [340.5651, 166.4418, 382.2570, 187.2570],
        [340.6526, 165.9516, 400.5381, 187.5914],
        [317.3834, 165.3361, 403.0616, 188.5375],
        [340.3804, 166.2585, 361.5844, 186.0361],
        [342.5940, 165.9247, 398.6001, 187.4874],
        [340.7811, 165.3605, 405.3461, 187.2196],
        [339.3376, 165.3049, 405.7627, 187.6285],
        [349.4848, 165.8411, 405.6776, 187.0760],
        [345.9579, 165.5661, 405.9234, 186.7516],
        [342.1427, 165.5078, 406.8171, 186.9609],
        [355.6924, 165.8729, 406.0263, 186.9720],
        [351.5202, 165.5473, 406.4234, 186.9042],
        [346.4220, 164.9894, 407.6580, 187.6042],
        [358.2287, 165.8660, 406.6039, 187.3591],
        [356.2065, 165.8007, 407.2137, 187.2257],
        [351.6302, 164.9033, 408.6741, 188.3434],
        [362.7694, 165.6267, 405.9896, 187.6546],
        [358.7389, 165.0338, 406.7005, 188.0611],
        [367.4610, 165.6402, 408.2896, 188.2388],
        [359.4428, 165.0450, 408.8128, 188.5826],
        [381.8687, 165.4845, 407.8391, 187.7708],
        [385.2007, 165.7454, 411.7816, 188.9505],
        [388.7673, 165.0703, 409.2444, 188.2504],
        [416.8008, 167.6118, 448.6385, 186.7265],
        [417.5709, 167.3659, 440.7754, 185.6224],
        [418.5559, 167.3179, 464.6382, 187.0083],
        [417.5041, 166.6025, 469.4177, 187.2305],
        [421.2673, 167.8729, 446.9106, 185.9745],
        [418.2906, 167.5389, 469.9304, 186.7937],
        [418.4862, 167.2492, 470.4449, 186.7623],
        [426.3720, 168.1407, 460.4749, 186.5237],
        [426.2682, 167.5497, 469.4652, 186.5363],
        [419.9720, 167.1158, 469.9684, 186.7150],
        [439.5257, 167.7187, 467.0304, 186.1745],
        [444.8795, 167.1486, 472.2797, 186.6279],
        [449.5045, 167.3172, 471.1264, 186.0238],
        [447.9998, 166.6613, 473.3600, 187.1376],
        [451.4949, 166.9119, 471.4929, 186.5557],
        [ 82.3201, 165.6113, 173.7951, 192.1852],
        [ 82.1456, 166.0011, 177.2849, 191.8629],
        [ 83.1056, 165.8984, 178.5093, 192.0858],
        [ 84.6710, 165.7180, 179.9536, 192.3375],
        [160.4978, 163.9818, 183.9451, 191.3041],
        [261.6829, 169.9734, 287.1318, 188.6927],
        [338.8998, 165.9483, 407.4609, 189.2197],
        [446.8940, 163.9081, 470.6573, 188.1233],
        [367.0428, 207.2039, 467.2462, 230.1317],
        [369.1393, 208.1651, 479.1175, 230.8775],
        [369.8092, 208.1630, 481.8236, 230.5371],
        [370.8247, 207.8502, 480.7412, 230.3787],
        [372.5068, 207.3831, 478.2040, 230.4581],
        [ 84.4945, 212.9887, 111.8528, 236.9151],
        [ 84.2366, 211.5908, 167.6145, 236.6334],
        [ 85.7962, 211.8624, 176.6395, 236.2871],
        [ 85.5091, 211.4849, 178.1024, 236.9772],
        [ 86.0083, 211.3941, 178.9407, 236.0210],
        [ 84.7201, 211.1718, 181.9095, 237.0614],
        [ 85.5025, 211.2407, 179.5331, 235.9661],
        [ 83.7557, 211.3016, 181.8193, 237.0714],
        [ 86.6411, 211.1526, 179.8343, 236.4458],
        [ 84.6741, 211.2269, 181.8235, 237.5443],
        [ 88.0712, 211.2293, 179.1397, 236.6889],
        [ 83.0242, 210.9525, 181.3520, 237.8757],
        [ 92.4701, 210.1562, 180.1425, 237.2772],
        [ 85.4847, 209.4699, 181.9899, 238.6183],
        [366.9934, 212.1173, 404.1743, 231.2401],
        [368.7624, 214.7122, 384.9533, 231.3878],
        [368.9642, 213.2882, 418.9329, 231.7792],
        [368.0580, 212.8857, 429.5124, 232.6036],
        [373.8216, 213.5762, 401.0577, 231.7575],
        [370.3425, 213.8664, 421.2226, 231.9442],
        [369.9915, 213.1776, 434.4999, 231.8820],
        [368.0530, 211.1507, 459.1003, 233.8219],
        [380.8568, 213.6396, 409.7225, 231.5674],
        [378.9740, 213.6722, 420.2515, 231.4519],
        [372.4191, 212.8082, 446.9280, 231.8393],
        [367.0049, 211.4263, 479.9498, 234.2582],
        [387.7632, 213.2917, 414.3506, 231.2702],
        [384.6013, 213.1798, 428.9046, 231.3505],
        [376.1344, 212.6389, 467.5424, 232.1433],
        [369.9523, 211.7221, 479.6847, 232.5639],
        [398.1536, 213.3108, 418.7214, 230.5023],
        [388.7513, 212.8000, 449.9896, 231.7582],
        [376.4401, 212.4940, 477.3660, 231.8275],
        [369.4686, 211.9141, 476.4069, 231.9204],
        [373.2374, 211.9384, 474.4557, 231.6415],
        [371.6767, 211.6965, 477.4037, 231.8647],
        [400.6929, 211.7702, 465.1674, 231.7667],
        [371.6525, 211.4349, 474.1819, 232.0988],
        [372.0881, 211.6985, 474.0522, 232.1531],
        [423.4034, 213.3729, 471.5188, 232.2731],
        [384.8586, 211.4338, 472.8369, 232.6129],
        [366.4221, 210.1794, 474.9067, 232.9573],
        [432.2288, 213.8234, 474.0404, 231.9875],
        [416.9967, 212.5639, 472.7346, 232.2767],
        [435.7807, 213.4148, 474.2633, 231.8150],
        [444.3289, 214.0641, 473.2474, 232.1348],
        [ 81.7213, 212.4089, 108.7900, 236.9691],
        [ 84.0211, 212.4111, 108.3968, 237.2016],
        [ 84.0617, 212.3419, 117.3781, 236.5277],
        [ 84.5406, 212.8975, 110.7298, 236.2874],
        [ 84.9635, 212.0043, 147.9960, 237.1359],
        [ 83.8902, 211.9808, 175.2668, 238.0774],
        [ 84.4918, 211.5712, 175.9261, 238.6882],
        [ 84.7669, 211.9427, 178.7400, 237.3459],
        [ 84.7771, 211.6750, 177.5427, 237.3022],
        [ 85.3146, 212.0000, 179.5774, 237.2038],
        [ 84.4597, 211.3255, 181.8422, 237.1934],
        [ 83.8732, 211.7755, 181.3285, 237.4651],
        [ 83.0050, 211.2137, 181.8494, 237.2518],
        [ 85.1497, 211.9015, 180.2068, 237.6995],
        [ 84.4243, 211.2099, 181.4356, 237.5806],
        [ 85.6795, 211.8336, 180.1968, 237.6120],
        [ 80.8079, 210.9492, 181.7341, 237.8663],
        [ 86.8141, 211.4003, 180.4706, 238.2538],
        [ 83.6004, 210.5279, 181.0652, 238.8846],
        [366.9279, 212.7518, 429.8895, 233.1506],
        [372.1125, 213.8028, 422.1776, 231.6644],
        [369.1310, 213.1145, 433.1054, 232.1409],
        [368.2202, 211.5302, 453.2524, 233.9393],
        [378.3182, 213.4922, 423.6606, 231.1204],
        [373.0925, 213.3605, 444.8656, 232.1474],
        [367.4290, 212.1792, 472.6450, 233.9755],
        [376.4347, 213.3526, 460.4362, 231.9471],
        [368.8262, 212.0243, 477.3486, 232.4758],
        [396.6963, 212.4912, 420.3616, 229.1684],
        [376.2318, 213.3588, 471.8132, 231.4786],
        [368.9406, 212.3383, 476.3122, 232.0962],
        [375.3345, 212.9861, 473.8346, 231.5758],
        [367.9172, 212.0110, 478.5304, 232.1739],
        [381.2178, 212.9617, 473.4631, 232.0103],
        [366.4850, 211.3747, 475.9538, 232.0835],
        [421.5971, 213.4081, 470.6431, 231.4046],
        [405.6178, 213.5722, 472.5717, 232.0938],
        [370.2496, 210.6421, 475.0110, 232.8634],
        [432.2633, 213.8350, 474.5652, 231.4657],
        [425.8143, 213.4306, 474.3595, 231.6883],
        [438.0998, 213.8336, 475.1234, 231.9267],
        [446.2942, 213.5817, 473.4218, 231.0361],
        [230.5986, 207.0495, 266.9580, 272.7154],
        [249.6225, 213.2953, 287.3961, 273.6192],
        [224.9193, 213.3096, 258.2704, 276.2855],
        [245.1089, 228.4045, 282.3095, 281.5490],
        [232.0052, 221.4787, 263.6764, 269.8426],
        [232.6540, 218.7929, 267.3286, 273.8154],
        [239.8074, 232.6155, 280.5615, 282.1949],
        [221.7453, 221.6460, 259.5301, 267.1133],
        [224.4686, 219.6314, 263.8306, 270.5168],
        [210.3688, 220.7722, 259.4781, 270.3424],
        [341.2245, 256.9555, 385.0797, 282.3885],
        [341.6232, 258.5982, 386.6267, 284.9642],
        [ 84.8017, 259.7008, 152.8762, 284.1018],
        [ 84.2772, 258.9240, 168.2962, 285.4622],
        [ 85.2845, 259.8960, 166.9774, 284.0886],
        [ 84.5146, 259.6485, 177.1957, 284.9575],
        [ 85.3453, 259.9662, 171.0157, 284.5431],
        [ 83.6234, 259.6301, 177.7876, 285.4199],
        [ 85.2074, 259.8764, 174.8758, 284.5822],
        [ 84.0730, 259.9723, 179.3714, 285.0544],
        [ 85.5844, 259.4072, 177.5293, 284.3900],
        [ 84.5403, 259.6088, 180.1779, 285.2615],
        [ 90.3565, 259.6276, 178.6454, 284.2272],
        [ 83.8932, 259.5691, 180.3943, 285.2033],
        [ 89.7540, 258.3619, 180.3206, 285.9521],
        [156.7694, 260.8615, 180.8302, 283.7905],
        [156.8983, 260.6554, 181.5014, 283.8651],
        [198.7953, 217.7440, 235.2664, 261.6900],
        [181.7263, 220.3687, 222.7264, 260.6179],
        [164.8890, 207.3119, 207.4187, 245.0969],
        [167.7643, 207.0000, 210.9461, 247.3008],
        [140.8596, 197.6120, 197.4279, 238.0014],
        [342.1474, 259.5000, 386.5973, 283.9598],
        [342.5889, 259.7015, 386.8514, 284.1958],
        [341.9603, 259.0052, 387.7924, 285.0562],
        [342.3351, 259.6332, 386.0043, 284.3272],
        [341.7841, 259.1100, 387.0239, 285.0601],
        [342.9835, 260.2133, 386.6154, 284.1554],
        [343.0031, 260.2612, 386.4008, 283.9603],
        [341.9008, 259.3777, 387.2254, 284.5886],
        [343.0153, 260.2557, 386.8514, 284.1075],
        [343.0817, 260.2992, 386.7505, 283.8857],
        [342.2776, 259.6216, 386.9843, 284.5818],
        [342.9821, 260.0035, 386.3608, 284.1829],
        [343.0107, 260.4782, 385.9280, 283.8777],
        [342.0493, 259.6932, 387.3629, 284.2797],
        [342.7677, 260.2758, 386.3647, 284.0490],
        [342.8007, 260.3236, 386.3242, 284.0887],
        [344.0594, 259.2776, 388.4413, 283.8872],
        [342.6517, 258.7389, 391.9804, 285.1809],
        [393.1700, 260.2233, 460.9330, 284.7290],
        [392.3634, 259.6482, 465.2450, 286.0198],
        [393.7408, 260.6696, 461.4090, 284.0672],
        [393.7828, 260.9303, 469.7900, 285.4518],
        [393.6534, 261.0471, 472.1211, 285.7643],
        [393.6486, 260.9573, 470.8017, 285.6429],
        [393.7186, 261.2010, 471.4125, 285.8577],
        [394.2664, 260.8441, 470.3903, 285.3294],
        [394.1482, 261.1069, 470.6343, 285.5750],
        [394.1443, 260.8487, 470.2370, 285.3058],
        [394.1881, 260.9355, 470.5104, 285.4458],
        [399.3681, 260.2956, 470.8542, 285.2876],
        [397.2696, 259.5590, 472.5169, 285.9993],
        [ 83.0470, 260.4017, 131.1447, 284.3269],
        [ 83.5784, 260.4003, 139.5884, 285.2916],
        [ 83.4746, 260.4168, 125.3214, 284.4754],
        [ 83.3294, 260.3166, 139.1010, 284.4743],
        [ 84.0009, 260.2552, 160.1881, 285.2605],
        [ 83.9741, 259.7136, 171.6745, 286.2571],
        [ 85.1141, 260.5730, 148.8876, 284.6436],
        [ 84.5041, 260.0541, 169.5781, 284.7614],
        [ 84.2763, 259.7864, 177.9229, 284.8857],
        [ 85.0975, 259.9390, 170.0049, 284.9009],
        [ 83.9825, 259.6633, 177.7446, 285.0352],
        [ 84.1346, 260.0613, 175.7848, 285.2443],
        [ 83.7998, 259.9301, 178.8913, 284.7821],
        [ 84.3534, 260.2477, 178.2494, 285.1748],
        [ 83.6490, 259.7072, 179.5488, 284.9839],
        [ 88.2285, 260.2320, 179.0948, 284.7616],
        [ 81.7047, 259.5091, 180.1501, 284.9791],
        [110.6614, 260.3901, 176.7894, 284.8235],
        [ 87.5502, 259.2214, 179.6628, 286.5648],
        [155.9318, 260.8184, 179.6482, 283.0635],
        [157.5541, 260.7451, 181.1137, 283.2492],
        [342.0984, 260.4490, 386.9121, 284.5590],
        [342.4580, 260.3477, 386.7641, 284.4972],
        [342.2315, 259.9039, 386.6846, 284.8060],
        [341.5599, 259.3292, 387.3053, 285.4969],
        [342.4509, 260.3137, 386.4551, 283.9516],
        [342.3488, 260.3736, 386.2644, 283.8629],
        [341.3666, 259.7321, 387.0860, 284.7888],
        [342.4357, 260.1768, 386.9002, 283.9755],
        [342.4115, 260.4422, 386.5853, 283.9407],
        [341.6345, 259.6988, 386.8077, 284.8366],
        [342.6398, 260.1677, 386.3218, 283.9164],
        [342.8939, 260.4500, 386.0633, 283.7580],
        [341.9802, 259.9290, 387.2864, 284.6490],
        [343.0372, 260.2747, 386.4897, 283.9138],
        [342.7393, 260.2244, 386.4343, 284.2761],
        [344.0074, 260.3469, 388.1357, 284.8992],
        [343.0358, 259.3864, 392.8087, 286.1243],
        [393.9277, 261.2738, 453.3293, 285.0424],
        [393.1822, 260.8825, 465.9729, 286.0148],
        [392.5569, 260.1352, 468.2982, 286.5595],
        [393.3517, 261.1081, 468.5343, 285.7934],
        [393.4798, 260.8531, 473.6708, 285.8119],
        [393.6572, 260.8841, 473.2495, 285.4720],
        [394.1539, 261.1100, 469.0061, 286.0622],
        [393.4936, 260.8304, 471.5935, 285.7271],
        [393.5764, 261.0305, 471.1756, 285.4721],
        [395.2397, 261.3807, 468.8678, 285.3950],
        [394.2156, 261.1577, 470.7667, 285.3981],
        [393.9977, 261.1557, 470.4986, 285.4006],
        [397.0023, 261.1902, 469.6065, 285.4602],
        [394.6434, 261.0537, 470.4604, 285.1590],
        [394.4846, 261.0750, 470.4643, 285.2404],
        [410.2686, 262.4426, 467.9777, 285.5200],
        [397.6703, 260.8452, 469.8975, 285.4901],
        [396.9576, 260.5187, 471.3069, 286.2367],
        [342.1887, 261.1553, 385.3724, 284.8513],
        [340.5988, 259.5271, 387.1533, 285.2247],
        [394.6227, 260.4741, 470.1836, 286.6523],
        [394.7395, 260.8932, 469.9951, 286.6187],
        [396.8163, 261.1528, 472.1047, 287.4119],
        [ 63.5690, 215.7543, 163.8168, 255.9201],
        [ 55.7815, 220.5565, 158.6578, 260.5516],
        [-14.8604, 168.9879, 238.4969, 213.0112],
        [ 27.7045, 176.0192, 241.5161, 220.3392],
        [ 60.7324, 178.9937, 256.4724, 227.6388],
        [ 85.0429, 186.0731, 277.2575, 238.5961],
        [114.1689, 199.5517, 297.8441, 251.6631],
        [147.6093, 214.3846, 322.2679, 262.5185],
        [182.0267, 224.5942, 349.3269, 269.7903],
        [210.5210, 228.9186, 373.7739, 274.0495],
        [232.5497, 229.4212, 391.6666, 275.6646],
        [244.7545, 228.8581, 404.7814, 275.1082],
        [249.1810, 227.6489, 409.1186, 272.0269],
        [248.8786, 226.9894, 403.7359, 268.6817],
        [247.4592, 225.6096, 391.2717, 265.3971],
        [245.0426, 222.7074, 371.9152, 261.8586],
        [241.2090, 220.8079, 354.4055, 260.8299],
        [ 67.4344, 242.2793, 185.2625, 286.5569],
        [155.2436, 220.6657, 345.2007, 267.7229],
        [182.3634, 231.7376, 367.2806, 277.8364],
        [ 84.0222, 343.5213, 182.4167, 368.1560],
        [ 83.3396, 343.8168, 181.9293, 368.4466],
        [ 82.6685, 343.9536, 181.4276, 368.2217],
        [ 81.7660, 343.5627, 180.7599, 368.3059],
        [ 84.6158, 343.3682, 181.3475, 368.0621],
        [272.8991, 344.1351, 323.7220, 363.8510],
        [273.5206, 344.5202, 325.5765, 364.2144],
        [274.6862, 344.4453, 316.2532, 364.1133],
        [273.6162, 344.6951, 326.0984, 363.7326],
        [273.8851, 345.5296, 325.9854, 363.8973],
        [273.3515, 344.5735, 327.4496, 364.4696],
        [274.0754, 344.3786, 325.4761, 364.6683],
        [275.5583, 343.9820, 325.8018, 362.8288],
        [273.0316, 344.3254, 326.5230, 363.5257],
        [271.9524, 343.4911, 329.0117, 364.6672],
        [331.2151, 341.1831, 373.6856, 360.6932],
        [330.4417, 343.3667, 378.7699, 363.3055],
        [333.3190, 345.7676, 362.0146, 363.1311],
        [330.3829, 342.2367, 372.3022, 363.0367],
        [332.2091, 344.0206, 379.8034, 362.9240],
        [332.1202, 344.2669, 379.7555, 363.2448],
        [336.8545, 345.0541, 371.0180, 362.7792],
        [331.9000, 343.7588, 379.7044, 363.6296],
        [334.5806, 344.1048, 379.8477, 362.2629],
        [332.8546, 343.8692, 384.5258, 362.9092],
        [333.9009, 341.3510, 415.6140, 364.0495],
        [343.4387, 343.8508, 378.0611, 361.5779],
        [344.3816, 341.8213, 384.5013, 359.4624],
        [333.5763, 341.6703, 421.2127, 362.4532],
        [360.5294, 343.3320, 382.4539, 359.2459],
        [342.8967, 342.3524, 438.3174, 360.5218],
        [330.9142, 295.9604, 402.2763, 315.4868],
        [343.5576, 343.8648, 432.7711, 360.0728],
        [291.2435, 254.0627, 364.2383, 276.0937],
        [340.5368, 344.5822, 437.4611, 359.4675],
        [261.6600, 224.4315, 320.3090, 247.6888],
        [349.1319, 344.2921, 438.2651, 358.8781],
        [245.2248, 214.4361, 301.2534, 236.4687],
        [256.1354, 216.9386, 312.4277, 238.1836],
        [284.6992, 229.3114, 360.0342, 249.1983],
        [295.4001, 235.6846, 371.4529, 256.4743],
        [286.4710, 224.0431, 354.4278, 246.0900],
        [270.1348, 213.9687, 318.2680, 234.8872],
        [240.4644, 206.5017, 282.5469, 227.9534],
        [ 83.1131, 342.7658, 165.3418, 367.8151],
        [ 83.9961, 342.2168, 180.9113, 369.0244],
        [ 83.6093, 341.1624, 182.2248, 370.3752],
        [ 84.5872, 343.1643, 185.3592, 368.4483],
        [ 84.9560, 342.8571, 181.5741, 368.7660],
        [ 83.8026, 343.3690, 180.7279, 368.3812],
        [ 83.9133, 343.1286, 181.2327, 368.6844],
        [ 83.6933, 343.4638, 182.3394, 368.6534],
        [ 84.2536, 343.4055, 182.1597, 368.7785],
        [ 82.0753, 343.6318, 181.2682, 368.7230],
        [ 82.4888, 343.6465, 181.0080, 368.8986],
        [ 89.4200, 343.7697, 177.4755, 366.5340],
        [ 82.7831, 343.8054, 180.8335, 368.2429],
        [ 83.2588, 343.6400, 180.7952, 368.7345],
        [ 83.3388, 343.4894, 181.3068, 367.9716],
        [ 81.1729, 342.4803, 182.4739, 369.0629],
        [273.3433, 344.4516, 321.1795, 364.6551],
        [271.7501, 343.3090, 325.1233, 365.6423],
        [273.1548, 344.8049, 302.9086, 364.1311],
        [273.8326, 344.6184, 326.4083, 363.7415],
        [273.7988, 344.6177, 325.9803, 363.8560],
        [274.0396, 343.8347, 322.4543, 364.3698],
        [273.4117, 344.9556, 325.7811, 363.3925],
        [273.7115, 345.1679, 325.7778, 363.3920],
        [273.0952, 344.4047, 326.8354, 364.3862],
        [274.9155, 344.2628, 323.5594, 364.1149],
        [273.5034, 344.0702, 325.6317, 364.8222],
        [273.6440, 345.0020, 325.4965, 363.3755],
        [273.3294, 344.9217, 325.7462, 363.6196],
        [272.6423, 343.8963, 327.8770, 365.1331],
        [277.2165, 344.4185, 324.6638, 364.1434],
        [276.1783, 344.9320, 326.4447, 363.7479],
        [273.8997, 344.2109, 328.8515, 364.6180],
        [330.4894, 345.2375, 363.2041, 363.9785],
        [331.3000, 345.2752, 353.3480, 363.5067],
        [332.9235, 345.6346, 370.7847, 363.6433],
        [332.0972, 344.9081, 375.0970, 363.9470],
        [333.1780, 345.8538, 363.8334, 363.4633],
        [330.3633, 344.5737, 371.7472, 365.2243],
        [333.2058, 345.0524, 375.9858, 362.8724],
        [332.7641, 344.7560, 377.3358, 362.8998],
        [334.9638, 345.1559, 371.1494, 363.2859],
        [332.2941, 344.1385, 378.4790, 364.0943],
        [333.5857, 344.5587, 380.2935, 362.5975],
        [333.3270, 344.5482, 382.1759, 362.5603],
        [334.2170, 342.6320, 411.3203, 364.3325],
        [338.6382, 344.1007, 379.1269, 363.1184],
        [336.5354, 344.1779, 382.1723, 362.4751],
        [332.9850, 343.0593, 411.9289, 362.7314],
        [332.1799, 341.3798, 434.1283, 363.3296],
        [355.1146, 343.5945, 381.5730, 360.5463],
        [348.0336, 331.2909, 408.2957, 349.3961],
        [337.9847, 342.1462, 434.6866, 361.1967],
        [328.9139, 293.1774, 403.5179, 314.5602],
        [341.8217, 342.4763, 436.3364, 359.6965],
        [340.8630, 341.8351, 439.8131, 360.8116],
        [292.8986, 248.1856, 382.8536, 273.9925],
        [341.4247, 342.8220, 441.4379, 358.5145],
        [338.1100, 342.4424, 450.1320, 360.5521],
        [273.4261, 220.2760, 349.1438, 246.4201],
        [349.6289, 345.2161, 443.2023, 360.1335],
        [265.0094, 208.8197, 334.2870, 234.4069],
        [370.8592, 345.4888, 460.2007, 360.3409],
        [259.3024, 202.7773, 337.7982, 229.7574],
        [276.1321, 206.8689, 363.9536, 232.1059],
        [381.0348, 343.0545, 483.6241, 357.2413],
        [284.4361, 215.1049, 378.2736, 241.8326],
        [280.3707, 212.8440, 370.1679, 241.7261],
        [273.7074, 214.0998, 329.9818, 239.3864],
        [245.7602, 207.7338, 290.1806, 232.0240],
        [ 84.8179, 342.8883, 180.7676, 369.4583],
        [ 83.3810, 342.9007, 182.3186, 368.6148],
        [ 83.8930, 343.3215, 182.0627, 368.9682],
        [ 83.3424, 343.5325, 180.7108, 368.6890],
        [ 82.8654, 343.4788, 180.5990, 368.6534],
        [273.8047, 344.7466, 326.3955, 364.6656],
        [ 84.1219, 389.3416, 181.2261, 416.4024],
        [ 83.7287, 389.6622, 180.8138, 416.9010],
        [ 83.7484, 389.9284, 180.3202, 416.7908],
        [ 82.8045, 389.9954, 181.0316, 416.8581],
        [ 85.2364, 389.9395, 180.9943, 416.2212],
        [ 86.9653, 387.8043, 183.9705, 416.1613],
        [387.8173, 391.7016, 473.0710, 415.9636],
        [387.8348, 391.8318, 474.1064, 415.6645],
        [387.1053, 391.5019, 474.2462, 415.7022],
        [387.3043, 390.9795, 473.9864, 415.5294],
        [ 83.0971, 389.4241, 184.6534, 417.9312],
        [ 82.9326, 388.7588, 184.8384, 419.6308],
        [ 84.0349, 390.2194, 185.6343, 417.2447],
        [ 83.4129, 389.7695, 183.6676, 417.8837],
        [ 83.6796, 390.2755, 179.5423, 417.0550],
        [ 82.9932, 389.8002, 180.8393, 417.5870],
        [ 84.1928, 389.9815, 181.1327, 417.5023],
        [ 84.0280, 389.7527, 181.6048, 417.7052],
        [ 83.0048, 390.5280, 180.7128, 417.5198],
        [ 82.9002, 390.3917, 181.2227, 417.7220],
        [ 81.4982, 391.1321, 180.8927, 416.6674],
        [ 82.2874, 390.8799, 181.3417, 417.0316],
        [ 80.6438, 390.6873, 181.9187, 417.1577],
        [ 78.1733, 389.9089, 182.3036, 417.8730],
        [387.4517, 390.4951, 462.7243, 417.2367],
        [387.2182, 391.3791, 469.9010, 416.1324],
        [387.5481, 391.0923, 473.5523, 416.7043],
        [386.5686, 390.6913, 472.6609, 417.1801],
        [388.2339, 391.7891, 471.4616, 415.8043],
        [387.6056, 391.8557, 472.9683, 416.2879],
        [387.4891, 391.6632, 473.7183, 416.4368],
        [388.2322, 391.9308, 472.7534, 415.7574],
        [387.2573, 391.7580, 474.8435, 416.1987],
        [387.4641, 391.8256, 474.6942, 416.2072],
        [388.8669, 392.2722, 472.2420, 415.5690],
        [386.9530, 391.9745, 474.3574, 416.2253],
        [387.2831, 392.0080, 474.2582, 416.3259],
        [386.8495, 391.7961, 472.4298, 415.4450],
        [386.4134, 391.6931, 474.0261, 416.0379],
        [387.1185, 391.6023, 474.0416, 416.2030],
        [392.7695, 391.6655, 472.8520, 415.3488],
        [383.6303, 391.1765, 474.3465, 416.3901],
        [385.7591, 390.3564, 475.0806, 417.3314],
        [ 83.8624, 390.7742, 182.1213, 419.2047],
        [ 83.0451, 390.7260, 181.1255, 418.2050],
        [ 84.3155, 390.5466, 181.0118, 418.3092],
        [ 84.2620, 390.8960, 180.7856, 418.1081],
        [ 83.2078, 391.4107, 180.6376, 417.6642],
        [284.0296, 333.8327, 351.6302, 372.0596],
        [276.0885, 330.9082, 345.4468, 368.8254],
        [385.1877, 390.7993, 471.3649, 418.2438],
        [386.8550, 391.3416, 474.1635, 416.3952],
        [387.5227, 392.5050, 472.7799, 416.8923],
        [386.8561, 391.5611, 474.6757, 415.9055],
        [387.7344, 391.7449, 474.0787, 416.0111],
        [390.2468, 392.7678, 472.5800, 417.1068],
        [387.3718, 391.4161, 474.3739, 416.6548],
        [388.7164, 391.1975, 476.0254, 418.2472],
        [ 84.3341, 437.6203, 177.5481, 463.8863],
        [ 84.9679, 437.4638, 180.2455, 463.9618],
        [ 86.2228, 437.3107, 180.2979, 464.0402],
        [ 86.0981, 437.6705, 180.5473, 463.5391],
        [ 87.2057, 437.7668, 180.8685, 463.2416],
        [336.5545, 437.4782, 421.8538, 462.3841],
        [338.4729, 438.1499, 421.0108, 461.1854],
        [337.5962, 438.7292, 423.2995, 462.6551],
        [337.0230, 438.7944, 423.3069, 462.8323],
        [339.5005, 438.0961, 422.2130, 461.5558],
        [336.7982, 438.5562, 423.7222, 463.0826],
        [341.6910, 438.4873, 423.0493, 462.1261],
        [337.6716, 438.1987, 423.9661, 463.3459],
        [428.4708, 439.3953, 468.6364, 459.2793],
        [429.8093, 440.1476, 475.2726, 459.6585],
        [429.1827, 439.9465, 476.0547, 459.9575],
        [430.8723, 439.8993, 474.3013, 459.6359],
        [429.8822, 439.8295, 475.6635, 460.8670],
        [430.9334, 439.1679, 476.9131, 459.3607],
        [430.3072, 439.4974, 476.7920, 460.1553],
        [433.8962, 439.8873, 475.4418, 459.8986],
        [430.6397, 439.1516, 476.8457, 461.6563],
        [ 84.4490, 438.5489, 108.9623, 464.5710],
        [ 84.1108, 438.8250, 113.9038, 463.5610],
        [ 85.5391, 438.3945, 144.6541, 464.3824],
        [ 85.8408, 438.0488, 177.2505, 465.3680],
        [ 85.1141, 437.3138, 183.5745, 466.8232],
        [ 87.4315, 438.9385, 157.9702, 463.9724],
        [ 84.6828, 438.6435, 179.7505, 464.6895],
        [ 83.7958, 438.5574, 177.9968, 464.7701],
        [ 91.1417, 439.4004, 166.0862, 463.5006],
        [ 85.2476, 438.7728, 178.8394, 464.4269],
        [ 84.3175, 438.5992, 179.9130, 464.6221],
        [ 92.8499, 439.2090, 172.4110, 463.7547],
        [ 85.6653, 438.0904, 180.4302, 465.0044],
        [ 85.6414, 437.9195, 180.3990, 464.9789],
        [ 93.8682, 439.1406, 175.5111, 463.5266],
        [ 85.7258, 438.2957, 180.6449, 464.4294],
        [ 85.4182, 438.1075, 180.8123, 464.4741],
        [ 95.3678, 439.2553, 177.6452, 462.9320],
        [ 86.4208, 438.7841, 180.6021, 463.7672],
        [ 84.4140, 438.3840, 181.1797, 463.9478],
        [115.0148, 439.8331, 178.1224, 462.6248],
        [ 86.3861, 438.6214, 181.2156, 464.1126],
        [ 85.0262, 437.9153, 181.2246, 464.4245],
        [330.7810, 432.6975, 349.1911, 452.9357],
        [337.7220, 439.6695, 359.9786, 460.4465],
        [338.0774, 437.6461, 418.0414, 463.8011],
        [338.5145, 438.4949, 415.0926, 462.8774],
        [337.5665, 438.0952, 424.0891, 462.9358],
        [337.0381, 437.8535, 423.3865, 463.1825],
        [338.8609, 438.7620, 419.7869, 462.8616],
        [337.3486, 438.5752, 423.8716, 462.8489],
        [337.1997, 438.6656, 423.8490, 462.9061],
        [339.0928, 439.1084, 421.8255, 462.8768],
        [336.8103, 438.6919, 424.0126, 462.9921],
        [337.1680, 438.8591, 423.5350, 462.9021],
        [340.6470, 439.4177, 422.2203, 462.5618],
        [336.0914, 438.8390, 424.1371, 463.0258],
        [335.9720, 438.7859, 423.9577, 463.0405],
        [341.3146, 439.3073, 422.8586, 462.7794],
        [336.5172, 439.0723, 424.0034, 463.2964],
        [336.7022, 438.7664, 424.3320, 463.6107],
        [354.6360, 439.3055, 422.5888, 462.6499],
        [339.6362, 438.5040, 423.1758, 463.9825],
        [337.6884, 437.4057, 423.8504, 465.0544],
        [371.6123, 439.6078, 422.3005, 462.5598],
        [357.1330, 438.3022, 422.8090, 464.2268],
        [429.8674, 440.9950, 474.7391, 459.9055],
        [429.0675, 440.3297, 475.3353, 460.6262],
        [429.2789, 440.1882, 472.6280, 460.8400],
        [430.7206, 440.9919, 475.2477, 460.1029],
        [430.0824, 440.7310, 475.6561, 460.4581],
        [431.1938, 440.5573, 474.7512, 460.3560],
        [430.4209, 439.9939, 475.5729, 461.1754],
        [431.0120, 440.8682, 475.1735, 460.2167],
        [430.5695, 440.4115, 475.8699, 460.6385],
        [430.8816, 440.3412, 475.5692, 461.0146],
        [431.0421, 439.2699, 476.5660, 462.1080],
        [433.9743, 440.5013, 475.4098, 461.4397],
        [431.6919, 439.0989, 476.7962, 462.3021],
        [ 83.8764, 439.0867, 176.9389, 465.4479],
        [ 84.2199, 439.2105, 178.8939, 464.6871],
        [ 84.9461, 438.7448, 179.5743, 464.7799],
        [ 86.2371, 438.7441, 180.4368, 464.2151],
        [ 87.7166, 438.9916, 180.6295, 463.6929],
        [337.1288, 439.1977, 422.8531, 463.0995],
        [337.3176, 439.2539, 423.0376, 462.7163],
        [337.5839, 439.1536, 423.4166, 462.8203],
        [339.1443, 439.3490, 424.3368, 464.1330],
        [429.8008, 441.4147, 474.6721, 461.9326],
        [428.9414, 441.1611, 476.3801, 462.1862],
        [430.5122, 440.3137, 475.1005, 461.2557],
        [437.8694, 442.0341, 474.2311, 461.7271],
        [431.7176, 439.9215, 476.9173, 462.6406],
        [341.8055, 259.6170, 387.3964, 285.3524]])

DEBUG:root:		boxlist = BoxList(detections, per_anchors.size, mode="xyxy") { // CALL
DEBUG:root:				BoxList.__init__(self, bbox, image_size, mode='xyxy') { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/structures/bounding_box.py

DEBUG:root:					// Params:
DEBUG:root:						// type(bbox):<class 'torch.Tensor'>
DEBUG:root:						// bbox.shape:torch.Size([846, 4])
DEBUG:root:						// image_size: (561, 480)

DEBUG:root:					// isinstance(bbox, torch.Tensor): True
DEBUG:root:					device = bbox.device if isinstance(bbox, torch.Tensor) else torch.device("cpu")
DEBUG:root:					// device: cuda:0

DEBUG:root:					bbox = torch.as_tensor(bbox, dtype=torch.float32, device=device)
DEBUG:root:					// bbox.shape: torch.Size([846, 4])

DEBUG:root:					// bbox.ndimension(): 2
DEBUG:root:					// bbox.size(-1): 4

DEBUG:root:					self.bbox = bbox
DEBUG:root:					self.size = image_size  # (image_width, image_height)
DEBUG:root:					self.mode = mode
DEBUG:root:					self.extra_fields = {}
DEBUG:root:				} // END BoxList.__init__(self, bbox, image_size, mode='xyxy')
DEBUG:root:		} boxlist = BoxList(detections, per_anchors.size, mode="xyxy") // RETURNED

DEBUG:root:		// type(boxlist): <class 'maskrcnn_benchmark.structures.bounding_box.BoxList'>
DEBUG:root:		// boxlist: BoxList(num_boxes=846, image_width=561, image_height=480, mode=xyxy)

DEBUG:root:		boxlist.add_field("labels", per_class)
DEBUG:root:		boxlist.add_field("scores", per_box_cls)
DEBUG:root:		boxlist = boxlist.clip_to_image(remove_empty=False)
DEBUG:root:				BoxList.__init__(self, bbox, image_size, mode='xyxy') { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/structures/bounding_box.py

DEBUG:root:					// Params:
DEBUG:root:						// type(bbox):<class 'torch.Tensor'>
DEBUG:root:						// bbox.shape:torch.Size([846, 4])
DEBUG:root:						// image_size: (561, 480)

DEBUG:root:					// isinstance(bbox, torch.Tensor): True
DEBUG:root:					device = bbox.device if isinstance(bbox, torch.Tensor) else torch.device("cpu")
DEBUG:root:					// device: cuda:0

DEBUG:root:					bbox = torch.as_tensor(bbox, dtype=torch.float32, device=device)
DEBUG:root:					// bbox.shape: torch.Size([846, 4])

DEBUG:root:					// bbox.ndimension(): 2
DEBUG:root:					// bbox.size(-1): 4

DEBUG:root:					self.bbox = bbox
DEBUG:root:					self.size = image_size  # (image_width, image_height)
DEBUG:root:					self.mode = mode
DEBUG:root:					self.extra_fields = {}
DEBUG:root:				} // END BoxList.__init__(self, bbox, image_size, mode='xyxy')
DEBUG:root:				BoxList.__init__(self, bbox, image_size, mode='xyxy') { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/structures/bounding_box.py

DEBUG:root:					// Params:
DEBUG:root:						// type(bbox):<class 'torch.Tensor'>
DEBUG:root:						// bbox.shape:torch.Size([846, 4])
DEBUG:root:						// image_size: (561, 480)

DEBUG:root:					// isinstance(bbox, torch.Tensor): True
DEBUG:root:					device = bbox.device if isinstance(bbox, torch.Tensor) else torch.device("cpu")
DEBUG:root:					// device: cuda:0

DEBUG:root:					bbox = torch.as_tensor(bbox, dtype=torch.float32, device=device)
DEBUG:root:					// bbox.shape: torch.Size([846, 4])

DEBUG:root:					// bbox.ndimension(): 2
DEBUG:root:					// bbox.size(-1): 4

DEBUG:root:					self.bbox = bbox
DEBUG:root:					self.size = image_size  # (image_width, image_height)
DEBUG:root:					self.mode = mode
DEBUG:root:					self.extra_fields = {}
DEBUG:root:				} // END BoxList.__init__(self, bbox, image_size, mode='xyxy')
DEBUG:root:		boxlist = remove_small_boxes(boxlist, self.min_size)
DEBUG:root:		results.append(boxlist)
DEBUG:root:	} // END for per_box_cls, per_box_regression, ... in zip():

DEBUG:root:	return results

DEBUG:root:} // END RetinaNetPostProcessor.forward_for_single_feature_map()
DEBUG:root:					}
DEBUG:root:					sampled_boxes.append(self.forward_for_single_feature_map(a, o, b)) // RETURNED

DEBUG:root:					} // END of for a, o, b in zip() iteration: 1/5

DEBUG:root:					{
DEBUG:root:					# BEGIN for a, o, b in zip()  iteration: 2/5
DEBUG:root:					# a: (BoxList(num_boxes=9720, image_width=561, image_height=480, mode=xyxy),)
DEBUG:root:					# o.shape: torch.Size([1, 9, 30, 36])
DEBUG:root:					# b.shape: torch.Size([1, 36, 30, 36])

DEBUG:root:					# 2-3-2-3-2 self.forward_for_single_feature_map
DEBUG:root:					// self.forward_for_single_feature_map: <bound method RetinaNetPostProcessor.forward_for_single_feature_map of RetinaNetPostProcessor()>
DEBUG:root:					sampled_boxes.append(self.forward_for_single_feature_map(a, o, b)) { // CALL
DEBUG:root:RetinaNetPostProcessor.forward_for_single_feature_map() { //BEGIN
DEBUG:root:	// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/retinanet/inference.py

DEBUG:root:	// Params:
DEBUG:root:		> anchors: list[BoxList]
DEBUG:root:		> box_cls: tensor of size N, A*C, H, W)
DEBUG:root:		> box_regression: tensor of size N, A*4, H, W)

DEBUG:root:	device = box_cls.device
DEBUG:root:	// device: cuda:0

DEBUG:root:	N, _, H, W = box_cls.shape
DEBUG:root:	// N:1, H:30, W:36

DEBUG:root:	A = box_regression.size(1) // 4
DEBUG:root:	// A : 9

DEBUG:root:	C = box_cls.size(1) // A
DEBUG:root:	// C: 1

DEBUG:root:	# put 'box_cls' in the same format as anchors
DEBUG:root:	box_cls = permute_and_flatten(box_cls, N, A, C, H, W)
DEBUG:root:	// box_cls.shape: torch.Size([1, 9720, 1])

DEBUG:root:	box_cls = box_cls.sigmoid()
DEBUG:root:	// box_cls.shape: torch.Size([1, 9720, 1])

DEBUG:root:	# put 'box_cls' in the same format as anchors
DEBUG:root:	box_regression = permute_and_flatten(box_regression, N, A, 4, H, W)
DEBUG:root:	// box_regression.shape: torch.Size([1, 9720, 4])

DEBUG:root:	box_regression = box_regression.reshape(N, -1, 4)
DEBUG:root:	// box_regression.shape: torch.Size([1, 9720, 4])

DEBUG:root:	num_anchors = A * H * W
DEBUG:root:	// num_anchors: 9720

DEBUG:root:	candidate_inds = box_cls > self.pre_nms_thresh
DEBUG:root:	// candidate_inds.shape: torch.Size([1, 9720, 1])

DEBUG:root:	pre_nms_top_n = candidate_inds.view(N, -1).sum(1)
DEBUG:root:	// pre_nms_top_n: tensor([88], device='cuda:0')

DEBUG:root:	pre_nms_top_n = pre_nms_top_n.clamp(max=self.pre_nms_top_n)
DEBUG:root:	// pre_nms_top_n: tensor([88], device='cuda:0')

DEBUG:root:	results = []

DEBUG:root:	// box_cls.shape: torch.Size([1, 9720, 1])
DEBUG:root:	// box_regression.shape: torch.Size([1, 9720, 4])
DEBUG:root:	// pre_nmns_top_n: tensor([88], device='cuda:0')
DEBUG:root:	// candidate.inds.shape: torch.Size([1, 9720, 1])
DEBUG:root:	// anchors: (BoxList(num_boxes=9720, image_width=561, image_height=480, mode=xyxy),)
DEBUG:root:	for per_box_cls, per_box_regression, ... in zip():
	{
DEBUG:root:		# ====================================
DEBUG:root:		# per_box_cls.shape: torch.Size([9720, 1])
DEBUG:root:		# type(per_box_cls): <class 'torch.Tensor'>
DEBUG:root:		# per_box_regression.shape: torch.Size([9720, 4])
DEBUG:root:		# per_pre_nms_top_n: 88
DEBUG:root:		# per_candidate_inds.shape: torch.Size([9720, 1])
DEBUG:root:		# per_anchors: BoxList(num_boxes=9720, image_width=561, image_height=480, mode=xyxy)
DEBUG:root:		# ====================================

DEBUG:root:		per_box_cls = per_box_cls[per_candidate_inds]
DEBUG:root:		per_box_cls, top_k_indices =per_box_cls.topk(per_pre_nms_top_n, sorted=False)
DEBUG:root:		// per_box_cls: tensor([0.3063, 0.9178, 0.4486, 0.3142, 0.8765, 0.2072, 0.0835, 0.8179, 0.1072,
        0.1078, 0.8230, 0.0567, 0.0750, 0.7270, 0.0889, 0.0817, 0.1293, 0.7392,
        0.1514, 0.4196, 0.7635, 0.1127, 0.0591, 0.2561, 0.3493, 0.3545, 0.3152,
        0.0579, 0.4951, 0.7703, 0.1035, 0.1520, 0.2925, 0.4284, 0.4669, 0.4075,
        0.0781, 0.0532, 0.2455, 0.5607, 0.0565, 0.1136, 0.3125, 0.1333, 0.2953,
        0.5437, 0.0613, 0.0586, 0.0686, 0.2354, 0.0616, 0.1282, 0.3321, 0.2313,
        0.3806, 0.1251, 0.2799, 0.2878, 0.3994, 0.0811, 0.5228, 0.3776, 0.8468,
        0.2046, 0.0577, 0.0655, 0.3927, 0.2511, 0.2516, 0.2304, 0.6081, 0.0908,
        0.7094, 0.7211, 0.0855, 0.4482, 0.0705, 0.4038, 0.1289, 0.4729, 0.0587,
        0.7709, 0.1338, 0.3082, 0.0656, 0.6066, 0.3232, 0.0527])
DEBUG:root:		// top_k_indices: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
        54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72,
        73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 63])

DEBUG:root:		per_candidate_nonzeros = \
DEBUG:root:		   per_candidate_inds.nonzero()[top_k_indices, :]
DEBUG:root:		// per_candidate_inds.shape: torch.Size([9720, 1])

DEBUG:root:		per_box_loc = per_candidate_nonzeros[:, 0]
DEBUG:root:		// per_box_loc.shape: torch.Size([88])

DEBUG:root:		per_class = per_candidate_nonzeros[:, 1]
DEBUG:root:		// per_class.shape: torch.Size([88])

DEBUG:root:		per_class += 1

DEBUG:root:		detections = self.box_coder.decode( ) { // CALL
DEBUG:root:		BoxCoder.decode(self, rel_codes, boxes) { // BEGIN
DEBUG:root:			// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/box_coder.py
DEBUG:root:			// Params:
DEBUG:root:				rel_codes.shape: torch.Size([88, 4])
DEBUG:root:				boxes.shape: torch.Size([88, 4])

DEBUG:root:			boxes = boxes.to(rel_codes.dtype)
DEBUG:root:			// boxes.shape: torch.Size([88, 4])

DEBUG:root:			TO_REMOVE = 1  # TODO remove

DEBUG:root:			widths = boxes[:, 2] - boxes[:, 0] + TO_REMOVE
DEBUG:root:			// widths.shape: torch.Size([88])

DEBUG:root:			heights = boxes[:, 3] - boxes[:, 1] + TO_REMOVE
DEBUG:root:			// heights.shape: torch.Size([88])

DEBUG:root:			ctr_x = boxes[:, 0] + 0.5 * widths
DEBUG:root:			// ctr_x.shape: torch.Size([88])

DEBUG:root:			ctr_y = boxes[:, 1] + 0.5 * heights
DEBUG:root:			// ctr_y.shape: torch.Size([88])


DEBUG:root:			wx, wy, ww, wh = self.weights
DEBUG:root:			// wx: 10.0, wy: 10.0, ww: 5.0, wh: 5.0

DEBUG:root:			dx = rel_codes[:, 0::4] / wx
DEBUG:root:			// dx.shape: torch.Size([88, 1])

DEBUG:root:			dy = rel_codes[:, 1::4] / wy
DEBUG:root:			// dy.shape: torch.Size([88, 1])

DEBUG:root:			dw = rel_codes[:, 2::4] / ww
DEBUG:root:			// dw.shape: torch.Size([88, 1])

DEBUG:root:			dh = rel_codes[:, 3::4] / wh
DEBUG:root:			// dh.shape: torch.Size([88, 1])


DEBUG:root:			# Prevent sending too large values into torch.exp()
DEBUG:root:			dw = torch.clamp(dw, max=self.bbox_xform_clip)
DEBUG:root:			// dw.shape: torch.Size([88, 1])

DEBUG:root:			dh = torch.clamp(dh, max=self.bbox_xform_clip)
DEBUG:root:			// dh.shape: torch.Size([88, 1])

DEBUG:root:			pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]
DEBUG:root:			// pred_ctr_x.shape: torch.Size([88, 1])

DEBUG:root:			pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]
DEBUG:root:			// pred_ctr_y.shape: torch.Size([88, 1])

DEBUG:root:			pred_w = torch.exp(dw) * widths[:, None]
DEBUG:root:			// pred_w.shape: torch.Size([88, 1])

DEBUG:root:			pred_h = torch.exp(dh) * heights[:, None]
DEBUG:root:			// pred_h.shape: torch.Size([88, 1])


DEBUG:root:			pred_boxes = torch.zeros_like(rel_codes)
DEBUG:root:			// pred_boxes.shape: torch.Size([88, 4])


DEBUG:root:			# x1
DEBUG:root:			pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w

DEBUG:root:			# y1
DEBUG:root:			pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h

DEBUG:root:			# x2 (note: '- 1' is correct; don't be fooled by the asymmetry)
DEBUG:root:			pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w - 1

DEBUG:root:			# y2 (note: '- 1' is correct; don't be fooled by the asymmetry)
DEBUG:root:			pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h - 1


DEBUG:root:			pred_boxes.shape: torch.Size([88, 4])

DEBUG:root:			return pred_boxes

DEBUG:root:		} // END BoxCoder.decode(self, rel_codes, boxes)

DEBUG:root:		} detections = self.box_coder.decode( ) // RETURNED

DEBUG:root:		// type(detections): <class 'torch.Tensor'>
DEBUG:root:		// detections: tensor([[186.5723,  45.8452, 277.0218,  76.2261],
        [187.2621,  47.1022, 276.7970,  74.6430],
        [186.6856,  46.2034, 277.5637,  75.6694],
        [282.1033,  45.9185, 371.2231,  75.4362],
        [283.0594,  46.5398, 371.3605,  74.1433],
        [283.8991,  45.3500, 372.3109,  74.9776],
        [185.6151,  46.8692, 276.4911,  78.2217],
        [187.8762,  46.9712, 277.0116,  74.8118],
        [186.9002,  47.3652, 280.6246,  77.5678],
        [279.2863,  46.4810, 369.4511,  77.1606],
        [283.2965,  46.5938, 371.6043,  74.5344],
        [284.4824,  46.5774, 373.0369,  76.9366],
        [236.1795,  78.9017, 319.3114, 110.9202],
        [239.1523,  81.1846, 319.6022, 111.5267],
        [238.2466,  79.4179, 318.3541, 113.1271],
        [239.5084,  79.7190, 322.6339, 111.0814],
        [238.1519,  81.4893, 320.3277, 112.7007],
        [239.1794,  81.4378, 320.0369, 111.2811],
        [239.2541,  80.1316, 323.2827, 112.4331],
        [ 81.6030, 163.6672, 183.0523, 191.8607],
        [ 82.2371, 164.6696, 183.0155, 191.8319],
        [ 81.1164, 163.0956, 184.3843, 194.2822],
        [ 83.6926, 161.9992, 184.7134, 191.8559],
        [261.6670, 164.4880, 407.2183, 188.4701],
        [263.1825, 165.0757, 407.5592, 188.3900],
        [263.6169, 164.8231, 409.1465, 188.2570],
        [263.8261, 163.9760, 410.3594, 188.0118],
        [292.3805, 162.3051, 410.5205, 188.5436],
        [ 81.7322, 163.0664, 183.0951, 192.0320],
        [ 82.0663, 163.1962, 182.5595, 190.9564],
        [ 81.5783, 161.9193, 183.1402, 193.1215],
        [ 81.5564, 162.2513, 183.5855, 193.2410],
        [260.3479, 164.8766, 409.1594, 189.5807],
        [261.9784, 164.9899, 408.3614, 189.1503],
        [262.0452, 164.7792, 408.5549, 188.8863],
        [262.0479, 163.8300, 410.1544, 188.4596],
        [289.3264, 163.1246, 410.9333, 189.8580],
        [472.4779, 177.8855, 518.4568, 239.1762],
        [ 80.9343, 211.5862, 179.4279, 238.9419],
        [ 81.8646, 212.1420, 180.0557, 238.3856],
        [ 81.1784, 210.4606, 181.5114, 240.3386],
        [365.7110, 207.4770, 476.6501, 234.2657],
        [367.4011, 207.8030, 476.8253, 233.7329],
        [367.6918, 206.7220, 477.5135, 234.9164],
        [ 81.3185, 210.9769, 179.0541, 238.8452],
        [ 82.1583, 211.1470, 179.2917, 237.7791],
        [ 81.5695, 209.8123, 180.4094, 239.7566],
        [ 81.7478, 209.7603, 181.7420, 240.1678],
        [366.4482, 208.5071, 474.5282, 234.5737],
        [368.1869, 208.5663, 476.0804, 233.2295],
        [369.4931, 207.7988, 478.2752, 235.6828],
        [ 80.5806, 257.8226, 179.9432, 286.2403],
        [ 81.6950, 258.7700, 181.2097, 285.5986],
        [389.3505, 257.9886, 473.8163, 286.9276],
        [392.2470, 258.4409, 473.2803, 286.9758],
        [ 80.4101, 257.9865, 179.5519, 286.7122],
        [ 81.8674, 258.6172, 180.4922, 285.8918],
        [389.8916, 258.3016, 472.8603, 286.9323],
        [391.8352, 258.4172, 472.7215, 286.4661],
        [ 83.1061, 341.1305, 180.4799, 368.8449],
        [ 84.2186, 342.5878, 181.9644, 368.9321],
        [ 83.3508, 342.0864, 182.0846, 369.4628],
        [ 83.7290, 342.7163, 181.8739, 368.5039],
        [ 83.2946, 341.3506, 182.1225, 370.3105],
        [356.4664, 338.3961, 475.7230, 363.8483],
        [ 82.3474, 388.5432, 181.2975, 415.8073],
        [ 83.6362, 390.8620, 182.6451, 416.0044],
        [386.8253, 389.7463, 476.0662, 417.4540],
        [387.7478, 389.2109, 476.6970, 416.8974],
        [ 82.6719, 389.6700, 181.2181, 416.8857],
        [ 83.7915, 390.4287, 181.3576, 415.8029],
        [ 83.5414, 388.7930, 181.6534, 417.4417],
        [386.7576, 389.6697, 475.4114, 416.7456],
        [387.4259, 389.8513, 475.7623, 416.6743],
        [ 81.4339, 435.7159, 181.3428, 463.5556],
        [ 82.2180, 437.5854, 183.1086, 463.5800],
        [ 81.2394, 435.5920, 184.5777, 465.5762],
        [336.4477, 435.5826, 424.9559, 464.1604],
        [337.4974, 434.3870, 428.5189, 463.2009],
        [ 81.3399, 437.3554, 181.2598, 465.8036],
        [ 78.9727, 435.2433, 182.0097, 468.2021],
        [ 81.9659, 437.8366, 181.0760, 464.9267],
        [ 81.2399, 436.2175, 182.9894, 467.1417],
        [ 82.0922, 436.0215, 181.8367, 466.0023],
        [334.2986, 433.5955, 421.2299, 464.8362],
        [337.5341, 436.9011, 423.3604, 464.2527],
        [338.4328, 436.3605, 427.6205, 464.1481],
        [ 82.9007, 340.6985, 182.7964, 370.8012]])

DEBUG:root:		boxlist = BoxList(detections, per_anchors.size, mode="xyxy") { // CALL
DEBUG:root:				BoxList.__init__(self, bbox, image_size, mode='xyxy') { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/structures/bounding_box.py

DEBUG:root:					// Params:
DEBUG:root:						// type(bbox):<class 'torch.Tensor'>
DEBUG:root:						// bbox.shape:torch.Size([88, 4])
DEBUG:root:						// image_size: (561, 480)

DEBUG:root:					// isinstance(bbox, torch.Tensor): True
DEBUG:root:					device = bbox.device if isinstance(bbox, torch.Tensor) else torch.device("cpu")
DEBUG:root:					// device: cuda:0

DEBUG:root:					bbox = torch.as_tensor(bbox, dtype=torch.float32, device=device)
DEBUG:root:					// bbox.shape: torch.Size([88, 4])

DEBUG:root:					// bbox.ndimension(): 2
DEBUG:root:					// bbox.size(-1): 4

DEBUG:root:					self.bbox = bbox
DEBUG:root:					self.size = image_size  # (image_width, image_height)
DEBUG:root:					self.mode = mode
DEBUG:root:					self.extra_fields = {}
DEBUG:root:				} // END BoxList.__init__(self, bbox, image_size, mode='xyxy')
DEBUG:root:		} boxlist = BoxList(detections, per_anchors.size, mode="xyxy") // RETURNED

DEBUG:root:		// type(boxlist): <class 'maskrcnn_benchmark.structures.bounding_box.BoxList'>
DEBUG:root:		// boxlist: BoxList(num_boxes=88, image_width=561, image_height=480, mode=xyxy)

DEBUG:root:		boxlist.add_field("labels", per_class)
DEBUG:root:		boxlist.add_field("scores", per_box_cls)
DEBUG:root:		boxlist = boxlist.clip_to_image(remove_empty=False)
DEBUG:root:				BoxList.__init__(self, bbox, image_size, mode='xyxy') { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/structures/bounding_box.py

DEBUG:root:					// Params:
DEBUG:root:						// type(bbox):<class 'torch.Tensor'>
DEBUG:root:						// bbox.shape:torch.Size([88, 4])
DEBUG:root:						// image_size: (561, 480)

DEBUG:root:					// isinstance(bbox, torch.Tensor): True
DEBUG:root:					device = bbox.device if isinstance(bbox, torch.Tensor) else torch.device("cpu")
DEBUG:root:					// device: cuda:0

DEBUG:root:					bbox = torch.as_tensor(bbox, dtype=torch.float32, device=device)
DEBUG:root:					// bbox.shape: torch.Size([88, 4])

DEBUG:root:					// bbox.ndimension(): 2
DEBUG:root:					// bbox.size(-1): 4

DEBUG:root:					self.bbox = bbox
DEBUG:root:					self.size = image_size  # (image_width, image_height)
DEBUG:root:					self.mode = mode
DEBUG:root:					self.extra_fields = {}
DEBUG:root:				} // END BoxList.__init__(self, bbox, image_size, mode='xyxy')
DEBUG:root:				BoxList.__init__(self, bbox, image_size, mode='xyxy') { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/structures/bounding_box.py

DEBUG:root:					// Params:
DEBUG:root:						// type(bbox):<class 'torch.Tensor'>
DEBUG:root:						// bbox.shape:torch.Size([88, 4])
DEBUG:root:						// image_size: (561, 480)

DEBUG:root:					// isinstance(bbox, torch.Tensor): True
DEBUG:root:					device = bbox.device if isinstance(bbox, torch.Tensor) else torch.device("cpu")
DEBUG:root:					// device: cuda:0

DEBUG:root:					bbox = torch.as_tensor(bbox, dtype=torch.float32, device=device)
DEBUG:root:					// bbox.shape: torch.Size([88, 4])

DEBUG:root:					// bbox.ndimension(): 2
DEBUG:root:					// bbox.size(-1): 4

DEBUG:root:					self.bbox = bbox
DEBUG:root:					self.size = image_size  # (image_width, image_height)
DEBUG:root:					self.mode = mode
DEBUG:root:					self.extra_fields = {}
DEBUG:root:				} // END BoxList.__init__(self, bbox, image_size, mode='xyxy')
DEBUG:root:		boxlist = remove_small_boxes(boxlist, self.min_size)
DEBUG:root:		results.append(boxlist)
DEBUG:root:	} // END for per_box_cls, per_box_regression, ... in zip():

DEBUG:root:	return results

DEBUG:root:} // END RetinaNetPostProcessor.forward_for_single_feature_map()
DEBUG:root:					}
DEBUG:root:					sampled_boxes.append(self.forward_for_single_feature_map(a, o, b)) // RETURNED

DEBUG:root:					} // END of for a, o, b in zip() iteration: 2/5

DEBUG:root:					{
DEBUG:root:					# BEGIN for a, o, b in zip()  iteration: 3/5
DEBUG:root:					# a: (BoxList(num_boxes=2430, image_width=561, image_height=480, mode=xyxy),)
DEBUG:root:					# o.shape: torch.Size([1, 9, 15, 18])
DEBUG:root:					# b.shape: torch.Size([1, 36, 15, 18])

DEBUG:root:					# 2-3-2-3-2 self.forward_for_single_feature_map
DEBUG:root:					// self.forward_for_single_feature_map: <bound method RetinaNetPostProcessor.forward_for_single_feature_map of RetinaNetPostProcessor()>
DEBUG:root:					sampled_boxes.append(self.forward_for_single_feature_map(a, o, b)) { // CALL
DEBUG:root:RetinaNetPostProcessor.forward_for_single_feature_map() { //BEGIN
DEBUG:root:	// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/retinanet/inference.py

DEBUG:root:	// Params:
DEBUG:root:		> anchors: list[BoxList]
DEBUG:root:		> box_cls: tensor of size N, A*C, H, W)
DEBUG:root:		> box_regression: tensor of size N, A*4, H, W)

DEBUG:root:	device = box_cls.device
DEBUG:root:	// device: cuda:0

DEBUG:root:	N, _, H, W = box_cls.shape
DEBUG:root:	// N:1, H:15, W:18

DEBUG:root:	A = box_regression.size(1) // 4
DEBUG:root:	// A : 9

DEBUG:root:	C = box_cls.size(1) // A
DEBUG:root:	// C: 1

DEBUG:root:	# put 'box_cls' in the same format as anchors
DEBUG:root:	box_cls = permute_and_flatten(box_cls, N, A, C, H, W)
DEBUG:root:	// box_cls.shape: torch.Size([1, 2430, 1])

DEBUG:root:	box_cls = box_cls.sigmoid()
DEBUG:root:	// box_cls.shape: torch.Size([1, 2430, 1])

DEBUG:root:	# put 'box_cls' in the same format as anchors
DEBUG:root:	box_regression = permute_and_flatten(box_regression, N, A, 4, H, W)
DEBUG:root:	// box_regression.shape: torch.Size([1, 2430, 4])

DEBUG:root:	box_regression = box_regression.reshape(N, -1, 4)
DEBUG:root:	// box_regression.shape: torch.Size([1, 2430, 4])

DEBUG:root:	num_anchors = A * H * W
DEBUG:root:	// num_anchors: 2430

DEBUG:root:	candidate_inds = box_cls > self.pre_nms_thresh
DEBUG:root:	// candidate_inds.shape: torch.Size([1, 2430, 1])

DEBUG:root:	pre_nms_top_n = candidate_inds.view(N, -1).sum(1)
DEBUG:root:	// pre_nms_top_n: tensor([0], device='cuda:0')

DEBUG:root:	pre_nms_top_n = pre_nms_top_n.clamp(max=self.pre_nms_top_n)
DEBUG:root:	// pre_nms_top_n: tensor([0], device='cuda:0')

DEBUG:root:	results = []

DEBUG:root:	// box_cls.shape: torch.Size([1, 2430, 1])
DEBUG:root:	// box_regression.shape: torch.Size([1, 2430, 4])
DEBUG:root:	// pre_nmns_top_n: tensor([0], device='cuda:0')
DEBUG:root:	// candidate.inds.shape: torch.Size([1, 2430, 1])
DEBUG:root:	// anchors: (BoxList(num_boxes=2430, image_width=561, image_height=480, mode=xyxy),)
DEBUG:root:	for per_box_cls, per_box_regression, ... in zip():
	{
DEBUG:root:		# ====================================
DEBUG:root:		# per_box_cls.shape: torch.Size([2430, 1])
DEBUG:root:		# type(per_box_cls): <class 'torch.Tensor'>
DEBUG:root:		# per_box_regression.shape: torch.Size([2430, 4])
DEBUG:root:		# per_pre_nms_top_n: 0
DEBUG:root:		# per_candidate_inds.shape: torch.Size([2430, 1])
DEBUG:root:		# per_anchors: BoxList(num_boxes=2430, image_width=561, image_height=480, mode=xyxy)
DEBUG:root:		# ====================================

DEBUG:root:		per_box_cls = per_box_cls[per_candidate_inds]
DEBUG:root:		per_box_cls, top_k_indices =per_box_cls.topk(per_pre_nms_top_n, sorted=False)
DEBUG:root:		// per_box_cls: tensor([])
DEBUG:root:		// top_k_indices: tensor([], dtype=torch.int64)

DEBUG:root:		per_candidate_nonzeros = \
DEBUG:root:		   per_candidate_inds.nonzero()[top_k_indices, :]
DEBUG:root:		// per_candidate_inds.shape: torch.Size([2430, 1])

DEBUG:root:		per_box_loc = per_candidate_nonzeros[:, 0]
DEBUG:root:		// per_box_loc.shape: torch.Size([0])

DEBUG:root:		per_class = per_candidate_nonzeros[:, 1]
DEBUG:root:		// per_class.shape: torch.Size([0])

DEBUG:root:		per_class += 1

DEBUG:root:		detections = self.box_coder.decode( ) { // CALL
DEBUG:root:		BoxCoder.decode(self, rel_codes, boxes) { // BEGIN
DEBUG:root:			// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/box_coder.py
DEBUG:root:			// Params:
DEBUG:root:				rel_codes.shape: torch.Size([0, 4])
DEBUG:root:				boxes.shape: torch.Size([0, 4])

DEBUG:root:			boxes = boxes.to(rel_codes.dtype)
DEBUG:root:			// boxes.shape: torch.Size([0, 4])

DEBUG:root:			TO_REMOVE = 1  # TODO remove

DEBUG:root:			widths = boxes[:, 2] - boxes[:, 0] + TO_REMOVE
DEBUG:root:			// widths.shape: torch.Size([0])

DEBUG:root:			heights = boxes[:, 3] - boxes[:, 1] + TO_REMOVE
DEBUG:root:			// heights.shape: torch.Size([0])

DEBUG:root:			ctr_x = boxes[:, 0] + 0.5 * widths
DEBUG:root:			// ctr_x.shape: torch.Size([0])

DEBUG:root:			ctr_y = boxes[:, 1] + 0.5 * heights
DEBUG:root:			// ctr_y.shape: torch.Size([0])


DEBUG:root:			wx, wy, ww, wh = self.weights
DEBUG:root:			// wx: 10.0, wy: 10.0, ww: 5.0, wh: 5.0

DEBUG:root:			dx = rel_codes[:, 0::4] / wx
DEBUG:root:			// dx.shape: torch.Size([0, 1])

DEBUG:root:			dy = rel_codes[:, 1::4] / wy
DEBUG:root:			// dy.shape: torch.Size([0, 1])

DEBUG:root:			dw = rel_codes[:, 2::4] / ww
DEBUG:root:			// dw.shape: torch.Size([0, 1])

DEBUG:root:			dh = rel_codes[:, 3::4] / wh
DEBUG:root:			// dh.shape: torch.Size([0, 1])


DEBUG:root:			# Prevent sending too large values into torch.exp()
DEBUG:root:			dw = torch.clamp(dw, max=self.bbox_xform_clip)
DEBUG:root:			// dw.shape: torch.Size([0, 1])

DEBUG:root:			dh = torch.clamp(dh, max=self.bbox_xform_clip)
DEBUG:root:			// dh.shape: torch.Size([0, 1])

DEBUG:root:			pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]
DEBUG:root:			// pred_ctr_x.shape: torch.Size([0, 1])

DEBUG:root:			pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]
DEBUG:root:			// pred_ctr_y.shape: torch.Size([0, 1])

DEBUG:root:			pred_w = torch.exp(dw) * widths[:, None]
DEBUG:root:			// pred_w.shape: torch.Size([0, 1])

DEBUG:root:			pred_h = torch.exp(dh) * heights[:, None]
DEBUG:root:			// pred_h.shape: torch.Size([0, 1])


DEBUG:root:			pred_boxes = torch.zeros_like(rel_codes)
DEBUG:root:			// pred_boxes.shape: torch.Size([0, 4])


DEBUG:root:			# x1
DEBUG:root:			pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w

DEBUG:root:			# y1
DEBUG:root:			pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h

DEBUG:root:			# x2 (note: '- 1' is correct; don't be fooled by the asymmetry)
DEBUG:root:			pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w - 1

DEBUG:root:			# y2 (note: '- 1' is correct; don't be fooled by the asymmetry)
DEBUG:root:			pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h - 1


DEBUG:root:			pred_boxes.shape: torch.Size([0, 4])

DEBUG:root:			return pred_boxes

DEBUG:root:		} // END BoxCoder.decode(self, rel_codes, boxes)

DEBUG:root:		} detections = self.box_coder.decode( ) // RETURNED

DEBUG:root:		// type(detections): <class 'torch.Tensor'>
DEBUG:root:		// detections: tensor([], size=(0, 4))

DEBUG:root:		boxlist = BoxList(detections, per_anchors.size, mode="xyxy") { // CALL
DEBUG:root:				BoxList.__init__(self, bbox, image_size, mode='xyxy') { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/structures/bounding_box.py

DEBUG:root:					// Params:
DEBUG:root:						// type(bbox):<class 'torch.Tensor'>
DEBUG:root:						// bbox.shape:torch.Size([0, 4])
DEBUG:root:						// image_size: (561, 480)

DEBUG:root:					// isinstance(bbox, torch.Tensor): True
DEBUG:root:					device = bbox.device if isinstance(bbox, torch.Tensor) else torch.device("cpu")
DEBUG:root:					// device: cuda:0

DEBUG:root:					bbox = torch.as_tensor(bbox, dtype=torch.float32, device=device)
DEBUG:root:					// bbox.shape: torch.Size([0, 4])

DEBUG:root:					// bbox.ndimension(): 2
DEBUG:root:					// bbox.size(-1): 4

DEBUG:root:					self.bbox = bbox
DEBUG:root:					self.size = image_size  # (image_width, image_height)
DEBUG:root:					self.mode = mode
DEBUG:root:					self.extra_fields = {}
DEBUG:root:				} // END BoxList.__init__(self, bbox, image_size, mode='xyxy')
DEBUG:root:		} boxlist = BoxList(detections, per_anchors.size, mode="xyxy") // RETURNED

DEBUG:root:		// type(boxlist): <class 'maskrcnn_benchmark.structures.bounding_box.BoxList'>
DEBUG:root:		// boxlist: BoxList(num_boxes=0, image_width=561, image_height=480, mode=xyxy)

DEBUG:root:		boxlist.add_field("labels", per_class)
DEBUG:root:		boxlist.add_field("scores", per_box_cls)
DEBUG:root:		boxlist = boxlist.clip_to_image(remove_empty=False)
DEBUG:root:				BoxList.__init__(self, bbox, image_size, mode='xyxy') { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/structures/bounding_box.py

DEBUG:root:					// Params:
DEBUG:root:						// type(bbox):<class 'torch.Tensor'>
DEBUG:root:						// bbox.shape:torch.Size([0, 4])
DEBUG:root:						// image_size: (561, 480)

DEBUG:root:					// isinstance(bbox, torch.Tensor): True
DEBUG:root:					device = bbox.device if isinstance(bbox, torch.Tensor) else torch.device("cpu")
DEBUG:root:					// device: cuda:0

DEBUG:root:					bbox = torch.as_tensor(bbox, dtype=torch.float32, device=device)
DEBUG:root:					// bbox.shape: torch.Size([0, 4])

DEBUG:root:					// bbox.ndimension(): 2
DEBUG:root:					// bbox.size(-1): 4

DEBUG:root:					self.bbox = bbox
DEBUG:root:					self.size = image_size  # (image_width, image_height)
DEBUG:root:					self.mode = mode
DEBUG:root:					self.extra_fields = {}
DEBUG:root:				} // END BoxList.__init__(self, bbox, image_size, mode='xyxy')
DEBUG:root:				BoxList.__init__(self, bbox, image_size, mode='xyxy') { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/structures/bounding_box.py

DEBUG:root:					// Params:
DEBUG:root:						// type(bbox):<class 'torch.Tensor'>
DEBUG:root:						// bbox.shape:torch.Size([0, 4])
DEBUG:root:						// image_size: (561, 480)

DEBUG:root:					// isinstance(bbox, torch.Tensor): True
DEBUG:root:					device = bbox.device if isinstance(bbox, torch.Tensor) else torch.device("cpu")
DEBUG:root:					// device: cuda:0

DEBUG:root:					bbox = torch.as_tensor(bbox, dtype=torch.float32, device=device)
DEBUG:root:					// bbox.shape: torch.Size([0, 4])

DEBUG:root:					// bbox.ndimension(): 2
DEBUG:root:					// bbox.size(-1): 4

DEBUG:root:					self.bbox = bbox
DEBUG:root:					self.size = image_size  # (image_width, image_height)
DEBUG:root:					self.mode = mode
DEBUG:root:					self.extra_fields = {}
DEBUG:root:				} // END BoxList.__init__(self, bbox, image_size, mode='xyxy')
DEBUG:root:		boxlist = remove_small_boxes(boxlist, self.min_size)
DEBUG:root:		results.append(boxlist)
DEBUG:root:	} // END for per_box_cls, per_box_regression, ... in zip():

DEBUG:root:	return results

DEBUG:root:} // END RetinaNetPostProcessor.forward_for_single_feature_map()
DEBUG:root:					}
DEBUG:root:					sampled_boxes.append(self.forward_for_single_feature_map(a, o, b)) // RETURNED

DEBUG:root:					} // END of for a, o, b in zip() iteration: 3/5

DEBUG:root:					{
DEBUG:root:					# BEGIN for a, o, b in zip()  iteration: 4/5
DEBUG:root:					# a: (BoxList(num_boxes=648, image_width=561, image_height=480, mode=xyxy),)
DEBUG:root:					# o.shape: torch.Size([1, 9, 8, 9])
DEBUG:root:					# b.shape: torch.Size([1, 36, 8, 9])

DEBUG:root:					# 2-3-2-3-2 self.forward_for_single_feature_map
DEBUG:root:					// self.forward_for_single_feature_map: <bound method RetinaNetPostProcessor.forward_for_single_feature_map of RetinaNetPostProcessor()>
DEBUG:root:					sampled_boxes.append(self.forward_for_single_feature_map(a, o, b)) { // CALL
DEBUG:root:RetinaNetPostProcessor.forward_for_single_feature_map() { //BEGIN
DEBUG:root:	// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/retinanet/inference.py

DEBUG:root:	// Params:
DEBUG:root:		> anchors: list[BoxList]
DEBUG:root:		> box_cls: tensor of size N, A*C, H, W)
DEBUG:root:		> box_regression: tensor of size N, A*4, H, W)

DEBUG:root:	device = box_cls.device
DEBUG:root:	// device: cuda:0

DEBUG:root:	N, _, H, W = box_cls.shape
DEBUG:root:	// N:1, H:8, W:9

DEBUG:root:	A = box_regression.size(1) // 4
DEBUG:root:	// A : 9

DEBUG:root:	C = box_cls.size(1) // A
DEBUG:root:	// C: 1

DEBUG:root:	# put 'box_cls' in the same format as anchors
DEBUG:root:	box_cls = permute_and_flatten(box_cls, N, A, C, H, W)
DEBUG:root:	// box_cls.shape: torch.Size([1, 648, 1])

DEBUG:root:	box_cls = box_cls.sigmoid()
DEBUG:root:	// box_cls.shape: torch.Size([1, 648, 1])

DEBUG:root:	# put 'box_cls' in the same format as anchors
DEBUG:root:	box_regression = permute_and_flatten(box_regression, N, A, 4, H, W)
DEBUG:root:	// box_regression.shape: torch.Size([1, 648, 4])

DEBUG:root:	box_regression = box_regression.reshape(N, -1, 4)
DEBUG:root:	// box_regression.shape: torch.Size([1, 648, 4])

DEBUG:root:	num_anchors = A * H * W
DEBUG:root:	// num_anchors: 648

DEBUG:root:	candidate_inds = box_cls > self.pre_nms_thresh
DEBUG:root:	// candidate_inds.shape: torch.Size([1, 648, 1])

DEBUG:root:	pre_nms_top_n = candidate_inds.view(N, -1).sum(1)
DEBUG:root:	// pre_nms_top_n: tensor([0], device='cuda:0')

DEBUG:root:	pre_nms_top_n = pre_nms_top_n.clamp(max=self.pre_nms_top_n)
DEBUG:root:	// pre_nms_top_n: tensor([0], device='cuda:0')

DEBUG:root:	results = []

DEBUG:root:	// box_cls.shape: torch.Size([1, 648, 1])
DEBUG:root:	// box_regression.shape: torch.Size([1, 648, 4])
DEBUG:root:	// pre_nmns_top_n: tensor([0], device='cuda:0')
DEBUG:root:	// candidate.inds.shape: torch.Size([1, 648, 1])
DEBUG:root:	// anchors: (BoxList(num_boxes=648, image_width=561, image_height=480, mode=xyxy),)
DEBUG:root:	for per_box_cls, per_box_regression, ... in zip():
	{
DEBUG:root:		# ====================================
DEBUG:root:		# per_box_cls.shape: torch.Size([648, 1])
DEBUG:root:		# type(per_box_cls): <class 'torch.Tensor'>
DEBUG:root:		# per_box_regression.shape: torch.Size([648, 4])
DEBUG:root:		# per_pre_nms_top_n: 0
DEBUG:root:		# per_candidate_inds.shape: torch.Size([648, 1])
DEBUG:root:		# per_anchors: BoxList(num_boxes=648, image_width=561, image_height=480, mode=xyxy)
DEBUG:root:		# ====================================

DEBUG:root:		per_box_cls = per_box_cls[per_candidate_inds]
DEBUG:root:		per_box_cls, top_k_indices =per_box_cls.topk(per_pre_nms_top_n, sorted=False)
DEBUG:root:		// per_box_cls: tensor([])
DEBUG:root:		// top_k_indices: tensor([], dtype=torch.int64)

DEBUG:root:		per_candidate_nonzeros = \
DEBUG:root:		   per_candidate_inds.nonzero()[top_k_indices, :]
DEBUG:root:		// per_candidate_inds.shape: torch.Size([648, 1])

DEBUG:root:		per_box_loc = per_candidate_nonzeros[:, 0]
DEBUG:root:		// per_box_loc.shape: torch.Size([0])

DEBUG:root:		per_class = per_candidate_nonzeros[:, 1]
DEBUG:root:		// per_class.shape: torch.Size([0])

DEBUG:root:		per_class += 1

DEBUG:root:		detections = self.box_coder.decode( ) { // CALL
DEBUG:root:		BoxCoder.decode(self, rel_codes, boxes) { // BEGIN
DEBUG:root:			// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/box_coder.py
DEBUG:root:			// Params:
DEBUG:root:				rel_codes.shape: torch.Size([0, 4])
DEBUG:root:				boxes.shape: torch.Size([0, 4])

DEBUG:root:			boxes = boxes.to(rel_codes.dtype)
DEBUG:root:			// boxes.shape: torch.Size([0, 4])

DEBUG:root:			TO_REMOVE = 1  # TODO remove

DEBUG:root:			widths = boxes[:, 2] - boxes[:, 0] + TO_REMOVE
DEBUG:root:			// widths.shape: torch.Size([0])

DEBUG:root:			heights = boxes[:, 3] - boxes[:, 1] + TO_REMOVE
DEBUG:root:			// heights.shape: torch.Size([0])

DEBUG:root:			ctr_x = boxes[:, 0] + 0.5 * widths
DEBUG:root:			// ctr_x.shape: torch.Size([0])

DEBUG:root:			ctr_y = boxes[:, 1] + 0.5 * heights
DEBUG:root:			// ctr_y.shape: torch.Size([0])


DEBUG:root:			wx, wy, ww, wh = self.weights
DEBUG:root:			// wx: 10.0, wy: 10.0, ww: 5.0, wh: 5.0

DEBUG:root:			dx = rel_codes[:, 0::4] / wx
DEBUG:root:			// dx.shape: torch.Size([0, 1])

DEBUG:root:			dy = rel_codes[:, 1::4] / wy
DEBUG:root:			// dy.shape: torch.Size([0, 1])

DEBUG:root:			dw = rel_codes[:, 2::4] / ww
DEBUG:root:			// dw.shape: torch.Size([0, 1])

DEBUG:root:			dh = rel_codes[:, 3::4] / wh
DEBUG:root:			// dh.shape: torch.Size([0, 1])


DEBUG:root:			# Prevent sending too large values into torch.exp()
DEBUG:root:			dw = torch.clamp(dw, max=self.bbox_xform_clip)
DEBUG:root:			// dw.shape: torch.Size([0, 1])

DEBUG:root:			dh = torch.clamp(dh, max=self.bbox_xform_clip)
DEBUG:root:			// dh.shape: torch.Size([0, 1])

DEBUG:root:			pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]
DEBUG:root:			// pred_ctr_x.shape: torch.Size([0, 1])

DEBUG:root:			pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]
DEBUG:root:			// pred_ctr_y.shape: torch.Size([0, 1])

DEBUG:root:			pred_w = torch.exp(dw) * widths[:, None]
DEBUG:root:			// pred_w.shape: torch.Size([0, 1])

DEBUG:root:			pred_h = torch.exp(dh) * heights[:, None]
DEBUG:root:			// pred_h.shape: torch.Size([0, 1])


DEBUG:root:			pred_boxes = torch.zeros_like(rel_codes)
DEBUG:root:			// pred_boxes.shape: torch.Size([0, 4])


DEBUG:root:			# x1
DEBUG:root:			pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w

DEBUG:root:			# y1
DEBUG:root:			pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h

DEBUG:root:			# x2 (note: '- 1' is correct; don't be fooled by the asymmetry)
DEBUG:root:			pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w - 1

DEBUG:root:			# y2 (note: '- 1' is correct; don't be fooled by the asymmetry)
DEBUG:root:			pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h - 1


DEBUG:root:			pred_boxes.shape: torch.Size([0, 4])

DEBUG:root:			return pred_boxes

DEBUG:root:		} // END BoxCoder.decode(self, rel_codes, boxes)

DEBUG:root:		} detections = self.box_coder.decode( ) // RETURNED

DEBUG:root:		// type(detections): <class 'torch.Tensor'>
DEBUG:root:		// detections: tensor([], size=(0, 4))

DEBUG:root:		boxlist = BoxList(detections, per_anchors.size, mode="xyxy") { // CALL
DEBUG:root:				BoxList.__init__(self, bbox, image_size, mode='xyxy') { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/structures/bounding_box.py

DEBUG:root:					// Params:
DEBUG:root:						// type(bbox):<class 'torch.Tensor'>
DEBUG:root:						// bbox.shape:torch.Size([0, 4])
DEBUG:root:						// image_size: (561, 480)

DEBUG:root:					// isinstance(bbox, torch.Tensor): True
DEBUG:root:					device = bbox.device if isinstance(bbox, torch.Tensor) else torch.device("cpu")
DEBUG:root:					// device: cuda:0

DEBUG:root:					bbox = torch.as_tensor(bbox, dtype=torch.float32, device=device)
DEBUG:root:					// bbox.shape: torch.Size([0, 4])

DEBUG:root:					// bbox.ndimension(): 2
DEBUG:root:					// bbox.size(-1): 4

DEBUG:root:					self.bbox = bbox
DEBUG:root:					self.size = image_size  # (image_width, image_height)
DEBUG:root:					self.mode = mode
DEBUG:root:					self.extra_fields = {}
DEBUG:root:				} // END BoxList.__init__(self, bbox, image_size, mode='xyxy')
DEBUG:root:		} boxlist = BoxList(detections, per_anchors.size, mode="xyxy") // RETURNED

DEBUG:root:		// type(boxlist): <class 'maskrcnn_benchmark.structures.bounding_box.BoxList'>
DEBUG:root:		// boxlist: BoxList(num_boxes=0, image_width=561, image_height=480, mode=xyxy)

DEBUG:root:		boxlist.add_field("labels", per_class)
DEBUG:root:		boxlist.add_field("scores", per_box_cls)
DEBUG:root:		boxlist = boxlist.clip_to_image(remove_empty=False)
DEBUG:root:				BoxList.__init__(self, bbox, image_size, mode='xyxy') { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/structures/bounding_box.py

DEBUG:root:					// Params:
DEBUG:root:						// type(bbox):<class 'torch.Tensor'>
DEBUG:root:						// bbox.shape:torch.Size([0, 4])
DEBUG:root:						// image_size: (561, 480)

DEBUG:root:					// isinstance(bbox, torch.Tensor): True
DEBUG:root:					device = bbox.device if isinstance(bbox, torch.Tensor) else torch.device("cpu")
DEBUG:root:					// device: cuda:0

DEBUG:root:					bbox = torch.as_tensor(bbox, dtype=torch.float32, device=device)
DEBUG:root:					// bbox.shape: torch.Size([0, 4])

DEBUG:root:					// bbox.ndimension(): 2
DEBUG:root:					// bbox.size(-1): 4

DEBUG:root:					self.bbox = bbox
DEBUG:root:					self.size = image_size  # (image_width, image_height)
DEBUG:root:					self.mode = mode
DEBUG:root:					self.extra_fields = {}
DEBUG:root:				} // END BoxList.__init__(self, bbox, image_size, mode='xyxy')
DEBUG:root:				BoxList.__init__(self, bbox, image_size, mode='xyxy') { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/structures/bounding_box.py

DEBUG:root:					// Params:
DEBUG:root:						// type(bbox):<class 'torch.Tensor'>
DEBUG:root:						// bbox.shape:torch.Size([0, 4])
DEBUG:root:						// image_size: (561, 480)

DEBUG:root:					// isinstance(bbox, torch.Tensor): True
DEBUG:root:					device = bbox.device if isinstance(bbox, torch.Tensor) else torch.device("cpu")
DEBUG:root:					// device: cuda:0

DEBUG:root:					bbox = torch.as_tensor(bbox, dtype=torch.float32, device=device)
DEBUG:root:					// bbox.shape: torch.Size([0, 4])

DEBUG:root:					// bbox.ndimension(): 2
DEBUG:root:					// bbox.size(-1): 4

DEBUG:root:					self.bbox = bbox
DEBUG:root:					self.size = image_size  # (image_width, image_height)
DEBUG:root:					self.mode = mode
DEBUG:root:					self.extra_fields = {}
DEBUG:root:				} // END BoxList.__init__(self, bbox, image_size, mode='xyxy')
DEBUG:root:		boxlist = remove_small_boxes(boxlist, self.min_size)
DEBUG:root:		results.append(boxlist)
DEBUG:root:	} // END for per_box_cls, per_box_regression, ... in zip():

DEBUG:root:	return results

DEBUG:root:} // END RetinaNetPostProcessor.forward_for_single_feature_map()
DEBUG:root:					}
DEBUG:root:					sampled_boxes.append(self.forward_for_single_feature_map(a, o, b)) // RETURNED

DEBUG:root:					} // END of for a, o, b in zip() iteration: 4/5

DEBUG:root:					{
DEBUG:root:					# BEGIN for a, o, b in zip()  iteration: 5/5
DEBUG:root:					# a: (BoxList(num_boxes=180, image_width=561, image_height=480, mode=xyxy),)
DEBUG:root:					# o.shape: torch.Size([1, 9, 4, 5])
DEBUG:root:					# b.shape: torch.Size([1, 36, 4, 5])

DEBUG:root:					# 2-3-2-3-2 self.forward_for_single_feature_map
DEBUG:root:					// self.forward_for_single_feature_map: <bound method RetinaNetPostProcessor.forward_for_single_feature_map of RetinaNetPostProcessor()>
DEBUG:root:					sampled_boxes.append(self.forward_for_single_feature_map(a, o, b)) { // CALL
DEBUG:root:RetinaNetPostProcessor.forward_for_single_feature_map() { //BEGIN
DEBUG:root:	// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/retinanet/inference.py

DEBUG:root:	// Params:
DEBUG:root:		> anchors: list[BoxList]
DEBUG:root:		> box_cls: tensor of size N, A*C, H, W)
DEBUG:root:		> box_regression: tensor of size N, A*4, H, W)

DEBUG:root:	device = box_cls.device
DEBUG:root:	// device: cuda:0

DEBUG:root:	N, _, H, W = box_cls.shape
DEBUG:root:	// N:1, H:4, W:5

DEBUG:root:	A = box_regression.size(1) // 4
DEBUG:root:	// A : 9

DEBUG:root:	C = box_cls.size(1) // A
DEBUG:root:	// C: 1

DEBUG:root:	# put 'box_cls' in the same format as anchors
DEBUG:root:	box_cls = permute_and_flatten(box_cls, N, A, C, H, W)
DEBUG:root:	// box_cls.shape: torch.Size([1, 180, 1])

DEBUG:root:	box_cls = box_cls.sigmoid()
DEBUG:root:	// box_cls.shape: torch.Size([1, 180, 1])

DEBUG:root:	# put 'box_cls' in the same format as anchors
DEBUG:root:	box_regression = permute_and_flatten(box_regression, N, A, 4, H, W)
DEBUG:root:	// box_regression.shape: torch.Size([1, 180, 4])

DEBUG:root:	box_regression = box_regression.reshape(N, -1, 4)
DEBUG:root:	// box_regression.shape: torch.Size([1, 180, 4])

DEBUG:root:	num_anchors = A * H * W
DEBUG:root:	// num_anchors: 180

DEBUG:root:	candidate_inds = box_cls > self.pre_nms_thresh
DEBUG:root:	// candidate_inds.shape: torch.Size([1, 180, 1])

DEBUG:root:	pre_nms_top_n = candidate_inds.view(N, -1).sum(1)
DEBUG:root:	// pre_nms_top_n: tensor([0], device='cuda:0')

DEBUG:root:	pre_nms_top_n = pre_nms_top_n.clamp(max=self.pre_nms_top_n)
DEBUG:root:	// pre_nms_top_n: tensor([0], device='cuda:0')

DEBUG:root:	results = []

DEBUG:root:	// box_cls.shape: torch.Size([1, 180, 1])
DEBUG:root:	// box_regression.shape: torch.Size([1, 180, 4])
DEBUG:root:	// pre_nmns_top_n: tensor([0], device='cuda:0')
DEBUG:root:	// candidate.inds.shape: torch.Size([1, 180, 1])
DEBUG:root:	// anchors: (BoxList(num_boxes=180, image_width=561, image_height=480, mode=xyxy),)
DEBUG:root:	for per_box_cls, per_box_regression, ... in zip():
	{
DEBUG:root:		# ====================================
DEBUG:root:		# per_box_cls.shape: torch.Size([180, 1])
DEBUG:root:		# type(per_box_cls): <class 'torch.Tensor'>
DEBUG:root:		# per_box_regression.shape: torch.Size([180, 4])
DEBUG:root:		# per_pre_nms_top_n: 0
DEBUG:root:		# per_candidate_inds.shape: torch.Size([180, 1])
DEBUG:root:		# per_anchors: BoxList(num_boxes=180, image_width=561, image_height=480, mode=xyxy)
DEBUG:root:		# ====================================

DEBUG:root:		per_box_cls = per_box_cls[per_candidate_inds]
DEBUG:root:		per_box_cls, top_k_indices =per_box_cls.topk(per_pre_nms_top_n, sorted=False)
DEBUG:root:		// per_box_cls: tensor([])
DEBUG:root:		// top_k_indices: tensor([], dtype=torch.int64)

DEBUG:root:		per_candidate_nonzeros = \
DEBUG:root:		   per_candidate_inds.nonzero()[top_k_indices, :]
DEBUG:root:		// per_candidate_inds.shape: torch.Size([180, 1])

DEBUG:root:		per_box_loc = per_candidate_nonzeros[:, 0]
DEBUG:root:		// per_box_loc.shape: torch.Size([0])

DEBUG:root:		per_class = per_candidate_nonzeros[:, 1]
DEBUG:root:		// per_class.shape: torch.Size([0])

DEBUG:root:		per_class += 1

DEBUG:root:		detections = self.box_coder.decode( ) { // CALL
DEBUG:root:		BoxCoder.decode(self, rel_codes, boxes) { // BEGIN
DEBUG:root:			// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/box_coder.py
DEBUG:root:			// Params:
DEBUG:root:				rel_codes.shape: torch.Size([0, 4])
DEBUG:root:				boxes.shape: torch.Size([0, 4])

DEBUG:root:			boxes = boxes.to(rel_codes.dtype)
DEBUG:root:			// boxes.shape: torch.Size([0, 4])

DEBUG:root:			TO_REMOVE = 1  # TODO remove

DEBUG:root:			widths = boxes[:, 2] - boxes[:, 0] + TO_REMOVE
DEBUG:root:			// widths.shape: torch.Size([0])

DEBUG:root:			heights = boxes[:, 3] - boxes[:, 1] + TO_REMOVE
DEBUG:root:			// heights.shape: torch.Size([0])

DEBUG:root:			ctr_x = boxes[:, 0] + 0.5 * widths
DEBUG:root:			// ctr_x.shape: torch.Size([0])

DEBUG:root:			ctr_y = boxes[:, 1] + 0.5 * heights
DEBUG:root:			// ctr_y.shape: torch.Size([0])


DEBUG:root:			wx, wy, ww, wh = self.weights
DEBUG:root:			// wx: 10.0, wy: 10.0, ww: 5.0, wh: 5.0

DEBUG:root:			dx = rel_codes[:, 0::4] / wx
DEBUG:root:			// dx.shape: torch.Size([0, 1])

DEBUG:root:			dy = rel_codes[:, 1::4] / wy
DEBUG:root:			// dy.shape: torch.Size([0, 1])

DEBUG:root:			dw = rel_codes[:, 2::4] / ww
DEBUG:root:			// dw.shape: torch.Size([0, 1])

DEBUG:root:			dh = rel_codes[:, 3::4] / wh
DEBUG:root:			// dh.shape: torch.Size([0, 1])


DEBUG:root:			# Prevent sending too large values into torch.exp()
DEBUG:root:			dw = torch.clamp(dw, max=self.bbox_xform_clip)
DEBUG:root:			// dw.shape: torch.Size([0, 1])

DEBUG:root:			dh = torch.clamp(dh, max=self.bbox_xform_clip)
DEBUG:root:			// dh.shape: torch.Size([0, 1])

DEBUG:root:			pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]
DEBUG:root:			// pred_ctr_x.shape: torch.Size([0, 1])

DEBUG:root:			pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]
DEBUG:root:			// pred_ctr_y.shape: torch.Size([0, 1])

DEBUG:root:			pred_w = torch.exp(dw) * widths[:, None]
DEBUG:root:			// pred_w.shape: torch.Size([0, 1])

DEBUG:root:			pred_h = torch.exp(dh) * heights[:, None]
DEBUG:root:			// pred_h.shape: torch.Size([0, 1])


DEBUG:root:			pred_boxes = torch.zeros_like(rel_codes)
DEBUG:root:			// pred_boxes.shape: torch.Size([0, 4])


DEBUG:root:			# x1
DEBUG:root:			pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w

DEBUG:root:			# y1
DEBUG:root:			pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h

DEBUG:root:			# x2 (note: '- 1' is correct; don't be fooled by the asymmetry)
DEBUG:root:			pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w - 1

DEBUG:root:			# y2 (note: '- 1' is correct; don't be fooled by the asymmetry)
DEBUG:root:			pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h - 1


DEBUG:root:			pred_boxes.shape: torch.Size([0, 4])

DEBUG:root:			return pred_boxes

DEBUG:root:		} // END BoxCoder.decode(self, rel_codes, boxes)

DEBUG:root:		} detections = self.box_coder.decode( ) // RETURNED

DEBUG:root:		// type(detections): <class 'torch.Tensor'>
DEBUG:root:		// detections: tensor([], size=(0, 4))

DEBUG:root:		boxlist = BoxList(detections, per_anchors.size, mode="xyxy") { // CALL
DEBUG:root:				BoxList.__init__(self, bbox, image_size, mode='xyxy') { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/structures/bounding_box.py

DEBUG:root:					// Params:
DEBUG:root:						// type(bbox):<class 'torch.Tensor'>
DEBUG:root:						// bbox.shape:torch.Size([0, 4])
DEBUG:root:						// image_size: (561, 480)

DEBUG:root:					// isinstance(bbox, torch.Tensor): True
DEBUG:root:					device = bbox.device if isinstance(bbox, torch.Tensor) else torch.device("cpu")
DEBUG:root:					// device: cuda:0

DEBUG:root:					bbox = torch.as_tensor(bbox, dtype=torch.float32, device=device)
DEBUG:root:					// bbox.shape: torch.Size([0, 4])

DEBUG:root:					// bbox.ndimension(): 2
DEBUG:root:					// bbox.size(-1): 4

DEBUG:root:					self.bbox = bbox
DEBUG:root:					self.size = image_size  # (image_width, image_height)
DEBUG:root:					self.mode = mode
DEBUG:root:					self.extra_fields = {}
DEBUG:root:				} // END BoxList.__init__(self, bbox, image_size, mode='xyxy')
DEBUG:root:		} boxlist = BoxList(detections, per_anchors.size, mode="xyxy") // RETURNED

DEBUG:root:		// type(boxlist): <class 'maskrcnn_benchmark.structures.bounding_box.BoxList'>
DEBUG:root:		// boxlist: BoxList(num_boxes=0, image_width=561, image_height=480, mode=xyxy)

DEBUG:root:		boxlist.add_field("labels", per_class)
DEBUG:root:		boxlist.add_field("scores", per_box_cls)
DEBUG:root:		boxlist = boxlist.clip_to_image(remove_empty=False)
DEBUG:root:				BoxList.__init__(self, bbox, image_size, mode='xyxy') { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/structures/bounding_box.py

DEBUG:root:					// Params:
DEBUG:root:						// type(bbox):<class 'torch.Tensor'>
DEBUG:root:						// bbox.shape:torch.Size([0, 4])
DEBUG:root:						// image_size: (561, 480)

DEBUG:root:					// isinstance(bbox, torch.Tensor): True
DEBUG:root:					device = bbox.device if isinstance(bbox, torch.Tensor) else torch.device("cpu")
DEBUG:root:					// device: cuda:0

DEBUG:root:					bbox = torch.as_tensor(bbox, dtype=torch.float32, device=device)
DEBUG:root:					// bbox.shape: torch.Size([0, 4])

DEBUG:root:					// bbox.ndimension(): 2
DEBUG:root:					// bbox.size(-1): 4

DEBUG:root:					self.bbox = bbox
DEBUG:root:					self.size = image_size  # (image_width, image_height)
DEBUG:root:					self.mode = mode
DEBUG:root:					self.extra_fields = {}
DEBUG:root:				} // END BoxList.__init__(self, bbox, image_size, mode='xyxy')
DEBUG:root:				BoxList.__init__(self, bbox, image_size, mode='xyxy') { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/structures/bounding_box.py

DEBUG:root:					// Params:
DEBUG:root:						// type(bbox):<class 'torch.Tensor'>
DEBUG:root:						// bbox.shape:torch.Size([0, 4])
DEBUG:root:						// image_size: (561, 480)

DEBUG:root:					// isinstance(bbox, torch.Tensor): True
DEBUG:root:					device = bbox.device if isinstance(bbox, torch.Tensor) else torch.device("cpu")
DEBUG:root:					// device: cuda:0

DEBUG:root:					bbox = torch.as_tensor(bbox, dtype=torch.float32, device=device)
DEBUG:root:					// bbox.shape: torch.Size([0, 4])

DEBUG:root:					// bbox.ndimension(): 2
DEBUG:root:					// bbox.size(-1): 4

DEBUG:root:					self.bbox = bbox
DEBUG:root:					self.size = image_size  # (image_width, image_height)
DEBUG:root:					self.mode = mode
DEBUG:root:					self.extra_fields = {}
DEBUG:root:				} // END BoxList.__init__(self, bbox, image_size, mode='xyxy')
DEBUG:root:		boxlist = remove_small_boxes(boxlist, self.min_size)
DEBUG:root:		results.append(boxlist)
DEBUG:root:	} // END for per_box_cls, per_box_regression, ... in zip():

DEBUG:root:	return results

DEBUG:root:} // END RetinaNetPostProcessor.forward_for_single_feature_map()
DEBUG:root:					}
DEBUG:root:					sampled_boxes.append(self.forward_for_single_feature_map(a, o, b)) // RETURNED

DEBUG:root:					} // END of for a, o, b in zip() iteration: 5/5

DEBUG:root:				}// END for a, o, b in zip(anchors, objectness, box_regression)

DEBUG:root:				# 2-3-2-3-2 boxlists = list(zip(*sampled_boxes))
DEBUG:root:				boxlists = list(zip(*sampled_boxes))
DEBUG:root:				boxlists: [(BoxList(num_boxes=846, image_width=561, image_height=480, mode=xyxy), BoxList(num_boxes=88, image_width=561, image_height=480, mode=xyxy), BoxList(num_boxes=0, image_width=561, image_height=480, mode=xyxy), BoxList(num_boxes=0, image_width=561, image_height=480, mode=xyxy), BoxList(num_boxes=0, image_width=561, image_height=480, mode=xyxy))]

DEBUG:root:				# 2-3-2-3-3 boxlists = [cat_boxlist(boxlist) for boxlist in boxlists]

DEBUG:root:				BoxList.__init__(self, bbox, image_size, mode='xyxy') { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/structures/bounding_box.py

DEBUG:root:					// Params:
DEBUG:root:						// type(bbox):<class 'torch.Tensor'>
DEBUG:root:						// bbox.shape:torch.Size([934, 4])
DEBUG:root:						// image_size: (561, 480)

DEBUG:root:					// isinstance(bbox, torch.Tensor): True
DEBUG:root:					device = bbox.device if isinstance(bbox, torch.Tensor) else torch.device("cpu")
DEBUG:root:					// device: cuda:0

DEBUG:root:					bbox = torch.as_tensor(bbox, dtype=torch.float32, device=device)
DEBUG:root:					// bbox.shape: torch.Size([934, 4])

DEBUG:root:					// bbox.ndimension(): 2
DEBUG:root:					// bbox.size(-1): 4

DEBUG:root:					self.bbox = bbox
DEBUG:root:					self.size = image_size  # (image_width, image_height)
DEBUG:root:					self.mode = mode
DEBUG:root:					self.extra_fields = {}
DEBUG:root:				} // END BoxList.__init__(self, bbox, image_size, mode='xyxy')
DEBUG:root:				boxlists = [cat_boxlist(boxlist) for boxlist in boxlists]

DEBUG:root:				boxlists: [BoxList(num_boxes=934, image_width=561, image_height=480, mode=xyxy)]

DEBUG:root:				if num_levels > 1:
DEBUG:root:					# 2-3-2-3-4 boxlists = self.select_over_all_levels(boxlists)
DEBUG:root:					boxlists = self.select_over_all_levels(boxlists) { // CALL
DEBUG:root:RetinaNetPostProcessor.select_over_all_levels() { //BEGIN
DEBUG:root:	// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/retinanet/inference.py

DEBUG:root:	// Params:
DEBUG:root:		> boxlists:
DEBUG:root:				BoxList.__init__(self, bbox, image_size, mode='xyxy') { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/structures/bounding_box.py

DEBUG:root:					// Params:
DEBUG:root:						// type(bbox):<class 'torch.Tensor'>
DEBUG:root:						// bbox.shape:torch.Size([934, 4])
DEBUG:root:						// image_size: (561, 480)

DEBUG:root:					// isinstance(bbox, torch.Tensor): True
DEBUG:root:					device = bbox.device if isinstance(bbox, torch.Tensor) else torch.device("cpu")
DEBUG:root:					// device: cuda:0

DEBUG:root:					bbox = torch.as_tensor(bbox, dtype=torch.float32, device=device)
DEBUG:root:					// bbox.shape: torch.Size([934, 4])

DEBUG:root:					// bbox.ndimension(): 2
DEBUG:root:					// bbox.size(-1): 4

DEBUG:root:					self.bbox = bbox
DEBUG:root:					self.size = image_size  # (image_width, image_height)
DEBUG:root:					self.mode = mode
DEBUG:root:					self.extra_fields = {}
DEBUG:root:				} // END BoxList.__init__(self, bbox, image_size, mode='xyxy')
DEBUG:root:				BoxList.__init__(self, bbox, image_size, mode='xyxy') { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/structures/bounding_box.py

DEBUG:root:					// Params:
DEBUG:root:						// type(bbox):<class 'torch.Tensor'>
DEBUG:root:						// bbox.shape:torch.Size([68, 4])
DEBUG:root:						// image_size: (561, 480)

DEBUG:root:					// isinstance(bbox, torch.Tensor): True
DEBUG:root:					device = bbox.device if isinstance(bbox, torch.Tensor) else torch.device("cpu")
DEBUG:root:					// device: cuda:0

DEBUG:root:					bbox = torch.as_tensor(bbox, dtype=torch.float32, device=device)
DEBUG:root:					// bbox.shape: torch.Size([68, 4])

DEBUG:root:					// bbox.ndimension(): 2
DEBUG:root:					// bbox.size(-1): 4

DEBUG:root:					self.bbox = bbox
DEBUG:root:					self.size = image_size  # (image_width, image_height)
DEBUG:root:					self.mode = mode
DEBUG:root:					self.extra_fields = {}
DEBUG:root:				} // END BoxList.__init__(self, bbox, image_size, mode='xyxy')
DEBUG:root:				BoxList.__init__(self, bbox, image_size, mode='xyxy') { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/structures/bounding_box.py

DEBUG:root:					// Params:
DEBUG:root:						// type(bbox):<class 'torch.Tensor'>
DEBUG:root:						// bbox.shape:torch.Size([68, 4])
DEBUG:root:						// image_size: (561, 480)

DEBUG:root:					// isinstance(bbox, torch.Tensor): True
DEBUG:root:					device = bbox.device if isinstance(bbox, torch.Tensor) else torch.device("cpu")
DEBUG:root:					// device: cuda:0

DEBUG:root:					bbox = torch.as_tensor(bbox, dtype=torch.float32, device=device)
DEBUG:root:					// bbox.shape: torch.Size([68, 4])

DEBUG:root:					// bbox.ndimension(): 2
DEBUG:root:					// bbox.size(-1): 4

DEBUG:root:					self.bbox = bbox
DEBUG:root:					self.size = image_size  # (image_width, image_height)
DEBUG:root:					self.mode = mode
DEBUG:root:					self.extra_fields = {}
DEBUG:root:				} // END BoxList.__init__(self, bbox, image_size, mode='xyxy')
DEBUG:root:} // END RetinaNetPostProcessor.select_over_all_levels()
DEBUG:root:					}
DEBUG:root:					boxlists = self.select_over_all_levels(boxlists) // RETURNED
DEBUG:root:				if self.training: False and targets: None is not None:
DEBUG:root:				// boxlists: [BoxList(num_boxes=68, image_width=561, image_height=480, mode=xyxy)]

DEBUG:root:				return boxlists

DEBUG:root:		} // END RPNProcessor.forward(self. anchors, objectness, box_regression, targets=None)
DEBUG:root:

DEBUG:root:	}
	boxes = self.box_selector_test(anchors, box_cls, box_regression) // RETURNED
DEBUG:root:	// len(boxes): 1
DEBUG:root:(boxes): [BoxList(num_boxes=68, image_width=561, image_height=480, mode=xyxy)]
DEBUG:root:return boxes, {} # {} is just empty dictionayr
DEBUG:root:

} // RetinaNetModule._forward_test(self, anchors, box_cls, box_regression): END
DEBUG:root:} // END RetinaNetModule.forward(self, images, features, targets=None)
DEBUG:root:

DEBUG:root:	}
	proposals, proposal_losses = self.rpn(images, features, targets) // RETURNED

DEBUG:root:x = features
DEBUG:root:result = proposals
DEBUG:root:return result
DEBUG:root:} // END GeneralizedRCNN.forward(self, images, targets=None)
DEBUG:root:		}
DEBUG:root:		pred = self.model(image_list) // RETURNED
DEBUG:root:				BoxList.__init__(self, bbox, image_size, mode='xyxy') { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/structures/bounding_box.py

DEBUG:root:					// Params:
DEBUG:root:						// type(bbox):<class 'torch.Tensor'>
DEBUG:root:						// bbox.shape:torch.Size([68, 4])
DEBUG:root:						// image_size: (561, 480)

DEBUG:root:					// isinstance(bbox, torch.Tensor): True
DEBUG:root:					device = bbox.device if isinstance(bbox, torch.Tensor) else torch.device("cpu")
DEBUG:root:					// device: cpu

DEBUG:root:					bbox = torch.as_tensor(bbox, dtype=torch.float32, device=device)
DEBUG:root:					// bbox.shape: torch.Size([68, 4])

DEBUG:root:					// bbox.ndimension(): 2
DEBUG:root:					// bbox.size(-1): 4

DEBUG:root:					self.bbox = bbox
DEBUG:root:					self.size = image_size  # (image_width, image_height)
DEBUG:root:					self.mode = mode
DEBUG:root:					self.extra_fields = {}
DEBUG:root:				} // END BoxList.__init__(self, bbox, image_size, mode='xyxy')
DEBUG:root:return pred
DEBUG:root:	pred: BoxList(num_boxes=68, image_width=561, image_height=480, mode=xyxy)
DEBUG:root:} // END compute_prediction(self, image)




DEBUG:root:				BoxList.__init__(self, bbox, image_size, mode='xyxy') { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/structures/bounding_box.py

DEBUG:root:					// Params:
DEBUG:root:						// type(bbox):<class 'torch.Tensor'>
DEBUG:root:						// bbox.shape:torch.Size([26, 4])
DEBUG:root:						// image_size: (561, 480)

DEBUG:root:					// isinstance(bbox, torch.Tensor): True
DEBUG:root:					device = bbox.device if isinstance(bbox, torch.Tensor) else torch.device("cpu")
DEBUG:root:					// device: cpu

DEBUG:root:					bbox = torch.as_tensor(bbox, dtype=torch.float32, device=device)
DEBUG:root:					// bbox.shape: torch.Size([26, 4])

DEBUG:root:					// bbox.ndimension(): 2
DEBUG:root:					// bbox.size(-1): 4

DEBUG:root:					self.bbox = bbox
DEBUG:root:					self.size = image_size  # (image_width, image_height)
DEBUG:root:					self.mode = mode
DEBUG:root:					self.extra_fields = {}
DEBUG:root:				} // END BoxList.__init__(self, bbox, image_size, mode='xyxy')
DEBUG:root:				BoxList.__init__(self, bbox, image_size, mode='xyxy') { //BEGIN
DEBUG:root:					// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/structures/bounding_box.py

DEBUG:root:					// Params:
DEBUG:root:						// type(bbox):<class 'torch.Tensor'>
DEBUG:root:						// bbox.shape:torch.Size([26, 4])
DEBUG:root:						// image_size: (512, 438)

DEBUG:root:					// isinstance(bbox, torch.Tensor): True
DEBUG:root:					device = bbox.device if isinstance(bbox, torch.Tensor) else torch.device("cpu")
DEBUG:root:					// device: cpu

DEBUG:root:					bbox = torch.as_tensor(bbox, dtype=torch.float32, device=device)
DEBUG:root:					// bbox.shape: torch.Size([26, 4])

DEBUG:root:					// bbox.ndimension(): 2
DEBUG:root:					// bbox.size(-1): 4

DEBUG:root:					self.bbox = bbox
DEBUG:root:					self.size = image_size  # (image_width, image_height)
DEBUG:root:					self.mode = mode
DEBUG:root:					self.extra_fields = {}
DEBUG:root:				} // END BoxList.__init__(self, bbox, image_size, mode='xyxy')
QXcbConnection: XCB error: 145 (Unknown), sequence: 171, resource id: 0, major code: 140 (Unknown), minor code: 20
DEBUG:matplotlib.font_manager:findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXGeneral' (STIXGeneralBolIta.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'cmss10' (cmss10.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'cmb10' (cmb10.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'cmmi10' (cmmi10.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Oblique.ttf) oblique normal 400 normal>) = 1.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'cmtt10' (cmtt10.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'cmsy10' (cmsy10.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXNonUnicode' (STIXNonUni.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Serif' (DejaVuSerif.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXSizeFourSym' (STIXSizFourSymBol.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXNonUnicode' (STIXNonUniIta.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans' (DejaVuSans.ttf) normal normal 400 normal>) = 0.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXSizeOneSym' (STIXSizOneSymBol.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXGeneral' (STIXGeneralItalic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-Italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXNonUnicode' (STIXNonUniBolIta.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans Display' (DejaVuSansDisplay.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXGeneral' (STIXGeneralBol.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-Oblique.ttf) oblique normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Bold.ttf) normal normal 700 normal>) = 0.33499999999999996
DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXGeneral' (STIXGeneral.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXSizeTwoSym' (STIXSizTwoSymBol.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXSizeThreeSym' (STIXSizThreeSymReg.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXNonUnicode' (STIXNonUniBol.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXSizeFiveSym' (STIXSizFiveSymReg.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Serif Display' (DejaVuSerifDisplay.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXSizeFourSym' (STIXSizFourSymReg.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXSizeOneSym' (STIXSizOneSymReg.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans' (DejaVuSans-BoldOblique.ttf) oblique normal 700 normal>) = 1.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXSizeThreeSym' (STIXSizThreeSymBol.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'cmr10' (cmr10.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-BoldItalic.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-BoldOblique.ttf) oblique normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'cmex10' (cmex10.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXSizeTwoSym' (STIXSizTwoSymReg.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Tai Viet' (NotoSansTaiViet-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'OpenSymbol' (opens___.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Ubuntu' (Ubuntu-R.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Telugu' (NotoSerifTelugu-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'KacstBook' (KacstBook.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans' (DejaVuSans-BoldOblique.ttf) oblique normal 700 normal>) = 1.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Uroob' (Uroob.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Cuneiform' (NotoSansCuneiform-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Serif' (DejaVuSerif.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Serif' (LiberationSerif-Italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Lao UI' (NotoSansLaoUI-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Georgian' (NotoSansGeorgian-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Sarai' (Sarai.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_Vector-Bold' (MathJax_Vector-Bold.otf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Carian' (NotoSansCarian-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Ethiopic' (NotoSansEthiopic-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Avestan' (NotoSansAvestan-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Garuda' (Garuda-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Droid Sans Fallback' (DroidSansFallbackFull.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans CJK JP' (NotoSansCJK-Light.ttc) normal normal 300 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Waree' (Waree-Oblique.ttf) oblique normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Lao UI' (NotoSansLaoUI-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'OpenDyslexicMono' (OpenDyslexicMono-Regular.otf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Old Italic' (NotoSansOldItalic-Regular.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Saab' (Saab.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Devanagari UI' (NotoSansDevanagariUI-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_SansSerif' (MathJax_SansSerif-Italic.otf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans' (DejaVuSansCondensed-BoldOblique.ttf) oblique normal 700 condensed>) = 1.535
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Lohit Odia' (Lohit-Odia.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Ubuntu Mono' (UbuntuMono-R.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Sawasdee' (Sawasdee-Oblique.ttf) oblique normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'KacstLetter' (KacstLetter.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Sans' (LiberationSans-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Norasi' (Norasi-Oblique.ttf) oblique normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Tibetan' (NotoSansTibetan-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Egyptian Hieroglyphs' (NotoSansEgyptianHieroglyphs-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_Caligraphic' (MathJax_Caligraphic-Regular.otf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Kannada' (NotoSerifKannada-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'padmaa' (padmaa.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Limbu' (NotoSansLimbu-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Gurmukhi' (NotoSansGurmukhi-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Malayalam' (NotoSansMalayalam-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tlwg Mono' (TlwgMono-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'LKLUG' (lklug.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias PCfont Z' (tiresias_pcfontz.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Tibetan' (NotoSansTibetan-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'FreeMono' (FreeMonoOblique.ttf) oblique normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Laksaman' (Laksaman-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Kannada' (NotoSansKannada-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Myanmar UI' (NotoSansMyanmarUI-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Gujarati' (NotoSansGujarati-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Hebrew' (NotoSansHebrew-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Samyak Gujarati' (Samyak-Gujarati.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'FreeSerif' (FreeSerif.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Laksaman' (Laksaman.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Gujarati' (NotoSansGujarati-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Rachana' (Rachana-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Samyak Malayalam' (Samyak-Malayalam.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Imperial Aramaic' (NotoSansImperialAramaic-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Gurmukhi' (NotoSansGurmukhi-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Buhid' (NotoSansBuhid-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_Size4' (MathJax_Size4-Regular.otf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Garuda' (Garuda.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Syriac Western' (NotoSansSyriacWestern-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif' (NotoSerif-Italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Lohit Tamil' (Lohit-Tamil.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Laksaman' (Laksaman-BoldItalic.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Old South Arabian' (NotoSansOldSouthArabian-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Samaritan' (NotoSansSamaritan-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'FreeSans' (FreeSansBoldOblique.ttf) oblique normal 600 normal>) = 11.24
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Coptic' (NotoSansCoptic-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Osage' (NotoSansOsage-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'RaghuMalayalam' (RaghuMalayalamSans-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Bengali UI' (NotoSansBengaliUI-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'KacstTitle' (KacstTitle.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'padmaa' (padmaa-Medium-0.5.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'KacstArt' (KacstArt.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'OpenDyslexic' (OpenDyslexic-Bold.otf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'OpenDyslexic' (OpenDyslexic-BoldItalic.otf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Khmer' (NotoSerifKhmer-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_WinChrome' (MathJax_WinChrome-Regular.otf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Display' (NotoSansDisplay-BoldItalic.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'FreeMono' (FreeMonoBoldOblique.ttf) oblique normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Pagul' (Pagul.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Khmer' (NotoSansKhmer-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'OpenDyslexicAlta' (OpenDyslexicAlta-Regular.otf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Georgian' (NotoSansGeorgian-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Deseret' (NotoSansDeseret-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Khmer OS' (KhmerOS.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Arabic UI' (NotoSansArabicUI-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Symbols' (NotoSansSymbols-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Likhan' (LikhanNormal.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Sans Narrow' (LiberationSansNarrow-BoldItalic.ttf) italic normal 700 condensed>) = 11.535
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Keraleeyam' (Keraleeyam.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Sawasdee' (Sawasdee-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans CJK JP' (NotoSansCJK-Black.ttc) normal normal 900 normal>) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Sans' (LiberationSans-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Lohit Kannada' (Lohit-Kannada.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Tagbanwa' (NotoSansTagbanwa-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Mono' (LiberationMono-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Tamil' (NotoSerifTamil-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_Script' (MathJax_Script-Regular.otf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Mono' (LiberationMono-BoldItalic.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Display' (NotoSansDisplay-Italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif CJK JP' (NotoSerifCJK-Black.ttc) normal normal 900 normal>) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tlwg Typo' (TlwgTypo-BoldOblique.ttf) oblique normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Padauk' (Padauk-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Runic' (NotoSansRunic-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Kufi Arabic' (NotoKufiArabic-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_Caligraphic' (MathJax_Caligraphic-Bold.otf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'KacstOne' (KacstOne.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Navilu' (Navilu.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tlwg Typewriter' (TlwgTypewriter-BoldOblique.ttf) oblique normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Kalimati' (kalimati.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Linear B' (NotoSansLinearB-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Telugu' (NotoSerifTelugu-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Bengali' (NotoSerifBengali-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Bengali UI' (NotoSansBengaliUI-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Meera' (Meera.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Armenian' (NotoSerifArmenian-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'KacstOffice' (KacstOffice.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Malayalam' (NotoSerifMalayalam-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Mono' (LiberationMono-Italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Serif' (DejaVuSerifCondensed-Italic.ttf) italic normal 400 condensed>) = 11.25
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias Keyfont V2' (tirekv__.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_Fraktur' (MathJax_Fraktur-Regular.otf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Manjari' (Manjari-Regular.otf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Mukti Narrow' (MuktiNarrowBold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Tai Tham' (NotoSansTaiTham-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Display' (NotoSansDisplay-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Naskh Arabic UI' (NotoNaskhArabicUI-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-Italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Oriya UI' (NotoSansOriyaUI-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans' (NotoSans-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'KacstScreen' (KacstScreen.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif' (NotoSerif-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Gubbi' (Gubbi.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Laksaman' (Laksaman-Italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_Math' (MathJax_Math-BoldItalic.otf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'AnjaliOldLipi' (AnjaliOldLipi.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Display' (NotoSerifDisplay-Italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'ori1Uni' (utkal.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Myanmar UI' (NotoSansMyanmarUI-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Syloti Nagri' (NotoSansSylotiNagri-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Umpush' (Umpush-Light.ttf) normal normal 300 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Cherokee' (NotoSansCherokee-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Gargi' (Gargi.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Mono' (LiberationMono-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Inscriptional Parthian' (NotoSansInscriptionalParthian-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias Infofont' (tiresias_infofont_italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-BoldItalic.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Lohit Bengali' (Lohit-Bengali.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif CJK JP' (NotoSerifCJK-Bold.ttc) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'padmaa-Bold.1.1' (padmaa-Bold.1.1.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Norasi' (Norasi-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias Signfont' (tiresias_signfont_italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Kannada' (NotoSansKannada-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Javanese' (NotoSansJavanese-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Symbola' (Symbola_hint.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Gurmukhi UI' (NotoSansGurmukhiUI-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tlwg Typo' (TlwgTypo-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Rachana' (Rachana-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Adlam' (NotoSansAdlam-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Myanmar' (NotoSerifMyanmar-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Canadian Aboriginal' (NotoSansCanadianAboriginal-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'KacstNaskh' (KacstNaskh.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_SansSerif' (MathJax_SansSerif-Regular.otf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Gujarati' (NotoSerifGujarati-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Serif' (DejaVuSerifCondensed-Bold.ttf) normal normal 700 condensed>) = 10.535
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Ubuntu' (Ubuntu-LI.ttf) italic normal 300 normal>) = 11.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Lao' (NotoSerifLao-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Mandaic' (NotoSansMandaic-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Devanagari' (NotoSerifDevanagari-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Rekha' (Rekha.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_Size2' (MathJax_Size2-Regular.otf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Saurashtra' (NotoSansSaurashtra-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tlwg Typist' (TlwgTypist.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Kinnari' (Kinnari-BoldItalic.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Devanagari' (NotoSansDevanagari-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Display' (NotoSerifDisplay-BoldItalic.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Phags Pa' (NotoSansPhagsPa-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Syriac Estrangela' (NotoSansSyriacEstrangela-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Mongolian' (NotoSansMongolian-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Symbols' (NotoSansSymbols-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Sinhala UI' (NotoSansSinhalaUI-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Display' (NotoSerifDisplay-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Suruma' (Suruma.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Waree' (Waree.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Ethiopic' (NotoSansEthiopic-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Khmer' (NotoSansKhmer-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Lycian' (NotoSansLycian-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_Main' (MathJax_Main-Italic.otf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Bengali' (NotoSerifBengali-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Sinhala' (NotoSerifSinhala-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'KacstDigital' (KacstDigital.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Serif' (LiberationSerif-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Devanagari' (NotoSerifDevanagari-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Kannada' (NotoSerifKannada-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tlwg Typist' (TlwgTypist-Oblique.ttf) oblique normal 500 normal>) = 11.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Purisa' (Purisa.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Lohit Gurmukhi' (Lohit-Gurmukhi.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias LPfont' (tiresias_lpfont_bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Khmer UI' (NotoSansKhmerUI-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Kinnari' (Kinnari-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Kinnari' (Kinnari-BoldOblique.ttf) oblique normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_Main' (MathJax_Main-Regular.otf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Lohit Malayalam' (Lohit-Malayalam.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'FreeMono' (FreeMono.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans' (DejaVuSans-ExtraLight.ttf) normal normal 200 normal>) = 0.24
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Ubuntu' (Ubuntu-B.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Gurmukhi UI' (NotoSansGurmukhiUI-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Pothana2000' (Pothana2000.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Norasi' (Norasi-BoldItalic.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Mono' (NotoSansMono-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_Typewriter' (MathJax_Typewriter-Regular.otf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Bold.ttf) normal normal 700 normal>) = 0.33499999999999996
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Display' (NotoSansDisplay-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'KacstTitleL' (KacstTitleL.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Sans' (LiberationSans-Italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Purisa' (Purisa-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Brahmi' (NotoSansBrahmi-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Norasi' (Norasi-BoldOblique.ttf) oblique normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Tamil UI' (NotoSansTamilUI-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif CJK JP' (NotoSerifCJK-Light.ttc) normal normal 300 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Ubuntu' (Ubuntu-RI.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Ethiopic' (NotoSerifEthiopic-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Lohit Gujarati' (Lohit-Gujarati.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Hebrew' (NotoSerifHebrew-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-Oblique.ttf) oblique normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_Size1' (MathJax_Size1-Regular.otf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Cham' (NotoSansCham-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Cypriot' (NotoSansCypriot-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_SansSerif' (MathJax_SansSerif-Bold.otf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Symbols2' (NotoSansSymbols2-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias Infofont Z' (tiresias_infofontz.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'FreeSans' (FreeSansOblique.ttf) oblique normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Thai' (NotoSerifThai-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Ol Chiki' (NotoSansOlChiki-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Sans' (LiberationSans-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Kharoshthi' (NotoSansKharoshthi-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Thai' (NotoSerifThai-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif CJK JP' (NotoSerifCJK-Medium.ttc) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Gothic' (NotoSansGothic-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias Signfont Z' (tiresias_signfontz_bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_Math' (MathJax_Math-Italic.otf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'FreeSans' (FreeSansBold.ttf) normal normal 600 normal>) = 10.24
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Khmer' (NotoSerifKhmer-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tlwg Typo' (TlwgTypo-Oblique.ttf) oblique normal 500 normal>) = 11.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias Infofont Z' (tiresias_infofontz_bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Ubuntu' (Ubuntu-Th.ttf) normal normal 250 normal>) = 10.1925
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Umpush' (Umpush-BoldOblique.ttf) oblique normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tlwg Typewriter' (TlwgTypewriter.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Ubuntu Mono' (UbuntuMono-BI.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'KacstPen' (KacstPen.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans CJK JP' (NotoSansCJK-Regular.ttc) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tlwg Typewriter' (TlwgTypewriter-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias Signfont Z' (tiresias_signfontz.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Loma' (Loma-BoldOblique.ttf) oblique normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Sans Narrow' (LiberationSansNarrow-Regular.ttf) normal normal 400 condensed>) = 10.25
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans' (NotoSans-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Tamil UI' (NotoSansTamilUI-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Gujarati UI' (NotoSansGujaratiUI-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'OpenDyslexic' (OpenDyslexic-Regular.otf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'KacstPoster' (KacstPoster.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Sans' (LiberationSans-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Vemana2000' (vemana2000.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Mono' (LiberationMono-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Sans' (LiberationSans-BoldItalic.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Jamrul' (JamrulNormal.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Mono' (LiberationMono-BoldItalic.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Purisa' (Purisa-Oblique.ttf) oblique normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Naskh Arabic' (NotoNaskhArabic-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Batak' (NotoSansBatak-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Old Turkic' (NotoSansOldTurkic-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Sinhala' (NotoSansSinhala-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Ubuntu' (Ubuntu-BI.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Anatolian Hieroglyphs' (NotoSansAnatolianHieroglyphs-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Tamil' (NotoSerifTamil-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Cherokee' (NotoSansCherokee-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans CJK JP' (NotoSansCJK-Thin.ttc) normal normal 100 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_AMS' (MathJax_AMS-Regular.otf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Kufi Arabic' (NotoKufiArabic-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Math TeX Gyre' (DejaVuMathTeXGyre.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans NKo' (NotoSansNKo-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Tai Le' (NotoSansTaiLe-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Sawasdee' (Sawasdee-BoldOblique.ttf) oblique normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Phoenician' (NotoSansPhoenician-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Padauk Book' (PadaukBook-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Ubuntu' (Ubuntu-MI.ttf) italic normal 500 normal>) = 11.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias PCfont Z' (tiresias_pcfontz_italic.ttf) italic normal 28926 normal>) = 38.149699999999996
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans' (DejaVuSansCondensed-Bold.ttf) normal normal 700 condensed>) = 0.5349999999999999
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Thai' (NotoSansThai-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Georgian' (NotoSerifGeorgian-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Oriya' (NotoSansOriya-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Serif' (DejaVuSerifCondensed.ttf) normal normal 400 condensed>) = 10.25
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_Vector' (MathJax_Vector-Regular.otf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif CJK JP' (NotoSerifCJK-Regular.ttc) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Lao' (NotoSansLao-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans CJK JP' (NotoSansCJK-Bold.ttc) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Thai UI' (NotoSansThaiUI-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Malayalam UI' (NotoSansMalayalamUI-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans New Tai Lue' (NotoSansNewTaiLue-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Kaithi' (NotoSansKaithi-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias Infofont' (tiresias_infofont.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Lohit Telugu' (Lohit-Telugu.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Sundanese' (NotoSansSundanese-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Kinnari' (Kinnari-Oblique.ttf) oblique normal 500 normal>) = 11.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Naskh Arabic UI' (NotoNaskhArabicUI-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Sinhala' (NotoSansSinhala-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Tamil' (NotoSansTamil-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Lohit Tamil Classical' (Lohit-Tamil-Classical.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Umpush' (Umpush-Oblique.ttf) oblique normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Ubuntu Mono' (UbuntuMono-B.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Oblique.ttf) oblique normal 400 normal>) = 1.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Norasi' (Norasi.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Armenian' (NotoSansArmenian-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans' (DejaVuSans.ttf) normal normal 400 normal>) = 0.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tlwg Typist' (TlwgTypist-BoldOblique.ttf) oblique normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Myanmar' (NotoSerifMyanmar-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Mono' (NotoSansMono-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Kalapi' (Kalapi.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Yi' (NotoSansYi-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Mono' (NotoMono-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Ubuntu' (Ubuntu-L.ttf) normal normal 300 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Shavian' (NotoSansShavian-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Vai' (NotoSansVai-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Mono' (LiberationMono-Italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Hanunoo' (NotoSansHanunoo-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Manjari' (Manjari-Bold.otf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Armenian' (NotoSerifArmenian-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'FreeSerif' (FreeSerifBold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Serif' (LiberationSerif-Italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'OpenDyslexicAlta' (OpenDyslexicAlta-BoldItalic.otf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Loma' (Loma-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Sinhala' (NotoSerifSinhala-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Mukti Narrow' (MuktiNarrow.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Kannada UI' (NotoSansKannadaUI-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'KacstFarsi' (KacstFarsi.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Sans Narrow' (LiberationSansNarrow-Bold.ttf) normal normal 700 condensed>) = 10.535
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Ani' (ani.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Lydian' (NotoSansLydian-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias Signfont' (tiresias_signfont_bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Tifinagh' (NotoSansTifinagh-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tlwg Typewriter' (TlwgTypewriter-Oblique.ttf) oblique normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'FreeSans' (FreeSans.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Thai UI' (NotoSansThaiUI-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Gujarati' (NotoSerifGujarati-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Serif' (LiberationSerif-BoldItalic.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Bengali' (NotoSansBengali-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Dyuthi' (Dyuthi.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Myanmar' (NotoSansMyanmar-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tlwg Typo' (TlwgTypo.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Lao' (NotoSerifLao-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif' (NotoSerif-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Norasi' (Norasi-Italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Myanmar' (NotoSansMyanmar-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_WinIE6' (MathJax_WinIE6-Regular.otf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Arabic UI' (NotoSansArabicUI-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Syriac Eastern' (NotoSansSyriacEastern-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'FreeSerif' (FreeSerifBoldItalic.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Waree' (Waree-BoldOblique.ttf) oblique normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'KacstQurn' (KacstQurn.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias Infofont Z' (tiresias_infofontz_italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Umpush' (Umpush-LightOblique.ttf) oblique normal 300 normal>) = 11.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Waree' (Waree-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_Size3' (MathJax_Size3-Regular.otf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Ethiopic' (NotoSerifEthiopic-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Arabic' (NotoSansArabic-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Malayalam UI' (NotoSansMalayalamUI-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Tamil' (NotoSansTamil-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Malayalam' (NotoSerifMalayalam-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Thaana' (NotoSansThaana-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'KacstDecorative' (KacstDecorative.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Serif' (LiberationSerif-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Telugu' (NotoSansTelugu-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Lepcha' (NotoSansLepcha-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'aakar' (aakar-medium.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Georgian' (NotoSerifGeorgian-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Padauk Book' (PadaukBook-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Kinnari' (Kinnari.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'mry_KacstQurn' (mry_KacstQurn.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Sans' (LiberationSans-BoldItalic.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias PCfont' (tiresias_pcfont_italic.ttf) italic normal 28926 normal>) = 38.149699999999996
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Samyak Devanagari' (Samyak-Devanagari.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Thai' (NotoSansThai-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'FreeSerif' (FreeSerifItalic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Serif' (LiberationSerif-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Inscriptional Pahlavi' (NotoSansInscriptionalPahlavi-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Garuda' (Garuda-Oblique.ttf) oblique normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Cham' (NotoSansCham-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tlwg Mono' (TlwgMono.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Lisu' (NotoSansLisu-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Samyak Tamil' (Samyak-Tamil.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Gujarati UI' (NotoSansGujaratiUI-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'KacstOne' (KacstOne-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Lohit Assamese' (Lohit-Assamese.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Devanagari' (NotoSansDevanagari-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans CJK JP' (NotoSansCJK-Medium.ttc) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias PCfont Z' (tiresias_pcfontz_bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Naskh Arabic' (NotoNaskhArabic-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Chilanka' (Chilanka-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias PCfont' (tiresias_pcfont.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tlwg Typist' (TlwgTypist-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Tagalog' (NotoSansTagalog-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Padauk' (Padauk-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Phetsarath OT' (Phetsarath_OT.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_Fraktur' (MathJax_Fraktur-Bold.otf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'OpenDyslexicAlta' (OpenDyslexicAlta-Bold.otf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans' (DejaVuSansCondensed-Oblique.ttf) oblique normal 400 condensed>) = 1.25
DEBUG:matplotlib.font_manager:findfont: score(<Font 'FreeMono' (FreeMonoBold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Lohit Devanagari' (Lohit-Devanagari.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Manjari' (Manjari-Thin.otf) normal normal 100 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Mono' (LiberationMono-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Kannada UI' (NotoSansKannadaUI-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Malayalam' (NotoSansMalayalam-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif' (NotoSerif-BoldItalic.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Buginese' (NotoSansBuginese-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Chandas' (chandas1-2.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Sahadeva' (sahadeva.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tlwg Mono' (TlwgMono-Oblique.ttf) oblique normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Balinese' (NotoSansBalinese-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Loma' (Loma-Oblique.ttf) oblique normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias Signfont Z' (tiresias_signfontz_italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Samanata' (samanata.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_Math' (MathJax_Math-Regular.otf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Chakma' (NotoSansChakma-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Old Persian' (NotoSansOldPersian-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Ogham' (NotoSansOgham-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Meetei Mayek' (NotoSansMeeteiMayek-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans CJK JP' (NotoSansCJK-DemiLight.ttc) normal normal 350 normal>) = 10.0975
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Ubuntu' (Ubuntu-M.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Sans Narrow' (LiberationSansNarrow-Italic.ttf) italic normal 400 condensed>) = 11.25
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias Infofont' (tiresias_infofont_bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Devanagari UI' (NotoSansDevanagariUI-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Ubuntu Mono' (UbuntuMono-RI.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Nakula' (nakula.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Ubuntu Condensed' (Ubuntu-C.ttf) normal normal 400 condensed>) = 10.25
DEBUG:matplotlib.font_manager:findfont: score(<Font 'OpenDyslexic' (OpenDyslexic-Italic.otf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Osmanya' (NotoSansOsmanya-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Bamum' (NotoSansBamum-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Sinhala UI' (NotoSansSinhalaUI-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Sawasdee' (Sawasdee.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-BoldOblique.ttf) oblique normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Loma' (Loma.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Oriya' (NotoSansOriya-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Lao' (NotoSansLao-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Umpush' (Umpush-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Purisa' (Purisa-BoldOblique.ttf) oblique normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Garuda' (Garuda-BoldOblique.ttf) oblique normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Armenian' (NotoSansArmenian-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Serif' (DejaVuSerifCondensed-BoldItalic.ttf) italic normal 700 condensed>) = 11.535
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Telugu' (NotoSansTelugu-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Thaana' (NotoSansThaana-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Kayah Li' (NotoSansKayahLi-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif CJK JP' (NotoSerifCJK-SemiBold.ttc) normal normal 600 normal>) = 10.24
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias LPfont' (tiresias_lpfont_italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Nastaliq Urdu' (NotoNastaliqUrdu-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Serif' (LiberationSerif-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Sans' (LiberationSans-Italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Rejang' (NotoSansRejang-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Oriya UI' (NotoSansOriyaUI-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Khmer OS System' (KhmerOSsys.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans' (DejaVuSansCondensed.ttf) normal normal 400 condensed>) = 0.25
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Telugu UI' (NotoSansTeluguUI-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Arabic' (NotoSansArabic-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias LPfont' (tiresias_lpfont.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Display' (NotoSerifDisplay-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans' (NotoSans-Italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Telugu UI' (NotoSansTeluguUI-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tlwg Mono' (TlwgMono-BoldOblique.ttf) oblique normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans' (NotoSans-BoldItalic.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Ugaritic' (NotoSansUgaritic-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Glagolitic' (NotoSansGlagolitic-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_Main' (MathJax_Main-Bold.otf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Karumbi' (Karumbi.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif CJK JP' (NotoSerifCJK-ExtraLight.ttc) normal normal 200 normal>) = 10.24
DEBUG:matplotlib.font_manager:findfont: score(<Font 'OpenDyslexicAlta' (OpenDyslexicAlta-Italic.otf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Bengali' (NotoSansBengali-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias Signfont' (tiresias_signfont.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Hebrew' (NotoSansHebrew-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Abyssinica SIL' (AbyssinicaSIL-R.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Khmer UI' (NotoSansKhmerUI-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias PCfont' (tiresias_pcfont_bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Serif' (LiberationSerif-BoldItalic.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Mitra Mono' (mitra.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Hebrew' (NotoSerifHebrew-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Kinnari' (Kinnari-Italic.ttf) italic normal 500 normal>) = 11.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Adlam Unjoined' (NotoSansAdlamUnjoined-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'D2Coding' (D2Coding-Ver1.3.2-20180524.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Umpush' (Umpush.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tibetan Machine Uni' (TibetanMachineUni.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/home/kimkk/miniconda3/envs/lomin/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
