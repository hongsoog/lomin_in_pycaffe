GeneralizedRCNN.__init(self, cfg) ====================== BEGIN
	super(GeneralizedRCNN, self).__init__()

	==== backbone build ====
	build_backbone: <function build_backbone at 0x7f338cb6e950>
	self.backbone = build_backbone(cfg)
build_backbone(cfg) ====== BEGIN
	registry.BACKBONES: {'TIMM-MOBILENETV2-100': <function build_timm_backbone at 0x7f338ce25730>, 'R-101-FPN-RETINANET': <function build_resnet_fpn_p3p7_backbone at 0x7f338cb6ed08>, 'R-50-FPN-RETINANET': <function build_resnet_fpn_p3p7_backbone at 0x7f338cb6ed08>}
	cfg.MODEL.BACKBONE.CONV_BODY: R-50-FPN-RETINANET
	cfg: DATALOADER:
  SIZE_DIVISIBILITY: 32
INPUT:
  FIXED_SIZE: (-1, -1)
  MAX_SIZE_TEST: 640
  MIN_SIZE_TEST: 480
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  RESIZE_MODE: keep_ratio
  TARGET_INTERPOLATION: bilinear
  TO_BGR255: True
  TO_N1P1: False
MODEL:
  BACKBONE:
    CONV_BODY: R-50-FPN-RETINANET
    FREEZE_CONV_BODY_AT: 2
  DEVICE: cuda
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RECOGNITION: False
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 2
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: -1
    USE_C5: True
  RETINANET_ON: True
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 2000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: True
  TEXT_RECOGNIZER:
    BATCH_MAX_LENGTH: 25
    CHARACTER: ('num', 'eng_cap', 'eng_low', 'kor_2350')
    CNN_CHANNELS: 512
    CNN_NUM_POOLING: 4
    OUTCONV_KS: (1, 1)
    TRANSFORMER_DECODER_MODULE_NO: -1
    TRANSFORMER_ENCODER_MODULE_NO: -1
    TRANSFORMER_FSIZE: 512
    TRANSFORMER_MODULE_NO: 6
    TRANSFORMER_NO_RECURRENT_PATH: False
    USE_PROJECTION: False
  TIMM:
    BACKBONE_OUT_CHANNELS: 256
    OUT_INDICES: (2, 3, 4)
    USE_PRETRAINED: True
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 8
  NMS_THRESH: 0.5
  SCORE_THRESHOLD: 0.3
build_resnet_fpn_p3p7_backbone(cfg) ====== BEGIN

=========================================== Resnet.__init__ BEGIN
	_STEM_MODULES: {'StemWithFixedBatchNorm': <class 'maskrcnn_benchmark.modeling.backbone.resnet.StemWithFixedBatchNorm'>}
	_cfg.MODEL.RESNETS.STEM_FUNC: StemWithFixedBatchNorm
	stem_module = _STEM_MODULES[cfg.MODEL.RESNETS.STEM_FUNC]
	stem_module: <class 'maskrcnn_benchmark.modeling.backbone.resnet.StemWithFixedBatchNorm'>
	_STAGE_SPECS: {'R-50-C4': (StageSpec(index=1, block_count=3, return_features=False), StageSpec(index=2, block_count=4, return_features=False), StageSpec(index=3, block_count=6, return_features=True)), 'R-50-C5': (StageSpec(index=1, block_count=3, return_features=False), StageSpec(index=2, block_count=4, return_features=False), StageSpec(index=3, block_count=6, return_features=False), StageSpec(index=4, block_count=3, return_features=True)), 'R-101-C4': (StageSpec(index=1, block_count=3, return_features=False), StageSpec(index=2, block_count=4, return_features=False), StageSpec(index=3, block_count=23, return_features=True)), 'R-101-C5': (StageSpec(index=1, block_count=3, return_features=False), StageSpec(index=2, block_count=4, return_features=False), StageSpec(index=3, block_count=23, return_features=False), StageSpec(index=4, block_count=3, return_features=True)), 'R-50-FPN': (StageSpec(index=1, block_count=3, return_features=True), StageSpec(index=2, block_count=4, return_features=True), StageSpec(index=3, block_count=6, return_features=True), StageSpec(index=4, block_count=3, return_features=True)), 'R-50-FPN-RETINANET': (StageSpec(index=1, block_count=3, return_features=True), StageSpec(index=2, block_count=4, return_features=True), StageSpec(index=3, block_count=6, return_features=True), StageSpec(index=4, block_count=3, return_features=True)), 'R-101-FPN': (StageSpec(index=1, block_count=3, return_features=True), StageSpec(index=2, block_count=4, return_features=True), StageSpec(index=3, block_count=23, return_features=True), StageSpec(index=4, block_count=3, return_features=True)), 'R-101-FPN-RETINANET': (StageSpec(index=1, block_count=3, return_features=True), StageSpec(index=2, block_count=4, return_features=True), StageSpec(index=3, block_count=23, return_features=True), StageSpec(index=4, block_count=3, return_features=True)), 'R-152-FPN': (StageSpec(index=1, block_count=3, return_features=True), StageSpec(index=2, block_count=8, return_features=True), StageSpec(index=3, block_count=36, return_features=True), StageSpec(index=4, block_count=3, return_features=True))}
	cfg.MODEL.BACKBONE.CONV_BODY: R-50-FPN-RETINANET
	stage_specs = _STAGE_SPECS[cfg.MODEL.BACKBONE.CONV_BODY]
	stage_specs: (StageSpec(index=1, block_count=3, return_features=True), StageSpec(index=2, block_count=4, return_features=True), StageSpec(index=3, block_count=6, return_features=True), StageSpec(index=4, block_count=3, return_features=True))
	_TRANSFORMATION_MODULES: {'BottleneckWithFixedBatchNorm': <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>}
	cfg.MODEL.RESNETS.TRANS_FUNC: BottleneckWithFixedBatchNorm
	transformation_module = _TRANSFORMATION_MODULES[cfg.MODEL.RESNETS.TRANS_FUNC]
	transformation_module: <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>
	self.stem = stem_module(cfg)
	self.stem: StemWithFixedBatchNorm(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): FrozenBatchNorm2d()
)
	num_groups = cfg.MODEL.RESNETS.NUM_GROUPS
	num_groups.stem: 1
	width_per_group = cfg.MODEL.RESNETS.WIDTH_PER_GROUP
	width_per_group: 64
	in_channels = cfg.MODEL.RESNETS.STEM_OUT_CHANNELS
	in_channels: 64
	stage2_bottleneck_channels = num_groups * width_per_group
	stage2_bottleneck_channels: 64
	stage2_out_channels = cfg.MODEL.RESNETS.RES2_OUT_CHANNELS
	stage2_out_channels: 256
	self.stages = []
	self.return_features = {}
	for stage_spec in stage_specs:
		stage_spec: StageSpec(index=1, block_count=3, return_features=True)
		stage_spec.index: 1
		name = "layer" + str(stage_spec.index)
		name: layer1
		stage2_relative_factor = 2 ** (stage_spec.index - 1)
		stage2_relative_factor: 1
		bottleneck_channels = stage2_bottleneck_channels * stage2_relative_factor
		bottlenec_channels: 64
		out_channels = stage2_out_channels * stage2_relative_factor
		out_channels: 256
		stage_with_dcn = cfg.MODEL.RESNETS.STAGE_WITH_DCN[stage_spec.index - 1]
		stage_wid_dcn: False
		module = _make_stage(
			transformation_module = <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>,
			in_channels = 64,
			bottleneck_channels = 64,
			out_channels = 256,
			stage_spec.block_count = 3,
			num_groups = 1,
			cfg.MODEL.RESNETS.STRIDE_IN_1X1 : True,
			first_stride=int(stage_spec.index > 1) + 1: 1,
			dcn_config={
				'stage_with_dcn': False,
				'with_modulated_dcn': False,
				'deformable_groups': 1,
				}
			)
		in_channels = out_channels
		in_channels: 256
		self.add_module(name=layer1, module=Sequential(
  (0): BottleneckWithFixedBatchNorm(
    (downsample): Sequential(
      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): FrozenBatchNorm2d()
    )
    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): FrozenBatchNorm2d()
    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): FrozenBatchNorm2d()
    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): FrozenBatchNorm2d()
  )
  (1): BottleneckWithFixedBatchNorm(
    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): FrozenBatchNorm2d()
    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): FrozenBatchNorm2d()
    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): FrozenBatchNorm2d()
  )
  (2): BottleneckWithFixedBatchNorm(
    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): FrozenBatchNorm2d()
    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): FrozenBatchNorm2d()
    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): FrozenBatchNorm2d()
  )
))
		self.stages.append(name=layer1)
		name: layer1
		stage_spec.return_features: True
		self.return_features[name] = stage_spec.return_features
		stage_spec: StageSpec(index=2, block_count=4, return_features=True)
		stage_spec.index: 2
		name = "layer" + str(stage_spec.index)
		name: layer2
		stage2_relative_factor = 2 ** (stage_spec.index - 1)
		stage2_relative_factor: 2
		bottleneck_channels = stage2_bottleneck_channels * stage2_relative_factor
		bottlenec_channels: 128
		out_channels = stage2_out_channels * stage2_relative_factor
		out_channels: 512
		stage_with_dcn = cfg.MODEL.RESNETS.STAGE_WITH_DCN[stage_spec.index - 1]
		stage_wid_dcn: False
		module = _make_stage(
			transformation_module = <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>,
			in_channels = 256,
			bottleneck_channels = 128,
			out_channels = 512,
			stage_spec.block_count = 4,
			num_groups = 1,
			cfg.MODEL.RESNETS.STRIDE_IN_1X1 : True,
			first_stride=int(stage_spec.index > 1) + 1: 2,
			dcn_config={
				'stage_with_dcn': False,
				'with_modulated_dcn': False,
				'deformable_groups': 1,
				}
			)
		in_channels = out_channels
		in_channels: 512
		self.add_module(name=layer2, module=Sequential(
  (0): BottleneckWithFixedBatchNorm(
    (downsample): Sequential(
      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): FrozenBatchNorm2d()
    )
    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (bn1): FrozenBatchNorm2d()
    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): FrozenBatchNorm2d()
    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): FrozenBatchNorm2d()
  )
  (1): BottleneckWithFixedBatchNorm(
    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): FrozenBatchNorm2d()
    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): FrozenBatchNorm2d()
    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): FrozenBatchNorm2d()
  )
  (2): BottleneckWithFixedBatchNorm(
    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): FrozenBatchNorm2d()
    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): FrozenBatchNorm2d()
    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): FrozenBatchNorm2d()
  )
  (3): BottleneckWithFixedBatchNorm(
    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): FrozenBatchNorm2d()
    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): FrozenBatchNorm2d()
    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): FrozenBatchNorm2d()
  )
))
		self.stages.append(name=layer2)
		name: layer2
		stage_spec.return_features: True
		self.return_features[name] = stage_spec.return_features
		stage_spec: StageSpec(index=3, block_count=6, return_features=True)
		stage_spec.index: 3
		name = "layer" + str(stage_spec.index)
		name: layer3
		stage2_relative_factor = 2 ** (stage_spec.index - 1)
		stage2_relative_factor: 4
		bottleneck_channels = stage2_bottleneck_channels * stage2_relative_factor
		bottlenec_channels: 256
		out_channels = stage2_out_channels * stage2_relative_factor
		out_channels: 1024
		stage_with_dcn = cfg.MODEL.RESNETS.STAGE_WITH_DCN[stage_spec.index - 1]
		stage_wid_dcn: False
		module = _make_stage(
			transformation_module = <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>,
			in_channels = 512,
			bottleneck_channels = 256,
			out_channels = 1024,
			stage_spec.block_count = 6,
			num_groups = 1,
			cfg.MODEL.RESNETS.STRIDE_IN_1X1 : True,
			first_stride=int(stage_spec.index > 1) + 1: 2,
			dcn_config={
				'stage_with_dcn': False,
				'with_modulated_dcn': False,
				'deformable_groups': 1,
				}
			)
		in_channels = out_channels
		in_channels: 1024
		self.add_module(name=layer3, module=Sequential(
  (0): BottleneckWithFixedBatchNorm(
    (downsample): Sequential(
      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): FrozenBatchNorm2d()
    )
    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (bn1): FrozenBatchNorm2d()
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): FrozenBatchNorm2d()
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): FrozenBatchNorm2d()
  )
  (1): BottleneckWithFixedBatchNorm(
    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): FrozenBatchNorm2d()
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): FrozenBatchNorm2d()
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): FrozenBatchNorm2d()
  )
  (2): BottleneckWithFixedBatchNorm(
    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): FrozenBatchNorm2d()
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): FrozenBatchNorm2d()
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): FrozenBatchNorm2d()
  )
  (3): BottleneckWithFixedBatchNorm(
    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): FrozenBatchNorm2d()
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): FrozenBatchNorm2d()
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): FrozenBatchNorm2d()
  )
  (4): BottleneckWithFixedBatchNorm(
    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): FrozenBatchNorm2d()
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): FrozenBatchNorm2d()
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): FrozenBatchNorm2d()
  )
  (5): BottleneckWithFixedBatchNorm(
    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): FrozenBatchNorm2d()
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): FrozenBatchNorm2d()
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): FrozenBatchNorm2d()
  )
))
		self.stages.append(name=layer3)
		name: layer3
		stage_spec.return_features: True
		self.return_features[name] = stage_spec.return_features
		stage_spec: StageSpec(index=4, block_count=3, return_features=True)
		stage_spec.index: 4
		name = "layer" + str(stage_spec.index)
		name: layer4
		stage2_relative_factor = 2 ** (stage_spec.index - 1)
		stage2_relative_factor: 8
		bottleneck_channels = stage2_bottleneck_channels * stage2_relative_factor
		bottlenec_channels: 512
		out_channels = stage2_out_channels * stage2_relative_factor
		out_channels: 2048
		stage_with_dcn = cfg.MODEL.RESNETS.STAGE_WITH_DCN[stage_spec.index - 1]
		stage_wid_dcn: False
		module = _make_stage(
			transformation_module = <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>,
			in_channels = 1024,
			bottleneck_channels = 512,
			out_channels = 2048,
			stage_spec.block_count = 3,
			num_groups = 1,
			cfg.MODEL.RESNETS.STRIDE_IN_1X1 : True,
			first_stride=int(stage_spec.index > 1) + 1: 2,
			dcn_config={
				'stage_with_dcn': False,
				'with_modulated_dcn': False,
				'deformable_groups': 1,
				}
			)
		in_channels = out_channels
		in_channels: 2048
		self.add_module(name=layer4, module=Sequential(
  (0): BottleneckWithFixedBatchNorm(
    (downsample): Sequential(
      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): FrozenBatchNorm2d()
    )
    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (bn1): FrozenBatchNorm2d()
    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): FrozenBatchNorm2d()
    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): FrozenBatchNorm2d()
  )
  (1): BottleneckWithFixedBatchNorm(
    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): FrozenBatchNorm2d()
    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): FrozenBatchNorm2d()
    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): FrozenBatchNorm2d()
  )
  (2): BottleneckWithFixedBatchNorm(
    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): FrozenBatchNorm2d()
    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): FrozenBatchNorm2d()
    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): FrozenBatchNorm2d()
  )
))
		self.stages.append(name=layer4)
		name: layer4
		stage_spec.return_features: True
		self.return_features[name] = stage_spec.return_features
		cfg.MODEL.BACKBONE.FREEZE_CONV_BODY_AT: 2)
		self._freeze_backbone(cfg.MODEL.BACKBONE.FREEZE_CONV_BODY_AT)

	=========================================== Resnet.__freeze_backbone() START
	=========================================== Resnet.__freeze_backbone() END

=========================================== Resnet.__init__ END

	body = resnet.ResNet(cfg)
	body: ResNet(
  (stem): StemWithFixedBatchNorm(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): FrozenBatchNorm2d()
  )
  (layer1): Sequential(
    (0): BottleneckWithFixedBatchNorm(
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): FrozenBatchNorm2d()
      )
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): FrozenBatchNorm2d()
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): FrozenBatchNorm2d()
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): FrozenBatchNorm2d()
    )
    (1): BottleneckWithFixedBatchNorm(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): FrozenBatchNorm2d()
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): FrozenBatchNorm2d()
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): FrozenBatchNorm2d()
    )
    (2): BottleneckWithFixedBatchNorm(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): FrozenBatchNorm2d()
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): FrozenBatchNorm2d()
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): FrozenBatchNorm2d()
    )
  )
  (layer2): Sequential(
    (0): BottleneckWithFixedBatchNorm(
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): FrozenBatchNorm2d()
      )
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (bn1): FrozenBatchNorm2d()
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): FrozenBatchNorm2d()
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): FrozenBatchNorm2d()
    )
    (1): BottleneckWithFixedBatchNorm(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): FrozenBatchNorm2d()
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): FrozenBatchNorm2d()
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): FrozenBatchNorm2d()
    )
    (2): BottleneckWithFixedBatchNorm(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): FrozenBatchNorm2d()
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): FrozenBatchNorm2d()
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): FrozenBatchNorm2d()
    )
    (3): BottleneckWithFixedBatchNorm(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): FrozenBatchNorm2d()
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): FrozenBatchNorm2d()
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): FrozenBatchNorm2d()
    )
  )
  (layer3): Sequential(
    (0): BottleneckWithFixedBatchNorm(
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): FrozenBatchNorm2d()
      )
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (bn1): FrozenBatchNorm2d()
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): FrozenBatchNorm2d()
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): FrozenBatchNorm2d()
    )
    (1): BottleneckWithFixedBatchNorm(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): FrozenBatchNorm2d()
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): FrozenBatchNorm2d()
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): FrozenBatchNorm2d()
    )
    (2): BottleneckWithFixedBatchNorm(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): FrozenBatchNorm2d()
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): FrozenBatchNorm2d()
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): FrozenBatchNorm2d()
    )
    (3): BottleneckWithFixedBatchNorm(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): FrozenBatchNorm2d()
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): FrozenBatchNorm2d()
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): FrozenBatchNorm2d()
    )
    (4): BottleneckWithFixedBatchNorm(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): FrozenBatchNorm2d()
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): FrozenBatchNorm2d()
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): FrozenBatchNorm2d()
    )
    (5): BottleneckWithFixedBatchNorm(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): FrozenBatchNorm2d()
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): FrozenBatchNorm2d()
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): FrozenBatchNorm2d()
    )
  )
  (layer4): Sequential(
    (0): BottleneckWithFixedBatchNorm(
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): FrozenBatchNorm2d()
      )
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (bn1): FrozenBatchNorm2d()
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): FrozenBatchNorm2d()
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): FrozenBatchNorm2d()
    )
    (1): BottleneckWithFixedBatchNorm(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): FrozenBatchNorm2d()
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): FrozenBatchNorm2d()
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): FrozenBatchNorm2d()
    )
    (2): BottleneckWithFixedBatchNorm(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): FrozenBatchNorm2d()
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): FrozenBatchNorm2d()
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): FrozenBatchNorm2d()
    )
  )
)

	cfg.MODEL.RESNETS.RES2_OUT_CHANNELS: 256
	in_channels_stage2 = cfg.MODEL.RESNETS.RES2_OUT_CHANNELS
	in_channels_stage2 = 256
	cfg.MODEL.RESNETS.BACKBONE_OUT_CHANNELS:1024
	out_channels = cfg.MODEL.RESNETS.BACKBONE_OUT_CHANNELS
	out_channels = 1024
	in_channels_stage2: 256
	out_channels: 1024
	cfg.MODEL.RETINANET.USE_C5: True
	in_channels_p6p7 = in_channels_stage2 * 8 if cfg.MODEL.RETINANET.USE_C5 else out_channels
	in_channels_p6p7 = 2048

	fpn = fpn_module.FPN(

			in_channels_list = [0, 512, 1024, 2048],

			out_channels = 1024, 

			conv_block=conv_with_kaiming_uniform( cfg.MODEL.FPN.USE_GN =False, cfg.MODEL.FPN.USE_RELU =False ),

			top_blocks=fpn_module.LastLevelP6P7(in_channels_p6p7=2048, out_channels=1024,)

		conv_with_kaiming_uniform(use_gn=False, use_relut=False) ======== BEGIN
			return make_conv
		tconv_with_kaiming_uniform(use_gn=False, use_relut=False) ======== END



		LastLevelP6P7.__init__(self, in_channels=2048, out_channels=1024) ====== BEGIN
			super(LastLevelP6P7, self).__init__()
			self.p6 = nn.Conv2d(in_channels=2048, out_channels=1024, 3, 2, 1)
			self.p7 = nn.Conv2d(out_channels=1024, out_channels=1024, 3, 2, 1)
			for module in [self.p6, self.p7]:
				module=Conv2d(2048, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
				nn.init.kaiming_uniform_(module.weight=module.weight, a=1)
				nn.init.constant_(module.bias=module.bias, 0)
				module=Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
				nn.init.kaiming_uniform_(module.weight=module.weight, a=1)
				nn.init.constant_(module.bias=module.bias, 0)
			self.use_p5 : False

		LastLevelP6P7.__init__(self, in_channels=2048, out_channels=1024) ====== END




=========================================== FPN.__init__ begin
	======constructor params
		in_channels_list: [0, 512, 1024, 2048]
		out_channels: 1024
		conv_block: <function conv_with_kaiming_uniform.<locals>.make_conv at 0x7f3360d83378>
		top_blocks: LastLevelP6P7(
  (p6): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (p7): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
)
	======constructor params
	super(FPN, self).__init__()

	for idx, in_channels in enumerate(in_channels_list, 1):

		==> iteration with idx:1, in_channels:0
		if in_channels ==0, skip


		==> iteration with idx:2, in_channels:512
		inner_block: fpn_inner2
		layer_block: fpn_layer2
		inner_block_module = conv_block(in_channels=512, out_channels=1024, 1)

			conv_with_kaiming_uniform().make_conv() ====== BEGIN
				Conv2d(in_channles=512, out_channels=1024, kernel_size=1, stride=1
				       padding=0, dilation=1, bias=True,
				nn.init.kaiming_uniform_(conv.weight, a=1)
				if not use_gn:
					nn.init.constant_(conv.bias, 0)
				module = [conv,]
				return conv

			conv_with_kaiming_uniform().make_conv() ====== END

		layer_block_module = conv_block(out_channels=1024, out_channels=1024, 3,1)

			conv_with_kaiming_uniform().make_conv() ====== BEGIN
				Conv2d(in_channles=1024, out_channels=1024, kernel_size=3, stride=1
				       padding=1, dilation=1, bias=True,
				nn.init.kaiming_uniform_(conv.weight, a=1)
				if not use_gn:
					nn.init.constant_(conv.bias, 0)
				module = [conv,]
				return conv

			conv_with_kaiming_uniform().make_conv() ====== END

		self.add_module(fpn_inner2, inner_block_module)
		self.add_module(fpn_layer2, layer_block_module)
		self.inner_blocks.append(fpn_inner2)
		self.layer_blocks.append(fpn_layer2)

		==> iteration with idx:3, in_channels:1024
		inner_block: fpn_inner3
		layer_block: fpn_layer3
		inner_block_module = conv_block(in_channels=1024, out_channels=1024, 1)

			conv_with_kaiming_uniform().make_conv() ====== BEGIN
				Conv2d(in_channles=1024, out_channels=1024, kernel_size=1, stride=1
				       padding=0, dilation=1, bias=True,
				nn.init.kaiming_uniform_(conv.weight, a=1)
				if not use_gn:
					nn.init.constant_(conv.bias, 0)
				module = [conv,]
				return conv

			conv_with_kaiming_uniform().make_conv() ====== END

		layer_block_module = conv_block(out_channels=1024, out_channels=1024, 3,1)

			conv_with_kaiming_uniform().make_conv() ====== BEGIN
				Conv2d(in_channles=1024, out_channels=1024, kernel_size=3, stride=1
				       padding=1, dilation=1, bias=True,
				nn.init.kaiming_uniform_(conv.weight, a=1)
				if not use_gn:
					nn.init.constant_(conv.bias, 0)
				module = [conv,]
				return conv

			conv_with_kaiming_uniform().make_conv() ====== END

		self.add_module(fpn_inner3, inner_block_module)
		self.add_module(fpn_layer3, layer_block_module)
		self.inner_blocks.append(fpn_inner3)
		self.layer_blocks.append(fpn_layer3)

		==> iteration with idx:4, in_channels:2048
		inner_block: fpn_inner4
		layer_block: fpn_layer4
		inner_block_module = conv_block(in_channels=2048, out_channels=1024, 1)

			conv_with_kaiming_uniform().make_conv() ====== BEGIN
				Conv2d(in_channles=2048, out_channels=1024, kernel_size=1, stride=1
				       padding=0, dilation=1, bias=True,
				nn.init.kaiming_uniform_(conv.weight, a=1)
				if not use_gn:
					nn.init.constant_(conv.bias, 0)
				module = [conv,]
				return conv

			conv_with_kaiming_uniform().make_conv() ====== END

		layer_block_module = conv_block(out_channels=1024, out_channels=1024, 3,1)

			conv_with_kaiming_uniform().make_conv() ====== BEGIN
				Conv2d(in_channles=1024, out_channels=1024, kernel_size=3, stride=1
				       padding=1, dilation=1, bias=True,
				nn.init.kaiming_uniform_(conv.weight, a=1)
				if not use_gn:
					nn.init.constant_(conv.bias, 0)
				module = [conv,]
				return conv

			conv_with_kaiming_uniform().make_conv() ====== END

		self.add_module(fpn_inner4, inner_block_module)
		self.add_module(fpn_layer4, layer_block_module)
		self.inner_blocks.append(fpn_inner4)
		self.layer_blocks.append(fpn_layer4)

	self.inner_blocks: ['fpn_inner2', 'fpn_inner3', 'fpn_inner4']
		self.fpn_inner2: Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
		self.fpn_inner3: Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
		self.fpn_inner4: Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))

	self.layer_blocks: ['fpn_layer2', 'fpn_layer3', 'fpn_layer4']
		self.fpn_layer2: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
		self.fpn_layer3: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
		self.fpn_layer4: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))

	self.top_blocks: LastLevelP6P7(
  (p6): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (p7): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
)
=========================================== FPN.__init__ end



	fpn: {fpn}
	model = nn.Sequential(OrderedDict([("body", body), ("fpn", fpn)]))
	model: Sequential(
  (body): ResNet(
    (stem): StemWithFixedBatchNorm(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): FrozenBatchNorm2d()
    )
    (layer1): Sequential(
      (0): BottleneckWithFixedBatchNorm(
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): FrozenBatchNorm2d()
        )
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
      (1): BottleneckWithFixedBatchNorm(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
      (2): BottleneckWithFixedBatchNorm(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
    )
    (layer2): Sequential(
      (0): BottleneckWithFixedBatchNorm(
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): FrozenBatchNorm2d()
        )
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
      (1): BottleneckWithFixedBatchNorm(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
      (2): BottleneckWithFixedBatchNorm(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
      (3): BottleneckWithFixedBatchNorm(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
    )
    (layer3): Sequential(
      (0): BottleneckWithFixedBatchNorm(
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): FrozenBatchNorm2d()
        )
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
      (1): BottleneckWithFixedBatchNorm(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
      (2): BottleneckWithFixedBatchNorm(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
      (3): BottleneckWithFixedBatchNorm(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
      (4): BottleneckWithFixedBatchNorm(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
      (5): BottleneckWithFixedBatchNorm(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
    )
    (layer4): Sequential(
      (0): BottleneckWithFixedBatchNorm(
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): FrozenBatchNorm2d()
        )
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
      (1): BottleneckWithFixedBatchNorm(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
      (2): BottleneckWithFixedBatchNorm(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
    )
  )
  (fpn): FPN(
    (fpn_inner2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
    (fpn_layer2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_inner3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
    (fpn_layer3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_inner4): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
    (fpn_layer4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_blocks): LastLevelP6P7(
      (p6): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
  )
)
	model.out_channels = out_channels
	model.out_channels: 1024
	return model
build_resnet_fpn_p3p7_backbone(cfg) ====== END


	registry.BACKBONES[cfg.MODEL.BACKBONE.CONV_BODY](cfg): Sequential(
  (body): ResNet(
    (stem): StemWithFixedBatchNorm(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): FrozenBatchNorm2d()
    )
    (layer1): Sequential(
      (0): BottleneckWithFixedBatchNorm(
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): FrozenBatchNorm2d()
        )
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
      (1): BottleneckWithFixedBatchNorm(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
      (2): BottleneckWithFixedBatchNorm(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
    )
    (layer2): Sequential(
      (0): BottleneckWithFixedBatchNorm(
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): FrozenBatchNorm2d()
        )
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
      (1): BottleneckWithFixedBatchNorm(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
      (2): BottleneckWithFixedBatchNorm(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
      (3): BottleneckWithFixedBatchNorm(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
    )
    (layer3): Sequential(
      (0): BottleneckWithFixedBatchNorm(
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): FrozenBatchNorm2d()
        )
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
      (1): BottleneckWithFixedBatchNorm(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
      (2): BottleneckWithFixedBatchNorm(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
      (3): BottleneckWithFixedBatchNorm(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
      (4): BottleneckWithFixedBatchNorm(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
      (5): BottleneckWithFixedBatchNorm(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
    )
    (layer4): Sequential(
      (0): BottleneckWithFixedBatchNorm(
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): FrozenBatchNorm2d()
        )
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
      (1): BottleneckWithFixedBatchNorm(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
      (2): BottleneckWithFixedBatchNorm(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
    )
  )
  (fpn): FPN(
    (fpn_inner2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
    (fpn_layer2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_inner3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
    (fpn_layer3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_inner4): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
    (fpn_layer4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_blocks): LastLevelP6P7(
      (p6): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
  )
)
	return registry.BACKBONES[cfg.MODEL.BACKBONE.CONV_BODY](cfg)
build_backbone(cfg) ====== END
build_resnet_fpn_p3p7_backbone(cfg) ====== BEGIN

=========================================== Resnet.__init__ BEGIN
	_STEM_MODULES: {'StemWithFixedBatchNorm': <class 'maskrcnn_benchmark.modeling.backbone.resnet.StemWithFixedBatchNorm'>}
	_cfg.MODEL.RESNETS.STEM_FUNC: StemWithFixedBatchNorm
	stem_module = _STEM_MODULES[cfg.MODEL.RESNETS.STEM_FUNC]
	stem_module: <class 'maskrcnn_benchmark.modeling.backbone.resnet.StemWithFixedBatchNorm'>
	_STAGE_SPECS: {'R-50-C4': (StageSpec(index=1, block_count=3, return_features=False), StageSpec(index=2, block_count=4, return_features=False), StageSpec(index=3, block_count=6, return_features=True)), 'R-50-C5': (StageSpec(index=1, block_count=3, return_features=False), StageSpec(index=2, block_count=4, return_features=False), StageSpec(index=3, block_count=6, return_features=False), StageSpec(index=4, block_count=3, return_features=True)), 'R-101-C4': (StageSpec(index=1, block_count=3, return_features=False), StageSpec(index=2, block_count=4, return_features=False), StageSpec(index=3, block_count=23, return_features=True)), 'R-101-C5': (StageSpec(index=1, block_count=3, return_features=False), StageSpec(index=2, block_count=4, return_features=False), StageSpec(index=3, block_count=23, return_features=False), StageSpec(index=4, block_count=3, return_features=True)), 'R-50-FPN': (StageSpec(index=1, block_count=3, return_features=True), StageSpec(index=2, block_count=4, return_features=True), StageSpec(index=3, block_count=6, return_features=True), StageSpec(index=4, block_count=3, return_features=True)), 'R-50-FPN-RETINANET': (StageSpec(index=1, block_count=3, return_features=True), StageSpec(index=2, block_count=4, return_features=True), StageSpec(index=3, block_count=6, return_features=True), StageSpec(index=4, block_count=3, return_features=True)), 'R-101-FPN': (StageSpec(index=1, block_count=3, return_features=True), StageSpec(index=2, block_count=4, return_features=True), StageSpec(index=3, block_count=23, return_features=True), StageSpec(index=4, block_count=3, return_features=True)), 'R-101-FPN-RETINANET': (StageSpec(index=1, block_count=3, return_features=True), StageSpec(index=2, block_count=4, return_features=True), StageSpec(index=3, block_count=23, return_features=True), StageSpec(index=4, block_count=3, return_features=True)), 'R-152-FPN': (StageSpec(index=1, block_count=3, return_features=True), StageSpec(index=2, block_count=8, return_features=True), StageSpec(index=3, block_count=36, return_features=True), StageSpec(index=4, block_count=3, return_features=True))}
	cfg.MODEL.BACKBONE.CONV_BODY: R-50-FPN-RETINANET
	stage_specs = _STAGE_SPECS[cfg.MODEL.BACKBONE.CONV_BODY]
	stage_specs: (StageSpec(index=1, block_count=3, return_features=True), StageSpec(index=2, block_count=4, return_features=True), StageSpec(index=3, block_count=6, return_features=True), StageSpec(index=4, block_count=3, return_features=True))
	_TRANSFORMATION_MODULES: {'BottleneckWithFixedBatchNorm': <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>}
	cfg.MODEL.RESNETS.TRANS_FUNC: BottleneckWithFixedBatchNorm
	transformation_module = _TRANSFORMATION_MODULES[cfg.MODEL.RESNETS.TRANS_FUNC]
	transformation_module: <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>
	self.stem = stem_module(cfg)
	self.stem: StemWithFixedBatchNorm(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): FrozenBatchNorm2d()
)
	num_groups = cfg.MODEL.RESNETS.NUM_GROUPS
	num_groups.stem: 1
	width_per_group = cfg.MODEL.RESNETS.WIDTH_PER_GROUP
	width_per_group: 64
	in_channels = cfg.MODEL.RESNETS.STEM_OUT_CHANNELS
	in_channels: 64
	stage2_bottleneck_channels = num_groups * width_per_group
	stage2_bottleneck_channels: 64
	stage2_out_channels = cfg.MODEL.RESNETS.RES2_OUT_CHANNELS
	stage2_out_channels: 256
	self.stages = []
	self.return_features = {}
	for stage_spec in stage_specs:
		stage_spec: StageSpec(index=1, block_count=3, return_features=True)
		stage_spec.index: 1
		name = "layer" + str(stage_spec.index)
		name: layer1
		stage2_relative_factor = 2 ** (stage_spec.index - 1)
		stage2_relative_factor: 1
		bottleneck_channels = stage2_bottleneck_channels * stage2_relative_factor
		bottlenec_channels: 64
		out_channels = stage2_out_channels * stage2_relative_factor
		out_channels: 256
		stage_with_dcn = cfg.MODEL.RESNETS.STAGE_WITH_DCN[stage_spec.index - 1]
		stage_wid_dcn: False
		module = _make_stage(
			transformation_module = <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>,
			in_channels = 64,
			bottleneck_channels = 64,
			out_channels = 256,
			stage_spec.block_count = 3,
			num_groups = 1,
			cfg.MODEL.RESNETS.STRIDE_IN_1X1 : True,
			first_stride=int(stage_spec.index > 1) + 1: 1,
			dcn_config={
				'stage_with_dcn': False,
				'with_modulated_dcn': False,
				'deformable_groups': 1,
				}
			)
		in_channels = out_channels
		in_channels: 256
		self.add_module(name=layer1, module=Sequential(
  (0): BottleneckWithFixedBatchNorm(
    (downsample): Sequential(
      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): FrozenBatchNorm2d()
    )
    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): FrozenBatchNorm2d()
    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): FrozenBatchNorm2d()
    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): FrozenBatchNorm2d()
  )
  (1): BottleneckWithFixedBatchNorm(
    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): FrozenBatchNorm2d()
    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): FrozenBatchNorm2d()
    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): FrozenBatchNorm2d()
  )
  (2): BottleneckWithFixedBatchNorm(
    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): FrozenBatchNorm2d()
    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): FrozenBatchNorm2d()
    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): FrozenBatchNorm2d()
  )
))
		self.stages.append(name=layer1)
		name: layer1
		stage_spec.return_features: True
		self.return_features[name] = stage_spec.return_features
		stage_spec: StageSpec(index=2, block_count=4, return_features=True)
		stage_spec.index: 2
		name = "layer" + str(stage_spec.index)
		name: layer2
		stage2_relative_factor = 2 ** (stage_spec.index - 1)
		stage2_relative_factor: 2
		bottleneck_channels = stage2_bottleneck_channels * stage2_relative_factor
		bottlenec_channels: 128
		out_channels = stage2_out_channels * stage2_relative_factor
		out_channels: 512
		stage_with_dcn = cfg.MODEL.RESNETS.STAGE_WITH_DCN[stage_spec.index - 1]
		stage_wid_dcn: False
		module = _make_stage(
			transformation_module = <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>,
			in_channels = 256,
			bottleneck_channels = 128,
			out_channels = 512,
			stage_spec.block_count = 4,
			num_groups = 1,
			cfg.MODEL.RESNETS.STRIDE_IN_1X1 : True,
			first_stride=int(stage_spec.index > 1) + 1: 2,
			dcn_config={
				'stage_with_dcn': False,
				'with_modulated_dcn': False,
				'deformable_groups': 1,
				}
			)
		in_channels = out_channels
		in_channels: 512
		self.add_module(name=layer2, module=Sequential(
  (0): BottleneckWithFixedBatchNorm(
    (downsample): Sequential(
      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): FrozenBatchNorm2d()
    )
    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (bn1): FrozenBatchNorm2d()
    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): FrozenBatchNorm2d()
    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): FrozenBatchNorm2d()
  )
  (1): BottleneckWithFixedBatchNorm(
    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): FrozenBatchNorm2d()
    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): FrozenBatchNorm2d()
    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): FrozenBatchNorm2d()
  )
  (2): BottleneckWithFixedBatchNorm(
    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): FrozenBatchNorm2d()
    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): FrozenBatchNorm2d()
    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): FrozenBatchNorm2d()
  )
  (3): BottleneckWithFixedBatchNorm(
    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): FrozenBatchNorm2d()
    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): FrozenBatchNorm2d()
    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): FrozenBatchNorm2d()
  )
))
		self.stages.append(name=layer2)
		name: layer2
		stage_spec.return_features: True
		self.return_features[name] = stage_spec.return_features
		stage_spec: StageSpec(index=3, block_count=6, return_features=True)
		stage_spec.index: 3
		name = "layer" + str(stage_spec.index)
		name: layer3
		stage2_relative_factor = 2 ** (stage_spec.index - 1)
		stage2_relative_factor: 4
		bottleneck_channels = stage2_bottleneck_channels * stage2_relative_factor
		bottlenec_channels: 256
		out_channels = stage2_out_channels * stage2_relative_factor
		out_channels: 1024
		stage_with_dcn = cfg.MODEL.RESNETS.STAGE_WITH_DCN[stage_spec.index - 1]
		stage_wid_dcn: False
		module = _make_stage(
			transformation_module = <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>,
			in_channels = 512,
			bottleneck_channels = 256,
			out_channels = 1024,
			stage_spec.block_count = 6,
			num_groups = 1,
			cfg.MODEL.RESNETS.STRIDE_IN_1X1 : True,
			first_stride=int(stage_spec.index > 1) + 1: 2,
			dcn_config={
				'stage_with_dcn': False,
				'with_modulated_dcn': False,
				'deformable_groups': 1,
				}
			)
		in_channels = out_channels
		in_channels: 1024
		self.add_module(name=layer3, module=Sequential(
  (0): BottleneckWithFixedBatchNorm(
    (downsample): Sequential(
      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): FrozenBatchNorm2d()
    )
    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (bn1): FrozenBatchNorm2d()
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): FrozenBatchNorm2d()
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): FrozenBatchNorm2d()
  )
  (1): BottleneckWithFixedBatchNorm(
    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): FrozenBatchNorm2d()
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): FrozenBatchNorm2d()
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): FrozenBatchNorm2d()
  )
  (2): BottleneckWithFixedBatchNorm(
    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): FrozenBatchNorm2d()
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): FrozenBatchNorm2d()
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): FrozenBatchNorm2d()
  )
  (3): BottleneckWithFixedBatchNorm(
    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): FrozenBatchNorm2d()
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): FrozenBatchNorm2d()
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): FrozenBatchNorm2d()
  )
  (4): BottleneckWithFixedBatchNorm(
    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): FrozenBatchNorm2d()
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): FrozenBatchNorm2d()
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): FrozenBatchNorm2d()
  )
  (5): BottleneckWithFixedBatchNorm(
    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): FrozenBatchNorm2d()
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): FrozenBatchNorm2d()
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): FrozenBatchNorm2d()
  )
))
		self.stages.append(name=layer3)
		name: layer3
		stage_spec.return_features: True
		self.return_features[name] = stage_spec.return_features
		stage_spec: StageSpec(index=4, block_count=3, return_features=True)
		stage_spec.index: 4
		name = "layer" + str(stage_spec.index)
		name: layer4
		stage2_relative_factor = 2 ** (stage_spec.index - 1)
		stage2_relative_factor: 8
		bottleneck_channels = stage2_bottleneck_channels * stage2_relative_factor
		bottlenec_channels: 512
		out_channels = stage2_out_channels * stage2_relative_factor
		out_channels: 2048
		stage_with_dcn = cfg.MODEL.RESNETS.STAGE_WITH_DCN[stage_spec.index - 1]
		stage_wid_dcn: False
		module = _make_stage(
			transformation_module = <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>,
			in_channels = 1024,
			bottleneck_channels = 512,
			out_channels = 2048,
			stage_spec.block_count = 3,
			num_groups = 1,
			cfg.MODEL.RESNETS.STRIDE_IN_1X1 : True,
			first_stride=int(stage_spec.index > 1) + 1: 2,
			dcn_config={
				'stage_with_dcn': False,
				'with_modulated_dcn': False,
				'deformable_groups': 1,
				}
			)
		in_channels = out_channels
		in_channels: 2048
		self.add_module(name=layer4, module=Sequential(
  (0): BottleneckWithFixedBatchNorm(
    (downsample): Sequential(
      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): FrozenBatchNorm2d()
    )
    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (bn1): FrozenBatchNorm2d()
    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): FrozenBatchNorm2d()
    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): FrozenBatchNorm2d()
  )
  (1): BottleneckWithFixedBatchNorm(
    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): FrozenBatchNorm2d()
    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): FrozenBatchNorm2d()
    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): FrozenBatchNorm2d()
  )
  (2): BottleneckWithFixedBatchNorm(
    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): FrozenBatchNorm2d()
    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): FrozenBatchNorm2d()
    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): FrozenBatchNorm2d()
  )
))
		self.stages.append(name=layer4)
		name: layer4
		stage_spec.return_features: True
		self.return_features[name] = stage_spec.return_features
		cfg.MODEL.BACKBONE.FREEZE_CONV_BODY_AT: 2)
		self._freeze_backbone(cfg.MODEL.BACKBONE.FREEZE_CONV_BODY_AT)

	=========================================== Resnet.__freeze_backbone() START
	=========================================== Resnet.__freeze_backbone() END

=========================================== Resnet.__init__ END

	body = resnet.ResNet(cfg)
	body: ResNet(
  (stem): StemWithFixedBatchNorm(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): FrozenBatchNorm2d()
  )
  (layer1): Sequential(
    (0): BottleneckWithFixedBatchNorm(
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): FrozenBatchNorm2d()
      )
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): FrozenBatchNorm2d()
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): FrozenBatchNorm2d()
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): FrozenBatchNorm2d()
    )
    (1): BottleneckWithFixedBatchNorm(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): FrozenBatchNorm2d()
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): FrozenBatchNorm2d()
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): FrozenBatchNorm2d()
    )
    (2): BottleneckWithFixedBatchNorm(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): FrozenBatchNorm2d()
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): FrozenBatchNorm2d()
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): FrozenBatchNorm2d()
    )
  )
  (layer2): Sequential(
    (0): BottleneckWithFixedBatchNorm(
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): FrozenBatchNorm2d()
      )
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (bn1): FrozenBatchNorm2d()
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): FrozenBatchNorm2d()
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): FrozenBatchNorm2d()
    )
    (1): BottleneckWithFixedBatchNorm(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): FrozenBatchNorm2d()
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): FrozenBatchNorm2d()
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): FrozenBatchNorm2d()
    )
    (2): BottleneckWithFixedBatchNorm(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): FrozenBatchNorm2d()
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): FrozenBatchNorm2d()
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): FrozenBatchNorm2d()
    )
    (3): BottleneckWithFixedBatchNorm(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): FrozenBatchNorm2d()
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): FrozenBatchNorm2d()
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): FrozenBatchNorm2d()
    )
  )
  (layer3): Sequential(
    (0): BottleneckWithFixedBatchNorm(
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): FrozenBatchNorm2d()
      )
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (bn1): FrozenBatchNorm2d()
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): FrozenBatchNorm2d()
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): FrozenBatchNorm2d()
    )
    (1): BottleneckWithFixedBatchNorm(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): FrozenBatchNorm2d()
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): FrozenBatchNorm2d()
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): FrozenBatchNorm2d()
    )
    (2): BottleneckWithFixedBatchNorm(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): FrozenBatchNorm2d()
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): FrozenBatchNorm2d()
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): FrozenBatchNorm2d()
    )
    (3): BottleneckWithFixedBatchNorm(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): FrozenBatchNorm2d()
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): FrozenBatchNorm2d()
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): FrozenBatchNorm2d()
    )
    (4): BottleneckWithFixedBatchNorm(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): FrozenBatchNorm2d()
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): FrozenBatchNorm2d()
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): FrozenBatchNorm2d()
    )
    (5): BottleneckWithFixedBatchNorm(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): FrozenBatchNorm2d()
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): FrozenBatchNorm2d()
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): FrozenBatchNorm2d()
    )
  )
  (layer4): Sequential(
    (0): BottleneckWithFixedBatchNorm(
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): FrozenBatchNorm2d()
      )
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (bn1): FrozenBatchNorm2d()
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): FrozenBatchNorm2d()
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): FrozenBatchNorm2d()
    )
    (1): BottleneckWithFixedBatchNorm(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): FrozenBatchNorm2d()
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): FrozenBatchNorm2d()
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): FrozenBatchNorm2d()
    )
    (2): BottleneckWithFixedBatchNorm(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): FrozenBatchNorm2d()
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): FrozenBatchNorm2d()
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): FrozenBatchNorm2d()
    )
  )
)

	cfg.MODEL.RESNETS.RES2_OUT_CHANNELS: 256
	in_channels_stage2 = cfg.MODEL.RESNETS.RES2_OUT_CHANNELS
	in_channels_stage2 = 256
	cfg.MODEL.RESNETS.BACKBONE_OUT_CHANNELS:1024
	out_channels = cfg.MODEL.RESNETS.BACKBONE_OUT_CHANNELS
	out_channels = 1024
	in_channels_stage2: 256
	out_channels: 1024
	cfg.MODEL.RETINANET.USE_C5: True
	in_channels_p6p7 = in_channels_stage2 * 8 if cfg.MODEL.RETINANET.USE_C5 else out_channels
	in_channels_p6p7 = 2048

	fpn = fpn_module.FPN(

			in_channels_list = [0, 512, 1024, 2048],

			out_channels = 1024, 

			conv_block=conv_with_kaiming_uniform( cfg.MODEL.FPN.USE_GN =False, cfg.MODEL.FPN.USE_RELU =False ),

			top_blocks=fpn_module.LastLevelP6P7(in_channels_p6p7=2048, out_channels=1024,)

		conv_with_kaiming_uniform(use_gn=False, use_relut=False) ======== BEGIN
			return make_conv
		tconv_with_kaiming_uniform(use_gn=False, use_relut=False) ======== END



		LastLevelP6P7.__init__(self, in_channels=2048, out_channels=1024) ====== BEGIN
			super(LastLevelP6P7, self).__init__()
			self.p6 = nn.Conv2d(in_channels=2048, out_channels=1024, 3, 2, 1)
			self.p7 = nn.Conv2d(out_channels=1024, out_channels=1024, 3, 2, 1)
			for module in [self.p6, self.p7]:
				module=Conv2d(2048, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
				nn.init.kaiming_uniform_(module.weight=module.weight, a=1)
				nn.init.constant_(module.bias=module.bias, 0)
				module=Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
				nn.init.kaiming_uniform_(module.weight=module.weight, a=1)
				nn.init.constant_(module.bias=module.bias, 0)
			self.use_p5 : False

		LastLevelP6P7.__init__(self, in_channels=2048, out_channels=1024) ====== END




=========================================== FPN.__init__ begin
	======constructor params
		in_channels_list: [0, 512, 1024, 2048]
		out_channels: 1024
		conv_block: <function conv_with_kaiming_uniform.<locals>.make_conv at 0x7f3360d8d048>
		top_blocks: LastLevelP6P7(
  (p6): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (p7): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
)
	======constructor params
	super(FPN, self).__init__()

	for idx, in_channels in enumerate(in_channels_list, 1):

		==> iteration with idx:1, in_channels:0
		if in_channels ==0, skip


		==> iteration with idx:2, in_channels:512
		inner_block: fpn_inner2
		layer_block: fpn_layer2
		inner_block_module = conv_block(in_channels=512, out_channels=1024, 1)

			conv_with_kaiming_uniform().make_conv() ====== BEGIN
				Conv2d(in_channles=512, out_channels=1024, kernel_size=1, stride=1
				       padding=0, dilation=1, bias=True,
				nn.init.kaiming_uniform_(conv.weight, a=1)
				if not use_gn:
					nn.init.constant_(conv.bias, 0)
				module = [conv,]
				return conv

			conv_with_kaiming_uniform().make_conv() ====== END

		layer_block_module = conv_block(out_channels=1024, out_channels=1024, 3,1)

			conv_with_kaiming_uniform().make_conv() ====== BEGIN
				Conv2d(in_channles=1024, out_channels=1024, kernel_size=3, stride=1
				       padding=1, dilation=1, bias=True,
				nn.init.kaiming_uniform_(conv.weight, a=1)
				if not use_gn:
					nn.init.constant_(conv.bias, 0)
				module = [conv,]
				return conv

			conv_with_kaiming_uniform().make_conv() ====== END

		self.add_module(fpn_inner2, inner_block_module)
		self.add_module(fpn_layer2, layer_block_module)
		self.inner_blocks.append(fpn_inner2)
		self.layer_blocks.append(fpn_layer2)

		==> iteration with idx:3, in_channels:1024
		inner_block: fpn_inner3
		layer_block: fpn_layer3
		inner_block_module = conv_block(in_channels=1024, out_channels=1024, 1)

			conv_with_kaiming_uniform().make_conv() ====== BEGIN
				Conv2d(in_channles=1024, out_channels=1024, kernel_size=1, stride=1
				       padding=0, dilation=1, bias=True,
				nn.init.kaiming_uniform_(conv.weight, a=1)
				if not use_gn:
					nn.init.constant_(conv.bias, 0)
				module = [conv,]
				return conv

			conv_with_kaiming_uniform().make_conv() ====== END

		layer_block_module = conv_block(out_channels=1024, out_channels=1024, 3,1)

			conv_with_kaiming_uniform().make_conv() ====== BEGIN
				Conv2d(in_channles=1024, out_channels=1024, kernel_size=3, stride=1
				       padding=1, dilation=1, bias=True,
				nn.init.kaiming_uniform_(conv.weight, a=1)
				if not use_gn:
					nn.init.constant_(conv.bias, 0)
				module = [conv,]
				return conv

			conv_with_kaiming_uniform().make_conv() ====== END

		self.add_module(fpn_inner3, inner_block_module)
		self.add_module(fpn_layer3, layer_block_module)
		self.inner_blocks.append(fpn_inner3)
		self.layer_blocks.append(fpn_layer3)

		==> iteration with idx:4, in_channels:2048
		inner_block: fpn_inner4
		layer_block: fpn_layer4
		inner_block_module = conv_block(in_channels=2048, out_channels=1024, 1)

			conv_with_kaiming_uniform().make_conv() ====== BEGIN
				Conv2d(in_channles=2048, out_channels=1024, kernel_size=1, stride=1
				       padding=0, dilation=1, bias=True,
				nn.init.kaiming_uniform_(conv.weight, a=1)
				if not use_gn:
					nn.init.constant_(conv.bias, 0)
				module = [conv,]
				return conv

			conv_with_kaiming_uniform().make_conv() ====== END

		layer_block_module = conv_block(out_channels=1024, out_channels=1024, 3,1)

			conv_with_kaiming_uniform().make_conv() ====== BEGIN
				Conv2d(in_channles=1024, out_channels=1024, kernel_size=3, stride=1
				       padding=1, dilation=1, bias=True,
				nn.init.kaiming_uniform_(conv.weight, a=1)
				if not use_gn:
					nn.init.constant_(conv.bias, 0)
				module = [conv,]
				return conv

			conv_with_kaiming_uniform().make_conv() ====== END

		self.add_module(fpn_inner4, inner_block_module)
		self.add_module(fpn_layer4, layer_block_module)
		self.inner_blocks.append(fpn_inner4)
		self.layer_blocks.append(fpn_layer4)

	self.inner_blocks: ['fpn_inner2', 'fpn_inner3', 'fpn_inner4']
		self.fpn_inner2: Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
		self.fpn_inner3: Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
		self.fpn_inner4: Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))

	self.layer_blocks: ['fpn_layer2', 'fpn_layer3', 'fpn_layer4']
		self.fpn_layer2: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
		self.fpn_layer3: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
		self.fpn_layer4: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))

	self.top_blocks: LastLevelP6P7(
  (p6): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (p7): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
)
=========================================== FPN.__init__ end



	fpn: {fpn}
	model = nn.Sequential(OrderedDict([("body", body), ("fpn", fpn)]))
	model: Sequential(
  (body): ResNet(
    (stem): StemWithFixedBatchNorm(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): FrozenBatchNorm2d()
    )
    (layer1): Sequential(
      (0): BottleneckWithFixedBatchNorm(
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): FrozenBatchNorm2d()
        )
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
      (1): BottleneckWithFixedBatchNorm(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
      (2): BottleneckWithFixedBatchNorm(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
    )
    (layer2): Sequential(
      (0): BottleneckWithFixedBatchNorm(
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): FrozenBatchNorm2d()
        )
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
      (1): BottleneckWithFixedBatchNorm(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
      (2): BottleneckWithFixedBatchNorm(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
      (3): BottleneckWithFixedBatchNorm(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
    )
    (layer3): Sequential(
      (0): BottleneckWithFixedBatchNorm(
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): FrozenBatchNorm2d()
        )
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
      (1): BottleneckWithFixedBatchNorm(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
      (2): BottleneckWithFixedBatchNorm(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
      (3): BottleneckWithFixedBatchNorm(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
      (4): BottleneckWithFixedBatchNorm(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
      (5): BottleneckWithFixedBatchNorm(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
    )
    (layer4): Sequential(
      (0): BottleneckWithFixedBatchNorm(
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): FrozenBatchNorm2d()
        )
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
      (1): BottleneckWithFixedBatchNorm(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
      (2): BottleneckWithFixedBatchNorm(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d()
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d()
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d()
      )
    )
  )
  (fpn): FPN(
    (fpn_inner2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
    (fpn_layer2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_inner3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
    (fpn_layer3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_inner4): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
    (fpn_layer4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_blocks): LastLevelP6P7(
      (p6): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
  )
)
	model.out_channels = out_channels
	model.out_channels: 1024
	return model
build_resnet_fpn_p3p7_backbone(cfg) ====== END


==== rpn build ==== 
self.backbone.out_channels: 1024
build_rpn : <function build_rpn at 0x7f338cb6ec80>
self.rpn = build_rpn(cfg, self.backbone.out_channels)


=========================================== RetinaNetModule.__init__(self, cfg, in_channels): BEGIN
	super(RetinaNetModule, self).__init__()
	self.cfg = cfg.clone()
	anchor_generator = make_anchor_generator_retinanet(cfg)

		=================   make_anchor_generator_retinanet(config) BEGIN
		config params
			anchor_sizes: (32, 64, 128, 256, 512)
			aspect_ratios: (0.5, 1.0, 2.0)
			anchor_strides: (8, 16, 32, 64, 128)
			straddle_thresh: -1
			octave: 2.0
			scales_per_octave: 3
		new_anchor_sizes = []
		for size in anchor_sizes:
			size: 32
			per_layer_anchor_sizes = []
			for scale_per_octave in range(scales_per_octave):
				octave : 2.0
				octave : 0
				octave_scale = octave ** (scale_per_octave / float(scales_per_octave))
				octave_scale: 1.0
				size: 32
				per_layer_anchor_sizes.append(octave_scale * size)
				per_layer_anchor_sizes: [32.0]
				octave : 2.0
				octave : 1
				octave_scale = octave ** (scale_per_octave / float(scales_per_octave))
				octave_scale: 1.2599210498948732
				size: 32
				per_layer_anchor_sizes.append(octave_scale * size)
				per_layer_anchor_sizes: [32.0, 40.31747359663594]
				octave : 2.0
				octave : 2
				octave_scale = octave ** (scale_per_octave / float(scales_per_octave))
				octave_scale: 1.5874010519681994
				size: 32
				per_layer_anchor_sizes.append(octave_scale * size)
				per_layer_anchor_sizes: [32.0, 40.31747359663594, 50.79683366298238]
			new_anchor_sizes.append(tuple(per_layer_anchor_sizes))
			new_anchor_sizes: [(32.0, 40.31747359663594, 50.79683366298238)]
			size: 64
			per_layer_anchor_sizes = []
			for scale_per_octave in range(scales_per_octave):
				octave : 2.0
				octave : 0
				octave_scale = octave ** (scale_per_octave / float(scales_per_octave))
				octave_scale: 1.0
				size: 64
				per_layer_anchor_sizes.append(octave_scale * size)
				per_layer_anchor_sizes: [64.0]
				octave : 2.0
				octave : 1
				octave_scale = octave ** (scale_per_octave / float(scales_per_octave))
				octave_scale: 1.2599210498948732
				size: 64
				per_layer_anchor_sizes.append(octave_scale * size)
				per_layer_anchor_sizes: [64.0, 80.63494719327188]
				octave : 2.0
				octave : 2
				octave_scale = octave ** (scale_per_octave / float(scales_per_octave))
				octave_scale: 1.5874010519681994
				size: 64
				per_layer_anchor_sizes.append(octave_scale * size)
				per_layer_anchor_sizes: [64.0, 80.63494719327188, 101.59366732596476]
			new_anchor_sizes.append(tuple(per_layer_anchor_sizes))
			new_anchor_sizes: [(32.0, 40.31747359663594, 50.79683366298238), (64.0, 80.63494719327188, 101.59366732596476)]
			size: 128
			per_layer_anchor_sizes = []
			for scale_per_octave in range(scales_per_octave):
				octave : 2.0
				octave : 0
				octave_scale = octave ** (scale_per_octave / float(scales_per_octave))
				octave_scale: 1.0
				size: 128
				per_layer_anchor_sizes.append(octave_scale * size)
				per_layer_anchor_sizes: [128.0]
				octave : 2.0
				octave : 1
				octave_scale = octave ** (scale_per_octave / float(scales_per_octave))
				octave_scale: 1.2599210498948732
				size: 128
				per_layer_anchor_sizes.append(octave_scale * size)
				per_layer_anchor_sizes: [128.0, 161.26989438654377]
				octave : 2.0
				octave : 2
				octave_scale = octave ** (scale_per_octave / float(scales_per_octave))
				octave_scale: 1.5874010519681994
				size: 128
				per_layer_anchor_sizes.append(octave_scale * size)
				per_layer_anchor_sizes: [128.0, 161.26989438654377, 203.18733465192952]
			new_anchor_sizes.append(tuple(per_layer_anchor_sizes))
			new_anchor_sizes: [(32.0, 40.31747359663594, 50.79683366298238), (64.0, 80.63494719327188, 101.59366732596476), (128.0, 161.26989438654377, 203.18733465192952)]
			size: 256
			per_layer_anchor_sizes = []
			for scale_per_octave in range(scales_per_octave):
				octave : 2.0
				octave : 0
				octave_scale = octave ** (scale_per_octave / float(scales_per_octave))
				octave_scale: 1.0
				size: 256
				per_layer_anchor_sizes.append(octave_scale * size)
				per_layer_anchor_sizes: [256.0]
				octave : 2.0
				octave : 1
				octave_scale = octave ** (scale_per_octave / float(scales_per_octave))
				octave_scale: 1.2599210498948732
				size: 256
				per_layer_anchor_sizes.append(octave_scale * size)
				per_layer_anchor_sizes: [256.0, 322.53978877308754]
				octave : 2.0
				octave : 2
				octave_scale = octave ** (scale_per_octave / float(scales_per_octave))
				octave_scale: 1.5874010519681994
				size: 256
				per_layer_anchor_sizes.append(octave_scale * size)
				per_layer_anchor_sizes: [256.0, 322.53978877308754, 406.37466930385904]
			new_anchor_sizes.append(tuple(per_layer_anchor_sizes))
			new_anchor_sizes: [(32.0, 40.31747359663594, 50.79683366298238), (64.0, 80.63494719327188, 101.59366732596476), (128.0, 161.26989438654377, 203.18733465192952), (256.0, 322.53978877308754, 406.37466930385904)]
			size: 512
			per_layer_anchor_sizes = []
			for scale_per_octave in range(scales_per_octave):
				octave : 2.0
				octave : 0
				octave_scale = octave ** (scale_per_octave / float(scales_per_octave))
				octave_scale: 1.0
				size: 512
				per_layer_anchor_sizes.append(octave_scale * size)
				per_layer_anchor_sizes: [512.0]
				octave : 2.0
				octave : 1
				octave_scale = octave ** (scale_per_octave / float(scales_per_octave))
				octave_scale: 1.2599210498948732
				size: 512
				per_layer_anchor_sizes.append(octave_scale * size)
				per_layer_anchor_sizes: [512.0, 645.0795775461751]
				octave : 2.0
				octave : 2
				octave_scale = octave ** (scale_per_octave / float(scales_per_octave))
				octave_scale: 1.5874010519681994
				size: 512
				per_layer_anchor_sizes.append(octave_scale * size)
				per_layer_anchor_sizes: [512.0, 645.0795775461751, 812.7493386077181]
			new_anchor_sizes.append(tuple(per_layer_anchor_sizes))
			new_anchor_sizes: [(32.0, 40.31747359663594, 50.79683366298238), (64.0, 80.63494719327188, 101.59366732596476), (128.0, 161.26989438654377, 203.18733465192952), (256.0, 322.53978877308754, 406.37466930385904), (512.0, 645.0795775461751, 812.7493386077181)]
		new_anchor_sizes:
			[(32.0, 40.31747359663594, 50.79683366298238), (64.0, 80.63494719327188, 101.59366732596476), (128.0, 161.26989438654377, 203.18733465192952), (256.0, 322.53978877308754, 406.37466930385904), (512.0, 645.0795775461751, 812.7493386077181)]
		aspect_ratios:
			(0.5, 1.0, 2.0)
		anchor_strides:
			(8, 16, 32, 64, 128)
		straddle_thresh:
			-1
		anchor_generator = AnchorGenerator( tuple(new_anchor_sizes), aspect_ratios, anchor_strides, straddle_thresh )
		=================   AnchorGenerator.__init__(sizes, apect_ratios, anchor_strides, straddle_thresh) BEGIN
			Params
				sizes: ((32.0, 40.31747359663594, 50.79683366298238), (64.0, 80.63494719327188, 101.59366732596476), (128.0, 161.26989438654377, 203.18733465192952), (256.0, 322.53978877308754, 406.37466930385904), (512.0, 645.0795775461751, 812.7493386077181))
				aspect_ratios: (0.5, 1.0, 2.0)
				anchor_strides: (8, 16, 32, 64, 128)
				straddle_thresh: -1
		else: i.e, len(anchor_strides) !=1 
			anchor_stride = anchor_strides[0]
			len(anchor_strides):5, len(size): 5
		else: i.e, len(anchor_strides) == len(sizes) 
		cell_anchors = [ generate_anchors( anchor_stride, size if isinstance(size, (tuple, list)) else (size,), aspect_ratios ).float()
		                 for anchor_stride, size in zip(anchor_strides, sizes)
=================   generate_anchors(stride, sizes, apect_ratios) BEGIN
	Params:
		stride: 8
		sizes: (32.0, 40.31747359663594, 50.79683366298238)
		aspect_ratios: (0.5, 1.0, 2.0)
return _generate_anchors(stride, 
     np.array(sizes, dtype=np.float) / stride,
     np.array(aspect_ratios, dtype=np.float),
=================   generate_anchors(stride, sizes, apect_ratios) END
=================   _generate_anchors(base_size, scales, apect_ratios) BEGIN
=================   _ratio_enum(anchor, ratios) BEGIN
	Param:
		anchor: [0. 0. 7. 7.]
		ratios: [0.5 1.  2. ]
=================   _whctrs(anchors) BEGIN
	Param:
		anchor: [0. 0. 7. 7.]
return w, h, x_ctr, y_ctr
=================   _whctrs(anchors) END
=================   _mkanchors(ws, hs, x_ctr, y_ctr) BEGIN
	Param:
		ws: [11.  8.  6.]
		hs: [ 6.  8. 12.]
		x_ctr: 3.5
		y_ctr: 3.5
anchors: [[-1.5  1.   8.5  6. ]
 [ 0.   0.   7.   7. ]
 [ 1.  -2.   6.   9. ]]
return anchors
=================   _mkanchors(ws, hs, x_ctr, y_ctr) END
anchors: [[-1.5  1.   8.5  6. ]
 [ 0.   0.   7.   7. ]
 [ 1.  -2.   6.   9. ]]
return anchors
=================   _ratio_enum(anchor, ratios) END
=================   _scale_enum(anchor, scales) BEGIN
	Param:
		anchor: [-1.5  1.   8.5  6. ]
		scales: [4.         5.0396842  6.34960421]
=================   _whctrs(anchors) BEGIN
	Param:
		anchor: [-1.5  1.   8.5  6. ]
return w, h, x_ctr, y_ctr
=================   _whctrs(anchors) END
=================   _mkanchors(ws, hs, x_ctr, y_ctr) BEGIN
	Param:
		ws: [44.         55.4365262  69.84564629]
		hs: [24.         30.2381052  38.09762525]
		x_ctr: 3.5
		y_ctr: 3.5
anchors: [[-18.          -8.          25.          15.        ]
 [-23.7182631  -11.1190526   30.7182631   18.1190526 ]
 [-30.92282314 -15.04881262  37.92282314  22.04881262]]
return anchors
=================   _mkanchors(ws, hs, x_ctr, y_ctr) END
anchors: [[-18.          -8.          25.          15.        ]
 [-23.7182631  -11.1190526   30.7182631   18.1190526 ]
 [-30.92282314 -15.04881262  37.92282314  22.04881262]]
=================   _scale_enum(anchor, scales) END
=================   _scale_enum(anchor, scales) BEGIN
	Param:
		anchor: [0. 0. 7. 7.]
		scales: [4.         5.0396842  6.34960421]
=================   _whctrs(anchors) BEGIN
	Param:
		anchor: [0. 0. 7. 7.]
return w, h, x_ctr, y_ctr
=================   _whctrs(anchors) END
=================   _mkanchors(ws, hs, x_ctr, y_ctr) BEGIN
	Param:
		ws: [32.         40.3174736  50.79683366]
		hs: [32.         40.3174736  50.79683366]
		x_ctr: 3.5
		y_ctr: 3.5
anchors: [[-12.         -12.          19.          19.        ]
 [-16.1587368  -16.1587368   23.1587368   23.1587368 ]
 [-21.39841683 -21.39841683  28.39841683  28.39841683]]
return anchors
=================   _mkanchors(ws, hs, x_ctr, y_ctr) END
anchors: [[-12.         -12.          19.          19.        ]
 [-16.1587368  -16.1587368   23.1587368   23.1587368 ]
 [-21.39841683 -21.39841683  28.39841683  28.39841683]]
=================   _scale_enum(anchor, scales) END
=================   _scale_enum(anchor, scales) BEGIN
	Param:
		anchor: [ 1. -2.  6.  9.]
		scales: [4.         5.0396842  6.34960421]
=================   _whctrs(anchors) BEGIN
	Param:
		anchor: [ 1. -2.  6.  9.]
return w, h, x_ctr, y_ctr
=================   _whctrs(anchors) END
=================   _mkanchors(ws, hs, x_ctr, y_ctr) BEGIN
	Param:
		ws: [24.         30.2381052  38.09762525]
		hs: [48.         60.47621039 76.19525049]
		x_ctr: 3.5
		y_ctr: 3.5
anchors: [[ -8.         -20.          15.          27.        ]
 [-11.1190526  -26.2381052   18.1190526   33.2381052 ]
 [-15.04881262 -34.09762525  22.04881262  41.09762525]]
return anchors
=================   _mkanchors(ws, hs, x_ctr, y_ctr) END
anchors: [[ -8.         -20.          15.          27.        ]
 [-11.1190526  -26.2381052   18.1190526   33.2381052 ]
 [-15.04881262 -34.09762525  22.04881262  41.09762525]]
=================   _scale_enum(anchor, scales) END
return torch.from_numpy(anchors)
=================   _generate_anchors(base_size, scales, apect_ratios) END
=================   generate_anchors(stride, sizes, apect_ratios) BEGIN
	Params:
		stride: 16
		sizes: (64.0, 80.63494719327188, 101.59366732596476)
		aspect_ratios: (0.5, 1.0, 2.0)
return _generate_anchors(stride, 
     np.array(sizes, dtype=np.float) / stride,
     np.array(aspect_ratios, dtype=np.float),
=================   generate_anchors(stride, sizes, apect_ratios) END
=================   _generate_anchors(base_size, scales, apect_ratios) BEGIN
=================   _ratio_enum(anchor, ratios) BEGIN
	Param:
		anchor: [ 0.  0. 15. 15.]
		ratios: [0.5 1.  2. ]
=================   _whctrs(anchors) BEGIN
	Param:
		anchor: [ 0.  0. 15. 15.]
return w, h, x_ctr, y_ctr
=================   _whctrs(anchors) END
=================   _mkanchors(ws, hs, x_ctr, y_ctr) BEGIN
	Param:
		ws: [23. 16. 11.]
		hs: [12. 16. 22.]
		x_ctr: 7.5
		y_ctr: 7.5
anchors: [[-3.5  2.  18.5 13. ]
 [ 0.   0.  15.  15. ]
 [ 2.5 -3.  12.5 18. ]]
return anchors
=================   _mkanchors(ws, hs, x_ctr, y_ctr) END
anchors: [[-3.5  2.  18.5 13. ]
 [ 0.   0.  15.  15. ]
 [ 2.5 -3.  12.5 18. ]]
return anchors
=================   _ratio_enum(anchor, ratios) END
=================   _scale_enum(anchor, scales) BEGIN
	Param:
		anchor: [-3.5  2.  18.5 13. ]
		scales: [4.         5.0396842  6.34960421]
=================   _whctrs(anchors) BEGIN
	Param:
		anchor: [-3.5  2.  18.5 13. ]
return w, h, x_ctr, y_ctr
=================   _whctrs(anchors) END
=================   _mkanchors(ws, hs, x_ctr, y_ctr) BEGIN
	Param:
		ws: [ 92.         115.91273659 146.04089678]
		hs: [48.         60.47621039 76.19525049]
		x_ctr: 7.5
		y_ctr: 7.5
anchors: [[-38.         -16.          53.          31.        ]
 [-49.9563683  -22.2381052   64.9563683   37.2381052 ]
 [-65.02044839 -30.09762525  80.02044839  45.09762525]]
return anchors
=================   _mkanchors(ws, hs, x_ctr, y_ctr) END
anchors: [[-38.         -16.          53.          31.        ]
 [-49.9563683  -22.2381052   64.9563683   37.2381052 ]
 [-65.02044839 -30.09762525  80.02044839  45.09762525]]
=================   _scale_enum(anchor, scales) END
=================   _scale_enum(anchor, scales) BEGIN
	Param:
		anchor: [ 0.  0. 15. 15.]
		scales: [4.         5.0396842  6.34960421]
=================   _whctrs(anchors) BEGIN
	Param:
		anchor: [ 0.  0. 15. 15.]
return w, h, x_ctr, y_ctr
=================   _whctrs(anchors) END
=================   _mkanchors(ws, hs, x_ctr, y_ctr) BEGIN
	Param:
		ws: [ 64.          80.63494719 101.59366733]
		hs: [ 64.          80.63494719 101.59366733]
		x_ctr: 7.5
		y_ctr: 7.5
anchors: [[-24.         -24.          39.          39.        ]
 [-32.3174736  -32.3174736   47.3174736   47.3174736 ]
 [-42.79683366 -42.79683366  57.79683366  57.79683366]]
return anchors
=================   _mkanchors(ws, hs, x_ctr, y_ctr) END
anchors: [[-24.         -24.          39.          39.        ]
 [-32.3174736  -32.3174736   47.3174736   47.3174736 ]
 [-42.79683366 -42.79683366  57.79683366  57.79683366]]
=================   _scale_enum(anchor, scales) END
=================   _scale_enum(anchor, scales) BEGIN
	Param:
		anchor: [ 2.5 -3.  12.5 18. ]
		scales: [4.         5.0396842  6.34960421]
=================   _whctrs(anchors) BEGIN
	Param:
		anchor: [ 2.5 -3.  12.5 18. ]
return w, h, x_ctr, y_ctr
=================   _whctrs(anchors) END
=================   _mkanchors(ws, hs, x_ctr, y_ctr) BEGIN
	Param:
		ws: [44.         55.4365262  69.84564629]
		hs: [ 88.         110.87305239 139.69129257]
		x_ctr: 7.5
		y_ctr: 7.5
anchors: [[-14.         -36.          29.          51.        ]
 [-19.7182631  -47.4365262   34.7182631   62.4365262 ]
 [-26.92282314 -61.84564629  41.92282314  76.84564629]]
return anchors
=================   _mkanchors(ws, hs, x_ctr, y_ctr) END
anchors: [[-14.         -36.          29.          51.        ]
 [-19.7182631  -47.4365262   34.7182631   62.4365262 ]
 [-26.92282314 -61.84564629  41.92282314  76.84564629]]
=================   _scale_enum(anchor, scales) END
return torch.from_numpy(anchors)
=================   _generate_anchors(base_size, scales, apect_ratios) END
=================   generate_anchors(stride, sizes, apect_ratios) BEGIN
	Params:
		stride: 32
		sizes: (128.0, 161.26989438654377, 203.18733465192952)
		aspect_ratios: (0.5, 1.0, 2.0)
return _generate_anchors(stride, 
     np.array(sizes, dtype=np.float) / stride,
     np.array(aspect_ratios, dtype=np.float),
=================   generate_anchors(stride, sizes, apect_ratios) END
=================   _generate_anchors(base_size, scales, apect_ratios) BEGIN
=================   _ratio_enum(anchor, ratios) BEGIN
	Param:
		anchor: [ 0.  0. 31. 31.]
		ratios: [0.5 1.  2. ]
=================   _whctrs(anchors) BEGIN
	Param:
		anchor: [ 0.  0. 31. 31.]
return w, h, x_ctr, y_ctr
=================   _whctrs(anchors) END
=================   _mkanchors(ws, hs, x_ctr, y_ctr) BEGIN
	Param:
		ws: [45. 32. 23.]
		hs: [22. 32. 46.]
		x_ctr: 15.5
		y_ctr: 15.5
anchors: [[-6.5  5.  37.5 26. ]
 [ 0.   0.  31.  31. ]
 [ 4.5 -7.  26.5 38. ]]
return anchors
=================   _mkanchors(ws, hs, x_ctr, y_ctr) END
anchors: [[-6.5  5.  37.5 26. ]
 [ 0.   0.  31.  31. ]
 [ 4.5 -7.  26.5 38. ]]
return anchors
=================   _ratio_enum(anchor, ratios) END
=================   _scale_enum(anchor, scales) BEGIN
	Param:
		anchor: [-6.5  5.  37.5 26. ]
		scales: [4.         5.0396842  6.34960421]
=================   _whctrs(anchors) BEGIN
	Param:
		anchor: [-6.5  5.  37.5 26. ]
return w, h, x_ctr, y_ctr
=================   _whctrs(anchors) END
=================   _mkanchors(ws, hs, x_ctr, y_ctr) BEGIN
	Param:
		ws: [180.         226.78578898 285.73218935]
		hs: [ 88.         110.87305239 139.69129257]
		x_ctr: 15.5
		y_ctr: 15.5
anchors: [[ -74.          -28.          105.           59.        ]
 [ -97.39289449  -39.4365262   128.39289449   70.4365262 ]
 [-126.86609468  -53.84564629  157.86609468   84.84564629]]
return anchors
=================   _mkanchors(ws, hs, x_ctr, y_ctr) END
anchors: [[ -74.          -28.          105.           59.        ]
 [ -97.39289449  -39.4365262   128.39289449   70.4365262 ]
 [-126.86609468  -53.84564629  157.86609468   84.84564629]]
=================   _scale_enum(anchor, scales) END
=================   _scale_enum(anchor, scales) BEGIN
	Param:
		anchor: [ 0.  0. 31. 31.]
		scales: [4.         5.0396842  6.34960421]
=================   _whctrs(anchors) BEGIN
	Param:
		anchor: [ 0.  0. 31. 31.]
return w, h, x_ctr, y_ctr
=================   _whctrs(anchors) END
=================   _mkanchors(ws, hs, x_ctr, y_ctr) BEGIN
	Param:
		ws: [128.         161.26989439 203.18733465]
		hs: [128.         161.26989439 203.18733465]
		x_ctr: 15.5
		y_ctr: 15.5
anchors: [[-48.         -48.          79.          79.        ]
 [-64.63494719 -64.63494719  95.63494719  95.63494719]
 [-85.59366733 -85.59366733 116.59366733 116.59366733]]
return anchors
=================   _mkanchors(ws, hs, x_ctr, y_ctr) END
anchors: [[-48.         -48.          79.          79.        ]
 [-64.63494719 -64.63494719  95.63494719  95.63494719]
 [-85.59366733 -85.59366733 116.59366733 116.59366733]]
=================   _scale_enum(anchor, scales) END
=================   _scale_enum(anchor, scales) BEGIN
	Param:
		anchor: [ 4.5 -7.  26.5 38. ]
		scales: [4.         5.0396842  6.34960421]
=================   _whctrs(anchors) BEGIN
	Param:
		anchor: [ 4.5 -7.  26.5 38. ]
return w, h, x_ctr, y_ctr
=================   _whctrs(anchors) END
=================   _mkanchors(ws, hs, x_ctr, y_ctr) BEGIN
	Param:
		ws: [ 92.         115.91273659 146.04089678]
		hs: [184.         231.82547318 292.08179356]
		x_ctr: 15.5
		y_ctr: 15.5
anchors: [[ -30.          -76.           61.          107.        ]
 [ -41.9563683   -99.91273659   72.9563683   130.91273659]
 [ -57.02044839 -130.04089678   88.02044839  161.04089678]]
return anchors
=================   _mkanchors(ws, hs, x_ctr, y_ctr) END
anchors: [[ -30.          -76.           61.          107.        ]
 [ -41.9563683   -99.91273659   72.9563683   130.91273659]
 [ -57.02044839 -130.04089678   88.02044839  161.04089678]]
=================   _scale_enum(anchor, scales) END
return torch.from_numpy(anchors)
=================   _generate_anchors(base_size, scales, apect_ratios) END
=================   generate_anchors(stride, sizes, apect_ratios) BEGIN
	Params:
		stride: 64
		sizes: (256.0, 322.53978877308754, 406.37466930385904)
		aspect_ratios: (0.5, 1.0, 2.0)
return _generate_anchors(stride, 
     np.array(sizes, dtype=np.float) / stride,
     np.array(aspect_ratios, dtype=np.float),
=================   generate_anchors(stride, sizes, apect_ratios) END
=================   _generate_anchors(base_size, scales, apect_ratios) BEGIN
=================   _ratio_enum(anchor, ratios) BEGIN
	Param:
		anchor: [ 0.  0. 63. 63.]
		ratios: [0.5 1.  2. ]
=================   _whctrs(anchors) BEGIN
	Param:
		anchor: [ 0.  0. 63. 63.]
return w, h, x_ctr, y_ctr
=================   _whctrs(anchors) END
=================   _mkanchors(ws, hs, x_ctr, y_ctr) BEGIN
	Param:
		ws: [91. 64. 45.]
		hs: [46. 64. 90.]
		x_ctr: 31.5
		y_ctr: 31.5
anchors: [[-13.5   9.   76.5  54. ]
 [  0.    0.   63.   63. ]
 [  9.5 -13.   53.5  76. ]]
return anchors
=================   _mkanchors(ws, hs, x_ctr, y_ctr) END
anchors: [[-13.5   9.   76.5  54. ]
 [  0.    0.   63.   63. ]
 [  9.5 -13.   53.5  76. ]]
return anchors
=================   _ratio_enum(anchor, ratios) END
=================   _scale_enum(anchor, scales) BEGIN
	Param:
		anchor: [-13.5   9.   76.5  54. ]
		scales: [4.         5.0396842  6.34960421]
=================   _whctrs(anchors) BEGIN
	Param:
		anchor: [-13.5   9.   76.5  54. ]
return w, h, x_ctr, y_ctr
=================   _whctrs(anchors) END
=================   _mkanchors(ws, hs, x_ctr, y_ctr) BEGIN
	Param:
		ws: [364.         458.61126216 577.81398292]
		hs: [184.         231.82547318 292.08179356]
		x_ctr: 31.5
		y_ctr: 31.5
anchors: [[-150.          -60.          213.          123.        ]
 [-197.30563108  -83.91273659  260.30563108  146.91273659]
 [-256.90699146 -114.04089678  319.90699146  177.04089678]]
return anchors
=================   _mkanchors(ws, hs, x_ctr, y_ctr) END
anchors: [[-150.          -60.          213.          123.        ]
 [-197.30563108  -83.91273659  260.30563108  146.91273659]
 [-256.90699146 -114.04089678  319.90699146  177.04089678]]
=================   _scale_enum(anchor, scales) END
=================   _scale_enum(anchor, scales) BEGIN
	Param:
		anchor: [ 0.  0. 63. 63.]
		scales: [4.         5.0396842  6.34960421]
=================   _whctrs(anchors) BEGIN
	Param:
		anchor: [ 0.  0. 63. 63.]
return w, h, x_ctr, y_ctr
=================   _whctrs(anchors) END
=================   _mkanchors(ws, hs, x_ctr, y_ctr) BEGIN
	Param:
		ws: [256.         322.53978877 406.3746693 ]
		hs: [256.         322.53978877 406.3746693 ]
		x_ctr: 31.5
		y_ctr: 31.5
anchors: [[ -96.          -96.          159.          159.        ]
 [-129.26989439 -129.26989439  192.26989439  192.26989439]
 [-171.18733465 -171.18733465  234.18733465  234.18733465]]
return anchors
=================   _mkanchors(ws, hs, x_ctr, y_ctr) END
anchors: [[ -96.          -96.          159.          159.        ]
 [-129.26989439 -129.26989439  192.26989439  192.26989439]
 [-171.18733465 -171.18733465  234.18733465  234.18733465]]
=================   _scale_enum(anchor, scales) END
=================   _scale_enum(anchor, scales) BEGIN
	Param:
		anchor: [  9.5 -13.   53.5  76. ]
		scales: [4.         5.0396842  6.34960421]
=================   _whctrs(anchors) BEGIN
	Param:
		anchor: [  9.5 -13.   53.5  76. ]
return w, h, x_ctr, y_ctr
=================   _whctrs(anchors) END
=================   _mkanchors(ws, hs, x_ctr, y_ctr) BEGIN
	Param:
		ws: [180.         226.78578898 285.73218935]
		hs: [360.         453.57157796 571.46437871]
		x_ctr: 31.5
		y_ctr: 31.5
anchors: [[ -58.         -148.          121.          211.        ]
 [ -81.39289449 -194.78578898  144.39289449  257.78578898]
 [-110.86609468 -253.73218935  173.86609468  316.73218935]]
return anchors
=================   _mkanchors(ws, hs, x_ctr, y_ctr) END
anchors: [[ -58.         -148.          121.          211.        ]
 [ -81.39289449 -194.78578898  144.39289449  257.78578898]
 [-110.86609468 -253.73218935  173.86609468  316.73218935]]
=================   _scale_enum(anchor, scales) END
return torch.from_numpy(anchors)
=================   _generate_anchors(base_size, scales, apect_ratios) END
=================   generate_anchors(stride, sizes, apect_ratios) BEGIN
	Params:
		stride: 128
		sizes: (512.0, 645.0795775461751, 812.7493386077181)
		aspect_ratios: (0.5, 1.0, 2.0)
return _generate_anchors(stride, 
     np.array(sizes, dtype=np.float) / stride,
     np.array(aspect_ratios, dtype=np.float),
=================   generate_anchors(stride, sizes, apect_ratios) END
=================   _generate_anchors(base_size, scales, apect_ratios) BEGIN
=================   _ratio_enum(anchor, ratios) BEGIN
	Param:
		anchor: [  0.   0. 127. 127.]
		ratios: [0.5 1.  2. ]
=================   _whctrs(anchors) BEGIN
	Param:
		anchor: [  0.   0. 127. 127.]
return w, h, x_ctr, y_ctr
=================   _whctrs(anchors) END
=================   _mkanchors(ws, hs, x_ctr, y_ctr) BEGIN
	Param:
		ws: [181. 128.  91.]
		hs: [ 90. 128. 182.]
		x_ctr: 63.5
		y_ctr: 63.5
anchors: [[-26.5  19.  153.5 108. ]
 [  0.    0.  127.  127. ]
 [ 18.5 -27.  108.5 154. ]]
return anchors
=================   _mkanchors(ws, hs, x_ctr, y_ctr) END
anchors: [[-26.5  19.  153.5 108. ]
 [  0.    0.  127.  127. ]
 [ 18.5 -27.  108.5 154. ]]
return anchors
=================   _ratio_enum(anchor, ratios) END
=================   _scale_enum(anchor, scales) BEGIN
	Param:
		anchor: [-26.5  19.  153.5 108. ]
		scales: [4.         5.0396842  6.34960421]
=================   _whctrs(anchors) BEGIN
	Param:
		anchor: [-26.5  19.  153.5 108. ]
return w, h, x_ctr, y_ctr
=================   _whctrs(anchors) END
=================   _mkanchors(ws, hs, x_ctr, y_ctr) BEGIN
	Param:
		ws: [ 724.          912.18284012 1149.27836162]
		hs: [360.         453.57157796 571.46437871]
		x_ctr: 63.5
		y_ctr: 63.5
anchors: [[-298.         -116.          425.          243.        ]
 [-392.09142006 -162.78578898  519.09142006  289.78578898]
 [-510.63918081 -221.73218935  637.63918081  348.73218935]]
return anchors
=================   _mkanchors(ws, hs, x_ctr, y_ctr) END
anchors: [[-298.         -116.          425.          243.        ]
 [-392.09142006 -162.78578898  519.09142006  289.78578898]
 [-510.63918081 -221.73218935  637.63918081  348.73218935]]
=================   _scale_enum(anchor, scales) END
=================   _scale_enum(anchor, scales) BEGIN
	Param:
		anchor: [  0.   0. 127. 127.]
		scales: [4.         5.0396842  6.34960421]
=================   _whctrs(anchors) BEGIN
	Param:
		anchor: [  0.   0. 127. 127.]
return w, h, x_ctr, y_ctr
=================   _whctrs(anchors) END
=================   _mkanchors(ws, hs, x_ctr, y_ctr) BEGIN
	Param:
		ws: [512.         645.07957755 812.74933861]
		hs: [512.         645.07957755 812.74933861]
		x_ctr: 63.5
		y_ctr: 63.5
anchors: [[-192.         -192.          319.          319.        ]
 [-258.53978877 -258.53978877  385.53978877  385.53978877]
 [-342.3746693  -342.3746693   469.3746693   469.3746693 ]]
return anchors
=================   _mkanchors(ws, hs, x_ctr, y_ctr) END
anchors: [[-192.         -192.          319.          319.        ]
 [-258.53978877 -258.53978877  385.53978877  385.53978877]
 [-342.3746693  -342.3746693   469.3746693   469.3746693 ]]
=================   _scale_enum(anchor, scales) END
=================   _scale_enum(anchor, scales) BEGIN
	Param:
		anchor: [ 18.5 -27.  108.5 154. ]
		scales: [4.         5.0396842  6.34960421]
=================   _whctrs(anchors) BEGIN
	Param:
		anchor: [ 18.5 -27.  108.5 154. ]
return w, h, x_ctr, y_ctr
=================   _whctrs(anchors) END
=================   _mkanchors(ws, hs, x_ctr, y_ctr) BEGIN
	Param:
		ws: [364.         458.61126216 577.81398292]
		hs: [ 728.          917.22252432 1155.62796583]
		x_ctr: 63.5
		y_ctr: 63.5
anchors: [[-118.         -300.          245.          427.        ]
 [-165.30563108 -394.61126216  292.30563108  521.61126216]
 [-224.90699146 -513.81398292  351.90699146  640.81398292]]
return anchors
=================   _mkanchors(ws, hs, x_ctr, y_ctr) END
anchors: [[-118.         -300.          245.          427.        ]
 [-165.30563108 -394.61126216  292.30563108  521.61126216]
 [-224.90699146 -513.81398292  351.90699146  640.81398292]]
=================   _scale_enum(anchor, scales) END
return torch.from_numpy(anchors)
=================   _generate_anchors(base_size, scales, apect_ratios) END
cell_anchors: [tensor([[-18.0000,  -8.0000,  25.0000,  15.0000],
        [-23.7183, -11.1191,  30.7183,  18.1191],
        [-30.9228, -15.0488,  37.9228,  22.0488],
        [-12.0000, -12.0000,  19.0000,  19.0000],
        [-16.1587, -16.1587,  23.1587,  23.1587],
        [-21.3984, -21.3984,  28.3984,  28.3984],
        [ -8.0000, -20.0000,  15.0000,  27.0000],
        [-11.1191, -26.2381,  18.1191,  33.2381],
        [-15.0488, -34.0976,  22.0488,  41.0976]]), tensor([[-38.0000, -16.0000,  53.0000,  31.0000],
        [-49.9564, -22.2381,  64.9564,  37.2381],
        [-65.0204, -30.0976,  80.0204,  45.0976],
        [-24.0000, -24.0000,  39.0000,  39.0000],
        [-32.3175, -32.3175,  47.3175,  47.3175],
        [-42.7968, -42.7968,  57.7968,  57.7968],
        [-14.0000, -36.0000,  29.0000,  51.0000],
        [-19.7183, -47.4365,  34.7183,  62.4365],
        [-26.9228, -61.8456,  41.9228,  76.8456]]), tensor([[ -74.0000,  -28.0000,  105.0000,   59.0000],
        [ -97.3929,  -39.4365,  128.3929,   70.4365],
        [-126.8661,  -53.8456,  157.8661,   84.8456],
        [ -48.0000,  -48.0000,   79.0000,   79.0000],
        [ -64.6349,  -64.6349,   95.6349,   95.6349],
        [ -85.5937,  -85.5937,  116.5937,  116.5937],
        [ -30.0000,  -76.0000,   61.0000,  107.0000],
        [ -41.9564,  -99.9127,   72.9564,  130.9127],
        [ -57.0204, -130.0409,   88.0204,  161.0409]]), tensor([[-150.0000,  -60.0000,  213.0000,  123.0000],
        [-197.3056,  -83.9127,  260.3056,  146.9127],
        [-256.9070, -114.0409,  319.9070,  177.0409],
        [ -96.0000,  -96.0000,  159.0000,  159.0000],
        [-129.2699, -129.2699,  192.2699,  192.2699],
        [-171.1873, -171.1873,  234.1873,  234.1873],
        [ -58.0000, -148.0000,  121.0000,  211.0000],
        [ -81.3929, -194.7858,  144.3929,  257.7858],
        [-110.8661, -253.7322,  173.8661,  316.7322]]), tensor([[-298.0000, -116.0000,  425.0000,  243.0000],
        [-392.0914, -162.7858,  519.0914,  289.7858],
        [-510.6392, -221.7322,  637.6392,  348.7322],
        [-192.0000, -192.0000,  319.0000,  319.0000],
        [-258.5398, -258.5398,  385.5398,  385.5398],
        [-342.3747, -342.3747,  469.3747,  469.3747],
        [-118.0000, -300.0000,  245.0000,  427.0000],
        [-165.3056, -394.6113,  292.3056,  521.6113],
        [-224.9070, -513.8140,  351.9070,  640.8140]])]
	self.strides: (8, 16, 32, 64, 128)
	self.cel_anchors: BufferList()
	self.straddle_thresh: -1
=================   AnchorGenerator.__init__(sizes, apect_ratios, anchor_strides, straddle_thresh) END
		return anchor_generator
		=================   make_anchor_generator_retinanet(config) END

head = RetinaNetHead(cfg, in_channels=1024)


=========================================== RetinaNetHead._init__(cfg, in_channels): BEGIN


=========================================== RetinaNetHead._init__(cfg, in_channels): END
box_coder = BoxCoder(weights=(10., 10., 5., 5.))
box_selector_test = make_retinanet_postprocessor(cfg, box_coder)
========== RPNPostProcessing.__init__() BEGIN
========== RPNPostProcessing.__init__() END
self.anchor_generator = anchor_generator
self.head = head
self.box_selector_test = box_selector_test


=========================================== RetinaNetModule.__init__(self, cfg, in_channels): END
self.rpn: RetinaNetModule(
  (anchor_generator): AnchorGenerator(
    (cell_anchors): BufferList()
  )
  (head): RetinaNetHead(
    (cls_tower): Sequential(
      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU()
      (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU()
      (6): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU()
    )
    (bbox_tower): Sequential(
      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU()
      (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU()
      (6): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU()
    )
    (cls_logits): Conv2d(1024, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (bbox_pred): Conv2d(1024, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (box_selector_test): RetinaNetPostProcessor()
)
GeneralizedRCNN.__init(self, cfg) ====================== END
INFO:maskrcnn_benchmark.utils.checkpoint:Loading checkpoint from ./model/detection/model_det_v2_200924_002_180k.pth
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.bn1.bias                  loaded from backbone.body.layer1.0.bn1.bias                  of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.bn1.running_mean          loaded from backbone.body.layer1.0.bn1.running_mean          of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.bn1.running_var           loaded from backbone.body.layer1.0.bn1.running_var           of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.bn1.weight                loaded from backbone.body.layer1.0.bn1.weight                of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.bn2.bias                  loaded from backbone.body.layer1.0.bn2.bias                  of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.bn2.running_mean          loaded from backbone.body.layer1.0.bn2.running_mean          of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.bn2.running_var           loaded from backbone.body.layer1.0.bn2.running_var           of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.bn2.weight                loaded from backbone.body.layer1.0.bn2.weight                of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.bn3.bias                  loaded from backbone.body.layer1.0.bn3.bias                  of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.bn3.running_mean          loaded from backbone.body.layer1.0.bn3.running_mean          of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.bn3.running_var           loaded from backbone.body.layer1.0.bn3.running_var           of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.bn3.weight                loaded from backbone.body.layer1.0.bn3.weight                of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.conv1.weight              loaded from backbone.body.layer1.0.conv1.weight              of shape (64, 64, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.conv2.weight              loaded from backbone.body.layer1.0.conv2.weight              of shape (64, 64, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.conv3.weight              loaded from backbone.body.layer1.0.conv3.weight              of shape (256, 64, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.downsample.0.weight       loaded from backbone.body.layer1.0.downsample.0.weight       of shape (256, 64, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.downsample.1.bias         loaded from backbone.body.layer1.0.downsample.1.bias         of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.downsample.1.running_mean loaded from backbone.body.layer1.0.downsample.1.running_mean of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.downsample.1.running_var  loaded from backbone.body.layer1.0.downsample.1.running_var  of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.downsample.1.weight       loaded from backbone.body.layer1.0.downsample.1.weight       of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.bn1.bias                  loaded from backbone.body.layer1.1.bn1.bias                  of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.bn1.running_mean          loaded from backbone.body.layer1.1.bn1.running_mean          of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.bn1.running_var           loaded from backbone.body.layer1.1.bn1.running_var           of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.bn1.weight                loaded from backbone.body.layer1.1.bn1.weight                of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.bn2.bias                  loaded from backbone.body.layer1.1.bn2.bias                  of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.bn2.running_mean          loaded from backbone.body.layer1.1.bn2.running_mean          of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.bn2.running_var           loaded from backbone.body.layer1.1.bn2.running_var           of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.bn2.weight                loaded from backbone.body.layer1.1.bn2.weight                of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.bn3.bias                  loaded from backbone.body.layer1.1.bn3.bias                  of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.bn3.running_mean          loaded from backbone.body.layer1.1.bn3.running_mean          of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.bn3.running_var           loaded from backbone.body.layer1.1.bn3.running_var           of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.bn3.weight                loaded from backbone.body.layer1.1.bn3.weight                of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.conv1.weight              loaded from backbone.body.layer1.1.conv1.weight              of shape (64, 256, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.conv2.weight              loaded from backbone.body.layer1.1.conv2.weight              of shape (64, 64, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.conv3.weight              loaded from backbone.body.layer1.1.conv3.weight              of shape (256, 64, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.bn1.bias                  loaded from backbone.body.layer1.2.bn1.bias                  of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.bn1.running_mean          loaded from backbone.body.layer1.2.bn1.running_mean          of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.bn1.running_var           loaded from backbone.body.layer1.2.bn1.running_var           of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.bn1.weight                loaded from backbone.body.layer1.2.bn1.weight                of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.bn2.bias                  loaded from backbone.body.layer1.2.bn2.bias                  of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.bn2.running_mean          loaded from backbone.body.layer1.2.bn2.running_mean          of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.bn2.running_var           loaded from backbone.body.layer1.2.bn2.running_var           of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.bn2.weight                loaded from backbone.body.layer1.2.bn2.weight                of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.bn3.bias                  loaded from backbone.body.layer1.2.bn3.bias                  of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.bn3.running_mean          loaded from backbone.body.layer1.2.bn3.running_mean          of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.bn3.running_var           loaded from backbone.body.layer1.2.bn3.running_var           of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.bn3.weight                loaded from backbone.body.layer1.2.bn3.weight                of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.conv1.weight              loaded from backbone.body.layer1.2.conv1.weight              of shape (64, 256, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.conv2.weight              loaded from backbone.body.layer1.2.conv2.weight              of shape (64, 64, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.conv3.weight              loaded from backbone.body.layer1.2.conv3.weight              of shape (256, 64, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.bn1.bias                  loaded from backbone.body.layer2.0.bn1.bias                  of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.bn1.running_mean          loaded from backbone.body.layer2.0.bn1.running_mean          of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.bn1.running_var           loaded from backbone.body.layer2.0.bn1.running_var           of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.bn1.weight                loaded from backbone.body.layer2.0.bn1.weight                of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.bn2.bias                  loaded from backbone.body.layer2.0.bn2.bias                  of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.bn2.running_mean          loaded from backbone.body.layer2.0.bn2.running_mean          of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.bn2.running_var           loaded from backbone.body.layer2.0.bn2.running_var           of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.bn2.weight                loaded from backbone.body.layer2.0.bn2.weight                of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.bn3.bias                  loaded from backbone.body.layer2.0.bn3.bias                  of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.bn3.running_mean          loaded from backbone.body.layer2.0.bn3.running_mean          of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.bn3.running_var           loaded from backbone.body.layer2.0.bn3.running_var           of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.bn3.weight                loaded from backbone.body.layer2.0.bn3.weight                of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.conv1.weight              loaded from backbone.body.layer2.0.conv1.weight              of shape (128, 256, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.conv2.weight              loaded from backbone.body.layer2.0.conv2.weight              of shape (128, 128, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.conv3.weight              loaded from backbone.body.layer2.0.conv3.weight              of shape (512, 128, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.downsample.0.weight       loaded from backbone.body.layer2.0.downsample.0.weight       of shape (512, 256, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.downsample.1.bias         loaded from backbone.body.layer2.0.downsample.1.bias         of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.downsample.1.running_mean loaded from backbone.body.layer2.0.downsample.1.running_mean of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.downsample.1.running_var  loaded from backbone.body.layer2.0.downsample.1.running_var  of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.downsample.1.weight       loaded from backbone.body.layer2.0.downsample.1.weight       of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.bn1.bias                  loaded from backbone.body.layer2.1.bn1.bias                  of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.bn1.running_mean          loaded from backbone.body.layer2.1.bn1.running_mean          of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.bn1.running_var           loaded from backbone.body.layer2.1.bn1.running_var           of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.bn1.weight                loaded from backbone.body.layer2.1.bn1.weight                of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.bn2.bias                  loaded from backbone.body.layer2.1.bn2.bias                  of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.bn2.running_mean          loaded from backbone.body.layer2.1.bn2.running_mean          of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.bn2.running_var           loaded from backbone.body.layer2.1.bn2.running_var           of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.bn2.weight                loaded from backbone.body.layer2.1.bn2.weight                of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.bn3.bias                  loaded from backbone.body.layer2.1.bn3.bias                  of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.bn3.running_mean          loaded from backbone.body.layer2.1.bn3.running_mean          of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.bn3.running_var           loaded from backbone.body.layer2.1.bn3.running_var           of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.bn3.weight                loaded from backbone.body.layer2.1.bn3.weight                of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.conv1.weight              loaded from backbone.body.layer2.1.conv1.weight              of shape (128, 512, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.conv2.weight              loaded from backbone.body.layer2.1.conv2.weight              of shape (128, 128, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.conv3.weight              loaded from backbone.body.layer2.1.conv3.weight              of shape (512, 128, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.bn1.bias                  loaded from backbone.body.layer2.2.bn1.bias                  of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.bn1.running_mean          loaded from backbone.body.layer2.2.bn1.running_mean          of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.bn1.running_var           loaded from backbone.body.layer2.2.bn1.running_var           of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.bn1.weight                loaded from backbone.body.layer2.2.bn1.weight                of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.bn2.bias                  loaded from backbone.body.layer2.2.bn2.bias                  of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.bn2.running_mean          loaded from backbone.body.layer2.2.bn2.running_mean          of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.bn2.running_var           loaded from backbone.body.layer2.2.bn2.running_var           of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.bn2.weight                loaded from backbone.body.layer2.2.bn2.weight                of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.bn3.bias                  loaded from backbone.body.layer2.2.bn3.bias                  of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.bn3.running_mean          loaded from backbone.body.layer2.2.bn3.running_mean          of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.bn3.running_var           loaded from backbone.body.layer2.2.bn3.running_var           of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.bn3.weight                loaded from backbone.body.layer2.2.bn3.weight                of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.conv1.weight              loaded from backbone.body.layer2.2.conv1.weight              of shape (128, 512, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.conv2.weight              loaded from backbone.body.layer2.2.conv2.weight              of shape (128, 128, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.conv3.weight              loaded from backbone.body.layer2.2.conv3.weight              of shape (512, 128, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.bn1.bias                  loaded from backbone.body.layer2.3.bn1.bias                  of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.bn1.running_mean          loaded from backbone.body.layer2.3.bn1.running_mean          of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.bn1.running_var           loaded from backbone.body.layer2.3.bn1.running_var           of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.bn1.weight                loaded from backbone.body.layer2.3.bn1.weight                of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.bn2.bias                  loaded from backbone.body.layer2.3.bn2.bias                  of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.bn2.running_mean          loaded from backbone.body.layer2.3.bn2.running_mean          of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.bn2.running_var           loaded from backbone.body.layer2.3.bn2.running_var           of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.bn2.weight                loaded from backbone.body.layer2.3.bn2.weight                of shape (128,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.bn3.bias                  loaded from backbone.body.layer2.3.bn3.bias                  of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.bn3.running_mean          loaded from backbone.body.layer2.3.bn3.running_mean          of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.bn3.running_var           loaded from backbone.body.layer2.3.bn3.running_var           of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.bn3.weight                loaded from backbone.body.layer2.3.bn3.weight                of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.conv1.weight              loaded from backbone.body.layer2.3.conv1.weight              of shape (128, 512, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.conv2.weight              loaded from backbone.body.layer2.3.conv2.weight              of shape (128, 128, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.conv3.weight              loaded from backbone.body.layer2.3.conv3.weight              of shape (512, 128, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.bn1.bias                  loaded from backbone.body.layer3.0.bn1.bias                  of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.bn1.running_mean          loaded from backbone.body.layer3.0.bn1.running_mean          of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.bn1.running_var           loaded from backbone.body.layer3.0.bn1.running_var           of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.bn1.weight                loaded from backbone.body.layer3.0.bn1.weight                of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.bn2.bias                  loaded from backbone.body.layer3.0.bn2.bias                  of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.bn2.running_mean          loaded from backbone.body.layer3.0.bn2.running_mean          of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.bn2.running_var           loaded from backbone.body.layer3.0.bn2.running_var           of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.bn2.weight                loaded from backbone.body.layer3.0.bn2.weight                of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.bn3.bias                  loaded from backbone.body.layer3.0.bn3.bias                  of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.bn3.running_mean          loaded from backbone.body.layer3.0.bn3.running_mean          of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.bn3.running_var           loaded from backbone.body.layer3.0.bn3.running_var           of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.bn3.weight                loaded from backbone.body.layer3.0.bn3.weight                of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.conv1.weight              loaded from backbone.body.layer3.0.conv1.weight              of shape (256, 512, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.conv2.weight              loaded from backbone.body.layer3.0.conv2.weight              of shape (256, 256, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.conv3.weight              loaded from backbone.body.layer3.0.conv3.weight              of shape (1024, 256, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.downsample.0.weight       loaded from backbone.body.layer3.0.downsample.0.weight       of shape (1024, 512, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.downsample.1.bias         loaded from backbone.body.layer3.0.downsample.1.bias         of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.downsample.1.running_mean loaded from backbone.body.layer3.0.downsample.1.running_mean of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.downsample.1.running_var  loaded from backbone.body.layer3.0.downsample.1.running_var  of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.downsample.1.weight       loaded from backbone.body.layer3.0.downsample.1.weight       of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.bn1.bias                  loaded from backbone.body.layer3.1.bn1.bias                  of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.bn1.running_mean          loaded from backbone.body.layer3.1.bn1.running_mean          of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.bn1.running_var           loaded from backbone.body.layer3.1.bn1.running_var           of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.bn1.weight                loaded from backbone.body.layer3.1.bn1.weight                of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.bn2.bias                  loaded from backbone.body.layer3.1.bn2.bias                  of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.bn2.running_mean          loaded from backbone.body.layer3.1.bn2.running_mean          of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.bn2.running_var           loaded from backbone.body.layer3.1.bn2.running_var           of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.bn2.weight                loaded from backbone.body.layer3.1.bn2.weight                of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.bn3.bias                  loaded from backbone.body.layer3.1.bn3.bias                  of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.bn3.running_mean          loaded from backbone.body.layer3.1.bn3.running_mean          of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.bn3.running_var           loaded from backbone.body.layer3.1.bn3.running_var           of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.bn3.weight                loaded from backbone.body.layer3.1.bn3.weight                of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.conv1.weight              loaded from backbone.body.layer3.1.conv1.weight              of shape (256, 1024, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.conv2.weight              loaded from backbone.body.layer3.1.conv2.weight              of shape (256, 256, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.conv3.weight              loaded from backbone.body.layer3.1.conv3.weight              of shape (1024, 256, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.bn1.bias                  loaded from backbone.body.layer3.2.bn1.bias                  of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.bn1.running_mean          loaded from backbone.body.layer3.2.bn1.running_mean          of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.bn1.running_var           loaded from backbone.body.layer3.2.bn1.running_var           of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.bn1.weight                loaded from backbone.body.layer3.2.bn1.weight                of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.bn2.bias                  loaded from backbone.body.layer3.2.bn2.bias                  of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.bn2.running_mean          loaded from backbone.body.layer3.2.bn2.running_mean          of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.bn2.running_var           loaded from backbone.body.layer3.2.bn2.running_var           of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.bn2.weight                loaded from backbone.body.layer3.2.bn2.weight                of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.bn3.bias                  loaded from backbone.body.layer3.2.bn3.bias                  of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.bn3.running_mean          loaded from backbone.body.layer3.2.bn3.running_mean          of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.bn3.running_var           loaded from backbone.body.layer3.2.bn3.running_var           of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.bn3.weight                loaded from backbone.body.layer3.2.bn3.weight                of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.conv1.weight              loaded from backbone.body.layer3.2.conv1.weight              of shape (256, 1024, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.conv2.weight              loaded from backbone.body.layer3.2.conv2.weight              of shape (256, 256, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.conv3.weight              loaded from backbone.body.layer3.2.conv3.weight              of shape (1024, 256, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.bn1.bias                  loaded from backbone.body.layer3.3.bn1.bias                  of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.bn1.running_mean          loaded from backbone.body.layer3.3.bn1.running_mean          of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.bn1.running_var           loaded from backbone.body.layer3.3.bn1.running_var           of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.bn1.weight                loaded from backbone.body.layer3.3.bn1.weight                of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.bn2.bias                  loaded from backbone.body.layer3.3.bn2.bias                  of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.bn2.running_mean          loaded from backbone.body.layer3.3.bn2.running_mean          of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.bn2.running_var           loaded from backbone.body.layer3.3.bn2.running_var           of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.bn2.weight                loaded from backbone.body.layer3.3.bn2.weight                of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.bn3.bias                  loaded from backbone.body.layer3.3.bn3.bias                  of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.bn3.running_mean          loaded from backbone.body.layer3.3.bn3.running_mean          of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.bn3.running_var           loaded from backbone.body.layer3.3.bn3.running_var           of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.bn3.weight                loaded from backbone.body.layer3.3.bn3.weight                of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.conv1.weight              loaded from backbone.body.layer3.3.conv1.weight              of shape (256, 1024, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.conv2.weight              loaded from backbone.body.layer3.3.conv2.weight              of shape (256, 256, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.conv3.weight              loaded from backbone.body.layer3.3.conv3.weight              of shape (1024, 256, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.bn1.bias                  loaded from backbone.body.layer3.4.bn1.bias                  of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.bn1.running_mean          loaded from backbone.body.layer3.4.bn1.running_mean          of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.bn1.running_var           loaded from backbone.body.layer3.4.bn1.running_var           of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.bn1.weight                loaded from backbone.body.layer3.4.bn1.weight                of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.bn2.bias                  loaded from backbone.body.layer3.4.bn2.bias                  of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.bn2.running_mean          loaded from backbone.body.layer3.4.bn2.running_mean          of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.bn2.running_var           loaded from backbone.body.layer3.4.bn2.running_var           of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.bn2.weight                loaded from backbone.body.layer3.4.bn2.weight                of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.bn3.bias                  loaded from backbone.body.layer3.4.bn3.bias                  of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.bn3.running_mean          loaded from backbone.body.layer3.4.bn3.running_mean          of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.bn3.running_var           loaded from backbone.body.layer3.4.bn3.running_var           of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.bn3.weight                loaded from backbone.body.layer3.4.bn3.weight                of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.conv1.weight              loaded from backbone.body.layer3.4.conv1.weight              of shape (256, 1024, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.conv2.weight              loaded from backbone.body.layer3.4.conv2.weight              of shape (256, 256, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.conv3.weight              loaded from backbone.body.layer3.4.conv3.weight              of shape (1024, 256, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.bn1.bias                  loaded from backbone.body.layer3.5.bn1.bias                  of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.bn1.running_mean          loaded from backbone.body.layer3.5.bn1.running_mean          of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.bn1.running_var           loaded from backbone.body.layer3.5.bn1.running_var           of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.bn1.weight                loaded from backbone.body.layer3.5.bn1.weight                of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.bn2.bias                  loaded from backbone.body.layer3.5.bn2.bias                  of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.bn2.running_mean          loaded from backbone.body.layer3.5.bn2.running_mean          of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.bn2.running_var           loaded from backbone.body.layer3.5.bn2.running_var           of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.bn2.weight                loaded from backbone.body.layer3.5.bn2.weight                of shape (256,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.bn3.bias                  loaded from backbone.body.layer3.5.bn3.bias                  of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.bn3.running_mean          loaded from backbone.body.layer3.5.bn3.running_mean          of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.bn3.running_var           loaded from backbone.body.layer3.5.bn3.running_var           of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.bn3.weight                loaded from backbone.body.layer3.5.bn3.weight                of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.conv1.weight              loaded from backbone.body.layer3.5.conv1.weight              of shape (256, 1024, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.conv2.weight              loaded from backbone.body.layer3.5.conv2.weight              of shape (256, 256, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.conv3.weight              loaded from backbone.body.layer3.5.conv3.weight              of shape (1024, 256, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.bn1.bias                  loaded from backbone.body.layer4.0.bn1.bias                  of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.bn1.running_mean          loaded from backbone.body.layer4.0.bn1.running_mean          of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.bn1.running_var           loaded from backbone.body.layer4.0.bn1.running_var           of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.bn1.weight                loaded from backbone.body.layer4.0.bn1.weight                of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.bn2.bias                  loaded from backbone.body.layer4.0.bn2.bias                  of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.bn2.running_mean          loaded from backbone.body.layer4.0.bn2.running_mean          of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.bn2.running_var           loaded from backbone.body.layer4.0.bn2.running_var           of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.bn2.weight                loaded from backbone.body.layer4.0.bn2.weight                of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.bn3.bias                  loaded from backbone.body.layer4.0.bn3.bias                  of shape (2048,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.bn3.running_mean          loaded from backbone.body.layer4.0.bn3.running_mean          of shape (2048,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.bn3.running_var           loaded from backbone.body.layer4.0.bn3.running_var           of shape (2048,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.bn3.weight                loaded from backbone.body.layer4.0.bn3.weight                of shape (2048,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.conv1.weight              loaded from backbone.body.layer4.0.conv1.weight              of shape (512, 1024, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.conv2.weight              loaded from backbone.body.layer4.0.conv2.weight              of shape (512, 512, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.conv3.weight              loaded from backbone.body.layer4.0.conv3.weight              of shape (2048, 512, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.downsample.0.weight       loaded from backbone.body.layer4.0.downsample.0.weight       of shape (2048, 1024, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.downsample.1.bias         loaded from backbone.body.layer4.0.downsample.1.bias         of shape (2048,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.downsample.1.running_mean loaded from backbone.body.layer4.0.downsample.1.running_mean of shape (2048,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.downsample.1.running_var  loaded from backbone.body.layer4.0.downsample.1.running_var  of shape (2048,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.downsample.1.weight       loaded from backbone.body.layer4.0.downsample.1.weight       of shape (2048,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.bn1.bias                  loaded from backbone.body.layer4.1.bn1.bias                  of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.bn1.running_mean          loaded from backbone.body.layer4.1.bn1.running_mean          of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.bn1.running_var           loaded from backbone.body.layer4.1.bn1.running_var           of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.bn1.weight                loaded from backbone.body.layer4.1.bn1.weight                of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.bn2.bias                  loaded from backbone.body.layer4.1.bn2.bias                  of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.bn2.running_mean          loaded from backbone.body.layer4.1.bn2.running_mean          of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.bn2.running_var           loaded from backbone.body.layer4.1.bn2.running_var           of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.bn2.weight                loaded from backbone.body.layer4.1.bn2.weight                of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.bn3.bias                  loaded from backbone.body.layer4.1.bn3.bias                  of shape (2048,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.bn3.running_mean          loaded from backbone.body.layer4.1.bn3.running_mean          of shape (2048,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.bn3.running_var           loaded from backbone.body.layer4.1.bn3.running_var           of shape (2048,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.bn3.weight                loaded from backbone.body.layer4.1.bn3.weight                of shape (2048,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.conv1.weight              loaded from backbone.body.layer4.1.conv1.weight              of shape (512, 2048, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.conv2.weight              loaded from backbone.body.layer4.1.conv2.weight              of shape (512, 512, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.conv3.weight              loaded from backbone.body.layer4.1.conv3.weight              of shape (2048, 512, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.bn1.bias                  loaded from backbone.body.layer4.2.bn1.bias                  of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.bn1.running_mean          loaded from backbone.body.layer4.2.bn1.running_mean          of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.bn1.running_var           loaded from backbone.body.layer4.2.bn1.running_var           of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.bn1.weight                loaded from backbone.body.layer4.2.bn1.weight                of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.bn2.bias                  loaded from backbone.body.layer4.2.bn2.bias                  of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.bn2.running_mean          loaded from backbone.body.layer4.2.bn2.running_mean          of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.bn2.running_var           loaded from backbone.body.layer4.2.bn2.running_var           of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.bn2.weight                loaded from backbone.body.layer4.2.bn2.weight                of shape (512,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.bn3.bias                  loaded from backbone.body.layer4.2.bn3.bias                  of shape (2048,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.bn3.running_mean          loaded from backbone.body.layer4.2.bn3.running_mean          of shape (2048,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.bn3.running_var           loaded from backbone.body.layer4.2.bn3.running_var           of shape (2048,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.bn3.weight                loaded from backbone.body.layer4.2.bn3.weight                of shape (2048,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.conv1.weight              loaded from backbone.body.layer4.2.conv1.weight              of shape (512, 2048, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.conv2.weight              loaded from backbone.body.layer4.2.conv2.weight              of shape (512, 512, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.conv3.weight              loaded from backbone.body.layer4.2.conv3.weight              of shape (2048, 512, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.stem.bn1.bias                      loaded from backbone.body.stem.bn1.bias                      of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.stem.bn1.running_mean              loaded from backbone.body.stem.bn1.running_mean              of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.stem.bn1.running_var               loaded from backbone.body.stem.bn1.running_var               of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.stem.bn1.weight                    loaded from backbone.body.stem.bn1.weight                    of shape (64,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.stem.conv1.weight                  loaded from backbone.body.stem.conv1.weight                  of shape (64, 3, 7, 7)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.fpn_inner2.bias                     loaded from backbone.fpn.fpn_inner2.bias                     of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.fpn_inner2.weight                   loaded from backbone.fpn.fpn_inner2.weight                   of shape (1024, 512, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.fpn_inner3.bias                     loaded from backbone.fpn.fpn_inner3.bias                     of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.fpn_inner3.weight                   loaded from backbone.fpn.fpn_inner3.weight                   of shape (1024, 1024, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.fpn_inner4.bias                     loaded from backbone.fpn.fpn_inner4.bias                     of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.fpn_inner4.weight                   loaded from backbone.fpn.fpn_inner4.weight                   of shape (1024, 2048, 1, 1)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.fpn_layer2.bias                     loaded from backbone.fpn.fpn_layer2.bias                     of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.fpn_layer2.weight                   loaded from backbone.fpn.fpn_layer2.weight                   of shape (1024, 1024, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.fpn_layer3.bias                     loaded from backbone.fpn.fpn_layer3.bias                     of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.fpn_layer3.weight                   loaded from backbone.fpn.fpn_layer3.weight                   of shape (1024, 1024, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.fpn_layer4.bias                     loaded from backbone.fpn.fpn_layer4.bias                     of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.fpn_layer4.weight                   loaded from backbone.fpn.fpn_layer4.weight                   of shape (1024, 1024, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.top_blocks.p6.bias                  loaded from backbone.fpn.top_blocks.p6.bias                  of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.top_blocks.p6.weight                loaded from backbone.fpn.top_blocks.p6.weight                of shape (1024, 2048, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.top_blocks.p7.bias                  loaded from backbone.fpn.top_blocks.p7.bias                  of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.top_blocks.p7.weight                loaded from backbone.fpn.top_blocks.p7.weight                of shape (1024, 1024, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.anchor_generator.cell_anchors.0              loaded from rpn.anchor_generator.cell_anchors.0              of shape (9, 4)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.anchor_generator.cell_anchors.1              loaded from rpn.anchor_generator.cell_anchors.1              of shape (9, 4)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.anchor_generator.cell_anchors.2              loaded from rpn.anchor_generator.cell_anchors.2              of shape (9, 4)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.anchor_generator.cell_anchors.3              loaded from rpn.anchor_generator.cell_anchors.3              of shape (9, 4)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.anchor_generator.cell_anchors.4              loaded from rpn.anchor_generator.cell_anchors.4              of shape (9, 4)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.bbox_pred.bias                          loaded from rpn.head.bbox_pred.bias                          of shape (36,)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.bbox_pred.weight                        loaded from rpn.head.bbox_pred.weight                        of shape (36, 1024, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.bbox_tower.0.bias                       loaded from rpn.head.bbox_tower.0.bias                       of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.bbox_tower.0.weight                     loaded from rpn.head.bbox_tower.0.weight                     of shape (1024, 1024, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.bbox_tower.2.bias                       loaded from rpn.head.bbox_tower.2.bias                       of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.bbox_tower.2.weight                     loaded from rpn.head.bbox_tower.2.weight                     of shape (1024, 1024, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.bbox_tower.4.bias                       loaded from rpn.head.bbox_tower.4.bias                       of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.bbox_tower.4.weight                     loaded from rpn.head.bbox_tower.4.weight                     of shape (1024, 1024, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.bbox_tower.6.bias                       loaded from rpn.head.bbox_tower.6.bias                       of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.bbox_tower.6.weight                     loaded from rpn.head.bbox_tower.6.weight                     of shape (1024, 1024, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.cls_logits.bias                         loaded from rpn.head.cls_logits.bias                         of shape (9,)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.cls_logits.weight                       loaded from rpn.head.cls_logits.weight                       of shape (9, 1024, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.cls_tower.0.bias                        loaded from rpn.head.cls_tower.0.bias                        of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.cls_tower.0.weight                      loaded from rpn.head.cls_tower.0.weight                      of shape (1024, 1024, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.cls_tower.2.bias                        loaded from rpn.head.cls_tower.2.bias                        of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.cls_tower.2.weight                      loaded from rpn.head.cls_tower.2.weight                      of shape (1024, 1024, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.cls_tower.4.bias                        loaded from rpn.head.cls_tower.4.bias                        of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.cls_tower.4.weight                      loaded from rpn.head.cls_tower.4.weight                      of shape (1024, 1024, 3, 3)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.cls_tower.6.bias                        loaded from rpn.head.cls_tower.6.bias                        of shape (1024,)
INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.cls_tower.6.weight                      loaded from rpn.head.cls_tower.6.weight                      of shape (1024, 1024, 3, 3)
compute_prediction(self, image)

	image: H, W=(438,512)

	image_tensor = self.transforms(image)

		transforms.py Compose class __call__  ====== BEGIN

		for t in self.transforms:
			image = <maskrcnn_benchmark.data.transforms.transforms.Resize object at 0x7f3364918080>(image)
			image = <maskrcnn_benchmark.data.transforms.transforms.ToTensor object at 0x7f3364918128>(image)
			image = <maskrcnn_benchmark.data.transforms.transforms.Normalize object at 0x7f33649180b8>(image)

		return image
		transforms.py Compose class __call__  ====== END

	image_tensor.shape: torch.Size([3, 480, 561])

	padding images for 32 divisible size on width and height
	image_list = to_image_list(image_tensor, 32).to(self.device)

	to_image_list(tensors, size_divisible=32) ====== BEGIN
		type(batched_imgs): <class 'torch.Tensor'>
		batched_imgs.shape: torch.Size([1, 3, 480, 576])
		image_sizes: [torch.Size([480, 561])]
		return ImageList(batched_imgs, image_sizes)
	to_image_list(tensors, size_divisible=32) ====== END

	image_list.image_sizes: [torch.Size([480, 561])]
	image_list.tensors.shape: torch.Size([1, 3, 480, 576])
	pred = self.model(image_list)


GeneralizedRCNN.forward(self, images, targets=None) ====================== BEGIN
type(images): <class 'maskrcnn_benchmark.structures.image_list.ImageList'>
targets: None
	if self.training == False: 
	images = to_image_list(images)

	to_image_list(tensors, size_divisible=0) ====== BEGIN
		if isinstance(tensors, ImageList):
		return tensors
	to_image_list(tensors, size_divisible=0) ====== END

	images.image_sizes: [torch.Size([480, 561])]
	images.tensors.shape: torch.Size([1, 3, 480, 576])
	model.backbone.forward(images.tensors) BEFORE

=========================================== Resnet.forward(self, x) BEGIN
	Param
		x.shape=torch.Size([1, 3, 480, 576])

	x = self.stem(x)
	x.shape: torch.Size([1, 64, 120, 144])
	for stage_name in self.stages:
		stage_name: layer1
			output shape of layer1: torch.Size([1, 256, 120, 144])
			outputs.append(x) stage_name: layer1
			x.shape: torch.Size([1, 256, 120, 144])
		stage_name: layer2
			output shape of layer2: torch.Size([1, 512, 60, 72])
			outputs.append(x) stage_name: layer2
			x.shape: torch.Size([1, 512, 60, 72])
		stage_name: layer3
			output shape of layer3: torch.Size([1, 1024, 30, 36])
			outputs.append(x) stage_name: layer3
			x.shape: torch.Size([1, 1024, 30, 36])
		stage_name: layer4
			output shape of layer4: torch.Size([1, 2048, 15, 18])
			outputs.append(x) stage_name: layer4
			x.shape: torch.Size([1, 2048, 15, 18])

	ResNet::forward return value
		outputs[0]: torch.Size([1, 256, 120, 144])
		outputs[1]: torch.Size([1, 512, 60, 72])
		outputs[2]: torch.Size([1, 1024, 30, 36])
		outputs[3]: torch.Size([1, 2048, 15, 18])

	return outputs

=========================================== Resnet.forward() END


FPN.forward(self,x) ====== BEGIN
	stem output of shape (1, 64, 120, 144) saved into ./npy_save/stem_output.npy
	layer1 output of shape (1, 256, 120, 144) saved into ./npy_save/layer1_output.npy
	layer2 output of shape (1, 512, 60, 72) saved into ./npy_save/layer2_output.npy
	layer3 output of shape (1, 1024, 30, 36) saved into ./npy_save/layer3_output.npy
	layer4 output of shape (1, 2048, 15, 18) saved into ./npy_save/layer4_output.npy

	======forward param: x  = [C2, C3, C4, C5] 
	len(x) = 4
	C[2].shape : torch.Size([1, 256, 120, 144])  <==== output of layer1, C2 is output of layer2 if we consider stem layer as layer 1
	C[3].shape : torch.Size([1, 512, 60, 72])    <==== output of layer2, C3 is output of layer3 if we consider stem layer as layer 1
	C[4].shape : torch.Size([1, 1024, 30, 36])   <==== output of layer3, C4 is output of layer4 if we consider stem layer as layer 1
	C[5].shape : torch.Size([1, 2048, 15, 18])   <==== output of layer4, C5 is output of layer5 if we consider stem layer as layer 1

	x[-1].shape = torch.Size([1, 2048, 15, 18])

	last_inner = fpn_inner4(C4)
		self.innerblocks[-1] = Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
		last_inner.shape = torch.Size([1, 1024, 15, 18])


	results.append(fpn_layer4(last_inner))
		self.layer_blocks[-1]: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
		results[0].shape: torch.Size([1, 1024, 15, 18])

	for feature, inner_block, layer_block
			in zip[(x[:-1][::-1], self.inner_blocks[:-1][::-1], self.layer_blocks[:-1][::-1]):

		====================================
		iteration 0 summary
		====================================
		feature.shape: torch.Size([1, 1024, 30, 36])
		inner_block: fpn_inner3 ==> Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
		layer_block: fpn_layer3 ==> Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
		last_inner.shape: torch.Size([1, 1024, 15, 18])
		====================================

		--------------------------------------------------
		0.1 Upsample : replace with Decovolution in caffe
		layer name in caffe: fpn_inner3_upsample = Deconvolution(last_inner)
		--------------------------------------------------
		inner_top_down = interpolate(last_inner, scale_factor=2, mode='nearest')

		last_inner.shape: torch.Size([1, 1024, 15, 18])
		inner_top_down.shape : torch.Size([1, 1024, 30, 36])
		--------------------------------------------------

		--------------------------------------------------
		0.2 inner_lateral = Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))(feature)
		layer name in caffe: fpn_inner3_lateral=Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))(feature)
		--------------------------------------------------
			inner_block: fpn_inner3 ==> Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
			input: feature.shape: torch.Size([1, 1024, 30, 36])
			output: inner_lateral.shape: torch.Size([1, 1024, 30, 36])

		--------------------------------------------------

		--------------------------------------------------
		0.3 Elementwise Addition: replaced with eltwise in caffe
		layer in caffe: eltwise_3 = eltwise(fpn_inner3_lateral, fpn_inner3_upsample )
		--------------------------------------------------
		last_inner = inner_lateral + inner_top_down
			inner_lateral.shape: torch.Size([1, 1024, 30, 36])
			inner_top_down.shape: torch.Size([1, 1024, 30, 36])
			last_inner.shape : torch.Size([1, 1024, 30, 36])
		--------------------------------------------------

		--------------------------------------------------
		0.4 results.insert(0, Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))(last_inner)
		layer in caffe: fpn_layer3 = Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))(eltwise_3)
		--------------------------------------------------
			layer_block: fpn_layer3 ==> Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
			input: last_inner.shape = torch.Size([1, 1024, 30, 36])
		--------------------------------------------------

		--------------------------------------------------
		results after iteration 0
		--------------------------------------------------
			results[0].shape: torch.Size([1, 1024, 30, 36])
			results[1].shape: torch.Size([1, 1024, 15, 18])
		--------------------------------------------------

		====================================
		iteration 1 summary
		====================================
		feature.shape: torch.Size([1, 512, 60, 72])
		inner_block: fpn_inner2 ==> Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
		layer_block: fpn_layer2 ==> Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
		last_inner.shape: torch.Size([1, 1024, 30, 36])
		====================================

		--------------------------------------------------
		1.1 Upsample : replace with Decovolution in caffe
		layer name in caffe: fpn_inner2_upsample = Deconvolution(last_inner)
		--------------------------------------------------
		inner_top_down = interpolate(last_inner, scale_factor=2, mode='nearest')

		last_inner.shape: torch.Size([1, 1024, 30, 36])
		inner_top_down.shape : torch.Size([1, 1024, 60, 72])
		--------------------------------------------------

		--------------------------------------------------
		1.2 inner_lateral = Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))(feature)
		layer name in caffe: fpn_inner2_lateral=Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))(feature)
		--------------------------------------------------
			inner_block: fpn_inner2 ==> Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
			input: feature.shape: torch.Size([1, 512, 60, 72])
			output: inner_lateral.shape: torch.Size([1, 1024, 60, 72])

		--------------------------------------------------

		--------------------------------------------------
		1.3 Elementwise Addition: replaced with eltwise in caffe
		layer in caffe: eltwise_2 = eltwise(fpn_inner2_lateral, fpn_inner2_upsample )
		--------------------------------------------------
		last_inner = inner_lateral + inner_top_down
			inner_lateral.shape: torch.Size([1, 1024, 60, 72])
			inner_top_down.shape: torch.Size([1, 1024, 60, 72])
			last_inner.shape : torch.Size([1, 1024, 60, 72])
		--------------------------------------------------

		--------------------------------------------------
		1.4 results.insert(0, Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))(last_inner)
		layer in caffe: fpn_layer2 = Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))(eltwise_2)
		--------------------------------------------------
			layer_block: fpn_layer2 ==> Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
			input: last_inner.shape = torch.Size([1, 1024, 60, 72])
		--------------------------------------------------

		--------------------------------------------------
		results after iteration 1
		--------------------------------------------------
			results[0].shape: torch.Size([1, 1024, 60, 72])
			results[1].shape: torch.Size([1, 1024, 30, 36])
			results[2].shape: torch.Size([1, 1024, 15, 18])
		--------------------------------------------------

	for loop END


	if isinstance(self.top_blocks, LastLevelP6P7):
			self.top_blocks: LastLevelP6P7(
  (p6): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (p7): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
)

	stem output of shape (1, 64, 120, 144) saved into ./npy_save/stem_output.npy
	layer1 output of shape (1, 256, 120, 144) saved into ./npy_save/layer1_output.npy
	layer2 output of shape (1, 512, 60, 72) saved into ./npy_save/layer2_output.npy
	layer3 output of shape (1, 1024, 30, 36) saved into ./npy_save/layer3_output.npy
	layer4 output of shape (1, 2048, 15, 18) saved into ./npy_save/layer4_output.npy

			len(x): 4
			x[0].shape : torch.Size([1, 256, 120, 144])  <== output of layer 1 and corresponds to C2 if we consider stem layer as layer 1
			x[1].shape : torch.Size([1, 512, 60, 72])    <== output of layer 2 and corresponds to C3 if we consider stem layer as layer 1
			x[2].shape : torch.Size([1, 1024, 30, 36])   <== output of layer 3 and corresponds to C4 if we consider stem layer as layer 1
			x[3].shape : torch.Size([1, 2048, 15, 18])   <== output of layer 4 and corresponds to C5 if we consider stem layer as layer 1

			x[-1].shape: torch.Size([1, 2048, 15, 18])


			len(results): 3
			results[0].shape : torch.Size([1, 1024, 60, 72]) <===  P3
			results[1].shape : torch.Size([1, 1024, 30, 36]) <===  P4
			results[2].shape : torch.Size([1, 1024, 15, 18]) <===  P5
			results[-1].shape: torch.Size([1, 1024, 15, 18])



		LastLevelP6P7.forward(self, c5, p5) ============= BEGIN 
			c5.shape: torch.Size([1, 2048, 15, 18])    <== output of layer 4 and corresponds to C5 if we consider stem layer as layer 1
			p5.shape: torch.Size([1, 1024, 15, 18])    <== results[-1]

			if (self.use_P5 == False)
				x=c5
			x.shape = torch.Size([1, 2048, 15, 18])
			p6 = self.p6(x)
				self.p6: Conv2d(2048, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
				p6.shape: torch.Size([1, 1024, 8, 9])

			p7 = self.p7(F.relu(p6))
				self.p7: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
				p7.shape: torch.Size([1, 1024, 4, 5])

			returns [p6, p7]
		LastLevelP6P7.forward(self, c5, p5) ============= END


		last_result = self.top_blocks(x[-1], results[-1])
			len(last_result):2
			last_results[0].shape : torch.Size([1, 1024, 8, 9])
			last_results[1].shape : torch.Size([1, 1024, 4, 5])
		results.extend(last_results)
			len(results): 5
			results[0].shape : torch.Size([1, 1024, 60, 72])
			results[1].shape : torch.Size([1, 1024, 30, 36])
			results[2].shape : torch.Size([1, 1024, 15, 18])
			results[3].shape : torch.Size([1, 1024, 8, 9])
			results[4].shape : torch.Size([1, 1024, 4, 5])




		results
		result[0].shape: torch.Size([1, 1024, 60, 72])
		result[1].shape: torch.Size([1, 1024, 30, 36])
		result[2].shape: torch.Size([1, 1024, 15, 18])
		result[3].shape: torch.Size([1, 1024, 8, 9])
		result[4].shape: torch.Size([1, 1024, 4, 5])

	return tuple(results)


FPN.forward(self,x) ====== END
	model.backbone.forward(images.tensors) DONE
proposals, proposal_losses = self.rpn(images, features, targets) BEFORE


=========================================== RetinaNetModule.forward(self, images, features, targets=None): BEGIN
	Params:
		type(images.image_size): <class 'list'>
		type(images.tensors): <class 'torch.Tensor'>
		len(features)): 5
			feature[0].shape: torch.Size([1, 1024, 60, 72])
			feature[1].shape: torch.Size([1, 1024, 30, 36])
			feature[2].shape: torch.Size([1, 1024, 15, 18])
			feature[3].shape: torch.Size([1, 1024, 8, 9])
			feature[4].shape: torch.Size([1, 1024, 4, 5])
self.head: RetinaNetHead(
  (cls_tower): Sequential(
    (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU()
    (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (5): ReLU()
    (6): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU()
  )
  (bbox_tower): Sequential(
    (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU()
    (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (5): ReLU()
    (6): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU()
  )
  (cls_logits): Conv2d(1024, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (bbox_pred): Conv2d(1024, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)
box_cls, box_regression = self.head(features)


=========================================== RetinaNetHead.forward(self, x): BEGIN
	Param:
		len(x)): 5 x is features returned from FPN
			x[0].shape: torch.Size([1, 1024, 60, 72])
			x[1].shape: torch.Size([1, 1024, 30, 36])
			x[2].shape: torch.Size([1, 1024, 15, 18])
			x[3].shape: torch.Size([1, 1024, 8, 9])
			x[4].shape: torch.Size([1, 1024, 4, 5])
logits = []
bbox_reg = []



for feature in x:
	===== iteration: 0 ====
	feature[0].shape: torch.Size([1, 1024, 60, 72])

	cls_tower => cls_logits => logits[]
	logits.append(self.cls_logits(self.cls_tower(feature)))

	bbox_tower => bbox_pre => bbox_reg[]
	bbox_reg.append(self.bbox_pred(self.bbox_tower(feature)))

	===== iteration: 1 ====
	feature[1].shape: torch.Size([1, 1024, 30, 36])

	cls_tower => cls_logits => logits[]
	logits.append(self.cls_logits(self.cls_tower(feature)))

	bbox_tower => bbox_pre => bbox_reg[]
	bbox_reg.append(self.bbox_pred(self.bbox_tower(feature)))

	===== iteration: 2 ====
	feature[2].shape: torch.Size([1, 1024, 15, 18])

	cls_tower => cls_logits => logits[]
	logits.append(self.cls_logits(self.cls_tower(feature)))

	bbox_tower => bbox_pre => bbox_reg[]
	bbox_reg.append(self.bbox_pred(self.bbox_tower(feature)))

	===== iteration: 3 ====
	feature[3].shape: torch.Size([1, 1024, 8, 9])

	cls_tower => cls_logits => logits[]
	logits.append(self.cls_logits(self.cls_tower(feature)))

	bbox_tower => bbox_pre => bbox_reg[]
	bbox_reg.append(self.bbox_pred(self.bbox_tower(feature)))

	===== iteration: 4 ====
	feature[4].shape: torch.Size([1, 1024, 4, 5])

	cls_tower => cls_logits => logits[]
	logits.append(self.cls_logits(self.cls_tower(feature)))

	bbox_tower => bbox_pre => bbox_reg[]
	bbox_reg.append(self.bbox_pred(self.bbox_tower(feature)))

 ==== logits ====
logits[0].shape: torch.Size([1, 9, 60, 72])
logits[1].shape: torch.Size([1, 9, 30, 36])
logits[2].shape: torch.Size([1, 9, 15, 18])
logits[3].shape: torch.Size([1, 9, 8, 9])
logits[4].shape: torch.Size([1, 9, 4, 5])

 ==== bbox_reg ====
bbox_reg[0].shape: torch.Size([1, 36, 60, 72])
bbox_reg[1].shape: torch.Size([1, 36, 30, 36])
bbox_reg[2].shape: torch.Size([1, 36, 15, 18])
bbox_reg[3].shape: torch.Size([1, 36, 8, 9])
bbox_reg[4].shape: torch.Size([1, 36, 4, 5])

return logits, bbox_reg


=========================================== RetinaNetHead.forward(self, x): END
self.anchor_generator: AnchorGenerator(
  (cell_anchors): BufferList()
)
anchors = self.anchor_generator(images, features)
=================   AnchorGenerator.forward(image_list, feature_maps) BEGIN
	Params:
		image_list:
			len(image_list.image_sizes): 1
			image_list.image_sizes[0]: torch.Size([480, 561])
			len(image_list.tensors): 1
			image_list.tensors[0].shape: torch.Size([3, 480, 576])
		feature_maps:
			feature_maps[0].shape: torch.Size([1, 1024, 60, 72])
			feature_maps[1].shape: torch.Size([1, 1024, 30, 36])
			feature_maps[2].shape: torch.Size([1, 1024, 15, 18])
			feature_maps[3].shape: torch.Size([1, 1024, 8, 9])
			feature_maps[4].shape: torch.Size([1, 1024, 4, 5])

grid_sizes = [feature_map.shape[-2:] for feature_map in feature_maps]
anchors_over_all_feature_maps = self.grid_anchors(grid_sizes)
=================   AnchorGenerator.grid_anchors(grid_sizes) BEGIN
	Param:
		grid_sizes: [torch.Size([60, 72]), torch.Size([30, 36]), torch.Size([15, 18]), torch.Size([8, 9]), torch.Size([4, 5])]
return anchors
=================   AnchorGenerator.grid_anchors(grid_sizes) END
anchors = []
for i, (image_height, image_width) in enumerate(image_list.image_sizes):

	anchors_in_image = []

	for anchors_per_feature_map in anchors_over_all_feature_maps:

		boxlist = BoxList( anchors_per_feature_map, (image_width, image_height), mode="xyxy" )
		boxlist:
			BoxList(num_boxes=38880, image_width=561, image_height=480, mode=xyxy)

		self.add_visibility_to(boxlist)

=================   AnchorGenerator.add_visibitity_to(boxlist) BEGIN
=================   AnchorGenerator.add_visibitity_to(boxlist) END
		boxlist:
			BoxList(num_boxes=38880, image_width=561, image_height=480, mode=xyxy)

		anchors_in_image.append(boxlist)

		boxlist = BoxList( anchors_per_feature_map, (image_width, image_height), mode="xyxy" )
		boxlist:
			BoxList(num_boxes=9720, image_width=561, image_height=480, mode=xyxy)

		self.add_visibility_to(boxlist)

=================   AnchorGenerator.add_visibitity_to(boxlist) BEGIN
=================   AnchorGenerator.add_visibitity_to(boxlist) END
		boxlist:
			BoxList(num_boxes=9720, image_width=561, image_height=480, mode=xyxy)

		anchors_in_image.append(boxlist)

		boxlist = BoxList( anchors_per_feature_map, (image_width, image_height), mode="xyxy" )
		boxlist:
			BoxList(num_boxes=2430, image_width=561, image_height=480, mode=xyxy)

		self.add_visibility_to(boxlist)

=================   AnchorGenerator.add_visibitity_to(boxlist) BEGIN
=================   AnchorGenerator.add_visibitity_to(boxlist) END
		boxlist:
			BoxList(num_boxes=2430, image_width=561, image_height=480, mode=xyxy)

		anchors_in_image.append(boxlist)

		boxlist = BoxList( anchors_per_feature_map, (image_width, image_height), mode="xyxy" )
		boxlist:
			BoxList(num_boxes=648, image_width=561, image_height=480, mode=xyxy)

		self.add_visibility_to(boxlist)

=================   AnchorGenerator.add_visibitity_to(boxlist) BEGIN
=================   AnchorGenerator.add_visibitity_to(boxlist) END
		boxlist:
			BoxList(num_boxes=648, image_width=561, image_height=480, mode=xyxy)

		anchors_in_image.append(boxlist)

		boxlist = BoxList( anchors_per_feature_map, (image_width, image_height), mode="xyxy" )
		boxlist:
			BoxList(num_boxes=180, image_width=561, image_height=480, mode=xyxy)

		self.add_visibility_to(boxlist)

=================   AnchorGenerator.add_visibitity_to(boxlist) BEGIN
=================   AnchorGenerator.add_visibitity_to(boxlist) END
		boxlist:
			BoxList(num_boxes=180, image_width=561, image_height=480, mode=xyxy)

		anchors_in_image.append(boxlist)

		anchors_in_image:
			[BoxList(num_boxes=38880, image_width=561, image_height=480, mode=xyxy), BoxList(num_boxes=9720, image_width=561, image_height=480, mode=xyxy), BoxList(num_boxes=2430, image_width=561, image_height=480, mode=xyxy), BoxList(num_boxes=648, image_width=561, image_height=480, mode=xyxy), BoxList(num_boxes=180, image_width=561, image_height=480, mode=xyxy)]

		anchors.append(anchors_in_image)

		anchors:
			[[BoxList(num_boxes=38880, image_width=561, image_height=480, mode=xyxy), BoxList(num_boxes=9720, image_width=561, image_height=480, mode=xyxy), BoxList(num_boxes=2430, image_width=561, image_height=480, mode=xyxy), BoxList(num_boxes=648, image_width=561, image_height=480, mode=xyxy), BoxList(num_boxes=180, image_width=561, image_height=480, mode=xyxy)]]

return anchors
=================   AnchorGenerator.forward(image_list, feature_maps) END
if self.training == False
	return self._forward_test(anchors, box_cls, box_regression)


=========================================== RetinaNetModule.forward(self, images, features, targets=None): END


=========================================== RetinaNetModule._forward_test(self, anchors, box_cls, box_regression): BEGIN
params:
	len(anchors)
: 1
	len(box_cls)
: 5
	len(box_regression): 5
self.box_selector_test: RetinaNetPostProcessor()
boxes = self.box_selector_test(anchors, box_cls, box_regression)
========== RPNPostProcessing.forward() BEGIN
========== RPNPostProcessing.forward() END
len(boxes): 1
return boxes, {} # {} is just empty dictionayr


=========================================== RetinaNetModule._forward_test(self, anchors, box_cls, box_regression): END
proposals, proposal_losses = self.rpn(images, features, targets) DONE
x = features
result = proposals
return result
GeneralizedRCNN.forward(self, images, targets=None) ====================== END
QXcbConnection: XCB error: 145 (Unknown), sequence: 171, resource id: 0, major code: 140 (Unknown), minor code: 20
DEBUG:matplotlib.font_manager:findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXGeneral' (STIXGeneralBolIta.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'cmss10' (cmss10.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'cmb10' (cmb10.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'cmmi10' (cmmi10.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Oblique.ttf) oblique normal 400 normal>) = 1.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'cmtt10' (cmtt10.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'cmsy10' (cmsy10.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXNonUnicode' (STIXNonUni.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Serif' (DejaVuSerif.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXSizeFourSym' (STIXSizFourSymBol.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXNonUnicode' (STIXNonUniIta.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans' (DejaVuSans.ttf) normal normal 400 normal>) = 0.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXSizeOneSym' (STIXSizOneSymBol.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXGeneral' (STIXGeneralItalic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-Italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXNonUnicode' (STIXNonUniBolIta.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans Display' (DejaVuSansDisplay.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXGeneral' (STIXGeneralBol.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-Oblique.ttf) oblique normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Bold.ttf) normal normal 700 normal>) = 0.33499999999999996
DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXGeneral' (STIXGeneral.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXSizeTwoSym' (STIXSizTwoSymBol.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXSizeThreeSym' (STIXSizThreeSymReg.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXNonUnicode' (STIXNonUniBol.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXSizeFiveSym' (STIXSizFiveSymReg.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Serif Display' (DejaVuSerifDisplay.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXSizeFourSym' (STIXSizFourSymReg.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXSizeOneSym' (STIXSizOneSymReg.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans' (DejaVuSans-BoldOblique.ttf) oblique normal 700 normal>) = 1.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXSizeThreeSym' (STIXSizThreeSymBol.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'cmr10' (cmr10.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-BoldItalic.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-BoldOblique.ttf) oblique normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'cmex10' (cmex10.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXSizeTwoSym' (STIXSizTwoSymReg.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Tai Viet' (NotoSansTaiViet-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'OpenSymbol' (opens___.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Ubuntu' (Ubuntu-R.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Telugu' (NotoSerifTelugu-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'KacstBook' (KacstBook.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans' (DejaVuSans-BoldOblique.ttf) oblique normal 700 normal>) = 1.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Uroob' (Uroob.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Cuneiform' (NotoSansCuneiform-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Serif' (DejaVuSerif.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Serif' (LiberationSerif-Italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Lao UI' (NotoSansLaoUI-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Georgian' (NotoSansGeorgian-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Sarai' (Sarai.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_Vector-Bold' (MathJax_Vector-Bold.otf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Carian' (NotoSansCarian-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Ethiopic' (NotoSansEthiopic-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Avestan' (NotoSansAvestan-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Garuda' (Garuda-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Droid Sans Fallback' (DroidSansFallbackFull.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans CJK JP' (NotoSansCJK-Light.ttc) normal normal 300 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Waree' (Waree-Oblique.ttf) oblique normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Lao UI' (NotoSansLaoUI-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'OpenDyslexicMono' (OpenDyslexicMono-Regular.otf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Old Italic' (NotoSansOldItalic-Regular.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Saab' (Saab.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Devanagari UI' (NotoSansDevanagariUI-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_SansSerif' (MathJax_SansSerif-Italic.otf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans' (DejaVuSansCondensed-BoldOblique.ttf) oblique normal 700 condensed>) = 1.535
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Lohit Odia' (Lohit-Odia.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Ubuntu Mono' (UbuntuMono-R.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Sawasdee' (Sawasdee-Oblique.ttf) oblique normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'KacstLetter' (KacstLetter.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Sans' (LiberationSans-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Norasi' (Norasi-Oblique.ttf) oblique normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Tibetan' (NotoSansTibetan-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Egyptian Hieroglyphs' (NotoSansEgyptianHieroglyphs-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_Caligraphic' (MathJax_Caligraphic-Regular.otf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Kannada' (NotoSerifKannada-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'padmaa' (padmaa.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Limbu' (NotoSansLimbu-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Gurmukhi' (NotoSansGurmukhi-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Malayalam' (NotoSansMalayalam-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tlwg Mono' (TlwgMono-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'LKLUG' (lklug.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias PCfont Z' (tiresias_pcfontz.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Tibetan' (NotoSansTibetan-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'FreeMono' (FreeMonoOblique.ttf) oblique normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Laksaman' (Laksaman-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Kannada' (NotoSansKannada-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Myanmar UI' (NotoSansMyanmarUI-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Gujarati' (NotoSansGujarati-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Hebrew' (NotoSansHebrew-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Samyak Gujarati' (Samyak-Gujarati.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'FreeSerif' (FreeSerif.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Laksaman' (Laksaman.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Gujarati' (NotoSansGujarati-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Rachana' (Rachana-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Samyak Malayalam' (Samyak-Malayalam.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Imperial Aramaic' (NotoSansImperialAramaic-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Gurmukhi' (NotoSansGurmukhi-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Buhid' (NotoSansBuhid-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_Size4' (MathJax_Size4-Regular.otf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Garuda' (Garuda.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Syriac Western' (NotoSansSyriacWestern-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif' (NotoSerif-Italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Lohit Tamil' (Lohit-Tamil.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Laksaman' (Laksaman-BoldItalic.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Old South Arabian' (NotoSansOldSouthArabian-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Samaritan' (NotoSansSamaritan-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'FreeSans' (FreeSansBoldOblique.ttf) oblique normal 600 normal>) = 11.24
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Coptic' (NotoSansCoptic-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Osage' (NotoSansOsage-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'RaghuMalayalam' (RaghuMalayalamSans-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Bengali UI' (NotoSansBengaliUI-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'KacstTitle' (KacstTitle.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'padmaa' (padmaa-Medium-0.5.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'KacstArt' (KacstArt.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'OpenDyslexic' (OpenDyslexic-Bold.otf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'OpenDyslexic' (OpenDyslexic-BoldItalic.otf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Khmer' (NotoSerifKhmer-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_WinChrome' (MathJax_WinChrome-Regular.otf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Display' (NotoSansDisplay-BoldItalic.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'FreeMono' (FreeMonoBoldOblique.ttf) oblique normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Pagul' (Pagul.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Khmer' (NotoSansKhmer-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'OpenDyslexicAlta' (OpenDyslexicAlta-Regular.otf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Georgian' (NotoSansGeorgian-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Deseret' (NotoSansDeseret-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Khmer OS' (KhmerOS.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Arabic UI' (NotoSansArabicUI-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Symbols' (NotoSansSymbols-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Likhan' (LikhanNormal.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Sans Narrow' (LiberationSansNarrow-BoldItalic.ttf) italic normal 700 condensed>) = 11.535
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Keraleeyam' (Keraleeyam.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Sawasdee' (Sawasdee-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans CJK JP' (NotoSansCJK-Black.ttc) normal normal 900 normal>) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Sans' (LiberationSans-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Lohit Kannada' (Lohit-Kannada.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Tagbanwa' (NotoSansTagbanwa-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Mono' (LiberationMono-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Tamil' (NotoSerifTamil-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_Script' (MathJax_Script-Regular.otf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Mono' (LiberationMono-BoldItalic.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Display' (NotoSansDisplay-Italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif CJK JP' (NotoSerifCJK-Black.ttc) normal normal 900 normal>) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tlwg Typo' (TlwgTypo-BoldOblique.ttf) oblique normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Padauk' (Padauk-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Runic' (NotoSansRunic-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Kufi Arabic' (NotoKufiArabic-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_Caligraphic' (MathJax_Caligraphic-Bold.otf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'KacstOne' (KacstOne.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Navilu' (Navilu.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tlwg Typewriter' (TlwgTypewriter-BoldOblique.ttf) oblique normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Kalimati' (kalimati.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Linear B' (NotoSansLinearB-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Telugu' (NotoSerifTelugu-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Bengali' (NotoSerifBengali-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Bengali UI' (NotoSansBengaliUI-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Meera' (Meera.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Armenian' (NotoSerifArmenian-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'KacstOffice' (KacstOffice.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Malayalam' (NotoSerifMalayalam-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Mono' (LiberationMono-Italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Serif' (DejaVuSerifCondensed-Italic.ttf) italic normal 400 condensed>) = 11.25
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias Keyfont V2' (tirekv__.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_Fraktur' (MathJax_Fraktur-Regular.otf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Manjari' (Manjari-Regular.otf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Mukti Narrow' (MuktiNarrowBold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Tai Tham' (NotoSansTaiTham-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Display' (NotoSansDisplay-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Naskh Arabic UI' (NotoNaskhArabicUI-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-Italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Oriya UI' (NotoSansOriyaUI-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans' (NotoSans-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'KacstScreen' (KacstScreen.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif' (NotoSerif-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Gubbi' (Gubbi.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Laksaman' (Laksaman-Italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_Math' (MathJax_Math-BoldItalic.otf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'AnjaliOldLipi' (AnjaliOldLipi.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Display' (NotoSerifDisplay-Italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'ori1Uni' (utkal.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Myanmar UI' (NotoSansMyanmarUI-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Syloti Nagri' (NotoSansSylotiNagri-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Umpush' (Umpush-Light.ttf) normal normal 300 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Cherokee' (NotoSansCherokee-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Gargi' (Gargi.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Mono' (LiberationMono-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Inscriptional Parthian' (NotoSansInscriptionalParthian-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias Infofont' (tiresias_infofont_italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-BoldItalic.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Lohit Bengali' (Lohit-Bengali.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif CJK JP' (NotoSerifCJK-Bold.ttc) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'padmaa-Bold.1.1' (padmaa-Bold.1.1.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Norasi' (Norasi-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias Signfont' (tiresias_signfont_italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Kannada' (NotoSansKannada-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Javanese' (NotoSansJavanese-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Symbola' (Symbola_hint.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Gurmukhi UI' (NotoSansGurmukhiUI-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tlwg Typo' (TlwgTypo-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Rachana' (Rachana-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Adlam' (NotoSansAdlam-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Myanmar' (NotoSerifMyanmar-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Canadian Aboriginal' (NotoSansCanadianAboriginal-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'KacstNaskh' (KacstNaskh.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_SansSerif' (MathJax_SansSerif-Regular.otf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Gujarati' (NotoSerifGujarati-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Serif' (DejaVuSerifCondensed-Bold.ttf) normal normal 700 condensed>) = 10.535
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Ubuntu' (Ubuntu-LI.ttf) italic normal 300 normal>) = 11.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Lao' (NotoSerifLao-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Mandaic' (NotoSansMandaic-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Devanagari' (NotoSerifDevanagari-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Rekha' (Rekha.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_Size2' (MathJax_Size2-Regular.otf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Saurashtra' (NotoSansSaurashtra-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tlwg Typist' (TlwgTypist.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Kinnari' (Kinnari-BoldItalic.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Devanagari' (NotoSansDevanagari-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Display' (NotoSerifDisplay-BoldItalic.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Phags Pa' (NotoSansPhagsPa-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Syriac Estrangela' (NotoSansSyriacEstrangela-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Mongolian' (NotoSansMongolian-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Symbols' (NotoSansSymbols-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Sinhala UI' (NotoSansSinhalaUI-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Display' (NotoSerifDisplay-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Suruma' (Suruma.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Waree' (Waree.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Ethiopic' (NotoSansEthiopic-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Khmer' (NotoSansKhmer-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Lycian' (NotoSansLycian-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_Main' (MathJax_Main-Italic.otf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Bengali' (NotoSerifBengali-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Sinhala' (NotoSerifSinhala-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'KacstDigital' (KacstDigital.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Serif' (LiberationSerif-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Devanagari' (NotoSerifDevanagari-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Kannada' (NotoSerifKannada-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tlwg Typist' (TlwgTypist-Oblique.ttf) oblique normal 500 normal>) = 11.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Purisa' (Purisa.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Lohit Gurmukhi' (Lohit-Gurmukhi.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias LPfont' (tiresias_lpfont_bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Khmer UI' (NotoSansKhmerUI-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Kinnari' (Kinnari-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Kinnari' (Kinnari-BoldOblique.ttf) oblique normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_Main' (MathJax_Main-Regular.otf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Lohit Malayalam' (Lohit-Malayalam.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'FreeMono' (FreeMono.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans' (DejaVuSans-ExtraLight.ttf) normal normal 200 normal>) = 0.24
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Ubuntu' (Ubuntu-B.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Gurmukhi UI' (NotoSansGurmukhiUI-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Pothana2000' (Pothana2000.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Norasi' (Norasi-BoldItalic.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Mono' (NotoSansMono-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_Typewriter' (MathJax_Typewriter-Regular.otf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Bold.ttf) normal normal 700 normal>) = 0.33499999999999996
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Display' (NotoSansDisplay-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'KacstTitleL' (KacstTitleL.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Sans' (LiberationSans-Italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Purisa' (Purisa-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Brahmi' (NotoSansBrahmi-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Norasi' (Norasi-BoldOblique.ttf) oblique normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Tamil UI' (NotoSansTamilUI-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif CJK JP' (NotoSerifCJK-Light.ttc) normal normal 300 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Ubuntu' (Ubuntu-RI.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Ethiopic' (NotoSerifEthiopic-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Lohit Gujarati' (Lohit-Gujarati.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Hebrew' (NotoSerifHebrew-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-Oblique.ttf) oblique normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_Size1' (MathJax_Size1-Regular.otf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Cham' (NotoSansCham-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Cypriot' (NotoSansCypriot-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_SansSerif' (MathJax_SansSerif-Bold.otf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Symbols2' (NotoSansSymbols2-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias Infofont Z' (tiresias_infofontz.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'FreeSans' (FreeSansOblique.ttf) oblique normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Thai' (NotoSerifThai-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Ol Chiki' (NotoSansOlChiki-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Sans' (LiberationSans-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Kharoshthi' (NotoSansKharoshthi-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Thai' (NotoSerifThai-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif CJK JP' (NotoSerifCJK-Medium.ttc) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Gothic' (NotoSansGothic-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias Signfont Z' (tiresias_signfontz_bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_Math' (MathJax_Math-Italic.otf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'FreeSans' (FreeSansBold.ttf) normal normal 600 normal>) = 10.24
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Khmer' (NotoSerifKhmer-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tlwg Typo' (TlwgTypo-Oblique.ttf) oblique normal 500 normal>) = 11.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias Infofont Z' (tiresias_infofontz_bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Ubuntu' (Ubuntu-Th.ttf) normal normal 250 normal>) = 10.1925
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Umpush' (Umpush-BoldOblique.ttf) oblique normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tlwg Typewriter' (TlwgTypewriter.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Ubuntu Mono' (UbuntuMono-BI.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'KacstPen' (KacstPen.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans CJK JP' (NotoSansCJK-Regular.ttc) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tlwg Typewriter' (TlwgTypewriter-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias Signfont Z' (tiresias_signfontz.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Loma' (Loma-BoldOblique.ttf) oblique normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Sans Narrow' (LiberationSansNarrow-Regular.ttf) normal normal 400 condensed>) = 10.25
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans' (NotoSans-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Tamil UI' (NotoSansTamilUI-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Gujarati UI' (NotoSansGujaratiUI-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'OpenDyslexic' (OpenDyslexic-Regular.otf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'KacstPoster' (KacstPoster.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Sans' (LiberationSans-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Vemana2000' (vemana2000.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Mono' (LiberationMono-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Sans' (LiberationSans-BoldItalic.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Jamrul' (JamrulNormal.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Mono' (LiberationMono-BoldItalic.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Purisa' (Purisa-Oblique.ttf) oblique normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Naskh Arabic' (NotoNaskhArabic-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Batak' (NotoSansBatak-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Old Turkic' (NotoSansOldTurkic-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Sinhala' (NotoSansSinhala-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Ubuntu' (Ubuntu-BI.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Anatolian Hieroglyphs' (NotoSansAnatolianHieroglyphs-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Tamil' (NotoSerifTamil-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Cherokee' (NotoSansCherokee-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans CJK JP' (NotoSansCJK-Thin.ttc) normal normal 100 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_AMS' (MathJax_AMS-Regular.otf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Kufi Arabic' (NotoKufiArabic-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Math TeX Gyre' (DejaVuMathTeXGyre.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans NKo' (NotoSansNKo-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Tai Le' (NotoSansTaiLe-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Sawasdee' (Sawasdee-BoldOblique.ttf) oblique normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Phoenician' (NotoSansPhoenician-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Padauk Book' (PadaukBook-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Ubuntu' (Ubuntu-MI.ttf) italic normal 500 normal>) = 11.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias PCfont Z' (tiresias_pcfontz_italic.ttf) italic normal 28926 normal>) = 38.149699999999996
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans' (DejaVuSansCondensed-Bold.ttf) normal normal 700 condensed>) = 0.5349999999999999
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Thai' (NotoSansThai-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Georgian' (NotoSerifGeorgian-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Oriya' (NotoSansOriya-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Serif' (DejaVuSerifCondensed.ttf) normal normal 400 condensed>) = 10.25
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_Vector' (MathJax_Vector-Regular.otf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif CJK JP' (NotoSerifCJK-Regular.ttc) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Lao' (NotoSansLao-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans CJK JP' (NotoSansCJK-Bold.ttc) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Thai UI' (NotoSansThaiUI-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Malayalam UI' (NotoSansMalayalamUI-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans New Tai Lue' (NotoSansNewTaiLue-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Kaithi' (NotoSansKaithi-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias Infofont' (tiresias_infofont.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Lohit Telugu' (Lohit-Telugu.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Sundanese' (NotoSansSundanese-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Kinnari' (Kinnari-Oblique.ttf) oblique normal 500 normal>) = 11.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Naskh Arabic UI' (NotoNaskhArabicUI-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Sinhala' (NotoSansSinhala-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Tamil' (NotoSansTamil-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Lohit Tamil Classical' (Lohit-Tamil-Classical.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Umpush' (Umpush-Oblique.ttf) oblique normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Ubuntu Mono' (UbuntuMono-B.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Oblique.ttf) oblique normal 400 normal>) = 1.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Norasi' (Norasi.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Armenian' (NotoSansArmenian-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans' (DejaVuSans.ttf) normal normal 400 normal>) = 0.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tlwg Typist' (TlwgTypist-BoldOblique.ttf) oblique normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Myanmar' (NotoSerifMyanmar-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Mono' (NotoSansMono-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Kalapi' (Kalapi.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Yi' (NotoSansYi-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Mono' (NotoMono-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Ubuntu' (Ubuntu-L.ttf) normal normal 300 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Shavian' (NotoSansShavian-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Vai' (NotoSansVai-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Mono' (LiberationMono-Italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Hanunoo' (NotoSansHanunoo-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Manjari' (Manjari-Bold.otf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Armenian' (NotoSerifArmenian-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'FreeSerif' (FreeSerifBold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Serif' (LiberationSerif-Italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'OpenDyslexicAlta' (OpenDyslexicAlta-BoldItalic.otf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Loma' (Loma-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Sinhala' (NotoSerifSinhala-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Mukti Narrow' (MuktiNarrow.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Kannada UI' (NotoSansKannadaUI-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'KacstFarsi' (KacstFarsi.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Sans Narrow' (LiberationSansNarrow-Bold.ttf) normal normal 700 condensed>) = 10.535
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Ani' (ani.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Lydian' (NotoSansLydian-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias Signfont' (tiresias_signfont_bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Tifinagh' (NotoSansTifinagh-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tlwg Typewriter' (TlwgTypewriter-Oblique.ttf) oblique normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'FreeSans' (FreeSans.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Thai UI' (NotoSansThaiUI-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Gujarati' (NotoSerifGujarati-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Serif' (LiberationSerif-BoldItalic.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Bengali' (NotoSansBengali-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Dyuthi' (Dyuthi.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Myanmar' (NotoSansMyanmar-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tlwg Typo' (TlwgTypo.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Lao' (NotoSerifLao-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif' (NotoSerif-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Norasi' (Norasi-Italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Myanmar' (NotoSansMyanmar-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_WinIE6' (MathJax_WinIE6-Regular.otf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Arabic UI' (NotoSansArabicUI-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Syriac Eastern' (NotoSansSyriacEastern-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'FreeSerif' (FreeSerifBoldItalic.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Waree' (Waree-BoldOblique.ttf) oblique normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'KacstQurn' (KacstQurn.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias Infofont Z' (tiresias_infofontz_italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Umpush' (Umpush-LightOblique.ttf) oblique normal 300 normal>) = 11.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Waree' (Waree-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_Size3' (MathJax_Size3-Regular.otf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Ethiopic' (NotoSerifEthiopic-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Arabic' (NotoSansArabic-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Malayalam UI' (NotoSansMalayalamUI-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Tamil' (NotoSansTamil-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Malayalam' (NotoSerifMalayalam-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Thaana' (NotoSansThaana-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'KacstDecorative' (KacstDecorative.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Serif' (LiberationSerif-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Telugu' (NotoSansTelugu-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Lepcha' (NotoSansLepcha-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'aakar' (aakar-medium.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Georgian' (NotoSerifGeorgian-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Padauk Book' (PadaukBook-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Kinnari' (Kinnari.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'mry_KacstQurn' (mry_KacstQurn.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Sans' (LiberationSans-BoldItalic.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias PCfont' (tiresias_pcfont_italic.ttf) italic normal 28926 normal>) = 38.149699999999996
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Samyak Devanagari' (Samyak-Devanagari.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Thai' (NotoSansThai-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'FreeSerif' (FreeSerifItalic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Serif' (LiberationSerif-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Inscriptional Pahlavi' (NotoSansInscriptionalPahlavi-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Garuda' (Garuda-Oblique.ttf) oblique normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Cham' (NotoSansCham-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tlwg Mono' (TlwgMono.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Lisu' (NotoSansLisu-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Samyak Tamil' (Samyak-Tamil.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Gujarati UI' (NotoSansGujaratiUI-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'KacstOne' (KacstOne-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Lohit Assamese' (Lohit-Assamese.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Devanagari' (NotoSansDevanagari-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans CJK JP' (NotoSansCJK-Medium.ttc) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias PCfont Z' (tiresias_pcfontz_bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Naskh Arabic' (NotoNaskhArabic-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Chilanka' (Chilanka-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias PCfont' (tiresias_pcfont.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tlwg Typist' (TlwgTypist-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Tagalog' (NotoSansTagalog-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Padauk' (Padauk-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Phetsarath OT' (Phetsarath_OT.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_Fraktur' (MathJax_Fraktur-Bold.otf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'OpenDyslexicAlta' (OpenDyslexicAlta-Bold.otf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans' (DejaVuSansCondensed-Oblique.ttf) oblique normal 400 condensed>) = 1.25
DEBUG:matplotlib.font_manager:findfont: score(<Font 'FreeMono' (FreeMonoBold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Lohit Devanagari' (Lohit-Devanagari.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Manjari' (Manjari-Thin.otf) normal normal 100 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Mono' (LiberationMono-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Kannada UI' (NotoSansKannadaUI-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Malayalam' (NotoSansMalayalam-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif' (NotoSerif-BoldItalic.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Buginese' (NotoSansBuginese-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Chandas' (chandas1-2.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Sahadeva' (sahadeva.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tlwg Mono' (TlwgMono-Oblique.ttf) oblique normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Balinese' (NotoSansBalinese-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Loma' (Loma-Oblique.ttf) oblique normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias Signfont Z' (tiresias_signfontz_italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Samanata' (samanata.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_Math' (MathJax_Math-Regular.otf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Chakma' (NotoSansChakma-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Old Persian' (NotoSansOldPersian-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Ogham' (NotoSansOgham-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Meetei Mayek' (NotoSansMeeteiMayek-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans CJK JP' (NotoSansCJK-DemiLight.ttc) normal normal 350 normal>) = 10.0975
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Ubuntu' (Ubuntu-M.ttf) normal normal 500 normal>) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Sans Narrow' (LiberationSansNarrow-Italic.ttf) italic normal 400 condensed>) = 11.25
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias Infofont' (tiresias_infofont_bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Devanagari UI' (NotoSansDevanagariUI-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Ubuntu Mono' (UbuntuMono-RI.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Nakula' (nakula.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Ubuntu Condensed' (Ubuntu-C.ttf) normal normal 400 condensed>) = 10.25
DEBUG:matplotlib.font_manager:findfont: score(<Font 'OpenDyslexic' (OpenDyslexic-Italic.otf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Osmanya' (NotoSansOsmanya-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Bamum' (NotoSansBamum-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Sinhala UI' (NotoSansSinhalaUI-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Sawasdee' (Sawasdee.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-BoldOblique.ttf) oblique normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Loma' (Loma.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Oriya' (NotoSansOriya-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Lao' (NotoSansLao-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Umpush' (Umpush-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Purisa' (Purisa-BoldOblique.ttf) oblique normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Garuda' (Garuda-BoldOblique.ttf) oblique normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Armenian' (NotoSansArmenian-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Serif' (DejaVuSerifCondensed-BoldItalic.ttf) italic normal 700 condensed>) = 11.535
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Telugu' (NotoSansTelugu-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Thaana' (NotoSansThaana-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Kayah Li' (NotoSansKayahLi-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif CJK JP' (NotoSerifCJK-SemiBold.ttc) normal normal 600 normal>) = 10.24
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias LPfont' (tiresias_lpfont_italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Nastaliq Urdu' (NotoNastaliqUrdu-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Serif' (LiberationSerif-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Sans' (LiberationSans-Italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Rejang' (NotoSansRejang-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Oriya UI' (NotoSansOriyaUI-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Khmer OS System' (KhmerOSsys.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans' (DejaVuSansCondensed.ttf) normal normal 400 condensed>) = 0.25
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Telugu UI' (NotoSansTeluguUI-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Arabic' (NotoSansArabic-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias LPfont' (tiresias_lpfont.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Display' (NotoSerifDisplay-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans' (NotoSans-Italic.ttf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Telugu UI' (NotoSansTeluguUI-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tlwg Mono' (TlwgMono-BoldOblique.ttf) oblique normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans' (NotoSans-BoldItalic.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Ugaritic' (NotoSansUgaritic-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Glagolitic' (NotoSansGlagolitic-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'MathJax_Main' (MathJax_Main-Bold.otf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Karumbi' (Karumbi.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif CJK JP' (NotoSerifCJK-ExtraLight.ttc) normal normal 200 normal>) = 10.24
DEBUG:matplotlib.font_manager:findfont: score(<Font 'OpenDyslexicAlta' (OpenDyslexicAlta-Italic.otf) italic normal 400 normal>) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Bengali' (NotoSansBengali-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias Signfont' (tiresias_signfont.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Hebrew' (NotoSansHebrew-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Abyssinica SIL' (AbyssinicaSIL-R.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Khmer UI' (NotoSansKhmerUI-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tiresias PCfont' (tiresias_pcfont_bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Liberation Serif' (LiberationSerif-BoldItalic.ttf) italic normal 700 normal>) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Mitra Mono' (mitra.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Serif Hebrew' (NotoSerifHebrew-Bold.ttf) normal normal 700 normal>) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Kinnari' (Kinnari-Italic.ttf) italic normal 500 normal>) = 11.145
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Noto Sans Adlam Unjoined' (NotoSansAdlamUnjoined-Regular.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'D2Coding' (D2Coding-Ver1.3.2-20180524.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Umpush' (Umpush.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(<Font 'Tibetan Machine Uni' (TibetanMachineUni.ttf) normal normal 400 normal>) = 10.05
DEBUG:matplotlib.font_manager:findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/home/kimkk/miniconda3/envs/lomin/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.

	stem output of shape (1, 64, 120, 144) saved into ./npy_save/stem_output.npy
	layer1 output of shape (1, 256, 120, 144) saved into ./npy_save/layer1_output.npy
	layer2 output of shape (1, 512, 60, 72) saved into ./npy_save/layer2_output.npy
	layer3 output of shape (1, 1024, 30, 36) saved into ./npy_save/layer3_output.npy
	layer4 output of shape (1, 2048, 15, 18) saved into ./npy_save/layer4_output.npy


