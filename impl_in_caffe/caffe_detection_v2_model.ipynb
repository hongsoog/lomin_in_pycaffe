{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95a66030",
   "metadata": {},
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ded3f37",
   "metadata": {},
   "source": [
    "## Coding Styles for Python\n",
    "\n",
    "* [PEP 8 -- Style Guide for Python Code](https://www.python.org/dev/peps/pep-0008/)\n",
    "* [python style guide in google](https://google.github.io/styleguide/pyguide.html)\n",
    "* [파이썬 docstring 스타일 가이드에 대한 정리](https://medium.com/@kkweon/%ED%8C%8C%EC%9D%B4%EC%8D%AC-doc-%EC%8A%A4%ED%83%80%EC%9D%BC-%EA%B0%80%EC%9D%B4%EB%93%9C%EC%97%90-%EB%8C%80%ED%95%9C-%EC%A0%95%EB%A6%AC-b6d27cd0a27c)\n",
    "\n",
    "----\n",
    "\n",
    "```python\n",
    "  def connect_to_next_port(self, minimum: int) -> int:\n",
    "    \"\"\"Connects to the next available port.\n",
    "\n",
    "    Args:\n",
    "      minimum: A port value greater or equal to 1024.\n",
    "\n",
    "    Returns:\n",
    "      The new minimum port.\n",
    "\n",
    "    Raises:\n",
    "      ConnectionError: If no available port is found.\n",
    "    \"\"\"\n",
    "    if minimum < 1024:\n",
    "      # Note that this raising of ValueError is not mentioned in the doc\n",
    "      # string's \"Raises:\" section because it is not appropriate to\n",
    "      # guarantee this specific behavioral reaction to API misuse.\n",
    "      raise ValueError(f'Min. port must be at least 1024, not {minimum}.')\n",
    "    port = self._find_next_open_port(minimum)\n",
    "    if not port:\n",
    "      raise ConnectionError(\n",
    "          f'Could not connect to service on port {minimum} or higher.')\n",
    "    assert port >= minimum, (\n",
    "        f'Unexpected port {port} when minimum was {minimum}.')\n",
    "    return port\n",
    "```\n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0661daba",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "* [How to get model info in caffe and pytorch](http://echo.etri.re.kr:8090/display/~kimkk/how+to+get+model+info+in+caffe+and+pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff5b1c1",
   "metadata": {},
   "source": [
    "# Import related modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798bfc70",
   "metadata": {},
   "source": [
    "## sys, inspect and pathlib modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f789b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import inspect\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44678f6b",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### **inspect 모듈을 사용한 함수내부에서 함수명 알아내기**\n",
    "\n",
    "Reference:\n",
    "* [Determine function name from within that function (without using traceback)](https://stackoverflow.com/questions/5067604/determine-function-name-from-within-that-function-without-using-traceback)\n",
    "\n",
    "```python\n",
    "import inspect\n",
    "\n",
    "def foo():\n",
    "   print(inspect.stack()[0][3])\n",
    "   print(inspect.stack()[1][3]) #will give the caller of foos name, if something called foo\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27eacc75",
   "metadata": {},
   "source": [
    "## numpy modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1c5cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb568e8",
   "metadata": {},
   "source": [
    "## pycaffe modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc92bf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import caffe\n",
    "from caffe import layers as L, params as P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3282d7f2",
   "metadata": {},
   "source": [
    "## PIL modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fe54e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05e63d8",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# Input Image Trasform Functions\n",
    "\n",
    "관련 confluence페이지 \n",
    "* [Input Image Transform and to_image_list()](http://echo.etri.re.kr:8090/pages/viewpage.action?pageId=78088792)\n",
    "\n",
    "입력으로 주어지는 이미지는 PIL.Image 클래스를 사용하여 RGB모드로 오픈하며, 다음과 같은 3가지 transform을 거친다.\n",
    "이 과정은 maskrcnn_benchmark/data/transforms/transforms.py에서 구현한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4d5294",
   "metadata": {},
   "source": [
    "\n",
    "* Resize\n",
    "\n",
    "> 주어진 입력 이미지를 detection 모델의 입력으로 사용할 수 있도록, aspect ratio를 보존하면서 resize한다.\n",
    "> resize할 크기는 get_size()함수로 결정한다. 기본적인 알고리즘은\n",
    ">  * w, h 중 작은 값을 480으로 aspect ratio를 유지하면서 w' h'으로 resize한 후,\n",
    ">  * w', h'중 큰 값이 640보다 크다면 640으로 aspect resize\n",
    ">\n",
    "> resize된 크기는 다시 to_image_list에서 W, H가 32의 배수가 되도록 모자라는 부분을 zero pixel로 패딩해준후 모델의 입력으로 >사용한다.\n",
    "\n",
    "* ToTensor\n",
    "\n",
    "> Normalize 처리를 위하여 이미지를 PIL.Image 타입에서 tensor (ndarray)로 변환하고, 픽셀값을 255로 나눠준다.\n",
    "\n",
    "* Normalize\n",
    "\n",
    "> tensor에 대하여 Channel Order를 RGB에서 BGR로 변경하고 픽셀값에 255를 곱해준다.\n",
    "> 각 픽셀에 대하여 mean을 빼주고, std로 나누어 주는 normalization을 수행한다.\n",
    "> * mean은 cfg.INPUT.PIXEL_MEAN: [102.9801, 115.9465, 122.7717]으로 지정된 고정값\n",
    "> * std는 cfg.INPUT.PIXEL_STD: [1.0, 1.0, 1.0]으로 지정된 고정값\n",
    "\n",
    "**Questions**\n",
    "* 애초에 BRG로 오픈하면 되지 않을까?\n",
    "* ToTensor에서 255로 나눠주고, Normalize에서 다시 255를 곱해주나?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662b614c",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Resize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb57dcb",
   "metadata": {},
   "source": [
    "### get_size()\n",
    "\n",
    "먼저 Resize할 크기를 결정하는 함수는 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f2c9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size(pil_image, mode='keep_ratio'):\n",
    "    # mask rcnn transforms.py get_size() replica\n",
    "    \"\"\"Return suitable size for detection or recognition model\n",
    "\n",
    "    Args:\n",
    "        pil_image (PIL.Image) : PIL image opened with RGB mode (512x438=WxH)\n",
    "        mode (str) : resize mode\n",
    "            \"horizontal_padding\" | 'keep_ratio'\n",
    "\n",
    "    Returns:\n",
    "        (int, int) : tuple of (width, height) for resizing\n",
    "    \"\"\"\n",
    "    # get size of pil_image\n",
    "    w, h =  pil_image.size\n",
    "    \n",
    "    # output image width and height initialize\n",
    "    ow, oh = -1, -1\n",
    "\n",
    "    # i) recognition model: 'horizontal_padding'\n",
    "    if (mode=='horizontal_padding'):\n",
    "        ow, oh = -1, -1\n",
    "        target_width = int(w * (oh/h))\n",
    "        if target_width < oh:\n",
    "            target_width = oh\n",
    "\n",
    "        if target_width > ow:\n",
    "            target_width = ow\n",
    "\n",
    "        ow = target_width\n",
    "\n",
    "    # ii) detection model: 'keep_ratio'\n",
    "    elif (mode == 'keep_ratio'):\n",
    "        min_size = 480\n",
    "        max_size = 640\n",
    "        min_original_size = float(min((w,h)))\n",
    "        max_original_size = float(max((w,h)))\n",
    "\n",
    "        # summary\n",
    "        # take smaller one from height or width, and resize smaller one to 480\n",
    "        # and larger one is resized while keeping ratio\n",
    "\n",
    "        # i) first determine max_size\n",
    "        #   max_size : min_size  = max_original_size : min_original_size  -- (1)\n",
    "        #       ? :  480  =  512 : 438\n",
    "        # from (1) max_size = max_original_size * min_size / min_orignal_size\n",
    "        #                   =  480*512/438 = 531.09 = 561\n",
    "        # max size= 561.095\n",
    "        calc_max_size = max_original_size / min_original_size * min_size\n",
    "        max_size = min(calc_max_size, max_size)\n",
    "\n",
    "        # ii) determine min_size from the determined max_size\n",
    "        #   max_size : min_size  = max_original_size : min_original_size  -- (2)\n",
    "        #      561.095  :  ?  =  512 : 438\n",
    "        # from (2) min_size  =  max_size * min_original_size /  max_original_size\n",
    "        #                    = 561.095 * 438 /512 = 479.99 = round(479.99) = 480\n",
    "        min_size = round(max_size * min_original_size / max_original_size)\n",
    "\n",
    "        # if input image is a vertical image, i.e, height > width\n",
    "        #   ow = min_size, oh = max_size\n",
    "        # if input image is a horizontal image, i.e, width > height\n",
    "        #   ow = max_size, oh = min_size\n",
    "        ow = min_size if w < h else max_size\n",
    "\n",
    "        oh = max_size if w < h else min_size\n",
    "\n",
    "        # oh : 480, ow = 561.095\n",
    "        # int() cause round off\n",
    "        # oh : 480, ow = 561,\n",
    "        # (438, 512)  => (480, 561)   ; keep ratio = 1.168\n",
    "\n",
    "    # return target size with WXH format\n",
    "    return (int(ow), int(oh))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f46e4a6",
   "metadata": {},
   "source": [
    "### pil_image_resize()\n",
    "\n",
    "resize할 크기를 결정하고 나면, 실제로 다음과 같은 함수를 통하여 PIL image를 resize한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c09688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_image_resize(pil_image):\n",
    "    \"\"\"Returns resized the PIL image using BILINEAR interpolation\n",
    "\n",
    "    Args:\n",
    "        pil_image (PIL.Image) : original PIL image to be resized\n",
    "            ex. 512x438 => 561 x 480\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image : resized PIL Image\n",
    "    \"\"\"\n",
    "    # cacl height and width after resize\n",
    "    #size = get_size(pil_image, mode='keep_ratio')\n",
    "    width, height = get_size(pil_image, mode='keep_ratio')\n",
    "    \n",
    "    # do resize with BILINEAR interpolaton\n",
    "    #resized_pil_image = Image.resize(size, resample=Image.BILINEAR)\n",
    "    resized_pil_image =pil_image.resize((width,height), resample=Image.BILINEAR)\n",
    "\n",
    "    # WxH = 512x438 RGB ==> WxH = 561x480 RGB\n",
    "    return resized_pil_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c146ac",
   "metadata": {},
   "source": [
    "## PIL image to numpy.ndarray conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeb7723",
   "metadata": {},
   "source": [
    "### to_ndarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fbedc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_ndarray(pil_image):\n",
    "    \"\"\"Returns numpy.ndarray converted from PIL image of RGB mode\n",
    "\n",
    "    Args:\n",
    "    pil_image (PIL.Image):  resized PIL image, 561x480 (WxH), mode=RGB\n",
    "\n",
    "    Returns:\n",
    "        ndarray of float32 : array with shape of CxHxW with pixel value range 0.0 ~ 1.0\n",
    "    \"\"\"\n",
    "    # read PIL image into np.ndarray\n",
    "    image_array = np.array(pil_image)\n",
    "\n",
    "    # pil_image.size : (w, h)\n",
    "    # pil_image.mode : \"RGB\", len(pil_image.mode) =3\n",
    "    w, h = pil_image.size\n",
    "    c = len(pil_image.mode)\n",
    "\n",
    "    # reshape 707840 into HWC (480, 561, 3) format\n",
    "    image_array = image_array.reshape(h, w, c)\n",
    "\n",
    "    # change dimension order from HWC to CHW format\n",
    "    image_array = image_array.transpose(2, 0, 1)\n",
    "\n",
    "    # change pixel value range 0 - 255 to 0.0 ~ 1.0\n",
    "    image_array = np.float32(image_array) / 255.0\n",
    "    \n",
    "    return image_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbf6ac5",
   "metadata": {},
   "source": [
    "## Normalize\n",
    "\n",
    "numpy.ndarray에 대하여 Channel Order를 RGB에서 BGR로 변경하고 픽셀값에 255를 곱해준다.\n",
    "각 픽셀에 대하여 mean을 빼주고, std로 나누어 주는 normalization을 수행한다.\n",
    "\n",
    "Note that\n",
    "PIL uses RGB ch. order while OpenCV BGR ch. order\n",
    "* [https://note.nkmk.me/en/python-opencv-bgr-rgb-cvtcolor/](https://note.nkmk.me/en/python-opencv-bgr-rgb-cvtcolor/)\n",
    "\n",
    "Normalization에 사용하는 mean과 std의 값은 configuration에서 고정된 값을 사용한다.\n",
    "- mean은 cfg.INPUT.PIXEL_MEAN: [102.9801, 115.9465, 122.7717]으로 지정된 고정값\n",
    "-  std는 cfg.INPUT.PIXEL_STD: [1.0, 1.0, 1.0]으로 지정된 고정값\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a77a04",
   "metadata": {},
   "source": [
    "### normalize()\n",
    "\n",
    "**To Do**\n",
    ">  <span style=\"color:purple\">Inference시에 training 이미지의 channel별 mean을 빼기보다, testing 이미지의 channel 별로 mean을 구해서 빼주는게 맞지 않을까 싶다.</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f41dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image_array):\n",
    "    \"\"\" Returns normalized ndarray of BGR ch. order\n",
    "        with configuration defined mean and std\n",
    "\n",
    "    Args:\n",
    "        image_array (np.ndarray) : array format of resized input image, RGB mode and CHW dimension order\n",
    "\n",
    "    Returns:\n",
    "       ndarray: normalized with configuration defined mean and std\n",
    "           dimension order: CHW, channel order: BGR\n",
    "    \"\"\"\n",
    "    mean = [102.9801, 115.9465, 122.7717]\n",
    "    std =  [1.0, 1.0, 1.0]\n",
    "\n",
    "    # change ch. order from RGB to BGR\n",
    "    # https://note.nkmk.me/en/python-opencv-bgr-rgb-cvtcolor/\n",
    "    image_array = image_array[[2,1,0], :, :]\n",
    "\n",
    "    # multiply 255 to each pixel value\n",
    "    image_array = image_array*255\n",
    "\n",
    "    # normalize with mean and std\n",
    "    # since std is [1.0, 1.0, 1.0], just subtract mean\n",
    "    # note that CHW shape with channel order BGR\n",
    "    image_array[0, :, :] = image_array[0, :, :] - mean[0]\n",
    "    image_array[1, :, :] = image_array[1, :, :] - mean[1]\n",
    "    image_array[2, :, :] = image_array[2, :, :] - mean[2]\n",
    "    \n",
    "\n",
    "    return image_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8002d595",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Zero padding for 32 divisiblity\n",
    "\n",
    "Transform을 통하여 ndarray로 변환된 이미지 데이타(```image_array````)는 최종적으로 height $H$와 width $W$가 32의 배수가 되도록 해주어야 하는데, 이때는 resize를 하지 않고, 추가된 영역을 zero image로 패딩해준다.\n",
    "\n",
    "* 이미지 데이타의 크기에서 32의 배수가 되는 height $H'$와 width $W'$을 다음과 같이 계산하고\n",
    "  * $H' = \\lceil H/32 \\rceil \\times 32 $\n",
    "  * $W' = \\lceil W/32 \\rceil \\times 32 $\n",
    "* $3 \\times H'  \\times W'$의 zero image (```padded_image_array```)를 생성하고,\n",
    "* ```padded_image_array```의 ```[0:3, 0:H, 0:W]``` 영역위로  $3 \\times H \\times W$ ```image_array```의 값으로 덮어쓴다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc611ba",
   "metadata": {},
   "source": [
    "### zero_padding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4873de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_padding(image_array, size_divisible = 32):\n",
    "    \"\"\"Returns batched padded array with new width/height with 32 divisible and pad with zero pixels\n",
    "\n",
    "    Args:\n",
    "        image_array (np.ndarray) : image array of CHW dimension order and RGB channel order\n",
    "            ndarray of shape format (3, H, W), RGB channel order\n",
    "        size_divisible (int, default:32) : which multiple of width and height\n",
    "\n",
    "    Returns:\n",
    "        ndarray of shape [1, 3, H', W']:\n",
    "            batched image array of shape (1, 3, H', W'), H' and W' is multiple of 32\n",
    "            increase region filled with zeros and batch dimension added at axis 0\n",
    "    \"\"\"\n",
    "    # calc size divisible new height and width\n",
    "    c, h, w = image_array.shape\n",
    "        \n",
    "    new_h = int(np.ceil(h / size_divisible )* size_divisible)\n",
    "    new_w = int(np.ceil(w / size_divisible )* size_divisible)\n",
    "\n",
    "          \n",
    "    # create black image with size divisible\n",
    "    padded_image_array = np.zeros((3, new_h, new_w), dtype= np.float32)\n",
    "\n",
    "    # overlay image_array on padded_image\n",
    "    padded_image_array[:c, :h, :w] = image_array\n",
    "    \n",
    "    # add batch dimension into image_array\n",
    "    # (3, H, W) => (1, 3, H, W)    \n",
    "    padded_image_array = np.expand_dims(padded_image_array, axis=0)\n",
    "    \n",
    "    return padded_image_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a598041",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## 동작 일치성 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffe2806",
   "metadata": {},
   "source": [
    "### input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c782279",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file_path = \"../sample_images/detection/1594202471809.jpg\"\n",
    "pil_image = Image.open(image_file_path).convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e30d4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_image.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a35e9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pil_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce33352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIL image resize\n",
    "resized_pil_image=pil_image_resize(pil_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ebfe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_pil_image.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c17764",
   "metadata": {},
   "source": [
    "### resized image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52943c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(resized_pil_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d712786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIL image to np.ndarray\n",
    "image_array = to_ndarray(resized_pil_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08378aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65584f8e",
   "metadata": {},
   "source": [
    "### ndarrayed image check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0277577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6973e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make deep copy\n",
    "tmp_img = image_array.copy()\n",
    "\n",
    "# pixel value range 0.0~1.0 to 0.0~255.0\n",
    "tmp_img *=  255\n",
    "\n",
    "\n",
    "# change dimension order from CHW to HWC for dispaly\n",
    "tmp_img = tmp_img.transpose(1, 2, 0)\n",
    "\n",
    "# chnage float32 to uint8\n",
    "tmp_img = tmp_img.astype(np.uint8)\n",
    "print(f\"ndarray tmp_img.shape (H, W, C): {tmp_img.shape}\")\n",
    "\n",
    "# conver image array to PIL.Image\n",
    "tmp_img = Image.fromarray(tmp_img, 'RGB')\n",
    "\n",
    "print(f\"PIL tmp_img.size (W, H): {tmp_img.size}\")\n",
    "plt.imshow(tmp_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27944dd6",
   "metadata": {},
   "source": [
    "### normalized image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c861deb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize with mean and std\n",
    "# mean and std is defined in configuration\n",
    "normalized_image_array = normalize(image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3714fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape CxHxW, ch. order BGR, pixel value range: -122.77 ~ 152.01\n",
    "# normalized with mean and std\n",
    "mean = [102.9801, 115.9465, 122.7717]\n",
    "std =  [1.0, 1.0, 1.0]\n",
    "\n",
    "# Make deep copy !!\n",
    "tmp_img = normalized_image_array.copy()\n",
    "\n",
    "# unnormalized to 0. ~ 255.0\n",
    "tmp_img[0, :, :] = tmp_img[0, :, :] + mean[0]\n",
    "tmp_img[1, :, :] = tmp_img[1, :, :] + mean[1]\n",
    "tmp_img[2, :, :] = tmp_img[2, :, :] + mean[2]\n",
    "\n",
    "# change ch. order from BGR to RGB\n",
    "# https://note.nkmk.me/en/python-opencv-bgr-rgb-cvtcolor/\n",
    "tmp_img = tmp_img[[2,1,0], :, :]\n",
    "\n",
    "# change dimension order from CHW to HWC for dispaly\n",
    "tmp_img = tmp_img.transpose(1, 2, 0)\n",
    "\n",
    "# flaot 0.0~255.0 to 0 ~ 255\n",
    "tmp_img_array = tmp_img.astype(np.uint8)\n",
    "\n",
    "print(f\"tmp_img_array.shape (H, W, C): {tmp_img_array.shape}\")\n",
    "\n",
    "# conver image array to PIL.Image\n",
    "tmp_img = Image.fromarray(tmp_img_array, 'RGB')\n",
    "print(f\"tmp_img.size (W, H): {tmp_img.size}\")\n",
    "plt.imshow(tmp_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4863e4a3",
   "metadata": {},
   "source": [
    "### zero padded image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8139a174",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_image_array = zero_padding(normalized_image_array, size_divisible = 32)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6b44b28d",
   "metadata": {},
   "source": [
    "def zero_padding(image_array, size_divisible = 32):\n",
    "    \"\"\"Returns batched padded array with new width/height with 32 divisible and pad with zero pixels\n",
    "\n",
    "    Args:\n",
    "        image_array (np.ndarray) : image array of CHW dimension order and RGB channel order\n",
    "            ndarray of shape format (3, H, W), RGB channel order\n",
    "        size_divisible (int, default:32) : which multiple of width and height\n",
    "\n",
    "    Returns:\n",
    "        ndarray of shape [1, 3, H', W']:\n",
    "            batched image array of shape (1, 3, H', W'), H' and W' is multiple of 32\n",
    "            increase region filled with zeros and batch dimension added at axis 0\n",
    "    \"\"\"\n",
    "    # calc size divisible new height and width\n",
    "    h, w, c = image_array.shape\n",
    "        \n",
    "    new_h = int(np.ceil(h / size_divisible )* size_divisible)\n",
    "    new_w = int(np.ceil(w / size_divisible )* size_divisible)\n",
    "   \n",
    "    # create black image with size divisible\n",
    "    padded_image_array = np.zeros((new_h, new_w, ), dtype= np.float32)\n",
    "\n",
    "    # overlay image_array on padded_image\n",
    "    padded_image_array[:c, :h, :w] = tmp\n",
    "    \n",
    "    # add batch dimension\n",
    "    # (3, H, W) => (1, 3, H, W)    \n",
    "    padded_image_array = np.expand_dims(padded_image_array, axis=0)\n",
    "    \n",
    "    return padded_image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d01c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_divisible = 32\n",
    "\n",
    "h, w, c = tmp_img_array.shape\n",
    "     \n",
    "new_h = int(np.ceil(h / size_divisible )* size_divisible)\n",
    "new_w = int(np.ceil(w / size_divisible )* size_divisible)\n",
    "\n",
    "# create black image with size divisible\n",
    "zero_padded = np.zeros((new_h, new_w, c), dtype= np.uint8)\n",
    "\n",
    "# overlay image_array on padded_image\n",
    "zero_padded[:h, :w, :c] = tmp_img_array\n",
    "\n",
    "# conver image array to PIL.Image\n",
    "zero_padded = Image.fromarray(zero_padded, 'RGB')\n",
    "print(f\"zero_padded.size: {zero_padded.size}\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 3)  # row 1, column 2\n",
    "fig.set_figheight(15)  # unit: inch\n",
    "fig.set_figwidth(15)   # unit: inch\n",
    "\n",
    "# ceate rectangle path for clear boundary dispaly\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "w,h = pil_image.size\n",
    "rect = patches.Rectangle( (2, 2), w-5, h-5, linewidth=5, edgecolor='r', facecolor='none')\n",
    "ax[0].add_patch(rect)\n",
    "ax[0].imshow(pil_image)\n",
    "ax[0].set_title(f\"Input PIL Image \\nwith WxH {pil_image.width}x{pil_image.height}\")\n",
    "\n",
    "w,h = tmp_img.size\n",
    "rect = patches.Rectangle( (2, 2), w-5, h-5, linewidth=5, edgecolor='r', facecolor='none')\n",
    "ax[1].add_patch(rect)\n",
    "ax[1].imshow(tmp_img)\n",
    "ax[1].set_title(f\"Resized PIL Image \\nwith WxH {tmp_img.width}x{tmp_img.height}\")\n",
    "\n",
    "w,h = zero_padded.size\n",
    "rect = patches.Rectangle( (2, 2), w-5, h-5, linewidth=5, edgecolor='r', facecolor='none')\n",
    "ax[2].add_patch(rect)\n",
    "ax[2].imshow(zero_padded)\n",
    "ax[2].set_title(f\"Zero Padded PIL Image (32 divisible) \\nwith WxH {zero_padded.width}x{zero_padded.height}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0867aa",
   "metadata": {},
   "source": [
    "### matplotlib fig\n",
    "\n",
    "Reference:\n",
    "> [Matplotlib에서 도형 크기 및 형식을 변경하는 방법](https://www.delftstack.com/ko/howto/matplotlib/how-to-change-the-size-and-format-of-a-figure-in-matplotlib/)   \n",
    "> [Figure size in different units](https://matplotlib.org/devdocs/gallery/subplots_axes_and_figures/figure_size_units.html)\n",
    "\n",
    "The native figure size unit in Matplotlib is inches, deriving from print industry standards. However, users may need to specify their figures in other units like centimeters or pixels. This example illustrates how to do this efficiently.\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "text_kwargs = dict(ha='center', va='center', fontsize=28, color='C1')\n",
    "```\n",
    "\n",
    "**Figure size in inches (default)**\n",
    "\n",
    "```python\n",
    "plt.subplots(figsize=(6, 2))\n",
    "plt.text(0.5, 0.5, '6 inches x 2 inches', **text_kwargs)\n",
    "plt.show()\n",
    "```\n",
    "<img src=\"https://matplotlib.org/devdocs/_images/sphx_glr_figure_size_units_001_2_0x.png\" alt=\"fig in inch size\" width=\"400\"/>\n",
    "\n",
    "**Figure size in centimeter**\n",
    "\n",
    "Multiplying centimeter-based numbers with a conversion factor from cm to inches, gives the right numbers. Naming the conversion factor cm makes the conversion almost look like appending a unit to the number, which is nicely readable.\n",
    "\n",
    "```python\n",
    "cm = 1/2.54  # centimeters in inches\n",
    "plt.subplots(figsize=(15*cm, 5*cm))\n",
    "plt.text(0.5, 0.5, '15cm x 5cm', **text_kwargs)\n",
    "plt.show()\n",
    "```\n",
    "<img src=\"https://matplotlib.org/devdocs/_images/sphx_glr_figure_size_units_002_2_0x.png\" alt=\"fig in cm size\" width=\"400\"/>\n",
    "\n",
    "**Figure size in pixel**\n",
    "\n",
    "Similarly, one can use a conversion from pixels.  \n",
    "Note that you could break this if you use savefig with a different explicit dpi value.\n",
    "```python\n",
    "px = 1/plt.rcParams['figure.dpi']  # pixel in inches\n",
    "plt.subplots(figsize=(600*px, 200*px))\n",
    "plt.text(0.5, 0.5, '600px x 200px', **text_kwargs)\n",
    "plt.show()\n",
    "```\n",
    "<img src=\"https://matplotlib.org/devdocs/_images/sphx_glr_figure_size_units_003_2_0x.png\" alt=\"fig in pixel size\" width=\"400\"/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3810366c",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "###  Transform 동작 일치성 확인\n",
    "* [numpy.array_equal](https://numpy.org/doc/stable/reference/generated/numpy.array_equal.html)\n",
    "* [numpy.array_equiv](https://numpy.org/doc/stable/reference/generated/numpy.array_equiv.html)\n",
    "* [numpy.allclose](https://numpy.org/doc/stable/reference/generated/numpy.allclose.html)\n",
    "\n",
    "check with Pytorch code `detection_model_debug.py` saved `./npy_save/transformed_tensor.npy` and current `normalized_image_array` variable\n",
    "```python \n",
    "image_tensor = self.transforms(image)\n",
    "\n",
    "import numpy as np\n",
    "np.save(\"./npy_save/transformed_tensor.npy\", image_tensor)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a538f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_tensor = np.load(\"../npy_save/transformed_tensor.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eaa78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transformed_tensor.shape, transformed_tensor.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57f5ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(normalized_image_array.shape, normalized_image_array.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bba6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(transformed_tensor, normalized_image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0572778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(transformed_tensor, normalized_image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271da742",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equiv(transformed_tensor, normalized_image_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152317a5",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### Padded Image 일치성 확인\n",
    "* [numpy.array_equal](https://numpy.org/doc/stable/reference/generated/numpy.array_equal.html)\n",
    "* [numpy.array_equiv](https://numpy.org/doc/stable/reference/generated/numpy.array_equiv.html)\n",
    "* [numpy.allclose](https://numpy.org/doc/stable/reference/generated/numpy.allclose.html)\n",
    "\n",
    "check with Pytorch code `detection_model_debug.py` saved `./npy_save/padded_tensor.npy` and current `batch_image_array` variable\n",
    "```python \n",
    "image_list = to_image_list(image_tensor, self.cfg.DATALOADER.SIZE_DIVISIBILITY).to(self.device)\n",
    "np.save(\"./npy_save/padded_tensor.npy\", image_list.tensors.cpu())\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7433a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_image_array = zero_padding(normalized_image_array, size_divisible = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1119e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_image_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318cff66",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_tensor = np.load(\"../npy_save/padded_tensor.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3531674",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb91ac05",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(padded_tensor, batch_image_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbcd4ea",
   "metadata": {},
   "source": [
    "---\n",
    "# Caffe Model Functions\n",
    "\n",
    "Detection model은 다음과 같은 구성요소로 이루어져 있다.\n",
    "* model.backbone\n",
    "  * model.backbone.body : ResNet50 (5 stages)\n",
    "  * model.fpn : feature pyramid network\n",
    "* model.rpn : region proposal net\n",
    "\n",
    "전체적인 구조는 [http://echo.etri.re.kr:8090/display/~kimkk/detection+model+v2+structure](http://echo.etri.re.kr:8090/display/~kimkk/detection+model+v2+structure)를 참고한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8123bfe2",
   "metadata": {},
   "source": [
    "----\n",
    "```java\n",
    "(base) kimkk@alpha ~/lomin $ vi detection_model_v2_structure_with_comments.txt\n",
    "\n",
    "// ------------------------------------------------------------------------------------------------------------------------\n",
    "// Note\n",
    "// This is just structure of detection model v2, its structure does not imply any order of layers.\n",
    "// In this structure analysis, some layers those not include learnable parameters, such as ReLU or maxpool are hidden.\n",
    "// ------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "(lomin) kimkk@alpha ~/lomin $ vi model_structure.txt\n",
    "\n",
    "GenerallizedRCNN    \"model\"\n",
    "  │\n",
    "  ├─── backbone     \"model.backbone\"\n",
    "  │     │\n",
    "  │     ├─── body  \"model.backbone.body\"\n",
    "  │     │     ├── stem   \"model.backbone.body.stem\"\n",
    "  │     │     │    │   related source: maskrcnn_benchmark/modelling/backbone/resenet.py StemWithFixedBatchNorm class\n",
    "  │     │     │    │   --> conv1 ->  bn1 (FronzenBatchNorm2d : bn -> scale ) -> relu -> max_pool2d\n",
    "  │     │     │    │\n",
    "  │     │     │    ├── conv1  \"model.backbone.body.stem.conv1\",  // def: Conv2d(in_channels=3, out_channels=64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)]\n",
    "  │     │     │    └── bn1    \"model.backbone.body.stem.bn1\",    // def: FrozenBatchNorm2d() : bn -> scale\n",
    "  │     │     │\n",
    "  │     │     ├── layer1 \"model.backbone.body.layer1\"\n",
    "  │     │     │    │\n",
    "  │     │     │    │    related source: maskrcnn_benchmark/modelling/backbone/resenet.py BottleneckWithFixedBatchNorm class\n",
    "  │     │     │    │        + ---------------------------------------> downnsample -----------------+\n",
    "  │     │     │    │        ^                                                                       |\n",
    "  │     │     │    │        │                                                                       V\n",
    "  │     │     │    │    --> + -> conv1 -> bn1 -> relu -> conv2 -> bn2 -> relue -> conv3 -> bn3 ->  Add  -> relu\n",
    "  │     │     │    │\n",
    "  │     │     │    ├─── 0   \"model.backbone.body.layer1.0\"\n",
    "  │     │     │    │    ├── downsample \"model.backbone.body.layer1.0.downsample\"\n",
    "  │     │     │    │    │    │\n",
    "  │     │     │    │    │    ├── 0     \"model.backbone.body.layer1.0.downsample.0\",   // def: Conv2d(in_channels=64, out_channels=256, kernel_size=(1, 1), stride=(1, 1), bias=False) x\n",
    "  │     │     │    │    │    └── 1     \"model.backbone.body.layer1.0.downsample.1\",   // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │    │    ├── conv1      \"model.backbone.body.layer1.0.conv1\",          // def: Conv2d(in_channels=64, out_channels=64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │    │    ├── bn1        \"model.backbone.body.layer1.0.bn1\",            // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │    │    ├── conv2      \"model.backbone.body.layer1.0.conv2\",          // def: Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  │     │     │    │    ├── bn2        \"model.backbone.body.layer1.0.bn2\",            // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │    │    ├── conv3      \"model.backbone.body.layer1.0.conv3\",          // def: Conv2d(in_channels=64, out_channels=256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │    │    └── bn3        \"model.backbone.body.layer1.0.bn3\",            // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │    │\n",
    "  │     │     │    │    --> conv1 -> bn1 -> relu -> conv2 -> bn2 -> relue -> conv3 -> bn3 -> relu\n",
    "  │     │     │    │\n",
    "  │     │     │    ├─── 1   \"model.backbone.body.layer1.1\"\n",
    "  │     │     │    │    ├── conv1      \"model.backbone.body.layer1.1.conv1\",          // def: Conv2d(in_channels=256, out_channels=64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │    │    ├── bn1        \"model.backbone.body.layer1.1.bn1\",            // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │    │    ├── conv2      \"model.backbone.body.layer1.1.conv2\",          // def: Conv2d(in_channels=64,  out_channels=64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  │     │     │    │    ├── bn2        \"model.backbone.body.layer1.1.bn1\",            // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │    │    ├── conv3      \"model.backbone.body.layer1.1.conv3\",          // def: Conv2d(in_channels=64,  out_channels=256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │    │    └── bn3        \"model.backbone.body.layer1.1.bn3\",            // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │    │\n",
    "  │     │     │    │    --> conv1 -> bn1 -> relu -> conv2 -> bn2 -> relue -> conv3 -> bn3 -> relu\n",
    "  │     │     │    │\n",
    "  │     │     │    └─── 2   \"model.backbone.body.layer1.2\"\n",
    "  │     │     │         ├── conv1      \"model.backbone.body.layer1.2.conv1\",          // def: Conv2d(in_channels=256, out_channels=64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │         ├── bn1        \"model.backbone.body.layer1.2.bn1\",            // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │         ├── conv2      \"model.backbone.body.layer1.2.conv2\",          // def: Conv2d(in_channels=64,  out_channels=64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  │     │     │         ├── bn2        \"model.backbone.body.layer1.2.bn2\",            // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │         ├── conv3      \"model.backbone.body.layer1.2.conv3\",          // def: Conv2d(in_channels=64,  out_channels=256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │         └── bn3        \"model.backbone.body.layer1.2.conv2\",          // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │\n",
    "  │     │     ├── layer2 \"model.backbone.body.layer2\"\n",
    "  │     │     │    │\n",
    "  │     │     │    ├─── 0   \"model.backbone.body.layer2.0\"\n",
    "  │     │     │    │    ├── downsample  \"model.backbone.body.layer2.0.downsample\"\n",
    "  │     │     │    │    │    │\n",
    "  │     │     │    │    │    ├── 0      \"model.backbone.body.layer2.0.downsample.0\" , // def: Conv2d(in_channels=256, out_channels=512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "  │     │     │    │    │    └── 1      \"model.backbone.body.layer2.0.downsample.1\",  // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │    │    ├── conv1       \"model.backbone.body.layer2.0.conv1\",         // def: Conv2d(in_channels=256, out_channels=128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "  │     │     │    │    ├── bn1         \"model.backbone.body.layer2.0.bn1\",           // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │    │    ├── conv2       \"model.backbone.body.layer2.0.conv2\",         // def: Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  │     │     │    │    ├── bn2         \"model.backbone.body.layer2.0.bn2\",,          // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │    │    ├── conv3       \"model.backbone.body.layer2.0.conv3\",         // def: Conv2d(in_channels=128, out_channels=512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │    │    └── bn3         \"model.backbone.body.layer2.0.bn3\",           // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │    │\n",
    "  │     │     │    ├─── 1   \"model.backbone.body.layer2.1\"\n",
    "  │     │     │    │    ├── conv1       \"model.backbone.body.layer2.1.conv1\",         // def: Conv2d(in_channels=512, out_channels=128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │    │    ├── bn1         \"model.backbone.body.layer2.1.bn1\",           // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │    │    ├── conv2       \"model.backbone.body.layer2.1.conv2\",         // def: Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  │     │     │    │    ├── bn2         \"model.backbone.body.layer2.1.bn2\",           // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │    │    ├── conv3       \"model.backbone.body.layer2.1.conv3\",         // def: Conv2d(in_channels=128, out_channels=512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │    │    └── bn3         \"model.backbone.body.layer2.1.bn3\",           // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │    │\n",
    "  │     │     │    ├─── 2   \"model.backbone.body.layer2.2\"\n",
    "  │     │     │    │    ├── conv1       \"model.backbone.body.layer2.2.conv1\",         // def: Conv2d(in_channels=512, out_channels=128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │    │    ├── bn1         \"model.backbone.body.layer2.2.bn1\",           // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │    │    ├── conv2       \"model.backbone.body.layer2.2.conv2\",         // def: Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  │     │     │    │    ├── bn2         \"model.backbone.body.layer2.2.bn2\",           // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │    │    ├── conv3       \"model.backbone.body.layer2.2.conv3\",         // def: Conv2d(in_channels=128, out_channels=512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │    │    └── bn3         \"model.backbone.body.layer2.2.bn3\",           // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │    │\n",
    "  │     │     │    └─── 3 \"model.backbone.body.layer2.3\"\n",
    "  │     │     │         ├── conv1       \"model.backbone.body.layer2.3.conv1\",         // def: Conv2d(in_channels=512, out_channels=128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │         ├── bn1         \"model.backbone.body.layer2.3.bn1\",           // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │         ├── conv2       \"model.backbone.body.layer2.3.conv2\",         // def: Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  │     │     │         ├── bn2         \"model.backbone.body.layer2.3.bn2\",           // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │         ├── conv3       \"model.backbone.body.layer2.3.conv3\",         // def: Conv2d(in_channels=128, out_channels=512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │         └── bn3         \"model.backbone.body.layer2.3.bn3\",           // def: FrozenBatchNorm2d() : bn -> scale -> relu \"==> C2, Input to FPN\"\n",
    "  │     │     │\n",
    "  │     │     ├── layer3 \"model.backbone.body.layer3\"\n",
    "  │     │     │    │\n",
    "  │     │     │    ├─── 0 \"model.backbone.body.layer3.0\"\n",
    "  │     │     │    │    ├── downsample \"model.backbone.body.layer3.0.downsamples\"\n",
    "  │     │     │    │    │    │\n",
    "  │     │     │    │    │    ├── 0      \"model.backbone.body.layer3.0.downsamples.0\", // def: Conv2d(in_channels=512, out_channels=1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "  │     │     │    │    │    └── 1      \"model.backbone.body.layer3.0.downsamples.0\", // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │    │    ├── conv1       \"model.backbone.body.layer3.0.conv1\",         // def: Conv2d(in_channels=512, out_channels=256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "  │     │     │    │    ├── bn1         \"model.backbone.body.layer3.0.bn1\",           // def: # FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │    │    ├── conv2       \"model.backbone.body.layer3.0.conv2\",         // def: Conv2d(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  │     │     │    │    ├── bn2         \"model.backbone.body.layer3.0.bn2\",           // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │    │    ├── conv3       \"model.backbone.body.layer3.0.conv3\",         // def: Conv2d(in_channels=256, out_channels=1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │    │    └── bn3         \"model.backbone.body.layer3.0.bn3\",           // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │    │\n",
    "  │     │     │    ├─── 1 \"model.backbone.body.layer3.1\"\n",
    "  │     │     │    │    ├── conv1       \"model.backbone.body.layer3.1.conv1\",         // def: Conv2d(in_channels=1024, out_channels=256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │    │    ├── bn1         \"model.backbone.body.layer3.1.bn1\",           // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │    │    ├── conv2       \"model.backbone.body.layer3.1.conv2\",         // def: Conv2d(in_channels=256,  out_channels=256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  │     │     │    │    ├── bn2         \"model.backbone.body.layer3.1.bn2\",           // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │    │    ├── conv3       \"model.backbone.body.layer3.1.conv3\",         // def: Conv2d(in_channels=256,  out_channels=1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │    │    └── bn3         \"model.backbone.body.layer3.1.bn3\",           // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │    │\n",
    "  │     │     │    ├─── 2 \"model.backbone.body.layer3.2\"\n",
    "  │     │     │    │    ├── conv1       \"model.backbone.body.layer3.2.conv1\",         // def: Conv2d(in_channels=1024, out_channels=256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │    │    ├── bn1         \"model.backbone.body.layer3.2.bn1\",           // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │    │    ├── conv2       \"model.backbone.body.layer3.2.conv2\",         // def: Conv2d(in_channels=256,  out_channels=256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  │     │     │    │    ├── bn2         \"model.backbone.body.layer3.2.bn2\",           // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │    │    ├── conv3       \"model.backbone.body.layer3.2.conv3\",         // def: Conv2d(in_channels=256,  out_channels=1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │    │    └── bn3         \"model.backbone.body.layer3.2.bn3\",           // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │    │\n",
    "  │     │     │    ├─── 3 \"model.backbone.body.layer3.3\"\n",
    "  │     │     │    │    ├── conv1       \"model.backbone.body.layer3.3.conv1\",         // def: Conv2d(in_channels=1024, out_channels=256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │    │    ├── bn1         \"model.backbone.body.layer3.3.bn1\",           // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │    │    ├── conv2       \"model.backbone.body.layer3.3.conv2\",         // def: Conv2d(in_channels=256,  out_channels=256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  │     │     │    │    ├── bn2         \"model.backbone.body.layer3.3.bn2\",           // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │    │    ├── conv3       \"model.backbone.body.layer3.3.conv3\",         // def: Conv2d(in_channels=256,  out_channels=1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │    │    └── bn3         \"model.backbone.body.layer3.3.bn3\",           // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │    │\n",
    "  │     │     │    ├─── 4 \"model.backbone.body.layer3.4\"\n",
    "  │     │     │    │    ├── conv1       \"model.backbone.body.layer3.4.conv1\",         // def: Conv2d(in_channels=1024, out_channels=256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │    │    ├── bn1         \"model.backbone.body.layer3.4.bn1\",           // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │    │    ├── conv2       \"model.backbone.body.layer3.4.conv2\",         // def: Conv2d(in_channels=256,  out_channels=256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  │     │     │    │    ├── bn2         \"model.backbone.body.layer3.4.bn2\",           // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │    │    ├── conv3       \"model.backbone.body.layer3.4.conv3\",         // def: Conv2d(in_channels=256,  out_channels=1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │    │    └── bn3         \"model.backbone.body.layer3.4.bn3\",           // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │    │\n",
    "  │     │     │    └─── 5 \"model.backbone.body.layer3.5\"\n",
    "  │     │     │         ├── conv1       \"model.backbone.body.layer3.5.conv1\",         // def: Conv2d(in_channels=1024, out_channels=256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │         ├── bn1         \"model.backbone.body.layer3.5.bn1\",           // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │         ├── conv2       \"model.backbone.body.layer3.5.conv2\",         // def: Conv2d(in_channels=256,  out_channels=256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  │     │     │         ├── bn2         \"model.backbone.body.layer3.5.bn2\",           // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │     │         ├── conv3       \"model.backbone.body.layer3.5.conv3\",         // def: Conv2d(in_channels=256,  out_channels=1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │         └── bn3         \"model.backbone.body.layer3.5.bn3\",           // def: FrozenBatchNorm2d() : bn -> scale -> relu \"==> C3 : Input to FPN\"\n",
    "  │     │     │\n",
    "  │     │     └── layer4 \"model.backbone.body.layer4\"\n",
    "  │     │          │\n",
    "  │     │          ├─── 0 \"model.backbone.body.layer4.0\"\n",
    "  │     │          │    ├── downsample  \"model.backbone.body.layer4.0.downsample\"\n",
    "  │     │          │    │   │\n",
    "  │     │          │    │   ├── 0       \"model.backbone.body.layer4.0.downsample.0\",  // def: Conv2d(in_channels=1024, out_channels=2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "  │     │          │    │   └── 1       \"model.backbone.body.layer4.0.downsample.1\",  // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │          │    ├── conv1       \"model.backbone.body.layer4.0.conv1\",         // def: Conv2d(in_channels=1024, out_channels=512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "  │     │          │    ├── bn1         \"model.backbone.body.layer4.0.bn1\",           // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │          │    ├── conv2       \"model.backbone.body.layer4.0.conv2\",         // def: Conv2d(in_channels=512,  out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  │     │          │    ├── bn2         \"model.backbone.body.layer4.0.bn2\",           // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │          │    ├── conv3       \"model.backbone.body.layer4.0.conv3\",         // def: Conv2d(in_channels=512,  out_channels=2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │          │    └── bn3         \"model.backbone.body.layer4.0.bn3\",           // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │          │\n",
    "  │     │          ├─── 1 \"model.backbone.body.layer4.1\"\n",
    "  │     │          │    ├── conv1       \"model.backbone.body.layer4.1.conv1\",         // def: Conv2d(in_channels=2048, out_channels=512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │          │    ├── bn1         \"model.backbone.body.layer4.1.bn1\",           // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │          │    ├── conv2       \"model.backbone.body.layer4.1.conv2\",         // def: Conv2d(in_channels=512,  out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  │     │          │    ├── bn2         \"model.backbone.body.layer4.1.bn2\",           // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │          │    ├── conv3       \"model.backbone.body.layer4.1.conv3\",         // def: Conv2d(in_channels=512,  out_channels=2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │          │    └── bn3         \"model.backbone.body.layer4.1.bn3\",           // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │          │\n",
    "  │     │          └─── 2 \"model.backbone.body.layer4.2\"\n",
    "  │     │               ├── conv1       \"model.backbone.body.layer4.2.conv1\",         // def: Conv2d(in_channels=2048, out_channels=512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │               ├── bn1         \"model.backbone.body.layer4.2.bn1\",           // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │               ├── conv2       \"model.backbone.body.layer4.2.conv2\",         // def: Conv2d(in_channels=512,  out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  │     │               ├── bn2         \"model.backbone.body.layer4.2.bn2\",           // def: FrozenBatchNorm2d() : bn -> scale -> relu\n",
    "  │     │               ├── conv3       \"model.backbone.body.layer4.2.conv3\",         // def: Conv2d(in_channels=512,  out_channels=2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │               └── bn3         \"model.backbone.body.layer4.2.bn3\",           // def: FrozenBatchNorm2d() : bn -> scale -> relu \"==> C4 : Input to FPN\"\n",
    "  │     │\n",
    "  │     └─── fpn \"model.backbone.fpn\"\n",
    "  │           ├── fpn_inner2            \"model.backbone.fpn.fpn_inner2\",              // def: Conv2d(in_channels=512,  out_channels=1024, kernel_size=(1, 1), stride=(1, 1))\n",
    "  │           ├── fpn_layer2            \"model.backbone.fpn.fpn_layer2\",              // def: Conv2d(in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  │           │\n",
    "  │           ├── fpn_inner3            \"model.backbone.fpn.fpn_inner3\",              // def: Conv2d(in_channels=1024, out_channels=1024, kernel_size=(1, 1), stride=(1, 1))\n",
    "  │           ├── fpn_layer3            \"model.backbone.fpn.fpn_layer3\",              // def: Conv2d(in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  │           │\n",
    "  │           ├── fpn_inner4            \"model.backbone.fpn.fpn_inner4\",              // def: Conv2d(in_channels=2048, out_channels=1024, kernel_size=(1, 1), stride=(1, 1))\n",
    "  │           ├── fpn_layer4            \"model.backbone.fpn.fpn_layer4\",              // def: Conv2d(in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  │           │\n",
    "  │           └── top_blocks \"model.backbone.fpn.topblocks\"\n",
    "  │                 │\n",
    "  │                 ├─── p6             \"model.backbone.fpn.topblocks.p6\",            // def: Conv2d(in_channels=2048, out_channels=1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "  │                 └─── p7             \"model.backbone.fpn.topblocks.p7\",            // def: Conv2d(in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "  │\n",
    "  └─── rpn          \"model.rpn\"\n",
    "        │\n",
    "        ├─── anchor_generator \"model.rpn.anchor_generator\"\n",
    "        │           │\n",
    "        │           └─── cell_anchors   \"model.rpn.anchor_generator.cell_achors\",     // def: BufferList()\n",
    "        │\n",
    "        ├─── head  \"model.rpn.head\"\n",
    "        │           │\n",
    "        │           ├─── cls_tower      \"model.rpn.head.cls_tower\",\n",
    "        │           │     ├─── 0        \"model.rpn.head.cls_tower.0\",                 // def: Conv2d(in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        │           │     ├─── 1        \"model.rpn.head.cls_tower.1\",                 // def: ReLU()\n",
    "        │           │     ├─── 2        \"model.rpn.head.cls_tower.2\",                 // def: Conv2d(in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        │           │     ├─── 3        \"model.rpn.head.cls_tower.3\",                 // def: ReLU()\n",
    "        │           │     ├─── 4        \"model.rpn.head.cls_tower.4\",                 // def: Conv2d(in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ReLU()\n",
    "        │           │     ├─── 5        \"model.rpn.head.cls_tower.5\",                 // def: ReLU()\n",
    "        │           │     ├─── 6        \"model.rpn.head.cls_tower.6\",                 // def: Conv2d(in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        │           │     └─── 7        \"model.rpn.head.cls_tower.7\",                 // def: ReLU()\n",
    "        │           │\n",
    "        │           ├─── bbox_tower     \"model.rpn.head.bbox_tower\"\n",
    "        │           │     ├─── 0        \"model.rpn.head.bbox_tower.0\",                // def: Conv2d(in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        │           │     ├─── 1        \"model.rpn.head.bbox_tower.1\",                // def: ReLU()\n",
    "        │           │     ├─── 2        \"model.rpn.head.bbox_tower.2\",                // def: Conv2d(in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        │           │     ├─── 3        \"model.rpn.head.bbox_tower.3\",                // def: ReLU()\n",
    "        │           │     ├─── 4        \"model.rpn.head.bbox_tower.4\",                // def: Conv2d(in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ReLU()\n",
    "        │           │     ├─── 5        \"model.rpn.head.bbox_tower.5\",                // def: ReLU()\n",
    "        │           │     ├─── 6        \"model.rpn.head.bbox_tower.6\",                // def: Conv2d(in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        │           │     └─── 7        \"model.rpn.head.bbox_tower.7\",                // def: ReLU()\n",
    "        │           │\n",
    "        │           ├─── cls_logits     \"model.rpn.head.cls_logits\",                  // def: Conv2d(in_channels=1024, out_channels=9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        │           │\n",
    "        │           └─── bbox_pred      \"model.rpn.head.bbox_pre\",                    // def: Conv2d(in_channels=1024, out_channels=36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        │\n",
    "        └─── box_selector_test \"model.rpn.box_selector_test\",                         // def: RetinaNetPostProcessor()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b086f112",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Backbone body (Resnet50) Build\n",
    "Original Code Source\n",
    "* [https://gist.github.com/kyamagu/80c343a14ae4564ef79b53f0b01cd57e](https://gist.github.com/kyamagu/80c343a14ae4564ef79b53f0b01cd57e)\n",
    "* [https://gist.github.com/rezoo/a1c8d1459b222fc5658f](https://gist.github.com/rezoo/a1c8d1459b222fc5658f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e061c86e",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### Common Conv-BN-Relu Block\n",
    "\n",
    "mask rcnn에서 사용하는 FrozenBatchNorm2d 방식으로 구현할 것.\n",
    "* [Why FrozenBatchNorm2d in ResNet?](http://echo.etri.re.kr:8090/pages/viewpage.action?pageId=78088692)\n",
    "* https://github.com/facebookresearch/maskrcnn-benchmark/issues/267\n",
    "* [Batch Normalization 설명 및 구현](http://echo.etri.re.kr:8090/pages/viewpage.action?pageId=78088844)\n",
    "\n",
    "**Caffe BatchNorm vs Torch BatchNorm2d**\n",
    "\n",
    "* [During test phase, the output of Batch Normalization layer is not equal to (input-mean)/sqrt(var + eps)?](https://github.com/BVLC/caffe/issues/4885)\n",
    "> `net.params['bn_1'][0].data` : mean  \n",
    "> `net.params['bn_1'][1].data` : variance   \n",
    "> `net.params['bn_1'][2].data` : scores a scale factor, which I should divide from each mean and variance at this layer.    \n",
    "\n",
    "So in Caffe, the output of BN layer calculated by: \n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "\\frac{\\frac{ \\text{input} - \\text{mean} }{ \\text{scale_factor} }}{\\sqrt { \\frac{ \\text{var }}{ \\text{scale_factor } } + \\epsilon}}\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "batchnorm 없이 scale 레이어로만해도  될듯...\n",
    "\n",
    "**Batch Norm Layer:**  \n",
    "* $\\gamma$ --> Var (1)   \n",
    "* $\\beta$  --> mean (0)   \n",
    "* $mean$  --> moving average fraction (=1)   \n",
    "\n",
    "**Scale Layer:**\n",
    "* scale --> 논문에서의 $\\gamma$   \n",
    "* bias  --> 논문에서의 $\\beta$   \n",
    "\n",
    "----\n",
    "\n",
    "```python\n",
    "# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.\n",
    "import torch\n",
    "from torch import nn\n",
    " \n",
    " \n",
    "class FrozenBatchNorm2d(nn.Module):\n",
    "    \"\"\"\n",
    "    BatchNorm2d where the batch statistics and the affine parameters\n",
    "    are fixed\n",
    "    \"\"\"\n",
    " \n",
    "    def __init__(self, n):\n",
    "        super(FrozenBatchNorm2d, self).__init__()\n",
    "        self.register_buffer(\"weight\", torch.ones(n))\n",
    "        self.register_buffer(\"bias\", torch.zeros(n))\n",
    "        self.register_buffer(\"running_mean\", torch.zeros(n))\n",
    "        self.register_buffer(\"running_var\", torch.ones(n))\n",
    " \n",
    "    def forward(self, x):\n",
    "        # Cast all fixed parameters to half() if necessary\n",
    "        if x.dtype == torch.float16:\n",
    "            self.weight = self.weight.half()\n",
    "            self.bias = self.bias.half()\n",
    "            self.running_mean = self.running_mean.half()\n",
    "            self.running_var = self.running_var.half()\n",
    " \n",
    "        scale = self.weight * self.running_var.rsqrt()\n",
    "        bias = self.bias - self.running_mean * scale\n",
    "        scale = scale.reshape(1, -1, 1, 1)\n",
    "        bias = bias.reshape(1, -1, 1, 1)\n",
    "        return x * scale + bias\n",
    "```\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cbf1af",
   "metadata": {},
   "source": [
    "\n",
    "#### conv_fbn()\n",
    "\n",
    "Resnet Stage의 sublayer를 구성하는 다음과 같은 building block을 생성한다.\n",
    "* [Conv2d()](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) +  [FrozenBatchNorm2d()](https://github.com/facebookresearch/maskrcnn-benchmark/blob/57eec25b75144d9fb1a6857f32553e1574177daf/maskrcnn_benchmark/layers/batch_norm.py#L6) + [ReLu()](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea77ed8a",
   "metadata": {},
   "source": [
    "def conv_bn_scale_org(bottom, nout, bias_term=False, **kwargs):\n",
    "    '''\n",
    "    build a Conv -> BN -> Scale block\n",
    "    \n",
    "        param: bottom : input to this conv/bn/scale block\n",
    "        type:  bottom : \n",
    "        param: nout   : num of oputs in Convolution Layer\n",
    "        type:  uint \n",
    "        param: bias_term : bias term used in Scale Layer\n",
    "        type: bool : default False\n",
    "        return: top of conv, bn, scale\n",
    "        rtype: \n",
    "        \n",
    "    '''\n",
    "    conv = L.Convolution(bottom, num_output=nout, bias_term=bias_term, **kwargs)\n",
    "    \n",
    "    # https://github.com/facebookresearch/maskrcnn-benchmark/blob/master/maskrcnn_benchmark/layers/batch_norm.py\n",
    "    bn = L.BatchNorm(conv, use_global_stats=True, in_place=True)\n",
    "    scale = L.Scale(bn, bias_term=True, in_place=True)\n",
    "    return conv, bn, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23503607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_fbn(bottom, nout, bias_term=False, **kwargs):\n",
    "    \"\"\" Bbuuild a Conv -> FronzeBN (FrozenBN is actually Scale layer)\n",
    "    Args:\n",
    "        bottom: input to this conv/bn/scale block\n",
    "        nout : num of oputs in Convolution Layer\n",
    "        use_bias_term_in_scale  : bias term used in Scale Layer\n",
    "\n",
    "    Reurns:\n",
    "        top of conv, fbn\n",
    "\n",
    "    \"\"\" \n",
    "    conv = L.Convolution(bottom, num_output=nout, bias_term=bias_term, **kwargs)\n",
    "    \n",
    "    # https://github.com/facebookresearch/maskrcnn-benchmark/blob/master/maskrcnn_benchmark/layers/batch_norm.py\n",
    "    #bn = L.BatchNorm(conv, use_global_stats=True, in_place=True)\n",
    "    #fbn = L.Scale(conv, bias_term=True, in_place=True)\n",
    "    fbn = L.Scale(conv, bias_term=True, in_place=False)\n",
    "    return conv, fbn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c98dc4",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### Resnet Stage Buid\n",
    "\n",
    "```conv_bn_scale()``` 함수를 사용하여 다음과 같이 Resnet의 Stage를 구성하는 sublayer들을 생성하는 ```resnet_stage_sublayer()```를 정의한다.\n",
    "\n",
    "\n",
    "**Overview diagram**\n",
    "\n",
    "```js\n",
    "             +------> [ *_downsample_0 -- *_downsample_1 --- *_downsample_scale ] -----------+\n",
    "             |                                                                               |\n",
    "    bottom --+---------> [ *_conv1 --- *_bn1 --- *_scale1 --- *_relu1 ] ----+                |\n",
    "             |                                                              |                | \n",
    "             |     +--------------------------------------------------------+                |\n",
    "             |     |                                                                         |\n",
    "             |     +---> [ *_conv2 --- *_bn2 --- *_scale2 --- *_relu2 ] ----+                |\n",
    "             |                                                              |                | if downsample == True\n",
    "             |     +--------------------------------------------------------+                | \n",
    "             |     |                                                                         V\n",
    "             |     +---> [ *_conv3 --- *_bn3 --- *_scale3 -------------------------> [ *_res: Eltwise ] ----> *__res_relu :ReLu\n",
    "             |                                                                                ^\n",
    "             |                                                                                | \n",
    "             |                                                                                | if downsample == False\n",
    "             +--------------------------------------------------------------------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bd314c",
   "metadata": {},
   "source": [
    "#### resnet_stage_sublayer()\n",
    "\n",
    "Resnet caffe codefrom\n",
    "* [https://gist.github.com/kyamagu/80c343a14ae4564ef79b53f0b01cd57e](https://gist.github.com/kyamagu/80c343a14ae4564ef79b53f0b01cd57e)\n",
    "* [https://gist.github.com/rezoo/a1c8d1459b222fc5658f](https://gist.github.com/rezoo/a1c8d1459b222fc5658f)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c2347e21",
   "metadata": {},
   "source": [
    "def residual_block(name, n, bottom, nout, branch1=False, initial_stride=2):\n",
    "    '''\n",
    "    function for building Basic Resnet Block\n",
    "    \n",
    "        param: name : residual block name\n",
    "        type:  string\n",
    "        param: n: NetSpec object\n",
    "        type: caffe.NetSpec\n",
    "        param: bottom : input to this residual block\n",
    "        type: \n",
    "        param: nout : num. of out ch.\n",
    "        type:\n",
    "        param: branch1 : whether or not to include of subsample at beginning of this residula block? \n",
    "               if BottleNeck architecutre used, set True (default: False)\n",
    "        type: bool\n",
    "        param: initial_stride: stride used in branch2a and branc2b. note that branch3b stride is always 1.\n",
    "        type: uint\n",
    "    '''\n",
    "       \n",
    "    # branch1\n",
    "    if branch1:\n",
    "        res_b1 = 'res{}_branch1'.format(name)\n",
    "        bn_b1 = 'bn{}_branch1'.format(name)\n",
    "        scale_b1 = 'scale{}_branch1'.format(name)\n",
    "        n[res_b1], n[bn_b1], n[scale_b1] = _conv_bn_scale(\n",
    "            bottom, 4 * nout, kernel_size=1, stride=initial_stride, pad=0)\n",
    "    else:\n",
    "        initial_stride = 1\n",
    "\n",
    "    # branch2a\n",
    "    res = 'res{}_branch2a'.format(name)\n",
    "    bn = 'bn{}_branch2a'.format(name)\n",
    "    scale = 'scale{}_branch2a'.format(name)\n",
    "    n[res], n[bn], n[scale] = _conv_bn_scale(\n",
    "        bottom, nout, kernel_size=1, stride=initial_stride, pad=0)\n",
    "    relu2a = 'res{}_branch2a_relu'.format(name)\n",
    "    n[relu2a] = L.ReLU(n[scale], in_place=True)\n",
    "    \n",
    "    # branch2b\n",
    "    res = 'res{}_branch2b'.format(name)\n",
    "    bn = 'bn{}_branch2b'.format(name)\n",
    "    scale = 'scale{}_branch2b'.format(name)\n",
    "    n[res], n[bn], n[scale] = _conv_bn_scale(\n",
    "        n[relu2a], nout, kernel_size=3, stride=1, pad=1)\n",
    "    relu2b = 'res{}_branch2b_relu'.format(name)\n",
    "    n[relu2b] = L.ReLU(n[scale], in_place=True)\n",
    "    \n",
    "    # branch2c\n",
    "    res = 'res{}_branch2c'.format(name)\n",
    "    bn = 'bn{}_branch2c'.format(name)\n",
    "    scale = 'scale{}_branch2c'.format(name)\n",
    "    n[res], n[bn], n[scale] = _conv_bn_scale(\n",
    "        n[relu2b], 4 * nout, kernel_size=1, stride=1, pad=0)\n",
    "    \n",
    "    # res{}\n",
    "    res = 'res{}'.format(name)\n",
    "    if branch1:\n",
    "        n[res] = L.Eltwise(n[scale_b1], n[scale])\n",
    "    else:\n",
    "        n[res] = L.Eltwise(bottom, n[scale])\n",
    "    relu = 'res{}_relu'.format(name)\n",
    "    n[relu] = L.ReLU(n[res], in_place=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "17b7e6dc",
   "metadata": {},
   "source": [
    "def resnet_block(stage_name, sublayer_num, n, bottom, nout, downsample_branch=False, initial_stride=2):\n",
    "    '''function for building Basic Resnet Block\n",
    "    \n",
    "    Prameters:\n",
    "       layer_num  : layer number as ? in \"backbone_body_layer?\"\n",
    "       sub_num    : sublayer number as # in \"backbone_body_layer?_#\"\n",
    "       n          : NetSpec object\n",
    "       bottom     : input to this residual block\n",
    "       nout       : num. of out ch.\n",
    "       downsample :  inclusion of subsample at beginning of this residula block? \n",
    "                     if BottleNeck architecutre used, set True (default: False)\\\n",
    "                  \n",
    "       initial_stride: stride used in branch2a and branc2b. note that branch3b stride is always 1.\n",
    "       \n",
    "       \n",
    "    Overview diagram:\n",
    "    \n",
    "             +------> [ *_downsample_0 -- *_downsample_1 --- *_downsample_scale ] -----------+\n",
    "             |                                                                               |\n",
    "    bottom --+---------> [ *_conv1 --- *_bn1 --- *_scale1 --- *_relu1 ] ----+                |\n",
    "             |                                                              |                | \n",
    "             |     +--------------------------------------------------------+                |\n",
    "             |     |                                                                         |\n",
    "             |     +---> [ *_conv2 --- *_bn2 --- *_scale2 --- *_relu2 ] ----+                |\n",
    "             |                                                              |                | if downsample == True\n",
    "             |     +--------------------------------------------------------+                | \n",
    "             |     |                                                                         V\n",
    "             |     +---> [ *_conv3 --- *_bn3 --- *_scale3 -------------------------> [ *_res: Eltwise ] ----> *__res_relu :ReLu\n",
    "             |                                                                                ^\n",
    "             |                                                                                | \n",
    "             |                                                                                | if downsample == False\n",
    "             +--------------------------------------------------------------------------------+\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    prefix =f'backbone_body_layer{stage_name}_{sublayer_num}'\n",
    "    \n",
    "    #-----------------------------------------------------------------\n",
    "    # input downsampling layer at the begining of every layer[0-4]\n",
    "    #------------------------------------------------------------------\n",
    "    # In pytorch model,\n",
    "    # backbone.body.laye{layer_num}.{sublayer_num}.downsample_0\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.downsample_1\n",
    "    #------------------------------------------------------------------\n",
    "    if downsample_branch:\n",
    "        # downsample at first layer in resnet block\n",
    "        downsample_0 = f'{prefix}_downsample_0'\n",
    "        downsample_1 =  f'{prefix}_downsample_1'\n",
    "        downsample_scale = f'{prefix}_downsample_scale'\n",
    "        n[downsample_0], n[downsample_1], n[downsample_scale] = _conv_bn_scale(\n",
    "            bottom, 4 * nout, kernel_size=1, stride=initial_stride, pad=0)\n",
    "    else:\n",
    "        initial_stride = 1\n",
    "\n",
    "    #------------------------------------------------------------------\n",
    "    # In pytorch model,\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.conv1 \n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.bn1\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.scale1\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.relu1\n",
    "    #------------------------------------------------------------------\n",
    "    conv1 = f'{prefix}_conv1'\n",
    "    bn1 = f'{prefix}_bn1'\n",
    "    scale1 = f'{prefix}_scale1'\n",
    "    \n",
    "    n[conv1], n[bn1], n[scale1] = _conv_bn_scale(\n",
    "        bottom, nout, kernel_size=1, stride=initial_stride, pad=0)\n",
    "    \n",
    "    relu1 = f'{prefix}_relu1'\n",
    "    n[relu1] = L.ReLU(n[scale1], in_place=True)\n",
    "    \n",
    "    #------------------------------------------------------------------\n",
    "    # In pytorch model,\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.conv2 \n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.bn2\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.scale2\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.relu2\n",
    "    #------------------------------------------------------------------\n",
    "    conv2 = f'{prefix}_conv2'\n",
    "    bn2 = f'{prefix}_bn2'\n",
    "    scale2 = f'{prefix}_scale2'\n",
    "    \n",
    "    n[conv2], n[bn2], n[scale2] = _conv_bn_scale(\n",
    "        n[relu1], nout, kernel_size=3, stride=1, pad=1)\n",
    "    \n",
    "    relu2 = f'{prefix}_relu2'\n",
    "    n[relu2] = L.ReLU(n[scale2], in_place=True)\n",
    "        \n",
    "    #------------------------------------------------------------------\n",
    "    # In pytorch model,\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.conv3 \n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.bn3\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.scale3\n",
    "    #------------------------------------------------------------------\n",
    "    con3 = f'{prefix}_conv3'\n",
    "    bn3 = f'{prefix}_bn3'\n",
    "    scale3 = f'{prefix}_scale3'\n",
    "    \n",
    "    n[conv3], n[bn3], n[scale3] = _conv_bn_scale(\n",
    "        n[relu22], 4 * nout, kernel_size=1, stride=1, pad=0)\n",
    "    \n",
    "    #---------------------------------------\n",
    "    # skip connection processing\n",
    "    #---------------------------------------\n",
    "    eltwise = f'{prefix}_eltwise'\n",
    "    \n",
    "    if downsample_branch:\n",
    "        n[eltwise] = L.Eltwise(n[downsample_scale], n[scale3])\n",
    "    else:\n",
    "        n[eltwise] = L.Eltwise(bottom, n[scale3])\n",
    "    \n",
    "    #---------------------------------------\n",
    "    # last relu \n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.relu\n",
    "    #---------------------------------------\n",
    "    relu = f'{prefix}_relu'.format(name)\n",
    "    n[relu] = L.ReLU(n[res], in_place=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d2755113",
   "metadata": {},
   "source": [
    "def resnet_stage_sublayer_org(layer_name, sublayer_num, n, bottom, nout, downsample_branch=False, initial_stride=2):\n",
    "    '''function for building Basic Resnet Stage\n",
    "       stage 0 (stem), stage 1, stage 2, stage 3 and stage 4\n",
    "\n",
    "    Prameters:\n",
    "       layer_num  : layer number as ? in \"backbone_body_layer?\"\n",
    "       sub_num    : sublayer number as # in \"backbone_body_layer?_#\"\n",
    "       n          : NetSpec object\n",
    "       bottom     : input to this residual block\n",
    "       nout       : num. of out ch.\n",
    "       downsample :  inclusion of subsample at beginning of this residula block?\n",
    "                     if BottleNeck architecutre used, set True (default: False)\\\n",
    "\n",
    "       initial_stride: stride used in branch2a and branc2b. note that branch3b stride is always 1.\n",
    "\n",
    "\n",
    "    Overview diagram:\n",
    "\n",
    "             +------> [ *_downsample_0 -- *_downsample_1 --- *_downsample_scale ] -----------+\n",
    "             |                                                                               |\n",
    "    bottom --+---------> [ *_conv1 --- *_bn1 --- *_scale1 --- *_relu1 ] ----+                |\n",
    "             |                                                              |                |\n",
    "             |     +--------------------------------------------------------+                |\n",
    "             |     |                                                                         |\n",
    "             |     +---> [ *_conv2 --- *_bn2 --- *_scale2 --- *_relu2 ] ----+                |\n",
    "             |                                                              |                | if downsample == True\n",
    "             |     +--------------------------------------------------------+                |\n",
    "             |     |                                                                         V\n",
    "             |     +---> [ *_conv3 --- *_bn3 --- *_scale3 -------------------------> [ *_res: Eltwise ] ----> *__res_relu :ReLu\n",
    "             |                                                                                ^\n",
    "             |                                                                                |\n",
    "             |                                                                                | if downsample == False\n",
    "             +--------------------------------------------------------------------------------+\n",
    "    '''\n",
    "    prefix = f'{layer_name}_{sublayer_num}'\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # input downsampling layer at the begining of every layer[0-4]\n",
    "    # ------------------------------------------------------------------\n",
    "    # In pytorch model,\n",
    "    # backbone.body.laye{layer_num}.{sublayer_num}.downsample_0\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.downsample_1\n",
    "    # ------------------------------------------------------------------\n",
    "    if downsample_branch:\n",
    "        # downsample at first layer in resnet block\n",
    "        downsample_conv = f'{prefix}_downsample_0'\n",
    "        downsample_bn = f'{prefix}_downsample_1'\n",
    "        downsample_scale = f'{prefix}_downsample_scale'\n",
    "        n[downsample_conv], n[downsample_bn], n[downsample_scale] = \\\n",
    "            conv_bn_scale( bottom, 4*nout, kernel_size=1, stride=initial_stride, pad=0)\n",
    "    else:\n",
    "        initial_stride = 1\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # In pytorch model,\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.conv1\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.bn1\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.scale1\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.relu1\n",
    "    # ------------------------------------------------------------------\n",
    "    conv1 = f'{prefix}_conv1'\n",
    "    bn1 = f'{prefix}_bn1'\n",
    "    scale1 = f'{prefix}_scale1'\n",
    "\n",
    "    n[conv1], n[bn1], n[scale1] = \\\n",
    "        conv_bn_scale( bottom, nout, kernel_size=1, stride=initial_stride, pad=0)\n",
    "\n",
    "    relu1 = f'{prefix}_relu1'\n",
    "    n[relu1] = L.ReLU(n[scale1], in_place=True)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # In pytorch model,\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.conv2\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.bn2\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.scale2\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.relu2\n",
    "    # ------------------------------------------------------------------\n",
    "    conv2 = f'{prefix}_conv2'\n",
    "    bn2 = f'{prefix}_bn2'\n",
    "    scale2 = f'{prefix}_scale2'\n",
    "\n",
    "    n[conv2], n[bn2], n[scale2] = \\\n",
    "        conv_bn_scale( n[relu1], nout, kernel_size=3, stride=1, pad=1)\n",
    "\n",
    "    relu2 = f'{prefix}_relu2'\n",
    "    n[relu2] = L.ReLU(n[scale2], in_place=True)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # In pytorch model,\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.conv3\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.bn3\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.scale3\n",
    "    # ------------------------------------------------------------------\n",
    "    conv3 = f'{prefix}_conv3'\n",
    "    bn3 = f'{prefix}_bn3'\n",
    "    scale3 = f'{prefix}_scale3'\n",
    "\n",
    "    n[conv3], n[bn3], n[scale3] = \\\n",
    "        conv_bn_scale( n[relu2], 4 * nout, kernel_size=1, stride=1, pad=0)\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # skip connection processing\n",
    "    # ---------------------------------------\n",
    "    eltwise = f'{prefix}_eltwise'\n",
    "\n",
    "    if downsample_branch:\n",
    "        n[eltwise] = L.Eltwise(n[downsample_scale], n[scale3])\n",
    "    else:\n",
    "        n[eltwise] = L.Eltwise(bottom, n[scale3])\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # last relu\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.relu\n",
    "    # ---------------------------------------\n",
    "    relu = f'{prefix}_relu'\n",
    "    n[relu] = L.ReLU(n[eltwise], in_place=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd050dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_stage_sublayer(layer_name, sublayer_num, n, bottom, nout, downsample_branch=False, initial_stride=2):\n",
    "    '''function for building Basic Resnet Stage\n",
    "       stage 0 (stem), stage 1, stage 2, stage 3 and stage 4\n",
    "\n",
    "    Prameters:\n",
    "       layer_num  : layer number as ? in \"backbone_body_layer?\"\n",
    "       sub_num    : sublayer number as # in \"backbone_body_layer?_#\"\n",
    "       n          : NetSpec object\n",
    "       bottom     : input to this residual block\n",
    "       nout       : num. of out ch.\n",
    "       downsample :  inclusion of subsample at beginning of this residula block?\n",
    "                     if BottleNeck architecutre used, set True (default: False)\\\n",
    "\n",
    "       initial_stride: stride used in branch2a and branc2b. note that branch3b stride is always 1.\n",
    "\n",
    "\n",
    "    Overview diagram:\n",
    "\n",
    "             +------> [ *_downsample_0 -- *_downsample_1 ]--------------------+\n",
    "             |                                                                |\n",
    "    bottom --+---------> [ *_conv1 --- *_bn1 --- *_relu1 ] ----+              |\n",
    "             |                                                 |              |\n",
    "             |     +-------------------------------------------+              |\n",
    "             |     |                                                          |\n",
    "             |     +---> [ *_conv2 --- *_bn2 --- *_relu2 ] ----+              |\n",
    "             |                                                 |              | if downsample == True\n",
    "             |     +-------------------------------------------+              |\n",
    "             |     |                                                          V\n",
    "             |     +---> [ *_conv3 --- *_bn3 --------------------------> [ *_res: Eltwise ] ----> *__res_relu :ReLu\n",
    "             |                                                                 ^\n",
    "             |                                                                 |\n",
    "             |                                                                 | if downsample == False\n",
    "             +-----------------------------------------------------------------+\n",
    "    '''\n",
    "    prefix = f'{layer_name}_{sublayer_num}'\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # input downsampling layer at the begining of every layer[0-4]\n",
    "    # ------------------------------------------------------------------\n",
    "    # In pytorch model,\n",
    "    # backbone.body.laye{layer_num}.{sublayer_num}.downsample_0\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.downsample_1\n",
    "    # ------------------------------------------------------------------\n",
    "    if downsample_branch:\n",
    "        # downsample at first layer in resnet block\n",
    "        downsample_conv = f'{prefix}_downsample_0'\n",
    "        downsample_bn = f'{prefix}_downsample_1'\n",
    "        #downsample_scale = f'{prefix}_downsample_scale'\n",
    "        n[downsample_conv], n[downsample_bn]  = \\\n",
    "            conv_fbn( bottom, 4*nout, kernel_size=1, stride=initial_stride, pad=0)\n",
    "    else:\n",
    "        initial_stride = 1\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # In pytorch model,\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.conv1\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.bn1\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.scale1\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.relu1\n",
    "    # ------------------------------------------------------------------\n",
    "    conv1 = f'{prefix}_conv1'\n",
    "    bn1 = f'{prefix}_bn1'\n",
    "    #scale1 = f'{prefix}_scale1'\n",
    "\n",
    "    n[conv1], n[bn1] = \\\n",
    "        conv_fbn( bottom, nout, kernel_size=1, stride=initial_stride, pad=0)\n",
    "\n",
    "    relu1 = f'{prefix}_relu1'\n",
    "    #n[relu1] = L.ReLU(n[bn1], in_place=True)\n",
    "    n[relu1] = L.ReLU(n[bn1], in_place=False)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # In pytorch model,\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.conv2\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.bn2\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.scale2\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.relu2\n",
    "    # ------------------------------------------------------------------\n",
    "    conv2 = f'{prefix}_conv2'\n",
    "    bn2 = f'{prefix}_bn2'\n",
    "    #scale2 = f'{prefix}_scale2'\n",
    "\n",
    "    n[conv2], n[bn2] = \\\n",
    "        conv_fbn( n[relu1], nout, kernel_size=3, stride=1, pad=1)\n",
    "\n",
    "    relu2 = f'{prefix}_relu2'\n",
    "    #n[relu2] = L.ReLU(n[bn2], in_place=True)\n",
    "    n[relu2] = L.ReLU(n[bn2], in_place=False)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # In pytorch model,\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.conv3\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.bn3\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.scale3\n",
    "    # ------------------------------------------------------------------\n",
    "    conv3 = f'{prefix}_conv3'\n",
    "    bn3 = f'{prefix}_bn3'\n",
    "    #scale3 = f'{prefix}_scale3'\n",
    "\n",
    "    n[conv3], n[bn3] = \\\n",
    "        conv_fbn( n[relu2], 4 * nout, kernel_size=1, stride=1, pad=0)\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # skip connection processing\n",
    "    # ---------------------------------------\n",
    "    eltwise = f'{prefix}_eltwise'\n",
    "\n",
    "    if downsample_branch:\n",
    "        n[eltwise] = L.Eltwise(n[downsample_bn], n[bn3])\n",
    "    else:\n",
    "        n[eltwise] = L.Eltwise(bottom, n[bn3])\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # last relu\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.relu\n",
    "    # ---------------------------------------\n",
    "    relu = f'{prefix}_relu'\n",
    "    # n[relu] = L.ReLU(n[eltwise], in_place=True)\n",
    "    n[relu] = L.ReLU(n[eltwise], in_place=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1be3bd",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## RPN (Region Proposal Net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50382e7",
   "metadata": {},
   "source": [
    "### cls_tower_logit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae90a033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cls_tower_logits(bottom, nout=9, bias_term=True, **kwargs):\n",
    "    '''Builds cls_tower_logits in form of [conv => relu]x4 + conv block.\n",
    "       all conv layer uses kernel:3, stride: 1, pad: 1\n",
    "\n",
    "       Params:\n",
    "          bottom (blob) : input to cls tower logits\n",
    "          nout (uint) : num. of outputs in cls logit (last conv layer)\n",
    "          bias_term (bool) : use bias term or not in conv layer\n",
    "    '''\n",
    "\n",
    "    # cls tower: 4 times repetition of [conv => relu]\n",
    "    conv1 = L.Convolution(bottom, num_output=1024, bias_term=bias_term, **kwargs)\n",
    "    relu1 = L.ReLU(conv1, in_place=True)\n",
    "\n",
    "    conv2 = L.Convolution(relu1, num_output=1024, bias_term=bias_term, **kwargs)\n",
    "    relu2 = L.ReLU(conv2, in_place=True)\n",
    "\n",
    "    conv3 = L.Convolution(relu2, num_output=1024, bias_term=bias_term, **kwargs)\n",
    "    relu3 = L.ReLU(conv3, in_place=True)\n",
    "\n",
    "    conv4 = L.Convolution(relu3, num_output=1024, bias_term=bias_term, **kwargs)\n",
    "    relu4 = L.ReLU(conv4, in_place=True)\n",
    "\n",
    "    # cl_logits with nout=9\n",
    "    cls_logits = L.Convolution(relu4, num_output=nout, **kwargs, bias_term=bias_term)\n",
    "\n",
    "    return conv1, relu1, conv2, relu2, conv3, relu3, conv4, relu4, cls_logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f0b508",
   "metadata": {},
   "source": [
    "### bbox_tower_pred()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb759fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_tower_pred(bottom, nout=36, bias_term=True, **kwargs):\n",
    "    '''Builds build a bbox_tower_pred in form of [conv => relu]x4 + conv block.\n",
    "       all conv layer uses kernel:3, stride: 1, pad: 1\n",
    "\n",
    "       Params:\n",
    "          bottom (blob) : input to cls tower logits\n",
    "          nout (uint) : num. of outputs in cls logit (last conv layer)\n",
    "          bias_term (bool) : use bias term or not in conv layer\n",
    "    '''\n",
    "    # bbox_tower: 4 times repetition of [conv => relut]\n",
    "    conv1 = L.Convolution(bottom, num_output=1024, bias_term=bias_term, **kwargs)\n",
    "    relu1 = L.ReLU(conv1, in_place=True)\n",
    "\n",
    "    conv2 = L.Convolution(relu1, num_output=1024, bias_term=bias_term, **kwargs)\n",
    "    relu2 = L.ReLU(conv2, in_place=True)\n",
    "\n",
    "    conv3 = L.Convolution(relu2, num_output=1024, bias_term=bias_term, **kwargs)\n",
    "    relu3 = L.ReLU(conv3, in_place=True)\n",
    "\n",
    "    conv4 = L.Convolution(relu3, num_output=1024, bias_term=bias_term, **kwargs)\n",
    "    relu4 = L.ReLU(conv4, in_place=True)\n",
    "\n",
    "    # bbox_pred with nout=36\n",
    "    bbox_pred = L.Convolution(relu4, num_output=nout, bias_term=bias_term, **kwargs)\n",
    "\n",
    "    return conv1, relu1, conv2, relu2, conv3, relu3, conv4, relu4, bbox_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15795e3c",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Detection V2 Nework Build\n",
    "\n",
    "Reference:\n",
    "* [how to understand caffe's bilinear upsampling](https://stackoverflow.com/questions/38431002/how-to-understand-caffes-bilinear-upsampling)\n",
    "\n",
    "caffe doc says that \n",
    "```js\n",
    "layer {\n",
    "  name: \"upsample\", type: \"Deconvolution\"\n",
    "  bottom: \"{{bottom_name}}\" top: \"{{top_name}}\"\n",
    "  convolution_param {\n",
    "    kernel_size: {{2 * factor - factor % 2}} stride: {{factor}}\n",
    "    num_output: {{C}} group: {{C}}\n",
    "    pad: {{ceil((factor - 1) / 2.)}}\n",
    "    weight_filler: { type: \"bilinear\" } bias_term: false\n",
    "  }\n",
    "  param { lr_mult: 0 decay_mult: 0 }\n",
    "}\n",
    "```\n",
    "I have no idea why to set kenrel_size, stride, and pad like this?\n",
    "\n",
    "> for upsampling, if you want resize factor to be 2, then the parameter would be kernel_size: 4, stride:2, pad:1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af39acc9",
   "metadata": {},
   "source": [
    "###  ++detection_network_v2_spec()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ad491aa6",
   "metadata": {},
   "source": [
    "#--------------------------------------------------\n",
    "# detection_network v2 model structure\n",
    "# model := backbone + rpn (region proposal network)\n",
    "# backbone := body + fpn (feature pyramid network)\n",
    "# body := resnet 50\n",
    "#--------------------------------------------------\n",
    "def detection_network_v2_spec_org(n, bottom):\n",
    "    '''Build Backbone with ResNet50 + FPN\n",
    "\n",
    "    Params:\n",
    "    n (caffe.NetSpec) : NetSpec instance\n",
    "    bottom (blob) : innput to detection network\n",
    "\n",
    "    '''\n",
    "    # keep list of feature maps in stage ofrder\n",
    "    features = []\n",
    "\n",
    "\n",
    "    # ************************************************\n",
    "    # 1. model.backbone\n",
    "    # ************************************************\n",
    "    # backbone := body + fpn\n",
    "    # ************************************************\n",
    "\n",
    "\n",
    "    # =================================================================\n",
    "    # 1.1 model.backbone.body\n",
    "    # body = stem (layer 0) +  layer 1 + layer 2 + layer 3 + layer 4\n",
    "    # =================================================================\n",
    "\n",
    "    prefix = \"backbone_body\"\n",
    "    # -------------------------------------\n",
    "    # 1.1.0 model.backbone.body.stem (layer0)\n",
    "    # sublayer: conv1,  bn1, scale, relu, maxpool\n",
    "    # -------------------------------------\n",
    "    layer = f'{prefix}_stem_'\n",
    "\n",
    "    n[layer + 'conv1'], n[layer + 'bn1'], n[layer + 'scale'] = conv_bn_scale(bottom, 64, bias_term=False,\n",
    "                                                                              kernel_size=7, pad=3, stride=2)\n",
    "    n[layer + 'relu'] = L.ReLU(n[layer + 'scale'], in_place=True)\n",
    "    n[layer + 'maxpool'] = L.Pooling(n[layer + 'relu'], kernel_size=3, stride=2, pool=P.Pooling.MAX)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.1.1 model.backbone.body.layer1\n",
    "    # sublayer: 0, 1, 2\n",
    "    # -------------------------------------\n",
    "    pre_layer = layer\n",
    "    layer = f'{prefix}_layer1'\n",
    "\n",
    "    resnet_stage_sublayer(layer, '0', n, n[pre_layer + 'maxpool'], 64, downsample_branch=True, initial_stride=1)\n",
    "\n",
    "    #resnet_stage_sublayer(layer_name, sublayer_num, n, bottom, nout, downsample_branch=False, initial_stride=2):\n",
    "    resnet_stage_sublayer(layer, '1', n, n[layer + '_0_relu'], 64)\n",
    "    resnet_stage_sublayer(layer, '2', n, n[layer + '_1_relu'], 64)\n",
    "\n",
    "    # feature C1\n",
    "    features.append(n[layer + '_2_relu'])\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.1.2 model.backbone.body.layer2 (stage 2)\n",
    "    # sublayer: 0, 1, 2, 3\n",
    "    # -------------------------------------\n",
    "    pre_layer = layer\n",
    "    layer = f'{prefix}_layer2'\n",
    "\n",
    "    resnet_stage_sublayer(layer, '0', n, n[pre_layer + '_2_relu'], 128, downsample_branch=True)\n",
    "    resnet_stage_sublayer(layer, '1', n, n[layer + '_0_relu'], 128)\n",
    "    resnet_stage_sublayer(layer, '2', n, n[layer + '_1_relu'], 128)\n",
    "    resnet_stage_sublayer(layer, '3', n, n[layer + '_2_relu'], 128)\n",
    "\n",
    "    # feature C2\n",
    "    features.append(n[layer + '_3_relu'])\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.1.3 model.backbone.body.layer3 (stage 3)\n",
    "    # sublayer: 0, 1, 2, 3, 4, 5\n",
    "    # -------------------------------------\n",
    "    pre_layer = layer\n",
    "    layer = f'{prefix}_layer3'\n",
    "\n",
    "    resnet_stage_sublayer(layer, '0', n, n[pre_layer + '_3_relu'], 256, downsample_branch=True)\n",
    "    resnet_stage_sublayer(layer, '1', n, n[layer + '_0_relu'], 256)\n",
    "    resnet_stage_sublayer(layer, '2', n, n[layer + '_1_relu'], 256)\n",
    "    resnet_stage_sublayer(layer, '3', n, n[layer + '_2_relu'], 256)\n",
    "    resnet_stage_sublayer(layer, '4', n, n[layer + '_3_relu'], 256)\n",
    "    resnet_stage_sublayer(layer, '5', n, n[layer + '_4_relu'], 256)\n",
    "\n",
    "    # feature C3\n",
    "    features.append(n[layer + '_5_relu'])\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.1.4 model.backbone.body.layer4 (stage 4)\n",
    "    # sublayer: 0, 1, 2\n",
    "    # -------------------------------------\n",
    "    pre_layer = layer\n",
    "    layer = f'{prefix}_layer4'\n",
    "\n",
    "    resnet_stage_sublayer(layer, '0', n, n[pre_layer + '_5_relu'], 512, downsample_branch=True)\n",
    "    resnet_stage_sublayer(layer, '1', n, n[layer + '_0_relu'], 512)\n",
    "    resnet_stage_sublayer(layer, '2', n, n[layer + '_1_relu'], 512)\n",
    "\n",
    "    # feature C4\n",
    "    features.append(n[layer + '_2_relu'])\n",
    "\n",
    "    C1, C2, C3, C4 = features\n",
    "\n",
    "    # =================================================================\n",
    "    # 1.2 model.backbone.fpn\n",
    "    # =================================================================\n",
    "    fpn_results = []\n",
    "    prefix = \"backbone_fpn\"\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.1 model.backbone.fpn_inner4\n",
    "    # -------------------------------------\n",
    "    layer = f'{prefix}_inner4'\n",
    "    last_inner = n[layer] = L.Convolution(C4, num_output=1024, kernel_size=1, stride=1)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.2 model.backbone.fpn_layer4\n",
    "    # -------------------------------------\n",
    "    layer = f'{prefix}_layer4'\n",
    "    n[layer] = L.Convolution(last_inner, num_output=1024, kernel_size=3, stride=1, pad=1)\n",
    "\n",
    "    # featuer pyramid feature P4 append\n",
    "    # P4 = conv (conv (C4))\n",
    "    fpn_results.append(n[layer])\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.3 model.backbone.fpn_inner3_upsample\n",
    "    # -------------------------------------\n",
    "    layer = f'{prefix}_inner3_upsample' # inner3__upsample\n",
    "    inner3_upsample = n[layer] = L.Deconvolution(last_inner,\n",
    "                               convolution_param\n",
    "                               = dict(num_output=1024, kernel_size=4, stride=2, pad=1,\n",
    "                                      weight_filler=dict(type ='bilinear'),\n",
    "                                      bias_term=False))\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.4 model.backbone.fpn_inner3_lateral\n",
    "    # -------------------------------------\n",
    "    layer = f'{prefix}_inner3_lateral'\n",
    "    inner3_lateral = n[layer] = L.Convolution(C3, num_output=1024, kernel_size=1, stride=1)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.5 model.backbone.fpn_inner3_lateral_sum\n",
    "    # -------------------------------------\n",
    "    layer = f'{prefix}_inner3_lateral_sum' # P3\n",
    "    last_inner = n[layer] = L.Eltwise(inner3_lateral,  inner3_upsample)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.6 model.backbone.fpn_layer3\n",
    "    # -------------------------------------\n",
    "    layer = f'{prefix}_layer3'\n",
    "    n[layer] = L.Convolution(last_inner, num_output=1024, kernel_size=3, stride=1, pad=1)\n",
    "\n",
    "    # feature pyramid P3 insert at idx 0\n",
    "    # P3 = unsample(P4) + conv(conv(C3))\n",
    "    fpn_results.insert(0, n[layer])\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.7 model.backbone.fpn_inner2_upsample\n",
    "    # -------------------------------------\n",
    "    layer = f'{prefix}_inner2_upsample' # inner2__upsample\n",
    "    inner2_upsample = n[layer] = L.Deconvolution(last_inner,\n",
    "                               convolution_param\n",
    "                               = dict(num_output=1024, kernel_size=4, stride=2, pad=1,\n",
    "                                      weight_filler=dict(type ='bilinear'),\n",
    "                                      bias_term=False))\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.8 model.backbone.fpn_inner3_lateral\n",
    "    # -------------------------------------\n",
    "    layer = f'{prefix}_inner2_lateral'\n",
    "    inner2_lateral = n[layer] = L.Convolution(C2, num_output=1024, kernel_size=1, stride=1)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.9 model.backbone.fpn_inner2_lateral_sum\n",
    "    # -------------------------------------\n",
    "    layer = f'{prefix}_inner2_lateral_sum' # P3\n",
    "    last_inner = n[layer] = L.Eltwise(inner2_lateral,  inner2_upsample)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.10 model.backbone.fpn_layer2\n",
    "    # -------------------------------------\n",
    "    layer = f'{prefix}_layer2'\n",
    "    n[layer] = L.Convolution(last_inner, num_output=1024, kernel_size=3, stride=1, pad=1)\n",
    "\n",
    "    # feature pyramid P2 insert at idx 0\n",
    "    # P2 = unsample(P3) + conv(conv(C2))\n",
    "    fpn_results.insert(0, n[layer])\n",
    "\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.11 model.fpn.top_blocks\n",
    "    # -------------------------------------\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.11.1 model.fpn.top_blocks.p6\n",
    "    # -------------------------------------\n",
    "    prefix = \"backbone_fpn_topblocks\"\n",
    "    layer = f'{prefix}_p6'\n",
    "    n[layer] = L.Convolution(C4, num_output=1024, kernel_size=3, stride=2, pad=1)\n",
    "\n",
    "    # feature pyramid P6 append at end\n",
    "    # P6 = (conv(C4)) ?\n",
    "    fpn_results.append(n[layer])\n",
    "\n",
    "    P6_relu = n[layer + 'relu'] = L.ReLU(n[layer], in_place=True)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.11.2 model.fpn.top_blocks.p7\n",
    "    # -------------------------------------\n",
    "\n",
    "    layer = f'{prefix}_p7'\n",
    "    n[layer] = L.Convolution(P6_relu, num_output=1024, kernel_size=3, stride=2, pad=1)\n",
    "\n",
    "    # feature pyramid P6 append at end\n",
    "    # P7 = (conv(P6))\n",
    "    fpn_results.append(n[layer])\n",
    "\n",
    "    # fpn_results = [P2, P3, P4, P6, P7]\n",
    "    # P2 shape: (1, 1024, 60, 72)\n",
    "    # P3 shape: (1, 1024, 30, 36)\n",
    "    # P4 shape: (1, 1024, 15, 18)\n",
    "    # P6 shape: (1, 1024,  8,  9)\n",
    "    # P7 shape: (1, 1024,  4,  5)\n",
    "\n",
    "\n",
    "    # ************************************************\n",
    "    # 2 model.rpn\n",
    "    # rpn := head\n",
    "    # head := cls_tower  => cls_logits\n",
    "    #       bbox_tower => bbox_pred\n",
    "    # ************************************************\n",
    "    logits = []\n",
    "    bbox_reg = []\n",
    "    for idx, p_num in enumerate([2,3,4,6,7]):\n",
    "\n",
    "        bottom = fpn_results[idx]\n",
    "\n",
    "        # cls_tower + cls_logits\n",
    "        prefix = f\"rpn_head_cls_tower_p{p_num}\"\n",
    "        cls_tower_conv1 = f'{prefix}_0'\n",
    "        cls_tower_relu1 = f'{prefix}_1'\n",
    "        cls_tower_conv2 = f'{prefix}_2'\n",
    "        cls_tower_relu2 = f'{prefix}_3'\n",
    "        cls_tower_conv3 = f'{prefix}_4'\n",
    "        cls_tower_relu3 = f'{prefix}_5'\n",
    "        cls_tower_conv4 = f'{prefix}_6'\n",
    "        cls_tower_relu4 = f'{prefix}_7'\n",
    "        cls_logits = f'rpn_head_cls_logits_p{p_num}'\n",
    "\n",
    "        n[cls_tower_conv1], n[cls_tower_relu1], n[cls_tower_conv2], n[cls_tower_relu2], \\\n",
    "        n[cls_tower_conv3], n[cls_tower_relu3], n[cls_tower_conv4], n[cls_tower_relu4], \\\n",
    "        n[cls_logits] = cls_tower_logits(bottom=bottom, nout=9, kernel_size=3, stride=1, pad =1 )\n",
    "\n",
    "        logits.append(n[cls_logits])\n",
    "\n",
    "        # bbox_tower + bbox_pred\n",
    "        prefix = f\"rpn_head_bbox_tower_p{p_num}\"\n",
    "        bbox_tower_conv1 = f'{prefix}_0'\n",
    "        bbox_tower_relu1 = f'{prefix}_1'\n",
    "        bbox_tower_conv2 = f'{prefix}_2'\n",
    "        bbox_tower_relu2 = f'{prefix}_3'\n",
    "        bbox_tower_conv3 = f'{prefix}_4'\n",
    "        bbox_tower_relu3 = f'{prefix}_5'\n",
    "        bbox_tower_conv4 = f'{prefix}_6'\n",
    "        bbox_tower_relu4 = f'{prefix}_7'\n",
    "        bbox_pred = f'rpn_head_bbox_pred_p{p_num}'\n",
    "\n",
    "        n[bbox_tower_conv1], n[bbox_tower_relu1], n[bbox_tower_conv2], n[bbox_tower_relu2], \\\n",
    "        n[bbox_tower_conv3], n[bbox_tower_relu3], n[bbox_tower_conv4], n[bbox_tower_relu4], \\\n",
    "        n[bbox_pred] = bbox_tower_pred(bottom=bottom, nout=36, kernel_size=3, stride=1, pad=1)\n",
    "\n",
    "        bbox_reg.append(n[bbox_pred])\n",
    "\n",
    "    return n.to_proto()\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "395c01d6",
   "metadata": {},
   "source": [
    "#--------------------------------------------------\n",
    "# detection_network v2 model structure\n",
    "# model := backbone + rpn (region proposal network)\n",
    "# backbone := body + fpn (feature pyramid network)\n",
    "# body := resnet 50\n",
    "#--------------------------------------------------\n",
    "def detection_network_v2_spec(n, bottom):\n",
    "    '''Build Backbone with ResNet50 + FPN\n",
    "\n",
    "    Params:\n",
    "    n (caffe.NetSpec) : NetSpec instance\n",
    "    bottom (blob) : innput to detection network\n",
    "\n",
    "    '''\n",
    "    # keep list of feature maps in stage ofrder\n",
    "    features = []\n",
    "\n",
    "\n",
    "    # ************************************************\n",
    "    # 1. model.backbone\n",
    "    # ************************************************\n",
    "    # backbone := body + fpn\n",
    "    # ************************************************\n",
    "\n",
    "\n",
    "    # =================================================================\n",
    "    # 1.1 model.backbone.body\n",
    "    # body = stem (layer 0) +  layer 1 + layer 2 + layer 3 + layer 4\n",
    "    # =================================================================\n",
    "\n",
    "    prefix = \"backbone_body\"\n",
    "    # -------------------------------------\n",
    "    # 1.1.0 model.backbone.body.stem (layer0)\n",
    "    # sublayer: conv1,  bn1, relu, maxpool\n",
    "    # -------------------------------------\n",
    "    layer = f'{prefix}_stem_'\n",
    "\n",
    "    n[layer + 'conv1'], n[layer + 'bn1'] = conv_fbn(bottom, 64, bias_term=False,\n",
    "                                                    kernel_size=7, pad=3, stride=2)\n",
    "    n[layer + 'relu'] = L.ReLU(n[layer + 'bn1'], in_place=True)\n",
    "    n[layer + 'maxpool'] = L.Pooling(n[layer + 'relu'], kernel_size=3, stride=2, pool=P.Pooling.MAX)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.1.1 model.backbone.body.layer1\n",
    "    # sublayer: 0, 1, 2\n",
    "    # -------------------------------------\n",
    "    pre_layer = layer\n",
    "    layer = f'{prefix}_layer1'\n",
    "\n",
    "    resnet_stage_sublayer(layer, '0', n, n[pre_layer + 'maxpool'], 64, downsample_branch=True, initial_stride=1)\n",
    "\n",
    "    #resnet_stage_sublayer(layer_name, sublayer_num, n, bottom, nout, downsample_branch=False, initial_stride=2):\n",
    "    resnet_stage_sublayer(layer, '1', n, n[layer + '_0_relu'], 64)\n",
    "    resnet_stage_sublayer(layer, '2', n, n[layer + '_1_relu'], 64)\n",
    "\n",
    "    # feature C1\n",
    "    features.append(n[layer + '_2_relu'])\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.1.2 model.backbone.body.layer2 (stage 2)\n",
    "    # sublayer: 0, 1, 2, 3\n",
    "    # -------------------------------------\n",
    "    pre_layer = layer\n",
    "    layer = f'{prefix}_layer2'\n",
    "\n",
    "    resnet_stage_sublayer(layer, '0', n, n[pre_layer + '_2_relu'], 128, downsample_branch=True)\n",
    "    resnet_stage_sublayer(layer, '1', n, n[layer + '_0_relu'], 128)\n",
    "    resnet_stage_sublayer(layer, '2', n, n[layer + '_1_relu'], 128)\n",
    "    resnet_stage_sublayer(layer, '3', n, n[layer + '_2_relu'], 128)\n",
    "\n",
    "    # feature C2\n",
    "    features.append(n[layer + '_3_relu'])\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.1.3 model.backbone.body.layer3 (stage 3)\n",
    "    # sublayer: 0, 1, 2, 3, 4, 5\n",
    "    # -------------------------------------\n",
    "    pre_layer = layer\n",
    "    layer = f'{prefix}_layer3'\n",
    "\n",
    "    resnet_stage_sublayer(layer, '0', n, n[pre_layer + '_3_relu'], 256, downsample_branch=True)\n",
    "    resnet_stage_sublayer(layer, '1', n, n[layer + '_0_relu'], 256)\n",
    "    resnet_stage_sublayer(layer, '2', n, n[layer + '_1_relu'], 256)\n",
    "    resnet_stage_sublayer(layer, '3', n, n[layer + '_2_relu'], 256)\n",
    "    resnet_stage_sublayer(layer, '4', n, n[layer + '_3_relu'], 256)\n",
    "    resnet_stage_sublayer(layer, '5', n, n[layer + '_4_relu'], 256)\n",
    "\n",
    "    # feature C3\n",
    "    features.append(n[layer + '_5_relu'])\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.1.4 model.backbone.body.layer4 (stage 4)\n",
    "    # sublayer: 0, 1, 2\n",
    "    # -------------------------------------\n",
    "    pre_layer = layer\n",
    "    layer = f'{prefix}_layer4'\n",
    "\n",
    "    resnet_stage_sublayer(layer, '0', n, n[pre_layer + '_5_relu'], 512, downsample_branch=True)\n",
    "    resnet_stage_sublayer(layer, '1', n, n[layer + '_0_relu'], 512)\n",
    "    resnet_stage_sublayer(layer, '2', n, n[layer + '_1_relu'], 512)\n",
    "\n",
    "    # feature C4\n",
    "    features.append(n[layer + '_2_relu'])\n",
    "\n",
    "    C1, C2, C3, C4 = features\n",
    "\n",
    "    # =================================================================\n",
    "    # 1.2 model.backbone.fpn\n",
    "    # =================================================================\n",
    "    fpn_results = []\n",
    "    prefix = \"backbone_fpn\"\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.1 model.backbone.fpn.fpn_inner4\n",
    "    # -------------------------------------\n",
    "    layer = f'{prefix}_fpn_inner4'\n",
    "    last_inner = n[layer] = L.Convolution(C4, num_output=1024, kernel_size=1, stride=1)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.2 model.backbone.fpn.fpn_layer4\n",
    "    # -------------------------------------\n",
    "    layer = f'{prefix}_fpn_layer4'\n",
    "    n[layer] = L.Convolution(last_inner, num_output=1024, kernel_size=3, stride=1, pad=1)\n",
    "\n",
    "    # featuer pyramid feature P4 append\n",
    "    # P4 = conv (conv (C4))\n",
    "    fpn_results.append(n[layer])\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.3 model.backbone.fpn_inner3_upsample\n",
    "    # -------------------------------------\n",
    "    layer = f'{prefix}_fpn_inner3_upsample' # inner3__upsample\n",
    "    inner3_upsample = n[layer] = L.Deconvolution(last_inner,\n",
    "                                 convolution_param = dict(num_output=1024, kernel_size=4, stride=2, pad=1,\n",
    "                                                          weight_filler=dict(type ='bilinear'),\n",
    "                                                          bias_term=False))\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.4 model.backbone.fpn_inner3_lateral\n",
    "    # -------------------------------------\n",
    "    layer = f'{prefix}_fpn_inner3_lateral'\n",
    "    inner3_lateral = n[layer] = L.Convolution(C3, num_output=1024, kernel_size=1, stride=1)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.5 model.backbone.fpn_inner3_lateral_sum\n",
    "    # -------------------------------------\n",
    "    layer = f'{prefix}_fpn_inner3_lateral_sum' # P3\n",
    "    last_inner = n[layer] = L.Eltwise(inner3_lateral,  inner3_upsample)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.6 model.backbone.fpn_layer3\n",
    "    # -------------------------------------\n",
    "    layer = f'{prefix}_fpn_layer3'\n",
    "    n[layer] = L.Convolution(last_inner, num_output=1024, kernel_size=3, stride=1, pad=1)\n",
    "\n",
    "    # feature pyramid P3 insert at idx 0\n",
    "    # P3 = unsample(P4) + conv(conv(C3))\n",
    "    fpn_results.insert(0, n[layer])\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.7 model.backbone.fpn_inner2_upsample\n",
    "    # -------------------------------------\n",
    "    layer = f'{prefix}_fpn_inner2_upsample' # inner2__upsample\n",
    "    inner2_upsample = n[layer] = L.Deconvolution(last_inner,\n",
    "                               convolution_param\n",
    "                               = dict(num_output=1024, kernel_size=4, stride=2, pad=1,\n",
    "                                      weight_filler=dict(type ='bilinear'),\n",
    "                                      bias_term=False))\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.8 model.backbone.fpn_inner2_lateral\n",
    "    # -------------------------------------\n",
    "    layer = f'{prefix}_fpn_inner2_lateral'\n",
    "    inner2_lateral = n[layer] = L.Convolution(C2, num_output=1024, kernel_size=1, stride=1)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.9 model.backbone.fpn_inner2_lateral_sum\n",
    "    # -------------------------------------\n",
    "    layer = f'{prefix}_fpn_inner2_lateral_sum' # P3\n",
    "    last_inner = n[layer] = L.Eltwise(inner2_lateral,  inner2_upsample)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.10 model.backbone.fpn_layer2\n",
    "    # -------------------------------------\n",
    "    layer = f'{prefix}_fpn_layer2'\n",
    "    n[layer] = L.Convolution(last_inner, num_output=1024, kernel_size=3, stride=1, pad=1)\n",
    "\n",
    "    # feature pyramid P2 insert at idx 0\n",
    "    # P2 = unsample(P3) + conv(conv(C2))\n",
    "    fpn_results.insert(0, n[layer])\n",
    "\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.11 model.fpn.top_blocks\n",
    "    # -------------------------------------\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.11.1 model.fpn.top_blocks.p6\n",
    "    # -------------------------------------\n",
    "    prefix = \"backbone_fpn_topblocks\"\n",
    "    layer = f'{prefix}_p6'\n",
    "    n[layer] = L.Convolution(C4, num_output=1024, kernel_size=3, stride=2, pad=1)\n",
    "\n",
    "    # feature pyramid P6 append at end\n",
    "    # P6 = (conv(C4)) ?\n",
    "    fpn_results.append(n[layer])\n",
    "\n",
    "    P6_relu = n[layer + 'relu'] = L.ReLU(n[layer], in_place=True)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.11.2 model.fpn.top_blocks.p7\n",
    "    # -------------------------------------\n",
    "\n",
    "    layer = f'{prefix}_p7'\n",
    "    n[layer] = L.Convolution(P6_relu, num_output=1024, kernel_size=3, stride=2, pad=1)\n",
    "\n",
    "    # feature pyramid P6 append at end\n",
    "    # P7 = (conv(P6))\n",
    "    fpn_results.append(n[layer])\n",
    "\n",
    "    # fpn_results = [P2, P3, P4, P6, P7]\n",
    "    # P2 shape: (1, 1024, 60, 72)\n",
    "    # P3 shape: (1, 1024, 30, 36)\n",
    "    # P4 shape: (1, 1024, 15, 18)\n",
    "    # P6 shape: (1, 1024,  8,  9)\n",
    "    # P7 shape: (1, 1024,  4,  5)\n",
    "\n",
    "\n",
    "    # ************************************************\n",
    "    # 2 model.rpn\n",
    "    # rpn := head\n",
    "    # head := cls_tower  => cls_logits\n",
    "    #       bbox_tower => bbox_pred\n",
    "    # ************************************************\n",
    "    logits = []\n",
    "    bbox_reg = []\n",
    "    for idx, p_num in enumerate([2,3,4,6,7]):\n",
    "\n",
    "        bottom = fpn_results[idx]\n",
    "\n",
    "        # cls_tower + cls_logits\n",
    "        prefix = f\"rpn_head_cls_tower_p{p_num}\"\n",
    "        cls_tower_conv1 = f'{prefix}_0'\n",
    "        cls_tower_relu1 = f'{prefix}_1'\n",
    "        cls_tower_conv2 = f'{prefix}_2'\n",
    "        cls_tower_relu2 = f'{prefix}_3'\n",
    "        cls_tower_conv3 = f'{prefix}_4'\n",
    "        cls_tower_relu3 = f'{prefix}_5'\n",
    "        cls_tower_conv4 = f'{prefix}_6'\n",
    "        cls_tower_relu4 = f'{prefix}_7'\n",
    "        cls_logits = f'rpn_head_cls_logits_p{p_num}'\n",
    "\n",
    "        n[cls_tower_conv1], n[cls_tower_relu1], n[cls_tower_conv2], n[cls_tower_relu2], \\\n",
    "        n[cls_tower_conv3], n[cls_tower_relu3], n[cls_tower_conv4], n[cls_tower_relu4], \\\n",
    "        n[cls_logits] = cls_tower_logits(bottom=bottom, nout=9, kernel_size=3, stride=1, pad =1 )\n",
    "\n",
    "        logits.append(n[cls_logits])\n",
    "\n",
    "        # bbox_tower + bbox_pred\n",
    "        prefix = f\"rpn_head_bbox_tower_p{p_num}\"\n",
    "        bbox_tower_conv1 = f'{prefix}_0'\n",
    "        bbox_tower_relu1 = f'{prefix}_1'\n",
    "        bbox_tower_conv2 = f'{prefix}_2'\n",
    "        bbox_tower_relu2 = f'{prefix}_3'\n",
    "        bbox_tower_conv3 = f'{prefix}_4'\n",
    "        bbox_tower_relu3 = f'{prefix}_5'\n",
    "        bbox_tower_conv4 = f'{prefix}_6'\n",
    "        bbox_tower_relu4 = f'{prefix}_7'\n",
    "        bbox_pred = f'rpn_head_bbox_pred_p{p_num}'\n",
    "\n",
    "        n[bbox_tower_conv1], n[bbox_tower_relu1], n[bbox_tower_conv2], n[bbox_tower_relu2], \\\n",
    "        n[bbox_tower_conv3], n[bbox_tower_relu3], n[bbox_tower_conv4], n[bbox_tower_relu4], \\\n",
    "        n[bbox_pred] = bbox_tower_pred(bottom=bottom, nout=36, kernel_size=3, stride=1, pad=1)\n",
    "\n",
    "        bbox_reg.append(n[bbox_pred])\n",
    "\n",
    "    return n.to_proto()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84f0b99",
   "metadata": {},
   "source": [
    "#### backbone_body_network_spec\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "14d225b8",
   "metadata": {},
   "source": [
    "#--------------------------------------------------\n",
    "# backbone_body_only network structure\n",
    "# resnet 50\n",
    "#--------------------------------------------------\n",
    "def backbone_body_network_spec(n, bottom):\n",
    "    '''Build Backbone body (ResNet50)\n",
    "\n",
    "    Params:\n",
    "    n (caffe.NetSpec) : NetSpec instance\n",
    "    bottom (blob) : innput to detection network\n",
    "\n",
    "    '''\n",
    "    # keep list of feature maps in stage order\n",
    "    features = []\n",
    "\n",
    "    # =================================================================\n",
    "    # 1.1 model.backbone.body\n",
    "    # body = stem (layer 0) +  layer 1 + layer 2 + layer 3 + layer 4\n",
    "    # =================================================================\n",
    "\n",
    "    prefix = \"backbone_body\"\n",
    "    # -------------------------------------\n",
    "    # 1.1.0 model.backbone.body.stem (layer0)\n",
    "    # sublayer: conv1,  bn1, relu, maxpool\n",
    "    # -------------------------------------\n",
    "    layer = f'{prefix}_stem_'\n",
    "\n",
    "    n[layer + 'conv1'], n[layer + 'bn1'] = conv_fbn(bottom, 64, bias_term=False,\n",
    "                                                    kernel_size=7, pad=3, stride=2)\n",
    "    n[layer + 'relu'] = L.ReLU(n[layer + 'bn1'], in_place=False)\n",
    "    \n",
    "    \"\"\"\n",
    "    [the diff of resnet18 between caffe and pytorch model is large #16 ](https://github.com/xxradon/PytorchToCaffe/issues/16)\n",
    "    [Inconsistency between caffe and pytorch for max-pooling](https://discuss.pytorch.org/t/inconsistency-between-caffe-and-pytorch-for-max-pooling/35553)\n",
    "    > the main reason is the difference of pooling layer, **caffe** default mode is **ceil** and **pytorc**h is **floor** ,  \n",
    "    > so we need add a para in caffe's pooling layer in PoolingParameter like below :   \n",
    "    `round_mode = FLOOR`\n",
    "\n",
    "    \"\"\"\n",
    "    n[layer + 'maxpool'] = L.Pooling(n[layer + 'relu'], kernel_size=3, stride=2, pool=P.Pooling.MAX)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.1.1 model.backbone.body.layer1\n",
    "    # sublayer: 0, 1, 2\n",
    "    # -------------------------------------\n",
    "    pre_layer = layer\n",
    "    layer = f'{prefix}_layer1'\n",
    "\n",
    "    resnet_stage_sublayer(layer, '0', n, n[pre_layer + 'maxpool'], 64, downsample_branch=True, initial_stride=1)\n",
    "\n",
    "    #resnet_stage_sublayer(layer_name, sublayer_num, n, bottom, nout, downsample_branch=False, initial_stride=2):\n",
    "    resnet_stage_sublayer(layer, '1', n, n[layer + '_0_relu'], 64)\n",
    "    resnet_stage_sublayer(layer, '2', n, n[layer + '_1_relu'], 64)\n",
    "\n",
    "    # feature C1\n",
    "    features.append(n[layer + '_2_relu'])\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.1.2 model.backbone.body.layer2 (stage 2)\n",
    "    # sublayer: 0, 1, 2, 3\n",
    "    # -------------------------------------\n",
    "    pre_layer = layer\n",
    "    layer = f'{prefix}_layer2'\n",
    "\n",
    "    resnet_stage_sublayer(layer, '0', n, n[pre_layer + '_2_relu'], 128, downsample_branch=True)\n",
    "    resnet_stage_sublayer(layer, '1', n, n[layer + '_0_relu'], 128)\n",
    "    resnet_stage_sublayer(layer, '2', n, n[layer + '_1_relu'], 128)\n",
    "    resnet_stage_sublayer(layer, '3', n, n[layer + '_2_relu'], 128)\n",
    "\n",
    "    # feature C2\n",
    "    features.append(n[layer + '_3_relu'])\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.1.3 model.backbone.body.layer3 (stage 3)\n",
    "    # sublayer: 0, 1, 2, 3, 4, 5\n",
    "    # -------------------------------------\n",
    "    pre_layer = layer\n",
    "    layer = f'{prefix}_layer3'\n",
    "\n",
    "    resnet_stage_sublayer(layer, '0', n, n[pre_layer + '_3_relu'], 256, downsample_branch=True)\n",
    "    resnet_stage_sublayer(layer, '1', n, n[layer + '_0_relu'], 256)\n",
    "    resnet_stage_sublayer(layer, '2', n, n[layer + '_1_relu'], 256)\n",
    "    resnet_stage_sublayer(layer, '3', n, n[layer + '_2_relu'], 256)\n",
    "    resnet_stage_sublayer(layer, '4', n, n[layer + '_3_relu'], 256)\n",
    "    resnet_stage_sublayer(layer, '5', n, n[layer + '_4_relu'], 256)\n",
    "\n",
    "    # feature C3\n",
    "    features.append(n[layer + '_5_relu'])\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.1.4 model.backbone.body.layer4 (stage 4)\n",
    "    # sublayer: 0, 1, 2\n",
    "    # -------------------------------------\n",
    "    pre_layer = layer\n",
    "    layer = f'{prefix}_layer4'\n",
    "\n",
    "    resnet_stage_sublayer(layer, '0', n, n[pre_layer + '_5_relu'], 512, downsample_branch=True)\n",
    "    resnet_stage_sublayer(layer, '1', n, n[layer + '_0_relu'], 512)\n",
    "    resnet_stage_sublayer(layer, '2', n, n[layer + '_1_relu'], 512)\n",
    "\n",
    "    # feature C4\n",
    "    features.append(n[layer + '_2_relu'])\n",
    "\n",
    "    C1, C2, C3, C4 = features    \n",
    "\n",
    "    return n.to_proto()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1140e599",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "#### detection_network_v2_spec()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1eb278",
   "metadata": {},
   "source": [
    "##### before code refactoring "
   ]
  },
  {
   "cell_type": "raw",
   "id": "a9f0cc87",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "#--------------------------------------------------\n",
    "# detection_network v2 model structure\n",
    "# model := backbone + rpn (region proposal network)\n",
    "# backbone := body + fpn (feature pyramid network)\n",
    "# body := resnet 50\n",
    "#--------------------------------------------------\n",
    "def detection_network_v2_spec(n, bottom):\n",
    "    '''Build Backbone with ResNet50 + FPN\n",
    "\n",
    "    Params:\n",
    "    n (caffe.NetSpec) : NetSpec instance\n",
    "    bottom (blob) : innput to detection network\n",
    "\n",
    "    '''\n",
    "    # keep list of feature maps in stage order\n",
    "    features = []\n",
    "\n",
    "\n",
    "    # ************************************************\n",
    "    # 1. model.backbone\n",
    "    # ************************************************\n",
    "    # backbone := body + fpn\n",
    "    # ************************************************\n",
    "\n",
    "\n",
    "    # =================================================================\n",
    "    # 1.1 model.backbone.body\n",
    "    # body = stem (layer 0) +  layer 1 + layer 2 + layer 3 + layer 4\n",
    "    # =================================================================\n",
    "\n",
    "    prefix = \"backbone_body\"\n",
    "    # -------------------------------------\n",
    "    # 1.1.0 model.backbone.body.stem (layer0)\n",
    "    # sublayer: conv1,  bn1, relu, maxpool\n",
    "    # -------------------------------------\n",
    "    layer = f'{prefix}_stem_'\n",
    "\n",
    "    n[layer + 'conv1'], n[layer + 'bn1'] = conv_fbn(bottom, 64, bias_term=False,\n",
    "                                                    kernel_size=7, pad=3, stride=2)\n",
    "    n[layer + 'relu'] = L.ReLU(n[layer + 'bn1'], in_place=True)\n",
    "    n[layer + 'maxpool'] = L.Pooling(n[layer + 'relu'], kernel_size=3, stride=2, pool=P.Pooling.MAX)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.1.1 model.backbone.body.layer1\n",
    "    # sublayer: 0, 1, 2\n",
    "    # -------------------------------------\n",
    "    pre_layer = layer\n",
    "    layer = f'{prefix}_layer1'\n",
    "\n",
    "    resnet_stage_sublayer(layer, '0', n, n[pre_layer + 'maxpool'], 64, downsample_branch=True, initial_stride=1)\n",
    "\n",
    "    #resnet_stage_sublayer(layer_name, sublayer_num, n, bottom, nout, downsample_branch=False, initial_stride=2):\n",
    "    resnet_stage_sublayer(layer, '1', n, n[layer + '_0_relu'], 64)\n",
    "    resnet_stage_sublayer(layer, '2', n, n[layer + '_1_relu'], 64)\n",
    "\n",
    "    # feature C1\n",
    "    features.append(n[layer + '_2_relu'])\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.1.2 model.backbone.body.layer2 (stage 2)\n",
    "    # sublayer: 0, 1, 2, 3\n",
    "    # -------------------------------------\n",
    "    pre_layer = layer\n",
    "    layer = f'{prefix}_layer2'\n",
    "\n",
    "    resnet_stage_sublayer(layer, '0', n, n[pre_layer + '_2_relu'], 128, downsample_branch=True)\n",
    "    resnet_stage_sublayer(layer, '1', n, n[layer + '_0_relu'], 128)\n",
    "    resnet_stage_sublayer(layer, '2', n, n[layer + '_1_relu'], 128)\n",
    "    resnet_stage_sublayer(layer, '3', n, n[layer + '_2_relu'], 128)\n",
    "\n",
    "    # feature C2\n",
    "    features.append(n[layer + '_3_relu'])\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.1.3 model.backbone.body.layer3 (stage 3)\n",
    "    # sublayer: 0, 1, 2, 3, 4, 5\n",
    "    # -------------------------------------\n",
    "    pre_layer = layer\n",
    "    layer = f'{prefix}_layer3'\n",
    "\n",
    "    resnet_stage_sublayer(layer, '0', n, n[pre_layer + '_3_relu'], 256, downsample_branch=True)\n",
    "    resnet_stage_sublayer(layer, '1', n, n[layer + '_0_relu'], 256)\n",
    "    resnet_stage_sublayer(layer, '2', n, n[layer + '_1_relu'], 256)\n",
    "    resnet_stage_sublayer(layer, '3', n, n[layer + '_2_relu'], 256)\n",
    "    resnet_stage_sublayer(layer, '4', n, n[layer + '_3_relu'], 256)\n",
    "    resnet_stage_sublayer(layer, '5', n, n[layer + '_4_relu'], 256)\n",
    "\n",
    "    # feature C3\n",
    "    features.append(n[layer + '_5_relu'])\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.1.4 model.backbone.body.layer4 (stage 4)\n",
    "    # sublayer: 0, 1, 2\n",
    "    # -------------------------------------\n",
    "    pre_layer = layer\n",
    "    layer = f'{prefix}_layer4'\n",
    "\n",
    "    resnet_stage_sublayer(layer, '0', n, n[pre_layer + '_5_relu'], 512, downsample_branch=True)\n",
    "    resnet_stage_sublayer(layer, '1', n, n[layer + '_0_relu'], 512)\n",
    "    resnet_stage_sublayer(layer, '2', n, n[layer + '_1_relu'], 512)\n",
    "\n",
    "    # feature C4\n",
    "    features.append(n[layer + '_2_relu'])\n",
    "\n",
    "    C1, C2, C3, C4 = features\n",
    "\n",
    "    # =================================================================\n",
    "    # 1.2 model.backbone.fpn\n",
    "    # =================================================================\n",
    "    fpn_results = []\n",
    "    prefix = \"backbone_fpn\"\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.1 model.backbone.fpn.fpn_inner4\n",
    "    # -------------------------------------\n",
    "    layer = f'{prefix}_fpn_inner4'\n",
    "    last_inner = n[layer] = L.Convolution(C4, num_output=1024, kernel_size=1, stride=1)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.2 model.backbone.fpn.fpn_layer4\n",
    "    # -------------------------------------\n",
    "    layer = f'{prefix}_fpn_layer4'\n",
    "    n[layer] = L.Convolution(last_inner, num_output=1024, kernel_size=3, stride=1, pad=1)\n",
    "\n",
    "    # featuer pyramid feature P4 append\n",
    "    # P4 = conv (conv (C4))\n",
    "    fpn_results.append(n[layer])\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.3 model.backbone.fpn_inner3_upsample\n",
    "    # -------------------------------------\n",
    "    layer = f'{prefix}_fpn_inner3_upsample' # inner3__upsample\n",
    "    \"\"\"\n",
    "    inner3_upsample = n[layer] = L.Deconvolution(last_inner,\n",
    "                                 convolution_param = dict(num_output=1024, kernel_size=4, stride=2, pad=1,\n",
    "                                                          weight_filler=dict(type ='bilinear'),\n",
    "                                                          bias_term=False))\n",
    "    \"\"\"\n",
    "    inner_topdown = n[layer] = L.Deconvolution(last_inner,\n",
    "                                 convolution_param = dict(num_output=1024, kernel_size=4, stride=2, pad=1,\n",
    "                                                          weight_filler=dict(type ='bilinear'),\n",
    "                                                          bias_term=False))\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.4 model.backbone.fpn_inner3\n",
    "    # -------------------------------------\n",
    "    layer = f'{prefix}_fpn_inner3'\n",
    "    inner_lateral = n[layer] = L.Convolution(C3, num_output=1024, kernel_size=1, stride=1)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.5 model.backbone.fpn_inner3_lateral_sum\n",
    "    # -------------------------------------\n",
    "    layer = f'{prefix}_fpn_inner3_lateral_sum' # P3\n",
    "    last_inner = n[layer] = L.Eltwise(inner_lateral,  inner_topdown)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.6 model.backbone.fpn_layer3\n",
    "    # -------------------------------------\n",
    "    layer = f'{prefix}_fpn_layer3'\n",
    "    n[layer] = L.Convolution(last_inner, num_output=1024, kernel_size=3, stride=1, pad=1)\n",
    "\n",
    "    # feature pyramid P3 insert at idx 0\n",
    "    # P3 = unsample(P4) + conv(conv(C3))\n",
    "    fpn_results.insert(0, n[layer])\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.7 model.backbone.fpn_inner2_upsample\n",
    "    # -------------------------------------\n",
    "    layer = f'{prefix}_fpn_inner2_upsample' # inner2__upsample\n",
    "    inner_topdown = n[layer] = L.Deconvolution(last_inner,\n",
    "                               convolution_param\n",
    "                               = dict(num_output=1024, kernel_size=4, stride=2, pad=1,\n",
    "                                      weight_filler=dict(type ='bilinear'),\n",
    "                                      bias_term=False))\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.8 model.backbone.fpn_inner2\n",
    "    # -------------------------------------\n",
    "    layer = f'{prefix}_fpn_inner2'\n",
    "    inner_lateral = n[layer] = L.Convolution(C2, num_output=1024, kernel_size=1, stride=1)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.9 model.backbone.fpn_inner2_lateral_sum\n",
    "    # -------------------------------------\n",
    "    layer = f'{prefix}_fpn_inner2_lateral_sum' # P3\n",
    "    last_inner = n[layer] = L.Eltwise(inner_lateral,  inner_topdown)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.10 model.backbone.fpn_layer2\n",
    "    # -------------------------------------\n",
    "    layer = f'{prefix}_fpn_layer2'\n",
    "    n[layer] = L.Convolution(last_inner, num_output=1024, kernel_size=3, stride=1, pad=1)\n",
    "\n",
    "    # feature pyramid P2 insert at idx 0\n",
    "    # P2 = unsample(P3) + conv(conv(C2))\n",
    "    fpn_results.insert(0, n[layer])\n",
    "\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.11 model.fpn.top_blocks\n",
    "    # -------------------------------------\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.11.1 model.fpn.top_blocks.p6\n",
    "    # -------------------------------------\n",
    "    prefix = \"backbone_fpn_top_blocks\"\n",
    "    layer = f'{prefix}_p6'\n",
    "    n[layer] = L.Convolution(C4, num_output=1024, kernel_size=3, stride=2, pad=1)\n",
    "\n",
    "    # feature pyramid P6 append at end\n",
    "    # P6 = conv(C4)\n",
    "    fpn_results.append(n[layer])\n",
    "\n",
    "    P6_relu = n[layer + 'relu'] = L.ReLU(n[layer], in_place=False)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.11.2 model.fpn.top_blocks.p7\n",
    "    # -------------------------------------\n",
    "    layer = f'{prefix}_p7'\n",
    "    n[layer] = L.Convolution(P6_relu, num_output=1024, kernel_size=3, stride=2, pad=1)\n",
    "\n",
    "    # feature pyramid P6 append at end\n",
    "    # P7 = (conv(P6))\n",
    "    fpn_results.append(n[layer])\n",
    "\n",
    "    # fpn_results = [P2, P3, P4, P6, P7]\n",
    "    # P2 shape: (1, 1024, 60, 72)\n",
    "    # P3 shape: (1, 1024, 30, 36)\n",
    "    # P4 shape: (1, 1024, 15, 18)\n",
    "    # P6 shape: (1, 1024,  8,  9)\n",
    "    # P7 shape: (1, 1024,  4,  5)\n",
    "\n",
    "\n",
    "    # ************************************************\n",
    "    # 2 model.rpn\n",
    "    # rpn := head\n",
    "    # head := cls_tower  => cls_logits\n",
    "    #       bbox_tower => bbox_pred\n",
    "    # ************************************************\n",
    "    logits = []\n",
    "    bbox_reg = []\n",
    "    for idx, p_num in enumerate([2,3,4,6,7]):\n",
    "\n",
    "        bottom = fpn_results[idx]\n",
    "\n",
    "        #------------------------\n",
    "        # cls_tower + cls_logits\n",
    "        #------------------------\n",
    "        #prefix = f\"rpn_head_cls_tower_p{p_num}\"\n",
    "        prefix = f\"rpn_head_cls_tower\"\n",
    "        suffix = f\"for_p{p_num}\"\n",
    "        cls_tower_conv1 = f'{prefix}_0_{suffix}'\n",
    "        cls_tower_relu1 = f'{prefix}_1_{suffix}'\n",
    "        cls_tower_conv2 = f'{prefix}_2_{suffix}'\n",
    "        cls_tower_relu2 = f'{prefix}_3_{suffix}'\n",
    "        cls_tower_conv3 = f'{prefix}_4_{suffix}'\n",
    "        cls_tower_relu3 = f'{prefix}_5_{suffix}'\n",
    "        cls_tower_conv4 = f'{prefix}_6_{suffix}'\n",
    "        cls_tower_relu4 = f'{prefix}_7_{suffix}'\n",
    "        \n",
    "        cls_logits = f'rpn_head_cls_logits_{suffix}'\n",
    "\n",
    "        n[cls_tower_conv1], n[cls_tower_relu1], n[cls_tower_conv2], n[cls_tower_relu2], \\\n",
    "        n[cls_tower_conv3], n[cls_tower_relu3], n[cls_tower_conv4], n[cls_tower_relu4], \\\n",
    "        n[cls_logits] = cls_tower_logits(bottom=bottom, nout=9, kernel_size=3, stride=1, pad =1 )\n",
    "\n",
    "        logits.append(n[cls_logits])\n",
    "\n",
    "        #------------------------\n",
    "        # bbox_tower + bbox_pred\n",
    "        #------------------------\n",
    "        # prefix = f\"rpn_head_bbox_tower_p{p_num}\"\n",
    "        prefix = f\"rpn_head_bbox_tower\"\n",
    "        suffix = f\"for_p{p_num}\"\n",
    "        bbox_tower_conv1 = f'{prefix}_0_{suffix}'\n",
    "        bbox_tower_relu1 = f'{prefix}_1_{suffix}'\n",
    "        bbox_tower_conv2 = f'{prefix}_2_{suffix}'\n",
    "        bbox_tower_relu2 = f'{prefix}_3_{suffix}'\n",
    "        bbox_tower_conv3 = f'{prefix}_4_{suffix}'\n",
    "        bbox_tower_relu3 = f'{prefix}_5_{suffix}'\n",
    "        bbox_tower_conv4 = f'{prefix}_6_{suffix}'\n",
    "        bbox_tower_relu4 = f'{prefix}_7_{suffix}'\n",
    "        \n",
    "        bbox_pred = f'rpn_head_bbox_pred_{suffix}'\n",
    "\n",
    "        n[bbox_tower_conv1], n[bbox_tower_relu1], n[bbox_tower_conv2], n[bbox_tower_relu2], \\\n",
    "        n[bbox_tower_conv3], n[bbox_tower_relu3], n[bbox_tower_conv4], n[bbox_tower_relu4], \\\n",
    "        n[bbox_pred] = bbox_tower_pred(bottom=bottom, nout=36, kernel_size=3, stride=1, pad=1)\n",
    "\n",
    "        bbox_reg.append(n[bbox_pred])\n",
    "\n",
    "    return n.to_proto()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed087e5",
   "metadata": {},
   "source": [
    "##### after code refactoring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "862526d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_network_v2_spec(net_spec, bottom, in_place_scale=False, in_place_relu=False):\n",
    "\n",
    "    \"\"\"Build Backbone with ResNet50 + FPN\n",
    "\n",
    "    Params:\n",
    "    n (caffe.NetSpec) : NetSpec instance\n",
    "    bottom (blob) : innput to detection network\n",
    "\n",
    "    \"\"\"\n",
    "    # keep list of feature maps in stage order\n",
    "    backbone_body_features = []\n",
    "\n",
    "\n",
    "    # ************************************************\n",
    "    # 1. model.backbone\n",
    "    # ************************************************\n",
    "    # backbone := body + fpn\n",
    "    # ************************************************\n",
    "\n",
    "\n",
    "    # =================================================================\n",
    "    # 1.1 model.backbone.body\n",
    "    # body = stem (layer 0) +  layer 1 + layer 2 + layer 3 + layer 4\n",
    "    # =================================================================\n",
    "\n",
    "    prefix = \"backbone_body\"\n",
    "    # -------------------------------------\n",
    "    # 1.1.0 model.backbone.body.stem (layer0)\n",
    "    # sublayer: conv1,  bn1, relu, maxpool\n",
    "    # -------------------------------------\n",
    "    layer_anme = f'{prefix}_stem_'\n",
    "\n",
    "    net_spec[layer_name + 'conv1'], net_spec[layer_name + 'bn1'] = \\\n",
    "        conv_fbn(bottom, 64, in_plce_scale=in_place_scale, kernel_size=7, pad=3, stride=2)\n",
    "\n",
    "    net_spec[layer_name + 'relu'] = L.ReLU(net_spec[layer_name + 'bn1'], in_place=in_place_relu)\n",
    "    net_spec[layer_name + 'maxpool'] = L.Pooling(net_spec[layer_name + 'relu'], kernel_size=3, stride=2, pool=P.Pooling.MAX)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.1.1 model.backbone.body.layer1\n",
    "    # sublayer: 0, 1, 2\n",
    "    # -------------------------------------\n",
    "    pre_layer_name = layer_name\n",
    "    layer_name = f'{prefix}_layer1'\n",
    "\n",
    "    resnet_stage_sublayer(layer_name=layer_name, sublayer_num='0', net_spec=net_spec,\n",
    "                          bottom=net_spec[pre_layer_name + 'maxpool'],\n",
    "                          nout=64, downsample_branch=True, initial_stride=1,\n",
    "                          in_place_scale=in_place_scale, in_place_relut=in_place_relu)\n",
    "\n",
    "    resnet_stage_sublayer(layer_name=layer_name, sublayer_num='1', net_spec=net_spec,\n",
    "                          bottom=net_spec[layer_name + '_0_relu'],\n",
    "                          nout=64,  downsample_branch=False, initial_stride=2,\n",
    "                          in_place_scale=in_place_Scale, in_place_relu=in_place_relu)\n",
    "\n",
    "    resnet_stage_sublayer(layer_name=layer_name, sublayer_num='2', net_spec=net_spec,\n",
    "                          bottom=net_spec[layer_name + '_1_relu'],\n",
    "                          nout=64, downsample_branch=False, initial_stride=2,\n",
    "                          in_place_scale = in_place_Scale, in_place_relu = in_place_relu)\n",
    "\n",
    "    # feature C1\n",
    "    backbone_body_features.append(net_spec[layer_name + '_2_relu'])\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.1.2 model.backbone.body.layer2 (stage 2)\n",
    "    # sublayer: 0, 1, 2, 3\n",
    "    # -------------------------------------\n",
    "    pre_layer_name = layer_name\n",
    "    layer_name = f'{prefix}_layer2'\n",
    "\n",
    "    resnet_stage_sublayer(layer_name=layer_name, sublayer_num='0', net_spec=net_spec,\n",
    "                          bottom=net_spec[pre_layer_name + '_2_relu'],\n",
    "                          nout=128, downsample_branch=True, initial_stride=2,\n",
    "                          in_place_scale = in_place_Scale, in_place_relu = in_place_relu)\n",
    "\n",
    "    resnet_stage_sublayer(layer_name=layer_name, sublayer_num='1', netw_spec=net_spec,\n",
    "                          bottom=net_spec[layer_name + '_0_relu'],\n",
    "                          nout=128, downsample_branch=False, initial_stride=2,\n",
    "                          in_place_scale = in_place_Scale, in_place_relu = in_place_relu)\n",
    "\n",
    "    resnet_stage_sublayer(layer_name=layer_name, sublayer_num='2', net_spec=net_spec,\n",
    "                          bottom=net_spec[layer + '_1_relu'],\n",
    "                          nout=128, downsample_branch=False, initial_stride=2,\n",
    "                          in_place_scale = in_place_Scale, in_place_relu = in_place_relu)\n",
    "\n",
    "    resnet_stage_sublayer(layer_name=layer_name, sublayer_num='3', net_spec=net_spec,\n",
    "                          bottom=net_spec[layer + '_2_relu'],\n",
    "                          nout=128, downsample_branch=False, initial_stride=2,\n",
    "                          in_place_scale = in_place_Scale, in_place_relu = in_place_relu)\n",
    "\n",
    "    # feature C2\n",
    "    backbone_features.append(netspec[layer_name + '_3_relu'])\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.1.3 model.backbone.body.layer3 (stage 3)\n",
    "    # sublayer: 0, 1, 2, 3, 4, 5\n",
    "    # -------------------------------------\n",
    "    pre_layer_name = layer_name\n",
    "    layer_name = f'{prefix}_layer3'\n",
    "\n",
    "    resnet_stage_sublayer(layer_name=layer_name, sublayer_num='0', net_spec=net_spec,\n",
    "                          bottom=net_spec[pre_layer_name + '_3_relu'],\n",
    "                          nout=256, downsample_branch=True, initial_stride=2,\n",
    "                          in_place_scale = in_place_Scale, in_place_relu = in_place_relu)\n",
    "\n",
    "    resnet_stage_sublayer(layer_name=layer_name, sublayer_num='1', netw_spec=net_spec,\n",
    "                          bottom=net_spec[layer_name + '_0_relu'],\n",
    "                          nout=256, downsample_branch=False, initial_stride=2,\n",
    "                          in_place_scale=in_place_Scale, in_place_relu=in_place_relu)\n",
    "\n",
    "    resnet_stage_sublayer(layer_name=layer_name, sublayer_num='2', netw_spec=net_spec,\n",
    "                          bottom=net_spec[layer_name + '_1_relu'],\n",
    "                          nout=256, downsample_branch=False, initial_stride=2,\n",
    "                          in_place_scale=in_place_Scale, in_place_relu=in_place_relu)\n",
    "\n",
    "    resnet_stage_sublayer(layer_name=layer_name, sublayer_num='3', netw_spec=net_spec,\n",
    "                          bottom=net_spec[layer_name + '_2_relu'],\n",
    "                          nout=256, downsample_branch=False, initial_stride=2,\n",
    "                          in_place_scale=in_place_Scale, in_place_relu=in_place_relu)\n",
    "\n",
    "    resnet_stage_sublayer(layer_name=layer_name, sublayer_num='4', netw_spec=net_spec,\n",
    "                          bottom=net_spec[layer_name + '_3_relu'],\n",
    "                          nout=256, downsample_branch=False, initial_stride=2,\n",
    "                          in_place_scale=in_place_Scale, in_place_relu=in_place_relu)\n",
    "\n",
    "    resnet_stage_sublayer(layer_name=layer_name, sublayer_num='5', netw_spec=net_spec,\n",
    "                          bottom=net_spec[layer_name + '_4_relu'],\n",
    "                          nout=256, downsample_branch=False, initial_stride=2,\n",
    "                          in_place_scale=in_place_Scale, in_place_relu=in_place_relu)\n",
    "\n",
    "\n",
    "    # feature C3\n",
    "    backbone_body_features.append(net_spec[layer_name + '_5_relu'])\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.1.4 model.backbone.body.layer4 (stage 4)\n",
    "    # sublayer: 0, 1, 2\n",
    "    # -------------------------------------\n",
    "    pre_layer_name = layer_name\n",
    "    layer_name = f'{prefix}_layer4'\n",
    "\n",
    "    \"\"\"\n",
    "    resnet_stage_sublayer(layer_name, sublayer_num, net_spec, bottom, nout, downsample_branch=False,\n",
    "                              initial_stride=2,\n",
    "                              in_place_scale=False, in_place_relu=False):\n",
    "    \"\"\"\n",
    "    resnet_stage_sublayer(layer_name=layer_name, sublayer_num='0', net_spec=net_spec,\n",
    "                          bottom=net_spec[pre_layer_name + '_5_relu'],\n",
    "                          nout=512, downsample_branch=True, initial_stride=2,\n",
    "                          in_place_scale = in_place_Scale, in_place_relu = in_place_relu)\n",
    "\n",
    "    resnet_stage_sublayer(layer_name=layer_name, sublayer_num='1', netw_spec=net_spec,\n",
    "                          bottom=net_spec[layer_name + '_0_relu'],\n",
    "                          nout=512, downsample_branch=False, initial_stride=2,\n",
    "                          in_place_scale=in_place_Scale, in_place_relu=in_place_relu)\n",
    "\n",
    "    resnet_stage_sublayer(layer_name=layer_name, sublayer_num='2', netw_spec=net_spec,\n",
    "                          bottom=net_spec[layer_name + '_1_relu'],\n",
    "                          nout=512, downsample_branch=False, initial_stride=2,\n",
    "                          in_place_scale=in_place_Scale, in_place_relu=in_place_relu)\n",
    "\n",
    "    # feature C4\n",
    "    backbone_body_features.append(net_spec[layer_name + '_2_relu'])\n",
    "\n",
    "    C1, C2, C3, C4 = backbone_body_features\n",
    "\n",
    "    # =================================================================\n",
    "    # 1.2 model.backbone.fpn\n",
    "    # =================================================================\n",
    "    backbone_fpn_features = []\n",
    "    prefix = \"backbone_fpn\"\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.1 model.backbone.fpn.fpn_inner4\n",
    "    # -------------------------------------\n",
    "    layer_name = f'{prefix}_fpn_inner4'\n",
    "    last_inner = net_spec[layer_name] = L.Convolution(C4, num_output=1024, kernel_size=1, stride=1)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.2 model.backbone.fpn.fpn_layer4\n",
    "    # -------------------------------------\n",
    "    layer_name = f'{prefix}_fpn_layer4'\n",
    "    net_spec[layer_name] = L.Convolution(last_inner, num_output=1024, kernel_size=3, stride=1, pad=1)\n",
    "\n",
    "    # featuer pyramid feature P4 append\n",
    "    # P4 = conv (conv (C4))\n",
    "    backbone_fpn_features.append(net_spec[layer_name])\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.3 model.backbone.fpn_inner3_upsample\n",
    "    # -------------------------------------\n",
    "    layer_name = f'{prefix}_fpn_inner3_upsample' # inner3__upsample\n",
    "    inner3_upsample = net_spec[layer_name] = \\\n",
    "        L.Deconvolution(last_inner, convolution_param = dict(num_output=1024,\n",
    "                                                             kernel_size=4,\n",
    "                                                             stride=2, pad=1,\n",
    "                                                             weight_filler=dict(type ='bilinear'),\n",
    "                                                             bias_term=False) )\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.4 model.backbone.fpn_inner3_lateral\n",
    "    # -------------------------------------\n",
    "    layer_name = f'{prefix}_fpn_inner3_lateral'\n",
    "    inner3_lateral = net_spec[layer_name] = L.Convolution(C3, num_output=1024, kernel_size=1, stride=1)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.5 model.backbone.fpn_inner3_lateral_sum\n",
    "    # -------------------------------------\n",
    "    layer_name = f'{prefix}_fpn_inner3_lateral_sum' # P3\n",
    "    last_inner = net_spec[layer_name] = L.Eltwise(inner3_lateral,  inner3_upsample)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.6 model.backbone.fpn_layer3\n",
    "    # -------------------------------------\n",
    "    layer_name = f'{prefix}_fpn_layer3'\n",
    "    net_spec[layer_name] = L.Convolution(last_inner, num_output=1024, kernel_size=3, stride=1, pad=1)\n",
    "\n",
    "    # feature pyramid P3 insert at idx 0\n",
    "    # P3 = unsample(P4) + conv(conv(C3))\n",
    "    backbone_fpn_features.insert(0, net_spec[layer_name])\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.7 model.backbone.fpn_inner2_upsample\n",
    "    # -------------------------------------\n",
    "    layer_name = f'{prefix}_fpn_inner2_upsample' # inner2__upsample\n",
    "    inner2_upsample = net_spec[layer_name] = \\\n",
    "        L.Deconvolution(last_inner, convolution_param = dict(num_output=1024,\n",
    "                                                             kernel_size=4,\n",
    "                                                             stride=2, pad=1,\n",
    "                                                             weight_filler=dict(type ='bilinear'),\n",
    "                                                             bias_term=False))\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.8 model.backbone.fpn_inner2_lateral\n",
    "    # -------------------------------------\n",
    "    layer_name = f'{prefix}_fpn_inner2_lateral'\n",
    "    inner2_lateral = net_spec[layer_name] = L.Convolution(C2, num_output=1024, kernel_size=1, stride=1)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.9 model.backbone.fpn_inner2_lateral_sum\n",
    "    # -------------------------------------\n",
    "    layer_name = f'{prefix}_fpn_inner2_lateral_sum' # P3\n",
    "    last_inner = net_spec[layer_name] = L.Eltwise(inner2_lateral,  inner2_upsample)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.10 model.backbone.fpn_layer2\n",
    "    # -------------------------------------\n",
    "    layer_name = f'{prefix}_fpn_layer2'\n",
    "    net_spec[layer_name] = L.Convolution(last_inner, num_output=1024, kernel_size=3, stride=1, pad=1)\n",
    "\n",
    "    # feature pyramid P2 insert at idx 0\n",
    "    # P2 = unsample(P3) + conv(conv(C2))\n",
    "    backbone_fpn_features.insert(0, net_spec[layer_name])\n",
    "\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.11 model.fpn.top_blocks\n",
    "    # -------------------------------------\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.11.1 model.fpn.top_blocks.p6\n",
    "    # -------------------------------------\n",
    "    prefix = \"backbone_fpn_topblocks\"\n",
    "    layer_name = f'{prefix}_p6'\n",
    "    net_spec[layer_name] = L.Convolution(C4, num_output=1024, kernel_size=3, stride=2, pad=1)\n",
    "\n",
    "    # feature pyramid P6 append at end\n",
    "    # P6 = (conv(C4)) ?\n",
    "    backbone_fpn_features.append(net_spec[layer_name])\n",
    "\n",
    "    P6_relu = net_spec[layer_name + 'relu'] = L.ReLU(n[layer], in_place=True)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1.2.11.2 model.fpn.top_blocks.p7\n",
    "    # -------------------------------------\n",
    "\n",
    "    layer_name = f'{prefix}_p7'\n",
    "    net_spec[layer_name] = L.Convolution(P6_relu, num_output=1024, kernel_size=3, stride=2, pad=1)\n",
    "\n",
    "    # feature pyramid P6 append at end\n",
    "    # P7 = (conv(P6))\n",
    "    backbone_fpn_features.append(net_spec[layer_name])\n",
    "\n",
    "    # fpn_results = [P2, P3, P4, P6, P7]\n",
    "    # P2 shape: (1, 1024, 60, 72)\n",
    "    # P3 shape: (1, 1024, 30, 36)\n",
    "    # P4 shape: (1, 1024, 15, 18)\n",
    "    # P6 shape: (1, 1024,  8,  9)\n",
    "    # P7 shape: (1, 1024,  4,  5)\n",
    "\n",
    "\n",
    "    # ************************************************\n",
    "    # 2 model.rpn\n",
    "    # rpn := head\n",
    "    # head := cls_tower  => cls_logits\n",
    "    #       bbox_tower => bbox_pred\n",
    "    # ************************************************\n",
    "    logits = []\n",
    "    bbox_reg = []\n",
    "    for idx, p_num in enumerate([2,3,4,6,7]):\n",
    "\n",
    "        bottom = backbone_fpn_features[idx]\n",
    "\n",
    "        # cls_tower + cls_logits\n",
    "        prefix = f\"rpn_head_cls_tower_p{p_num}\"\n",
    "        cls_tower_conv1 = f'{prefix}_0'\n",
    "        cls_tower_relu1 = f'{prefix}_1'\n",
    "        cls_tower_conv2 = f'{prefix}_2'\n",
    "        cls_tower_relu2 = f'{prefix}_3'\n",
    "        cls_tower_conv3 = f'{prefix}_4'\n",
    "        cls_tower_relu3 = f'{prefix}_5'\n",
    "        cls_tower_conv4 = f'{prefix}_6'\n",
    "        cls_tower_relu4 = f'{prefix}_7'\n",
    "        cls_logits = f'rpn_head_cls_logits_p{p_num}'\n",
    "\n",
    "        net_spec[cls_tower_conv1], net_spec[cls_tower_relu1], net_spec[cls_tower_conv2], \\\n",
    "        net_spec[cls_tower_relu2], net_spec[cls_tower_conv3], net_spec[cls_tower_relu3], \\\n",
    "        net_spec[cls_tower_conv4], net_spec[cls_tower_relu4], net_spec[cls_logits] = \\\n",
    "            cls_tower_logits(bottom=bottom, nout=9, kernel_size=3, stride=1, pad =1 )\n",
    "\n",
    "        logits.append(net_spec[cls_logits])\n",
    "\n",
    "        # bbox_tower + bbox_pred\n",
    "        prefix = f\"rpn_head_bbox_tower_p{p_num}\"\n",
    "        bbox_tower_conv1 = f'{prefix}_0'\n",
    "        bbox_tower_relu1 = f'{prefix}_1'\n",
    "        bbox_tower_conv2 = f'{prefix}_2'\n",
    "        bbox_tower_relu2 = f'{prefix}_3'\n",
    "        bbox_tower_conv3 = f'{prefix}_4'\n",
    "        bbox_tower_relu3 = f'{prefix}_5'\n",
    "        bbox_tower_conv4 = f'{prefix}_6'\n",
    "        bbox_tower_relu4 = f'{prefix}_7'\n",
    "        bbox_pred = f'rpn_head_bbox_pred_p{p_num}'\n",
    "\n",
    "        net_spec[bbox_tower_conv1], net_spec[bbox_tower_relu1], net_spec[bbox_tower_conv2], \\\n",
    "        net_spec[bbox_tower_relu2], net_spec[bbox_tower_conv3], net_spec[bbox_tower_relu3], \\\n",
    "        net_spec[bbox_tower_conv4], net_spec[bbox_tower_relu4], net_spec[bbox_pred] = \\\n",
    "            bbox_tower_pred(bottom=bottom, nout=36, kernel_size=3, stride=1, pad=1)\n",
    "\n",
    "        bbox_reg.append(net_spec[bbox_pred])\n",
    "\n",
    "    return net_spec.to_proto()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54257e3b",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### Logits and Bbopx regs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f93740",
   "metadata": {},
   "source": [
    "#### logits_and_bbox_regs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda35f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_and_bbox_regs(network):\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4af3d4",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### Anchor Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c437ef6",
   "metadata": {},
   "source": [
    "#### anchor_generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6199332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anchor_generate(image_list, feature_maps):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a8b27d",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### Box Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4bbb0f",
   "metadata": {},
   "source": [
    "#### box_generate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa47ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_generate(anchors, objectness, rpn_box_regression):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1383de0",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# 동작 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e8ab07",
   "metadata": {},
   "source": [
    "## NetSpec instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30487db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------\n",
    "# 1. detection network v2 spec preparation\n",
    "#------------------------------------------------------\n",
    "nw_spec = caffe.NetSpec()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86273cb",
   "metadata": {},
   "source": [
    "## input image transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a0e728",
   "metadata": {},
   "source": [
    "### image file loading into PIL.Image with RGB mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7497664",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_file = \"../sample_images/detection/1594202471809.jpg\"\n",
    "img = Image.open(img_file).convert('RGB')\n",
    "pil_image.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19ad84f",
   "metadata": {},
   "source": [
    "### resize PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e54b9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIL image resize\n",
    "resized_img=pil_image_resize(img)\n",
    "print(f\"resized_img.size (WxH): {resized_img.size}\\nresized_img.mode: {resized_img.mode}\")\n",
    "\n",
    "pvalues = resized_img.getextrema()\n",
    "\n",
    "#print(f\"pvalues: {pvalues}\")\n",
    "for c, p in zip(\"RGB\", pvalues):\n",
    "    print(f\"{c} ch. min/max pixel value: {p[0]}, {p[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dd0902",
   "metadata": {},
   "source": [
    "#### PIL.Image to ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc4fb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIL image to np.ndarray\n",
    "img_arr = to_ndarray(resized_img)\n",
    "print(f\"img_arr.shape (CxHxW): {img_arr.shape}, ch. order in C dimension is RGB\")\n",
    "print(f\"img_arr.dtype: {img_arr.dtype}\")\n",
    "\n",
    "for c, c_i in zip(\"RGB\", range(3)):\n",
    "    print(f\"{c} ch. min/max value: {img_arr[c_i].min()}, {img_arr[c_i].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc331a9f",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "\n",
    "Normalization시 ch. 순서를 RGB에서 BGR로 바꾸고, 각 원소의 값에 255를 다시 곱해주고, 다음과 같은 파라메터를 사용하여 normalize한다.\n",
    "* mean = [102.9801, 115.9465, 122.7717]\n",
    "*std = [1.0, 1.0, 1.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366d1b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize with mean and std\n",
    "# mean and std is defined in configuration\n",
    "img_arr = normalize(img_arr)\n",
    "\n",
    "print(f\"img_arr.shape (CxHxW): {img_arr.shape}, ch. order in C dimension is GBR\")\n",
    "print(f\"img_arr.dtype: {img_arr.dtype}\")\n",
    "\n",
    "for c, c_i in zip(\"GBR\", range(3)):\n",
    "    print(f\"{c} ch. min/max value: {img_arr[c_i].min()}, {img_arr[c_i].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9d750e",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### Zero Padding\n",
    "\n",
    "이미지의 width, height를 32의 배수가 되는 크기의 black background에 overlay하고, batch 채널을 추가\n",
    "* CHW ==> NCHW, Ch. order: BGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1d0fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_arr = zero_padding(img_arr, size_divisible = 32)\n",
    "print(f\"batched_arr.shape (NxCxHxW): {batched_arr.shape}, ch. order in C dimension is GBR\")\n",
    "print(f\"batched_arr.dtype: {img_arr.dtype}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075d1867",
   "metadata": {},
   "source": [
    "----\n",
    "## Set Shape of Data Input in Detection Network Spec\n",
    "\n",
    "referece:\n",
    "* [How to present ndarray to trained caffe net in python?](https://stackoverflow.com/questions/55843935/how-to-present-ndarray-to-trained-caffe-net-in-python)\n",
    "* [Passing captured video frame (numpy array object) from webcam feed to caffe model](https://stackoverflow.com/questions/39998038/passing-captured-video-frame-numpy-array-object-from-webcam-feed-to-caffe-mode)\n",
    "* [pyCaffe Tools, Examples and Resources - David Stutz](https://davidstutz.de/pycaffe-tools-examples-and-resources/#testing)- Testing section\n",
    "* [(How to create Data layer in caffe?](https://stackoverflow.com/questions/42500383/how-to-create-data-layer-in-caffe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6cae5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#detection_network_spec.data = L.DummyData(shape=[dict(dim=[1, 3, 480, 576])])\n",
    "nw_spec.data = L.DummyData(shape=[dict(dim=list(batched_arr.shape))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b5577b",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## ++Network Spec prototxt Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3fcd33",
   "metadata": {},
   "source": [
    "### backbone body (resnet50) prototxt generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcfd1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_body_prototxt = backbone_body_network_spec(nw_spec, nw_spec.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f62e926",
   "metadata": {},
   "source": [
    "### detection_nework_v2 prototxt generation - temporay disabling for testing of backbone_body only"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a9ef3ade",
   "metadata": {},
   "source": [
    "detection_nework_v2_prototxt = detection_network_v2_spec(nw_spec, nw_spec.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7864296",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Saving prototxt into file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc1ed3a",
   "metadata": {},
   "source": [
    "### Saving backbone_only prototxt into file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c63f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_body_prototxt_file = './backbone_body_network.prototxt'\n",
    "\n",
    "with open(backbone_body_prototxt_file, 'w') as f:\n",
    "    f.write(str(backbone_body_prototxt))\n",
    "    \n",
    "print(f\"{backbone_body_prototxt_file} written ....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271bea8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ./backbone_body_network.prototxt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c48c466",
   "metadata": {},
   "source": [
    "### Saving detection_network_v2 prototxt into file - temporay disabling for testing of backbone_body only"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6d5e776d",
   "metadata": {},
   "source": [
    "detection_nework_v2_prototxt_file = './detection_model_v2.prototxt'\n",
    "\n",
    "with open(detection_nework_v2_prototxt_file, 'w') as f:\n",
    "    f.write(str(detection_nework_v2_prototxt))\n",
    "    \n",
    "print(f\"{detection_nework_v2_prototxt} written ....\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b9854610",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "!cat ./detection_model_v2.prototxt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6735edd",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Network Instantiation for Test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4970e201",
   "metadata": {},
   "source": [
    "### Backbone body Network Instanatiaion\n",
    "\n",
    "파일로 저장된 backbone body (resnet50) spec용 prototxt 파일을 읽어서, test용 backbone body Network 인스턴스를 생성한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b0d64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_body_nw = caffe.Net(backbone_body_prototxt_file, caffe.TEST)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bf7239",
   "metadata": {},
   "source": [
    "### Detection Network V2 Instanatiaion - temporay disabling for testing of backbone_body only\n",
    "\n",
    "파일로 저장된 detection network v2 spec용 prototxt 파일을 읽어서, test용 Detection Network 인스턴스를 생성한다.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6f0b62d0",
   "metadata": {},
   "source": [
    "detection_nw = caffe.Net(prototxt_file, caffe.TEST)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a608d4",
   "metadata": {},
   "source": [
    "### caffe.Net class\n",
    "\n",
    "refrence: [How to get model inform in caffe and pytorch](http://echo.etri.re.kr:8090/display/~kimkk/how+to+get+model+info+in+caffe+and+pytorch)\n",
    "> defined in `_caffe.so`\n",
    "\n",
    "* [caffe.Net example codes in programtalk.com](https://programtalk.com/python-examples/caffe.Net/)\n",
    "* [caffe.Net example codes in programcrrek.com](https://www.programcreek.com/python/example/83289/caffe.Net)\n",
    "* [pycaffe_doc.ipynb](./pycaffe_doc.ipynb)\n",
    "\n",
    "파이썬 코드로 `caffe.Net` 클래스를 생성할 때, 네트워크는 `.prototxt` 파일에 정의된 네트워크 정의를 사용하여 빌드된다. \n",
    "> 네트워크의 모든 파라메터 (weight + bias) 정보가 저장된 `.caffemodel` 파일을 로드할 때,  `*.caffemodel`에 명시된 모든 레이어들은 prototext 로 정의된 레이어들과 name을 통하여 매칭된다.   \n",
    "> **i) `.prototxt` 파일상에서 정의된 레이어가 `.caffemodel` 파일에 존재하는 경우,**   \n",
    "> * 레이어의 파라메터 (weight + bias, etc.) shape까지 매칭되는 경우, 매칭되는 레이어로 복사된다.    \n",
    "> * 레이어의 파라메터 shape 매칭에 실패하는 경우, shape mismatch 관련 에러 메시지를 발생시킨다.    \n",
    ">\n",
    "> **ii) `.prototxt` 파일상에서 정의된 레이어가 `.caffemodel` 파일에 존재하지 않는 경우,**\n",
    "> * `.prototxt` 파일에서 지정한 내용에 따라 해당 레이어의 파라메터를 초기화한다. 일반적으로 랜덤 값으로 초기화한다.    \n",
    "> * `.caffemodel` 파일에는 있지만, `prototxt` 파일에서 명시되지 않은 모든 레이어의 경우 무시한다.    \n",
    "* source : [What if the model does not match the network config?](https://groups.google.com/g/caffe-users/c/eCygJO2LG30/m/67KqcA-tAwAJ)\n",
    "\n",
    "caffe.Net() 함수를 통하여 로딩한 네트워크를 저장한 Net 클래스 인스턴스인 net 의 attribute를 통하여 사용하여 네트워크의 정보들을 확인할 수있다.\n",
    "\n",
    "* Input layer들의 이름은 ```print(net.inputs)``` 을 통하여 확인할 수 있다.\n",
    "\n",
    "----\n",
    "\n",
    "그외에도 net 오브젝트에는 다음과 같은 3개의  ordered dict가 포함되어 있다.\n",
    "\n",
    "* **caffe.Net.blobs** \n",
    "* **caffe.Net.params**\n",
    "* **caffe.Net.layer_dict**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3157d630",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "\n",
    "### caffe.Net.blobs : input and intermediate results\n",
    "\n",
    "caffe.Net.blobs는 입력 데이타와 입력 데이타가 레이어들을 따라 계산된 결과를 저장하는 텐서들에 대한 딕셔너리로 다음과 같이 해당 레이어의 top 필드에 사용한 이름을 key로 사용하여 텐서를 접근할 수 있다.\n",
    "* net.blobs['data'] : shape가 (1, 1, 100, 100)인 입력 데이타 텐서\n",
    "* net.blobs['conv']: ‘conv’ (1, 3, 96, 96)를 통하여 계산된 결과 텐서로 0으로 초기화된다.\n",
    "\n",
    "아래와 같은 코드를 통하여 전체 입력 텐서로부터 각 레이어들에서 계산된 결과를 저장한 텐서들의 전체 sahpe 정보를 확인할 수 있다.\n",
    "```python\n",
    "[(k, v.data.shape) for k, v in net.blobs.items()]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32237e31",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "\n",
    "### caffe.Net.params: learned parameters\n",
    "\n",
    "net.params는 트레이닝을 통하여 학습되는 파라메터를 가지는 learnable layers의 weights와 bias 정보를 저장하는 텐서들에 대한 딕셔너리로, 해당 레이어의 top 필드에 사용한 이름을 key로 사용하여 [weght, bias] 리스트를 접근할 수 있다.\n",
    "* net.params['conv'][0] : \"conv\" 레이어의 shape가 (3, 1, 5, 5)인 weight 텐서\n",
    "* net.params['conv'][1] : conv\" 레이어의 shape가 (3, )인 bias 텐서\n",
    "\n",
    "weight와 bias는 각각 .prototxt  파일의 \"conv‘ 레이어 설정에서 weight_filler 와 bias_filler 필드에 지정된 알고리즘과 설정값으로 초기화된다.\n",
    "\n",
    "아래와 같은 코드를 통하여 네트워크 모델내의 모든 learlable layer에 대하여 weight와 bias의 shape를 확인할 수 있다.\n",
    "```python\n",
    "[(k, v[0].data.shape, v[1].data.shape) for k, v in net.params.items()]\n",
    "```\n",
    "\n",
    "**Blobs**은 mode (CPU, GPU)에 따라 결정되는 디바이스상의 메모리에 대한 abstraction object (aka Tensor)로 실제 데이타는 data  필드에 저장되므로, 'conv` 레이어에 대한 데이타는 다음과 같이 접근할 수 있다.\n",
    "```python\n",
    "print net.blobs['conv'].data.shape\n",
    "```\n",
    "* data  필드에는 해당 데이타의 shape 정보를 포함하는 shape attribute가 있다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73cbdbd",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### caffe.Net.layer_dict\n",
    "\n",
    "네트워크의 bottom에서 top, 즉 input to ouput에 대한 정보를 가지고 있는 Ordered Dict로 레이어의 이름을 key로 사용한다.\n",
    "```python\n",
    "# net is instace of caffe.Net class\n",
    "for idx, layer_name in enumerate(net.layer_dict):\n",
    "    print(f\"-----------------------------\")\n",
    "    print(f\"layer index: {idx}\")\n",
    "    print(f\"-----------------------------\")\n",
    "    print(f\"layer name: {layer_name}\")\n",
    "    print(f\"layer type: {caffe_network.layer_dict[layer_name].type}\")\n",
    "    print(f\"blobs:\")\n",
    "    for blob in caffe_network.layer_dict[layer_name].blobs:\n",
    "        print(f\"\\t{blob}\")\n",
    "        print(f\"\\tblob.channels: {blob.channels}\")\n",
    "        print(f\"\\tblob.data.shape: {blob.data.shape}\")\n",
    "        print(\"\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e37d7a",
   "metadata": {},
   "source": [
    "---- \n",
    "\n",
    "## check layer in Detection Network for Test"
   ]
  },
  {
   "cell_type": "raw",
   "id": "56679f44",
   "metadata": {},
   "source": [
    "help(caffe.Net)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "70dcdc88",
   "metadata": {},
   "source": [
    "help(caffe._caffe.Blob)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8b95b415",
   "metadata": {},
   "source": [
    "for l in detection_nw.layers:\n",
    "    print(f\"l type: {l.type}\")\n",
    "    print(f\"l blobs: {l.blobs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d3db1c",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### caffe.Net.inputs: Network level input\n",
    "\n",
    "Network 수준에서의 input에 대한 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9030aab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(caffe.Net.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3539d23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_body_nw.inputs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "35d5cac3",
   "metadata": {},
   "source": [
    "detection_nw.inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65019e5",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### caffe.Net.outputs: Network level outputs\n",
    "\n",
    "Network 수준에서의 outputs에 대한 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54781ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(caffe.Net.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641a91a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_body_nw.outputs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0b1df3c2",
   "metadata": {},
   "source": [
    "detection_nw.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edb63ff",
   "metadata": {},
   "source": [
    "----\n",
    "### caffe.Net.params: learned parameters\n",
    "\n",
    "`caffe.Net.params`는 트레이닝을 통하여 학습되는 파라메터를 가지는 learnable layers의 weights와 bias 정보를 저장하는 텐서(type: caffe._caffe.Blob)들에 대한 딕셔너리로, 해당 레이어의 top 필드에 사용한 이름을 key로 사용하여 [weght, bias] 리스트를 접근할 수 있다.\n",
    "* net.params['conv'][0] : \"conv\" 레이어의 shape가 (3, 1, 5, 5)인 weight 텐서 \n",
    "* net.params['conv'][1] : conv\" 레이어의 shape가 (3, )인 bias 텐서\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3e9d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(caffe.Net.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4586cf5",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### caffe.Net.blobs : input and itermediate resutls\n",
    "\n",
    "`caffe.Net.blobs`는 입력 데이타와 입력 데이타가 레이어들을 따라 **계산된 결과**를 저장하는 텐서들에 대한 딕셔너리로 다음과 같이 해당 레이어의 top 필드에 사용한 이름을 key로 사용하여 텐서를 접근할 수 있다.\n",
    "\n",
    "> `net.blobs['data']` : shape가 (1, 1, 100, 100)인 입력 데이타 텐서  \n",
    "> `net.blobs['conv']`: 'conv' (1, 3, 96, 96)를 통하여 계산된 결과 텐서로 0으로 초기화된다.\n",
    "\n",
    "\n",
    "아래와 같은 코드를 통하여 전체 입력 텐서로부터 각 레이어들에서 계산된 결과를 저장한 텐서들의 전체 sahpe 정보를 확인할 수 있다.\n",
    "```python\n",
    "[(k, v.data.shape) for k, v in net.blobs.items()]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385f6c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(caffe.Net.blobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37f67c0",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### caff._caffe.Blob\n",
    "\n",
    "----\n",
    "\n",
    "> Blob in Caffe\n",
    "> reference\n",
    "> * [Blobs, Layers, and Nets: anatomy of a Caffe model](https://caffe.berkeleyvision.org/tutorial/net_layer_blob.html) - caffe documentations\n",
    "> * [caffe::Blob<Dtype> Class Template Reference](https://caffe.berkeleyvision.org/doxygen/classcaffe_1_1Blob.html) - C++ source for Blob class\n",
    ">\n",
    "> A **Blob** is a wrapper over the actual data being processed and passed along by Caffe, and also under the hood provides synchronization capability between the CPU and the GPU.  Mathematically, a blob is an N-dimensional array stored in a C-contiguous fashion.\n",
    ">\n",
    "> Caffe stores and communicates data using blobs. Blobs provide a unified memory interface holding data; e.g., \n",
    ">> * batches of images, \n",
    ">> * model parameters, and \n",
    ">> * derivatives for optimization.\n",
    ">\n",
    ">Blobs conceal the computational and mental overhead of mixed CPU/GPU operation by synchronizing from the CPU host to the GPU device as needed. Memory on the host and device is allocated on demand (lazily) for efficient memory usage.\n",
    ">\n",
    ">The conventional blob dimensions for **batches of image data** are $\\text{number } N \\times \\text{channel } K \\times \\text{height } H \\times \\text{width } W$ (aka **NCHW** format). Blob memory is row-major in layout, so the last / rightmost dimension changes fastest.  \n",
    "> For example, in a 4D blob, the value at index $(n, k, h, w)$ is physically located at index $((n \\times K + k) \\times  H + h) \\times  W + w$.\n",
    ">\n",
    ">> * $\\text{Number } N$ is the batch size of the data. Batch processing achieves better throughput for communication and device processing.  \n",
    ">>   * For an ImageNet training batch of $256$ images $N = 256$.\n",
    ">> * $\\text{Channel } K$ is the feature dimension e.g. \n",
    ">>  * for RGB images $K = 3$.\n",
    ">\n",
    "> Note that although many blobs in Caffe examples are 4D with axes for image applications, it is totally valid to use blobs for non-image applications. \n",
    ">> * For example, if you simply need fully-connected networks like the conventional multi-layer perceptron, \n",
    ">>   * use 2D blobs (shape $(N, D)$) and call the InnerProductLayer (which we will cover soon).\n",
    ">   \n",
    "> **Parameter blob** dimensions vary according to the type and configuration of the layer.   \n",
    ">> * For a convolution layer with $96$ filters of $11 \\times 11$ spatial dimension and 3 inputs the blob is $96 \\times 3 \\times 11 \\times 11$.   \n",
    ">> * For an inner product / fully-connected layer with $1000$ output channels and $1024$ input channels the parameter blob is $1000 \\times 1024$.  \n",
    ">\n",
    ">\n",
    "> For **custom data**, it may be necessary to hack your own input preparation tool or data layer. However once your data is in your job is done. The modularity of layers accomplishes the rest of the work for you.\n",
    "----\n",
    "\n",
    "`caffe._caffe.Blob` 클래스는 다음과 같은 경우에 대하여 blob(Tensor)의 값 자체를 저장하는 메모리 구조에 대한 클래스이다.\n",
    "* `caffe.Net.params`: Network를 구성하는 learnable parameter를 가지는 레이어들의 이름(name)을 key로 하고, value는 해당 레이어의 list of multiple blobs인 Ordered Dictionary이다.\n",
    "* `caffe.Net.blobs`: 입력 데이타와 입력 데이타가 레이어들을 따라 **계산된 결과**를 저장하는 blob(tensor)들에 대한 딕셔너리로, 해당 레이어의 top 필드에 사용한 이름을 key로 사용하여 blob을  value로 한다.\n",
    "* `batch of images` \n",
    "\n",
    "`caffe._caffe.Blob` 클래스는 다음과 같은 필드로 구성되어 있다.   \n",
    "> `data`: blob의 데이타 메모리 포인터  \n",
    "> `diff` : gradient value  \n",
    "> `shape` : shape of `NCHW` format  \n",
    ">> * `shape[0]` : num  \n",
    ">> * `shape[1]` : channels  \n",
    ">> * `shape[2]` : height  \n",
    ">> * `shape[3]` : width  \n",
    "\n",
    "> `num` : size of batch, shape[0]  \n",
    "> `channels` : blob의 채널의 갯수  \n",
    "> `height` : height, shape[2]  \n",
    "> `width` : width, shape[3]  \n",
    "> `count` : 전체 elements의 갯수, $\\text{num} \\times \\text{channels} \\times \\text{height} \\times \\text{width}$, i.e, product of dimensions among arange of axes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41779160",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "\n",
    "### caffe.Net.blob_loss_weights\n",
    "\n",
    "An OrderedDict (bottom to top, i.e., input to output) of network\n",
    "blob loss weights indexed by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a8db8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(caffe.Net.blob_loss_weights)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b484b736",
   "metadata": {},
   "source": [
    "detection_nw.blob_loss_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e434a01",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## layer information check"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dc8a1769",
   "metadata": {},
   "source": [
    "k_list = list(detection_nw.params.keys())\n",
    "\n",
    "for idx, layer_name in enumerate(detection_nw.layer_dict):\n",
    "    print(f\"\\n-----------------------------\")\n",
    "    print(f\"layer index: {idx}\")\n",
    "    print(f\"layer name: '{layer_name}''\")\n",
    "    print(f\"layer type: '{detection_nw.layers[idx].type}' \")\n",
    "        \n",
    "    if layer_name in k_list:\n",
    "        params = detection_nw.params[layer_name]\n",
    "        print(f\"{len(params)} learnable parameters in ''{detection_nw.layers[idx].type}' type\")\n",
    "        \n",
    "        for i, p in enumerate(params):\n",
    "            #print(f\"\\tparams[{i}]: {p}\")\n",
    "            #print(f\"\\tparams[{i}] CxHxW: {p.channels}x{p.height}x{p.width}\")\n",
    "            print(f\"\\tp[{i}]: {p.data.shape} of {p.data.dtype}\")\n",
    "                       \n",
    "            \n",
    "            #for j, v in enumerate(p.shape):\n",
    "            #    print(f\"\\t\\tp[{j}]: {v}\")\n",
    "                \n",
    "            #print(f\"\\tparams[{i}]: {p.data}\")\n",
    "    else:\n",
    "        print(f\"no learnable parameters in '{layer_name}' of '{detection_nw.layers[idx].type}' type'\")\n",
    "                \n",
    "        \"\"\"\n",
    "        weight = detection_nw.params[layer_name][0]\n",
    "        bias = detection_nw.params[layer_name][1]\n",
    "        print(f\"\\weight of shape: {weight.shape}\")\n",
    "        print(f\"\\bias of shape: {bias.shape}\")\n",
    "        print(\"\")\n",
    "        \"\"\"\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "id": "7678d363",
   "metadata": {},
   "source": [
    "help(detection_nw.params)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a3815b3d",
   "metadata": {},
   "source": [
    "k_list = list(detection_nw.params.keys())\n",
    "for k in k_list:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3f5480",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# PyTorch Detection V2 model Load - run once or only if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a3b1f2",
   "metadata": {},
   "source": [
    "caffe._caffe.Layer 클래스에 다음과 같은 2개의 필드가 포함되어 있다.\n",
    "* `blobs`:\n",
    "* `type`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e6a536",
   "metadata": {},
   "source": [
    "## caffe.Net\n",
    "\n",
    "caffe.Net 클래스는 `.prototxt` 로 정의된 네트워크 구조를 로딩하여 만들어지는 네트워크를 나타내며, 네트워크의 상세 정보들을 다음과 같은 properties로 제공한다.\n",
    "> `blob_loss_weights`  \n",
    "> An OrderedDict (bottom to top, i.e., input to output) of network blob loss weights indexed by layer name  \n",
    "\n",
    "> `blobs`  \n",
    "> An OrderedDict (bottom to top, i.e., input to output) of network blobs indexed by layer name  \n",
    "\n",
    "> `bottom_names`  \n",
    "> all bottom names in the network  \n",
    "\n",
    "> `inputs`  \n",
    "> inputs to this network\n",
    "\n",
    ">`layer_dict`  \n",
    "> An OrderedDict (bottom to top, i.e., input to output) of network layers indexed by layer name\n",
    "\n",
    "> `layers`: `caffe._caffe.LayerVec` - list of caffe.Layer\n",
    "> list of Layer objects in the network, Layer classs has `blobs` field for layer's parameters memory and `type` for layer type (e.g, Convolution, Data, etc)\n",
    "\n",
    "> `outputs`  \n",
    "> outputs from this network\n",
    "\n",
    "> `params`  \n",
    "> An OrderedDict (bottom to top, i.e., input to output) of network parameters indexed by name; each is a list of multiple blobs (e.g., weights and biases)  \n",
    "\n",
    ">`top_names`   \n",
    "> all top names in the network   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a455c7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(caffe.Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123f6a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(caffe.Net.blobs)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "be466271",
   "metadata": {},
   "source": [
    "for layer in detection_nw.layers:\n",
    "    print(f\"layer.type: {layer.type}\")\n",
    "    #for blob in layer.blobs:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9764f1e",
   "metadata": {},
   "source": [
    "## caffe.Net.params vs caffe.Net.layers\n",
    "\n",
    "`caffe.Net.params`는 Network를 구성하는 learnable parameter를 가지는 레이어들의 이름(name)을 key로 하고, value는 해당 레이어의 list of multiple blobs인 Ordered Dictionary이다.\n",
    "\n",
    "`caffe.Net.layers`는 Network를 구성하는 모든 레이어들의 type 정보와 blob 정보를 저장하는 caffe.Layer 오브젝트들을 리스트 형태로 유지한다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a544ff23",
   "metadata": {},
   "source": [
    "help(caffe.Net.params)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f756a281",
   "metadata": {},
   "source": [
    "help(caffe.Net.layers)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b66f770",
   "metadata": {},
   "source": [
    "help(caffe.Layer)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6328a63d",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "k_list = list(detection_nw.params.keys())\n",
    "\n",
    "for idx, layer_name in enumerate(detection_nw.layer_dict):\n",
    "    print(f\"\\n-----------------------------\")\n",
    "    print(f\"layer index: {idx}\")\n",
    "    print(f\"layer name: '{layer_name}''\")\n",
    "    print(f\"layer type: '{detection_nw.layers[idx].type}' \")\n",
    "        \n",
    "    if layer_name in k_list:\n",
    "        params = detection_nw.params[layer_name]\n",
    "        print(f\"{len(params)} learnable parameters in '{detection_nw.layers[idx].type}' type\")\n",
    "        \n",
    "        for i, p in enumerate(params):\n",
    "            #print(f\"\\tparams[{i}]: {p}\")\n",
    "            #print(f\"\\tparams[{i}] CxHxW: {p.channels}x{p.height}x{p.width}\")\n",
    "            print(f\"\\tp[{i}]: {p.data.shape} of {p.data.dtype}\")\n",
    "            print(f\"\\tp: {p}\")            \n",
    "    else:\n",
    "        print(f\"no learnable parameters in '{layer_name}' of '{detection_nw.layers[idx].type}' type'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa61a43",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## PyToch Detection Model Loading\n",
    "\n",
    "Note: Run following section code only once or if needed for generating new .npy files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7631b4",
   "metadata": {},
   "source": [
    "### import for PyTorch Detection Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15e45be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:# ======================\n",
      "DEBUG:root:# Registered Modules\n",
      "DEBUG:root:# ======================\n",
      "DEBUG:root:\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/resnet.py\n",
      "DEBUG:root:\t// _TRANSFORMATION_MODULES: {'BottleneckWithFixedBatchNorm': <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>}\n",
      "\n",
      "DEBUG:root:\t// _STEM_MODULES : {'BottleneckWithFixedBatchNorm': <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>}\n",
      "\n",
      "DEBUG:root:\n",
      "# Networks Stage Specs:\n",
      "DEBUG:root:\t'R-50-C4':\n",
      "DEBUG:root:\t(\n",
      "DEBUG:root:\t\tStageSpec(index=1, block_count=3, return_features=False)\n",
      "DEBUG:root:\t\tStageSpec(index=2, block_count=4, return_features=False)\n",
      "DEBUG:root:\t\tStageSpec(index=3, block_count=6, return_features=True)\n",
      "DEBUG:root:\t)\n",
      "\n",
      "DEBUG:root:\t'R-50-C5':\n",
      "DEBUG:root:\t(\n",
      "DEBUG:root:\t\tStageSpec(index=1, block_count=3, return_features=False)\n",
      "DEBUG:root:\t\tStageSpec(index=2, block_count=4, return_features=False)\n",
      "DEBUG:root:\t\tStageSpec(index=3, block_count=6, return_features=False)\n",
      "DEBUG:root:\t\tStageSpec(index=4, block_count=3, return_features=True)\n",
      "DEBUG:root:\t)\n",
      "\n",
      "DEBUG:root:\t'R-101-C4':\n",
      "DEBUG:root:\t(\n",
      "DEBUG:root:\t\tStageSpec(index=1, block_count=3, return_features=False)\n",
      "DEBUG:root:\t\tStageSpec(index=2, block_count=4, return_features=False)\n",
      "DEBUG:root:\t\tStageSpec(index=3, block_count=23, return_features=True)\n",
      "DEBUG:root:\t)\n",
      "\n",
      "DEBUG:root:\t'R-101-C5':\n",
      "DEBUG:root:\t(\n",
      "DEBUG:root:\t\tStageSpec(index=1, block_count=3, return_features=False)\n",
      "DEBUG:root:\t\tStageSpec(index=2, block_count=4, return_features=False)\n",
      "DEBUG:root:\t\tStageSpec(index=3, block_count=23, return_features=False)\n",
      "DEBUG:root:\t\tStageSpec(index=4, block_count=3, return_features=True)\n",
      "DEBUG:root:\t)\n",
      "\n",
      "DEBUG:root:\t'R-50-FPN':\n",
      "DEBUG:root:\t(\n",
      "DEBUG:root:\t\tStageSpec(index=1, block_count=3, return_features=True)\n",
      "DEBUG:root:\t\tStageSpec(index=2, block_count=4, return_features=True)\n",
      "DEBUG:root:\t\tStageSpec(index=3, block_count=6, return_features=True)\n",
      "DEBUG:root:\t\tStageSpec(index=4, block_count=3, return_features=True)\n",
      "DEBUG:root:\t)\n",
      "\n",
      "DEBUG:root:\t'R-50-FPN-RETINANET':\n",
      "DEBUG:root:\t(\n",
      "DEBUG:root:\t\tStageSpec(index=1, block_count=3, return_features=True)\n",
      "DEBUG:root:\t\tStageSpec(index=2, block_count=4, return_features=True)\n",
      "DEBUG:root:\t\tStageSpec(index=3, block_count=6, return_features=True)\n",
      "DEBUG:root:\t\tStageSpec(index=4, block_count=3, return_features=True)\n",
      "DEBUG:root:\t)\n",
      "\n",
      "DEBUG:root:\t'R-101-FPN':\n",
      "DEBUG:root:\t(\n",
      "DEBUG:root:\t\tStageSpec(index=1, block_count=3, return_features=True)\n",
      "DEBUG:root:\t\tStageSpec(index=2, block_count=4, return_features=True)\n",
      "DEBUG:root:\t\tStageSpec(index=3, block_count=23, return_features=True)\n",
      "DEBUG:root:\t\tStageSpec(index=4, block_count=3, return_features=True)\n",
      "DEBUG:root:\t)\n",
      "\n",
      "DEBUG:root:\t'R-101-FPN-RETINANET':\n",
      "DEBUG:root:\t(\n",
      "DEBUG:root:\t\tStageSpec(index=1, block_count=3, return_features=True)\n",
      "DEBUG:root:\t\tStageSpec(index=2, block_count=4, return_features=True)\n",
      "DEBUG:root:\t\tStageSpec(index=3, block_count=23, return_features=True)\n",
      "DEBUG:root:\t\tStageSpec(index=4, block_count=3, return_features=True)\n",
      "DEBUG:root:\t)\n",
      "\n",
      "DEBUG:root:\t'R-152-FPN':\n",
      "DEBUG:root:\t(\n",
      "DEBUG:root:\t\tStageSpec(index=1, block_count=3, return_features=True)\n",
      "DEBUG:root:\t\tStageSpec(index=2, block_count=8, return_features=True)\n",
      "DEBUG:root:\t\tStageSpec(index=3, block_count=36, return_features=True)\n",
      "DEBUG:root:\t\tStageSpec(index=4, block_count=3, return_features=True)\n",
      "DEBUG:root:\t)\n",
      "\n",
      "DEBUG:root:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from maskrcnn_benchmark.config import cfg\n",
    "from maskrcnn_benchmark.data.transforms import build_transforms\n",
    "from maskrcnn_benchmark.modeling.detector import build_detection_model\n",
    "from maskrcnn_benchmark.utils.checkpoint import DetectronCheckpointer\n",
    "from maskrcnn_benchmark.structures.image_list import to_image_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07990c5a",
   "metadata": {},
   "source": [
    "### Function for PyTorch Model Loding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ebc9910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pytorch_model_load():\n",
    "\n",
    "    from maskrcnn_benchmark.config import cfg\n",
    "\n",
    "    # detection model conf and weight file names\n",
    "    detect_model = {\n",
    "        \"v1\":\n",
    "            {\n",
    "                \"config_file\": \"config_det_v1_200723_001_180k.yaml\",\n",
    "                \"weight_file\": \"model_det_v1_200723_001_180k.pth\"\n",
    "\n",
    "            },\n",
    "        \"v2\":\n",
    "            {\n",
    "                \"config_file\": \"config_det_v2_200924_002_180k.yaml\",\n",
    "                \"weight_file\": \"model_det_v2_200924_002_180k.pth\"\n",
    "            }\n",
    "    }\n",
    "\n",
    "    # model version\n",
    "    version = \"v2\"\n",
    "\n",
    "    # test image file path\n",
    "    image_file_path = \"../sample_images/detection/1594202471809.jpg\"\n",
    "\n",
    "    config_file = os.path.join('../model/detection', detect_model[version][\"config_file\"])\n",
    "    weight_file = os.path.join('../model/detection', detect_model[version][\"weight_file\"])\n",
    "\n",
    "    is_recognition = False\n",
    "    # clone project level config and merge with experiment config\n",
    "    cfg = cfg.clone()\n",
    "    cfg.merge_from_file(config_file)\n",
    "\n",
    "    cfg = cfg.clone()\n",
    "    device = torch.device(cfg.MODEL.DEVICE)\n",
    "\n",
    "    model = build_detection_model(cfg)\n",
    "    model.to(device)\n",
    "\n",
    "    # set to evaluation mode for interference\n",
    "    model.eval()\n",
    "\n",
    "    checkpointer = DetectronCheckpointer(cfg, model, save_dir='/dev/null')\n",
    "    _ = checkpointer.load(weight_file)\n",
    "\n",
    "    # build_transforms defined in maskrcnn_benchmark.data.transforms/*.py\n",
    "    transforms = build_transforms(cfg, is_recognition)\n",
    "    cpu_device = torch.device(\"cpu\")\n",
    "    score_thresh = cfg.TEST.SCORE_THRESHOLD\n",
    "    return model, transforms\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fe1dbf",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## PyTorch detection model v2 learnable parameter save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e480fa03",
   "metadata": {},
   "source": [
    "### Function for Saving Non learnable Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "834fbbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def save_pytorch_model_non_learnable_parameters(model):\n",
    "    \n",
    "    #----------------------------------\n",
    "    # Fixed parameters of FrozenBatchNorm2d\n",
    "    #----------------------------------\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"-\"*80)\n",
    "    print(\"saving non-learnalbe parameters of FrozenBatchNorm2d in detection v2 model\")\n",
    "    print(\"-\"*80)\n",
    "    itr = model.named_buffers()  # get iterator\n",
    "    \n",
    "    for buffer_name, buffer in itr:\n",
    "        file_name = f\"./npy_save/{buffer_name.replace('.', '_')}\"\n",
    "        t_list = buffer_name.split('.')\n",
    "    \n",
    "        if t_list[-1] == 'weight' or t_list[-1] == 'bias':\n",
    "            \n",
    "            # convert torch in cpu to numpy ndarray\n",
    "            if buffer.requires_grad:\n",
    "                arr = buffer.detach().cpu().numpy()               \n",
    "                \n",
    "            else:\n",
    "                arr = buffer.cpu().numpy()\n",
    "                \n",
    "            np.save(file_name, arr)\n",
    "            print(f\"{buffer_name} of {arr.shape}\\n\\t\\tsaved in {file_name}\")\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cc9662",
   "metadata": {},
   "source": [
    "### Function for Saving learnable Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42beb965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def save_pytorch_model_learnable_parameters(model):\n",
    "    \n",
    "    #----------------------------------\n",
    "    # learnable parameters of Conv2d\n",
    "    #----------------------------------\n",
    "    print(\"-\"*80)\n",
    "    print(\"saving learnalbe parameters of layers in detection v2 model\")\n",
    "    print(\"-\"*80)\n",
    "    itr = model.named_parameters()  # get iterator\n",
    "    \n",
    "    for param_name, param in itr:\n",
    "        file_name = f\"./npy_save/{param_name.replace('.', '_')}\"\n",
    "        \n",
    "        if param.requires_grad:\n",
    "            arr = param.detach().cpu().numpy()       \n",
    "        else:\n",
    "            arr = param.cpu().numpy()\n",
    "    \n",
    "        np.save(file_name, arr)\n",
    "        print(f\"{param_name} of {arr.shape}\\n\\t\\tsaved in {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66692b0b",
   "metadata": {},
   "source": [
    "### Function for Saving Learnabl and Non-Learnable Parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "764b212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pytorch_model_parameters(model):\n",
    "    \n",
    "    # save Conv2d parameters\n",
    "    save_pytorch_model_learnable_parameters(model)\n",
    "    \n",
    "    # save FrozenBatchNora2d parameters\n",
    "    save_pytorch_model_non_learnable_parameters(model)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcf1ce7",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Loading PyTorch Detection Model and Saving Parameters into npy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a84d63cf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:GeneralizedRCNN.__init__(self, cfg) { //BEGIN\n",
      "DEBUG:root:\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/detector/generalized_rcnn.py\n",
      "\n",
      "DEBUG:root:\t\t// Params:\n",
      "DEBUG:root:\t\t\t// cfg:\n",
      "\n",
      "DEBUG:root:\tsuper(GeneralizedRCNN, self).__init__()\n",
      "\n",
      "DEBUG:root:\t# ===========================================\n",
      "DEBUG:root:\t# 1.1 Backbone(Resnet50 + FPN) build\n",
      "DEBUG:root:\t# ===========================================\n",
      "DEBUG:root:\t{ // BEGIN of 1.1\n",
      "\n",
      "DEBUG:root:\tself.backbone = build_backbone(cfg) // CALL\n",
      "DEBUG:root:\t{\n",
      "\n",
      "DEBUG:root:\n",
      "\tbuild_backbone(cfg) { // BEGIN\n",
      "DEBUG:root:\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/backbone.py\n",
      "\n",
      "DEBUG:root:\t\t// Params:\n",
      "DEBUG:root:\t\t\t// cfg:\n",
      "\n",
      "DEBUG:root:\t\t// cfg.MODEL.BACKBONE.CONV_BODY: R-50-FPN-RETINANET\n",
      "DEBUG:root:\t\t// registry.BACKBONES[cfg.MODEL.BACKBONE.CONV_BODY]:\n",
      "DEBUG:root:\t\t// <function build_resnet_fpn_p3p7_backbone at 0x7fb977493510>\n",
      "\n",
      "DEBUG:root:\t\treturn registry.BACKBONES[cfg.MODEL.BACKBONE.CONV_BODY](cfg)\n",
      "DEBUG:root:\n",
      "\tbuild_resnet_fpn_p3p7_backbone(cfg) { // BEGIN\n",
      "DEBUG:root:\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/backbone.py\n",
      "\n",
      "DEBUG:root:\t\t// Params:\n",
      "DEBUG:root:\t\t\t// cfg:\n",
      "\n",
      "DEBUG:root:\t\t# ================================\n",
      "DEBUG:root:\t\t# 1-1-1 ResNet50 build\n",
      "DEBUG:root:\t\t# ================================\n",
      "DEBUG:root:\t\tbody = resnet.ResNet(cfg) // CALL\n",
      "DEBUG:root:\t\t{\n",
      "DEBUG:root:\n",
      "\tResnet.__init__(self, cfg) { //BEGIN\n",
      "DEBUG:root:\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/resnet.py\n",
      "\n",
      "DEBUG:root:\t\t// Params:\n",
      "DEBUG:root:\t\t\t// cfg:\n",
      "\n",
      "DEBUG:root:\t\tsuper(ResNet, self).__init__()\n",
      "\n",
      "DEBUG:root:\t\t// _STEM_MODULES: {'StemWithFixedBatchNorm': <class 'maskrcnn_benchmark.modeling.backbone.resnet.StemWithFixedBatchNorm'>}\n",
      "\n",
      "DEBUG:root:\t\t// _cfg.MODEL.RESNETS.STEM_FUNC: StemWithFixedBatchNorm\n",
      "DEBUG:root:\t\tstem_module = _STEM_MODULES[cfg.MODEL.RESNETS.STEM_FUNC]\n",
      "DEBUG:root:\t\t// stem_module: <class 'maskrcnn_benchmark.modeling.backbone.resnet.StemWithFixedBatchNorm'>\n",
      "\n",
      "DEBUG:root:\t\t// cfg.MODEL.BACKBONE.CONV_BODY: R-50-FPN-RETINANET\n",
      "DEBUG:root:\t\tstage_specs = _STAGE_SPECS[cfg.MODEL.BACKBONE.CONV_BODY=R-50-FPN-RETINANET]\n",
      "DEBUG:root:\t\t// stage_specs: (StageSpec(index=1, block_count=3, return_features=True), StageSpec(index=2, block_count=4, return_features=True), StageSpec(index=3, block_count=6, return_features=True), StageSpec(index=4, block_count=3, return_features=True))\n",
      "\n",
      "DEBUG:root:\t\t// _TRANSFORMATION_MODULES: {'BottleneckWithFixedBatchNorm': <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>}\n",
      "DEBUG:root:\t\t// cfg.MODEL.RESNETS.TRANS_FUNC: BottleneckWithFixedBatchNorm\n",
      "DEBUG:root:\t\ttransformation_module = _TRANSFORMATION_MODULES[cfg.MODEL.RESNETS.TRANS_FUNC=BottleneckWithFixedBatchNorm]\n",
      "DEBUG:root:\t\t// transformation_module: <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>\n",
      "DEBUG:root:\t\tself.stem = stem_module(cfg) // CALL\n",
      "DEBUG:root:\t\t{\n",
      "DEBUG:root:\n",
      "\tStemWithFixedBatchNorm.__init__() { //BEGIN\n",
      "DEBUG:root:\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/resnet.py\n",
      "\n",
      "DEBUG:root:\n",
      "\tBaseStem.__init__() { //BEGIN\n",
      "DEBUG:root:\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/resnet.py\n",
      "\n",
      "DEBUG:root:\n",
      "\t} // END BaseStem.__init__()\n",
      "DEBUG:root:\n",
      "\t} // END StemWithFixedBatchNorm.__init__()\n",
      "DEBUG:root:\n",
      "\t\t}\n",
      "DEBUG:root:\t\tself.stem = stem_module(cfg) // RETURNED\n",
      "DEBUG:root:\t\t// self.stem: StemWithFixedBatchNorm(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): FrozenBatchNorm2d()\n",
      ")\n",
      "DEBUG:root:\t\tnum_groups = cfg.MODEL.RESNETS.NUM_GROUPS\n",
      "DEBUG:root:\t\t// num_groups.stem: 1\n",
      "DEBUG:root:\t\twidth_per_group = cfg.MODEL.RESNETS.WIDTH_PER_GROUP\n",
      "DEBUG:root:\t\t// width_per_group: 64\n",
      "DEBUG:root:\t\tin_channels = cfg.MODEL.RESNETS.STEM_OUT_CHANNELS\n",
      "DEBUG:root:\t\t// in_channels: 64\n",
      "DEBUG:root:\t\tstage2_bottleneck_channels = num_groups * width_per_group\n",
      "DEBUG:root:\t\t// stage2_bottleneck_channels: 64\n",
      "DEBUG:root:\t\tstage2_out_channels = cfg.MODEL.RESNETS.RES2_OUT_CHANNELS\n",
      "DEBUG:root:\t\tstage2_out_channels: 256\n",
      "DEBUG:root:\t\tself.stages = []\n",
      "DEBUG:root:\t\tself.return_features = {}\n",
      "DEBUG:root:\t\tfor stage_spec in stage_specs {\n",
      "\n",
      "DEBUG:root:\n",
      "\t\t\t{\n",
      "DEBUG:root:\t\t\t# ---------------------------------------------------------------\n",
      "DEBUG:root:\t\t\t# iteration 1/4\n",
      "DEBUG:root:\t\t\t#  1-th stage_spec: StageSpec(index=1, block_count=3, return_features=True)\n",
      "DEBUG:root:\t\t\t# ---------------------------------------------------------------\n",
      "DEBUG:root:\t\t\tname = \"layer\" + str(stage_spec.index)\n",
      "DEBUG:root:\t\t\t// name: layer1\n",
      "\n",
      "DEBUG:root:\t\t\tstage2_relative_factor = 2 ** (stage_spec.index - 1)\n",
      "DEBUG:root:\t\t\t// stage2_relative_factor: 1\n",
      "\n",
      "DEBUG:root:\t\t\tbottleneck_channels = stage2_bottleneck_channels * stage2_relative_factor\n",
      "DEBUG:root:\t\t\t// bottlenec_channels: 64\n",
      "\n",
      "DEBUG:root:\t\t\tout_channels = stage2_out_channels * stage2_relative_factor\n",
      "DEBUG:root:\t\t\t// out_channels: 256\n",
      "\n",
      "DEBUG:root:\t\t\tstage_with_dcn = cfg.MODEL.RESNETS.STAGE_WITH_DCN[stage_spec.index - 1]\n",
      "DEBUG:root:\t\t\t// stage_with_dcn: False\n",
      "\n",
      "DEBUG:root:\t\t\tmodule = _make_stage(\n",
      "DEBUG:root:\t\t\t\ttransformation_module = <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>,\n",
      "DEBUG:root:\t\t\t\tin_channels = 64,\n",
      "DEBUG:root:\t\t\t\tbottleneck_channels = 64,\n",
      "DEBUG:root:\t\t\t\tout_channels = 256,\n",
      "DEBUG:root:\t\t\t\tstage_spec.block_count = 3,\n",
      "DEBUG:root:\t\t\t\tnum_groups = 1,\n",
      "DEBUG:root:\t\t\t\tcfg.MODEL.RESNETS.STRIDE_IN_1X1 : True,\n",
      "DEBUG:root:\t\t\t\tfirst_stride=int(stage_spec.index > 1) + 1: 1,\n",
      "DEBUG:root:\t\t\t\tdcn_config={\n",
      "DEBUG:root:\t\t\t\t\t'stage_with_dcn': False,\n",
      "DEBUG:root:\t\t\t\t\t'with_modulated_dcn': False,\n",
      "DEBUG:root:\t\t\t\t\t'deformable_groups': 1,\n",
      "DEBUG:root:\t\t\t\t\t}\n",
      "DEBUG:root:\t\t\t\t) // CALL\n",
      "DEBUG:root:\t\t\t\t{\n",
      "DEBUG:root:\n",
      "\t_make_stage() { //BEGIN\n",
      "DEBUG:root:\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/resnet.py\n",
      "\n",
      "DEBUG:root:\t\t// Params:\n",
      "DEBUG:root:\t\t\t// transformation_module: <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>\n",
      "DEBUG:root:\t\t\t// in_channels: 64\n",
      "DEBUG:root:\t\t\t// bottleneck_channels: 64\n",
      "DEBUG:root:\t\t\t// out_channels: 256\n",
      "DEBUG:root:\t\t\t// block_count: 3\n",
      "DEBUG:root:\t\t\t// num_groups: 3\n",
      "DEBUG:root:\t\t\t// stride_in_1x1: True\n",
      "DEBUG:root:\t\t\t// first_stride: 1\n",
      "DEBUG:root:\t\t\t// dilation: 1\n",
      "DEBUG:root:\t\t\t// dcn_config: {'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}\n",
      "\n",
      "DEBUG:root:\t\tblocks = []\n",
      "\n",
      "DEBUG:root:\t\tstride = first_stride\n",
      "\n",
      "DEBUG:root:\t\tfor _ in range(block_count):  {\n",
      "DEBUG:root:\t\t\t{\n",
      "DEBUG:root:\t\t\t# --------------\n",
      "DEBUG:root:\t\t\t# blocks.append iteration 1/3\n",
      "DEBUG:root:\t\t\t# --------------\n",
      "DEBUG:root:\t\t\tblocks.append(\n",
      "DEBUG:root:\t\t\t    transformation_module(\n",
      "DEBUG:root:\t\t\t        in_channels=64,\n",
      "DEBUG:root:\t\t\t        bottleneck_channels=64,\n",
      "DEBUG:root:\t\t\t        out_channels=256,\n",
      "DEBUG:root:\t\t\t        num_groups=1,\n",
      "DEBUG:root:\t\t\t        stride_in_1x1=True,\n",
      "DEBUG:root:\t\t\t        stride=1,\n",
      "DEBUG:root:\t\t\t        dilation=1,\n",
      "DEBUG:root:\t\t\t        dcn_config={'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}\n",
      "DEBUG:root:\t\t\t   )\n",
      "DEBUG:root:\t\t\t)\n",
      "\n",
      "DEBUG:root:\t\t\tblocks[-1]:BottleneckWithFixedBatchNorm(\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): FrozenBatchNorm2d()\n",
      "  )\n",
      "  (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): FrozenBatchNorm2d()\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): FrozenBatchNorm2d()\n",
      "  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): FrozenBatchNorm2d()\n",
      ")\n",
      "DEBUG:root:\t\t\tstride = 1\n",
      "DEBUG:root:\t\t\tin_channels = out_channels\n",
      "DEBUG:root:\n",
      "\t\t\t}\n",
      "DEBUG:root:\t\t\t{\n",
      "DEBUG:root:\t\t\t# --------------\n",
      "DEBUG:root:\t\t\t# blocks.append iteration 2/3\n",
      "DEBUG:root:\t\t\t# --------------\n",
      "DEBUG:root:\t\t\tblocks.append(\n",
      "DEBUG:root:\t\t\t    transformation_module(\n",
      "DEBUG:root:\t\t\t        in_channels=256,\n",
      "DEBUG:root:\t\t\t        bottleneck_channels=64,\n",
      "DEBUG:root:\t\t\t        out_channels=256,\n",
      "DEBUG:root:\t\t\t        num_groups=1,\n",
      "DEBUG:root:\t\t\t        stride_in_1x1=True,\n",
      "DEBUG:root:\t\t\t        stride=1,\n",
      "DEBUG:root:\t\t\t        dilation=1,\n",
      "DEBUG:root:\t\t\t        dcn_config={'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}\n",
      "DEBUG:root:\t\t\t   )\n",
      "DEBUG:root:\t\t\t)\n",
      "\n",
      "DEBUG:root:\t\t\tblocks[-1]:BottleneckWithFixedBatchNorm(\n",
      "  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): FrozenBatchNorm2d()\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): FrozenBatchNorm2d()\n",
      "  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): FrozenBatchNorm2d()\n",
      ")\n",
      "DEBUG:root:\t\t\tstride = 1\n",
      "DEBUG:root:\t\t\tin_channels = out_channels\n",
      "DEBUG:root:\n",
      "\t\t\t}\n",
      "DEBUG:root:\t\t\t{\n",
      "DEBUG:root:\t\t\t# --------------\n",
      "DEBUG:root:\t\t\t# blocks.append iteration 3/3\n",
      "DEBUG:root:\t\t\t# --------------\n",
      "DEBUG:root:\t\t\tblocks.append(\n",
      "DEBUG:root:\t\t\t    transformation_module(\n",
      "DEBUG:root:\t\t\t        in_channels=256,\n",
      "DEBUG:root:\t\t\t        bottleneck_channels=64,\n",
      "DEBUG:root:\t\t\t        out_channels=256,\n",
      "DEBUG:root:\t\t\t        num_groups=1,\n",
      "DEBUG:root:\t\t\t        stride_in_1x1=True,\n",
      "DEBUG:root:\t\t\t        stride=1,\n",
      "DEBUG:root:\t\t\t        dilation=1,\n",
      "DEBUG:root:\t\t\t        dcn_config={'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}\n",
      "DEBUG:root:\t\t\t   )\n",
      "DEBUG:root:\t\t\t)\n",
      "\n",
      "DEBUG:root:\t\t\tblocks[-1]:BottleneckWithFixedBatchNorm(\n",
      "  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): FrozenBatchNorm2d()\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): FrozenBatchNorm2d()\n",
      "  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): FrozenBatchNorm2d()\n",
      ")\n",
      "DEBUG:root:\t\t\tstride = 1\n",
      "DEBUG:root:\t\t\tin_channels = out_channels\n",
      "DEBUG:root:\n",
      "\t\t\t}\n",
      "DEBUG:root:\t\t}// END for _ in range(block_count):\n",
      "\n",
      "DEBUG:root:\t\treturn nn.Sequential(*blocks)\n",
      "\n",
      "DEBUG:root:\n",
      "\t} // END _make_stage()\n",
      "DEBUG:root:\t\t\t\t}\n",
      "DEBUG:root:\t\t\tmodule = _make_stage(\n",
      "DEBUG:root:\t\t\t\ttransformation_module = <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>,\n",
      "DEBUG:root:\t\t\t\tin_channels = 64,\n",
      "DEBUG:root:\t\t\t\tbottleneck_channels = 64,\n",
      "DEBUG:root:\t\t\t\tout_channels = 256,\n",
      "DEBUG:root:\t\t\t\tstage_spec.block_count = 3,\n",
      "DEBUG:root:\t\t\t\tnum_groups = 1,\n",
      "DEBUG:root:\t\t\t\tcfg.MODEL.RESNETS.STRIDE_IN_1X1 : True,\n",
      "DEBUG:root:\t\t\t\tfirst_stride=int(stage_spec.index > 1) + 1: 1,\n",
      "DEBUG:root:\t\t\t\tdcn_config={\n",
      "DEBUG:root:\t\t\t\t\t'stage_with_dcn': False,\n",
      "DEBUG:root:\t\t\t\t\t'with_modulated_dcn': False,\n",
      "DEBUG:root:\t\t\t\t\t'deformable_groups': 1,\n",
      "DEBUG:root:\t\t\t\t\t}\n",
      "DEBUG:root:\t\t\t\t) // RETURNED\n",
      "\n",
      "DEBUG:root:\t\t\tin_channels = out_channels\n",
      "DEBUG:root:\t\t\t// in_channels: 256\n",
      "\n",
      "DEBUG:root:\t\t\tself.add_module(name=layer1, module)\n",
      "\n",
      "DEBUG:root:\t\t\tself.stages.append(name=layer1)\n",
      "\n",
      "DEBUG:root:\t\t\t// name: layer1\n",
      "DEBUG:root:\t\t\t// stage_spec.return_features: True\n",
      "DEBUG:root:\t\t\tself.return_features[name] = stage_spec.return_features\n",
      "\n",
      "DEBUG:root:\t\t\t}  // END of iteration 1/4\n",
      "\n",
      "DEBUG:root:\n",
      "\t\t\t{\n",
      "DEBUG:root:\t\t\t# ---------------------------------------------------------------\n",
      "DEBUG:root:\t\t\t# iteration 2/4\n",
      "DEBUG:root:\t\t\t#  2-th stage_spec: StageSpec(index=2, block_count=4, return_features=True)\n",
      "DEBUG:root:\t\t\t# ---------------------------------------------------------------\n",
      "DEBUG:root:\t\t\tname = \"layer\" + str(stage_spec.index)\n",
      "DEBUG:root:\t\t\t// name: layer2\n",
      "\n",
      "DEBUG:root:\t\t\tstage2_relative_factor = 2 ** (stage_spec.index - 1)\n",
      "DEBUG:root:\t\t\t// stage2_relative_factor: 2\n",
      "\n",
      "DEBUG:root:\t\t\tbottleneck_channels = stage2_bottleneck_channels * stage2_relative_factor\n",
      "DEBUG:root:\t\t\t// bottlenec_channels: 128\n",
      "\n",
      "DEBUG:root:\t\t\tout_channels = stage2_out_channels * stage2_relative_factor\n",
      "DEBUG:root:\t\t\t// out_channels: 512\n",
      "\n",
      "DEBUG:root:\t\t\tstage_with_dcn = cfg.MODEL.RESNETS.STAGE_WITH_DCN[stage_spec.index - 1]\n",
      "DEBUG:root:\t\t\t// stage_with_dcn: False\n",
      "\n",
      "DEBUG:root:\t\t\tmodule = _make_stage(\n",
      "DEBUG:root:\t\t\t\ttransformation_module = <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>,\n",
      "DEBUG:root:\t\t\t\tin_channels = 256,\n",
      "DEBUG:root:\t\t\t\tbottleneck_channels = 128,\n",
      "DEBUG:root:\t\t\t\tout_channels = 512,\n",
      "DEBUG:root:\t\t\t\tstage_spec.block_count = 4,\n",
      "DEBUG:root:\t\t\t\tnum_groups = 1,\n",
      "DEBUG:root:\t\t\t\tcfg.MODEL.RESNETS.STRIDE_IN_1X1 : True,\n",
      "DEBUG:root:\t\t\t\tfirst_stride=int(stage_spec.index > 1) + 1: 2,\n",
      "DEBUG:root:\t\t\t\tdcn_config={\n",
      "DEBUG:root:\t\t\t\t\t'stage_with_dcn': False,\n",
      "DEBUG:root:\t\t\t\t\t'with_modulated_dcn': False,\n",
      "DEBUG:root:\t\t\t\t\t'deformable_groups': 1,\n",
      "DEBUG:root:\t\t\t\t\t}\n",
      "DEBUG:root:\t\t\t\t) // CALL\n",
      "DEBUG:root:\t\t\t\t{\n",
      "DEBUG:root:\n",
      "\t_make_stage() { //BEGIN\n",
      "DEBUG:root:\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/resnet.py\n",
      "\n",
      "DEBUG:root:\t\t// Params:\n",
      "DEBUG:root:\t\t\t// transformation_module: <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>\n",
      "DEBUG:root:\t\t\t// in_channels: 256\n",
      "DEBUG:root:\t\t\t// bottleneck_channels: 128\n",
      "DEBUG:root:\t\t\t// out_channels: 512\n",
      "DEBUG:root:\t\t\t// block_count: 4\n",
      "DEBUG:root:\t\t\t// num_groups: 4\n",
      "DEBUG:root:\t\t\t// stride_in_1x1: True\n",
      "DEBUG:root:\t\t\t// first_stride: 2\n",
      "DEBUG:root:\t\t\t// dilation: 1\n",
      "DEBUG:root:\t\t\t// dcn_config: {'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}\n",
      "\n",
      "DEBUG:root:\t\tblocks = []\n",
      "\n",
      "DEBUG:root:\t\tstride = first_stride\n",
      "\n",
      "DEBUG:root:\t\tfor _ in range(block_count):  {\n",
      "DEBUG:root:\t\t\t{\n",
      "DEBUG:root:\t\t\t# --------------\n",
      "DEBUG:root:\t\t\t# blocks.append iteration 1/4\n",
      "DEBUG:root:\t\t\t# --------------\n",
      "DEBUG:root:\t\t\tblocks.append(\n",
      "DEBUG:root:\t\t\t    transformation_module(\n",
      "DEBUG:root:\t\t\t        in_channels=256,\n",
      "DEBUG:root:\t\t\t        bottleneck_channels=128,\n",
      "DEBUG:root:\t\t\t        out_channels=512,\n",
      "DEBUG:root:\t\t\t        num_groups=1,\n",
      "DEBUG:root:\t\t\t        stride_in_1x1=True,\n",
      "DEBUG:root:\t\t\t        stride=2,\n",
      "DEBUG:root:\t\t\t        dilation=1,\n",
      "DEBUG:root:\t\t\t        dcn_config={'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}\n",
      "DEBUG:root:\t\t\t   )\n",
      "DEBUG:root:\t\t\t)\n",
      "\n",
      "DEBUG:root:\t\t\tblocks[-1]:BottleneckWithFixedBatchNorm(\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): FrozenBatchNorm2d()\n",
      "  )\n",
      "  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (bn1): FrozenBatchNorm2d()\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): FrozenBatchNorm2d()\n",
      "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): FrozenBatchNorm2d()\n",
      ")\n",
      "DEBUG:root:\t\t\tstride = 1\n",
      "DEBUG:root:\t\t\tin_channels = out_channels\n",
      "DEBUG:root:\n",
      "\t\t\t}\n",
      "DEBUG:root:\t\t\t{\n",
      "DEBUG:root:\t\t\t# --------------\n",
      "DEBUG:root:\t\t\t# blocks.append iteration 2/4\n",
      "DEBUG:root:\t\t\t# --------------\n",
      "DEBUG:root:\t\t\tblocks.append(\n",
      "DEBUG:root:\t\t\t    transformation_module(\n",
      "DEBUG:root:\t\t\t        in_channels=512,\n",
      "DEBUG:root:\t\t\t        bottleneck_channels=128,\n",
      "DEBUG:root:\t\t\t        out_channels=512,\n",
      "DEBUG:root:\t\t\t        num_groups=1,\n",
      "DEBUG:root:\t\t\t        stride_in_1x1=True,\n",
      "DEBUG:root:\t\t\t        stride=1,\n",
      "DEBUG:root:\t\t\t        dilation=1,\n",
      "DEBUG:root:\t\t\t        dcn_config={'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}\n",
      "DEBUG:root:\t\t\t   )\n",
      "DEBUG:root:\t\t\t)\n",
      "\n",
      "DEBUG:root:\t\t\tblocks[-1]:BottleneckWithFixedBatchNorm(\n",
      "  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): FrozenBatchNorm2d()\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): FrozenBatchNorm2d()\n",
      "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): FrozenBatchNorm2d()\n",
      ")\n",
      "DEBUG:root:\t\t\tstride = 1\n",
      "DEBUG:root:\t\t\tin_channels = out_channels\n",
      "DEBUG:root:\n",
      "\t\t\t}\n",
      "DEBUG:root:\t\t\t{\n",
      "DEBUG:root:\t\t\t# --------------\n",
      "DEBUG:root:\t\t\t# blocks.append iteration 3/4\n",
      "DEBUG:root:\t\t\t# --------------\n",
      "DEBUG:root:\t\t\tblocks.append(\n",
      "DEBUG:root:\t\t\t    transformation_module(\n",
      "DEBUG:root:\t\t\t        in_channels=512,\n",
      "DEBUG:root:\t\t\t        bottleneck_channels=128,\n",
      "DEBUG:root:\t\t\t        out_channels=512,\n",
      "DEBUG:root:\t\t\t        num_groups=1,\n",
      "DEBUG:root:\t\t\t        stride_in_1x1=True,\n",
      "DEBUG:root:\t\t\t        stride=1,\n",
      "DEBUG:root:\t\t\t        dilation=1,\n",
      "DEBUG:root:\t\t\t        dcn_config={'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}\n",
      "DEBUG:root:\t\t\t   )\n",
      "DEBUG:root:\t\t\t)\n",
      "\n",
      "DEBUG:root:\t\t\tblocks[-1]:BottleneckWithFixedBatchNorm(\n",
      "  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): FrozenBatchNorm2d()\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): FrozenBatchNorm2d()\n",
      "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): FrozenBatchNorm2d()\n",
      ")\n",
      "DEBUG:root:\t\t\tstride = 1\n",
      "DEBUG:root:\t\t\tin_channels = out_channels\n",
      "DEBUG:root:\n",
      "\t\t\t}\n",
      "DEBUG:root:\t\t\t{\n",
      "DEBUG:root:\t\t\t# --------------\n",
      "DEBUG:root:\t\t\t# blocks.append iteration 4/4\n",
      "DEBUG:root:\t\t\t# --------------\n",
      "DEBUG:root:\t\t\tblocks.append(\n",
      "DEBUG:root:\t\t\t    transformation_module(\n",
      "DEBUG:root:\t\t\t        in_channels=512,\n",
      "DEBUG:root:\t\t\t        bottleneck_channels=128,\n",
      "DEBUG:root:\t\t\t        out_channels=512,\n",
      "DEBUG:root:\t\t\t        num_groups=1,\n",
      "DEBUG:root:\t\t\t        stride_in_1x1=True,\n",
      "DEBUG:root:\t\t\t        stride=1,\n",
      "DEBUG:root:\t\t\t        dilation=1,\n",
      "DEBUG:root:\t\t\t        dcn_config={'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}\n",
      "DEBUG:root:\t\t\t   )\n",
      "DEBUG:root:\t\t\t)\n",
      "\n",
      "DEBUG:root:\t\t\tblocks[-1]:BottleneckWithFixedBatchNorm(\n",
      "  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): FrozenBatchNorm2d()\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): FrozenBatchNorm2d()\n",
      "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): FrozenBatchNorm2d()\n",
      ")\n",
      "DEBUG:root:\t\t\tstride = 1\n",
      "DEBUG:root:\t\t\tin_channels = out_channels\n",
      "DEBUG:root:\n",
      "\t\t\t}\n",
      "DEBUG:root:\t\t}// END for _ in range(block_count):\n",
      "\n",
      "DEBUG:root:\t\treturn nn.Sequential(*blocks)\n",
      "\n",
      "DEBUG:root:\n",
      "\t} // END _make_stage()\n",
      "DEBUG:root:\t\t\t\t}\n",
      "DEBUG:root:\t\t\tmodule = _make_stage(\n",
      "DEBUG:root:\t\t\t\ttransformation_module = <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>,\n",
      "DEBUG:root:\t\t\t\tin_channels = 256,\n",
      "DEBUG:root:\t\t\t\tbottleneck_channels = 128,\n",
      "DEBUG:root:\t\t\t\tout_channels = 512,\n",
      "DEBUG:root:\t\t\t\tstage_spec.block_count = 4,\n",
      "DEBUG:root:\t\t\t\tnum_groups = 1,\n",
      "DEBUG:root:\t\t\t\tcfg.MODEL.RESNETS.STRIDE_IN_1X1 : True,\n",
      "DEBUG:root:\t\t\t\tfirst_stride=int(stage_spec.index > 1) + 1: 2,\n",
      "DEBUG:root:\t\t\t\tdcn_config={\n",
      "DEBUG:root:\t\t\t\t\t'stage_with_dcn': False,\n",
      "DEBUG:root:\t\t\t\t\t'with_modulated_dcn': False,\n",
      "DEBUG:root:\t\t\t\t\t'deformable_groups': 1,\n",
      "DEBUG:root:\t\t\t\t\t}\n",
      "DEBUG:root:\t\t\t\t) // RETURNED\n",
      "\n",
      "DEBUG:root:\t\t\tin_channels = out_channels\n",
      "DEBUG:root:\t\t\t// in_channels: 512\n",
      "\n",
      "DEBUG:root:\t\t\tself.add_module(name=layer2, module)\n",
      "\n",
      "DEBUG:root:\t\t\tself.stages.append(name=layer2)\n",
      "\n",
      "DEBUG:root:\t\t\t// name: layer2\n",
      "DEBUG:root:\t\t\t// stage_spec.return_features: True\n",
      "DEBUG:root:\t\t\tself.return_features[name] = stage_spec.return_features\n",
      "\n",
      "DEBUG:root:\t\t\t}  // END of iteration 2/4\n",
      "\n",
      "DEBUG:root:\n",
      "\t\t\t{\n",
      "DEBUG:root:\t\t\t# ---------------------------------------------------------------\n",
      "DEBUG:root:\t\t\t# iteration 3/4\n",
      "DEBUG:root:\t\t\t#  3-th stage_spec: StageSpec(index=3, block_count=6, return_features=True)\n",
      "DEBUG:root:\t\t\t# ---------------------------------------------------------------\n",
      "DEBUG:root:\t\t\tname = \"layer\" + str(stage_spec.index)\n",
      "DEBUG:root:\t\t\t// name: layer3\n",
      "\n",
      "DEBUG:root:\t\t\tstage2_relative_factor = 2 ** (stage_spec.index - 1)\n",
      "DEBUG:root:\t\t\t// stage2_relative_factor: 4\n",
      "\n",
      "DEBUG:root:\t\t\tbottleneck_channels = stage2_bottleneck_channels * stage2_relative_factor\n",
      "DEBUG:root:\t\t\t// bottlenec_channels: 256\n",
      "\n",
      "DEBUG:root:\t\t\tout_channels = stage2_out_channels * stage2_relative_factor\n",
      "DEBUG:root:\t\t\t// out_channels: 1024\n",
      "\n",
      "DEBUG:root:\t\t\tstage_with_dcn = cfg.MODEL.RESNETS.STAGE_WITH_DCN[stage_spec.index - 1]\n",
      "DEBUG:root:\t\t\t// stage_with_dcn: False\n",
      "\n",
      "DEBUG:root:\t\t\tmodule = _make_stage(\n",
      "DEBUG:root:\t\t\t\ttransformation_module = <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>,\n",
      "DEBUG:root:\t\t\t\tin_channels = 512,\n",
      "DEBUG:root:\t\t\t\tbottleneck_channels = 256,\n",
      "DEBUG:root:\t\t\t\tout_channels = 1024,\n",
      "DEBUG:root:\t\t\t\tstage_spec.block_count = 6,\n",
      "DEBUG:root:\t\t\t\tnum_groups = 1,\n",
      "DEBUG:root:\t\t\t\tcfg.MODEL.RESNETS.STRIDE_IN_1X1 : True,\n",
      "DEBUG:root:\t\t\t\tfirst_stride=int(stage_spec.index > 1) + 1: 2,\n",
      "DEBUG:root:\t\t\t\tdcn_config={\n",
      "DEBUG:root:\t\t\t\t\t'stage_with_dcn': False,\n",
      "DEBUG:root:\t\t\t\t\t'with_modulated_dcn': False,\n",
      "DEBUG:root:\t\t\t\t\t'deformable_groups': 1,\n",
      "DEBUG:root:\t\t\t\t\t}\n",
      "DEBUG:root:\t\t\t\t) // CALL\n",
      "DEBUG:root:\t\t\t\t{\n",
      "DEBUG:root:\n",
      "\t_make_stage() { //BEGIN\n",
      "DEBUG:root:\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/resnet.py\n",
      "\n",
      "DEBUG:root:\t\t// Params:\n",
      "DEBUG:root:\t\t\t// transformation_module: <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>\n",
      "DEBUG:root:\t\t\t// in_channels: 512\n",
      "DEBUG:root:\t\t\t// bottleneck_channels: 256\n",
      "DEBUG:root:\t\t\t// out_channels: 1024\n",
      "DEBUG:root:\t\t\t// block_count: 6\n",
      "DEBUG:root:\t\t\t// num_groups: 6\n",
      "DEBUG:root:\t\t\t// stride_in_1x1: True\n",
      "DEBUG:root:\t\t\t// first_stride: 2\n",
      "DEBUG:root:\t\t\t// dilation: 1\n",
      "DEBUG:root:\t\t\t// dcn_config: {'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}\n",
      "\n",
      "DEBUG:root:\t\tblocks = []\n",
      "\n",
      "DEBUG:root:\t\tstride = first_stride\n",
      "\n",
      "DEBUG:root:\t\tfor _ in range(block_count):  {\n",
      "DEBUG:root:\t\t\t{\n",
      "DEBUG:root:\t\t\t# --------------\n",
      "DEBUG:root:\t\t\t# blocks.append iteration 1/6\n",
      "DEBUG:root:\t\t\t# --------------\n",
      "DEBUG:root:\t\t\tblocks.append(\n",
      "DEBUG:root:\t\t\t    transformation_module(\n",
      "DEBUG:root:\t\t\t        in_channels=512,\n",
      "DEBUG:root:\t\t\t        bottleneck_channels=256,\n",
      "DEBUG:root:\t\t\t        out_channels=1024,\n",
      "DEBUG:root:\t\t\t        num_groups=1,\n",
      "DEBUG:root:\t\t\t        stride_in_1x1=True,\n",
      "DEBUG:root:\t\t\t        stride=2,\n",
      "DEBUG:root:\t\t\t        dilation=1,\n",
      "DEBUG:root:\t\t\t        dcn_config={'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}\n",
      "DEBUG:root:\t\t\t   )\n",
      "DEBUG:root:\t\t\t)\n",
      "\n",
      "DEBUG:root:\t\t\tblocks[-1]:BottleneckWithFixedBatchNorm(\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): FrozenBatchNorm2d()\n",
      "  )\n",
      "  (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (bn1): FrozenBatchNorm2d()\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): FrozenBatchNorm2d()\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): FrozenBatchNorm2d()\n",
      ")\n",
      "DEBUG:root:\t\t\tstride = 1\n",
      "DEBUG:root:\t\t\tin_channels = out_channels\n",
      "DEBUG:root:\n",
      "\t\t\t}\n",
      "DEBUG:root:\t\t\t{\n",
      "DEBUG:root:\t\t\t# --------------\n",
      "DEBUG:root:\t\t\t# blocks.append iteration 2/6\n",
      "DEBUG:root:\t\t\t# --------------\n",
      "DEBUG:root:\t\t\tblocks.append(\n",
      "DEBUG:root:\t\t\t    transformation_module(\n",
      "DEBUG:root:\t\t\t        in_channels=1024,\n",
      "DEBUG:root:\t\t\t        bottleneck_channels=256,\n",
      "DEBUG:root:\t\t\t        out_channels=1024,\n",
      "DEBUG:root:\t\t\t        num_groups=1,\n",
      "DEBUG:root:\t\t\t        stride_in_1x1=True,\n",
      "DEBUG:root:\t\t\t        stride=1,\n",
      "DEBUG:root:\t\t\t        dilation=1,\n",
      "DEBUG:root:\t\t\t        dcn_config={'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}\n",
      "DEBUG:root:\t\t\t   )\n",
      "DEBUG:root:\t\t\t)\n",
      "\n",
      "DEBUG:root:\t\t\tblocks[-1]:BottleneckWithFixedBatchNorm(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): FrozenBatchNorm2d()\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): FrozenBatchNorm2d()\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): FrozenBatchNorm2d()\n",
      ")\n",
      "DEBUG:root:\t\t\tstride = 1\n",
      "DEBUG:root:\t\t\tin_channels = out_channels\n",
      "DEBUG:root:\n",
      "\t\t\t}\n",
      "DEBUG:root:\t\t\t{\n",
      "DEBUG:root:\t\t\t# --------------\n",
      "DEBUG:root:\t\t\t# blocks.append iteration 3/6\n",
      "DEBUG:root:\t\t\t# --------------\n",
      "DEBUG:root:\t\t\tblocks.append(\n",
      "DEBUG:root:\t\t\t    transformation_module(\n",
      "DEBUG:root:\t\t\t        in_channels=1024,\n",
      "DEBUG:root:\t\t\t        bottleneck_channels=256,\n",
      "DEBUG:root:\t\t\t        out_channels=1024,\n",
      "DEBUG:root:\t\t\t        num_groups=1,\n",
      "DEBUG:root:\t\t\t        stride_in_1x1=True,\n",
      "DEBUG:root:\t\t\t        stride=1,\n",
      "DEBUG:root:\t\t\t        dilation=1,\n",
      "DEBUG:root:\t\t\t        dcn_config={'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}\n",
      "DEBUG:root:\t\t\t   )\n",
      "DEBUG:root:\t\t\t)\n",
      "\n",
      "DEBUG:root:\t\t\tblocks[-1]:BottleneckWithFixedBatchNorm(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): FrozenBatchNorm2d()\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): FrozenBatchNorm2d()\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): FrozenBatchNorm2d()\n",
      ")\n",
      "DEBUG:root:\t\t\tstride = 1\n",
      "DEBUG:root:\t\t\tin_channels = out_channels\n",
      "DEBUG:root:\n",
      "\t\t\t}\n",
      "DEBUG:root:\t\t\t{\n",
      "DEBUG:root:\t\t\t# --------------\n",
      "DEBUG:root:\t\t\t# blocks.append iteration 4/6\n",
      "DEBUG:root:\t\t\t# --------------\n",
      "DEBUG:root:\t\t\tblocks.append(\n",
      "DEBUG:root:\t\t\t    transformation_module(\n",
      "DEBUG:root:\t\t\t        in_channels=1024,\n",
      "DEBUG:root:\t\t\t        bottleneck_channels=256,\n",
      "DEBUG:root:\t\t\t        out_channels=1024,\n",
      "DEBUG:root:\t\t\t        num_groups=1,\n",
      "DEBUG:root:\t\t\t        stride_in_1x1=True,\n",
      "DEBUG:root:\t\t\t        stride=1,\n",
      "DEBUG:root:\t\t\t        dilation=1,\n",
      "DEBUG:root:\t\t\t        dcn_config={'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}\n",
      "DEBUG:root:\t\t\t   )\n",
      "DEBUG:root:\t\t\t)\n",
      "\n",
      "DEBUG:root:\t\t\tblocks[-1]:BottleneckWithFixedBatchNorm(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): FrozenBatchNorm2d()\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): FrozenBatchNorm2d()\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): FrozenBatchNorm2d()\n",
      ")\n",
      "DEBUG:root:\t\t\tstride = 1\n",
      "DEBUG:root:\t\t\tin_channels = out_channels\n",
      "DEBUG:root:\n",
      "\t\t\t}\n",
      "DEBUG:root:\t\t\t{\n",
      "DEBUG:root:\t\t\t# --------------\n",
      "DEBUG:root:\t\t\t# blocks.append iteration 5/6\n",
      "DEBUG:root:\t\t\t# --------------\n",
      "DEBUG:root:\t\t\tblocks.append(\n",
      "DEBUG:root:\t\t\t    transformation_module(\n",
      "DEBUG:root:\t\t\t        in_channels=1024,\n",
      "DEBUG:root:\t\t\t        bottleneck_channels=256,\n",
      "DEBUG:root:\t\t\t        out_channels=1024,\n",
      "DEBUG:root:\t\t\t        num_groups=1,\n",
      "DEBUG:root:\t\t\t        stride_in_1x1=True,\n",
      "DEBUG:root:\t\t\t        stride=1,\n",
      "DEBUG:root:\t\t\t        dilation=1,\n",
      "DEBUG:root:\t\t\t        dcn_config={'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}\n",
      "DEBUG:root:\t\t\t   )\n",
      "DEBUG:root:\t\t\t)\n",
      "\n",
      "DEBUG:root:\t\t\tblocks[-1]:BottleneckWithFixedBatchNorm(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): FrozenBatchNorm2d()\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): FrozenBatchNorm2d()\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): FrozenBatchNorm2d()\n",
      ")\n",
      "DEBUG:root:\t\t\tstride = 1\n",
      "DEBUG:root:\t\t\tin_channels = out_channels\n",
      "DEBUG:root:\n",
      "\t\t\t}\n",
      "DEBUG:root:\t\t\t{\n",
      "DEBUG:root:\t\t\t# --------------\n",
      "DEBUG:root:\t\t\t# blocks.append iteration 6/6\n",
      "DEBUG:root:\t\t\t# --------------\n",
      "DEBUG:root:\t\t\tblocks.append(\n",
      "DEBUG:root:\t\t\t    transformation_module(\n",
      "DEBUG:root:\t\t\t        in_channels=1024,\n",
      "DEBUG:root:\t\t\t        bottleneck_channels=256,\n",
      "DEBUG:root:\t\t\t        out_channels=1024,\n",
      "DEBUG:root:\t\t\t        num_groups=1,\n",
      "DEBUG:root:\t\t\t        stride_in_1x1=True,\n",
      "DEBUG:root:\t\t\t        stride=1,\n",
      "DEBUG:root:\t\t\t        dilation=1,\n",
      "DEBUG:root:\t\t\t        dcn_config={'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}\n",
      "DEBUG:root:\t\t\t   )\n",
      "DEBUG:root:\t\t\t)\n",
      "\n",
      "DEBUG:root:\t\t\tblocks[-1]:BottleneckWithFixedBatchNorm(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): FrozenBatchNorm2d()\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): FrozenBatchNorm2d()\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): FrozenBatchNorm2d()\n",
      ")\n",
      "DEBUG:root:\t\t\tstride = 1\n",
      "DEBUG:root:\t\t\tin_channels = out_channels\n",
      "DEBUG:root:\n",
      "\t\t\t}\n",
      "DEBUG:root:\t\t}// END for _ in range(block_count):\n",
      "\n",
      "DEBUG:root:\t\treturn nn.Sequential(*blocks)\n",
      "\n",
      "DEBUG:root:\n",
      "\t} // END _make_stage()\n",
      "DEBUG:root:\t\t\t\t}\n",
      "DEBUG:root:\t\t\tmodule = _make_stage(\n",
      "DEBUG:root:\t\t\t\ttransformation_module = <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>,\n",
      "DEBUG:root:\t\t\t\tin_channels = 512,\n",
      "DEBUG:root:\t\t\t\tbottleneck_channels = 256,\n",
      "DEBUG:root:\t\t\t\tout_channels = 1024,\n",
      "DEBUG:root:\t\t\t\tstage_spec.block_count = 6,\n",
      "DEBUG:root:\t\t\t\tnum_groups = 1,\n",
      "DEBUG:root:\t\t\t\tcfg.MODEL.RESNETS.STRIDE_IN_1X1 : True,\n",
      "DEBUG:root:\t\t\t\tfirst_stride=int(stage_spec.index > 1) + 1: 2,\n",
      "DEBUG:root:\t\t\t\tdcn_config={\n",
      "DEBUG:root:\t\t\t\t\t'stage_with_dcn': False,\n",
      "DEBUG:root:\t\t\t\t\t'with_modulated_dcn': False,\n",
      "DEBUG:root:\t\t\t\t\t'deformable_groups': 1,\n",
      "DEBUG:root:\t\t\t\t\t}\n",
      "DEBUG:root:\t\t\t\t) // RETURNED\n",
      "\n",
      "DEBUG:root:\t\t\tin_channels = out_channels\n",
      "DEBUG:root:\t\t\t// in_channels: 1024\n",
      "\n",
      "DEBUG:root:\t\t\tself.add_module(name=layer3, module)\n",
      "\n",
      "DEBUG:root:\t\t\tself.stages.append(name=layer3)\n",
      "\n",
      "DEBUG:root:\t\t\t// name: layer3\n",
      "DEBUG:root:\t\t\t// stage_spec.return_features: True\n",
      "DEBUG:root:\t\t\tself.return_features[name] = stage_spec.return_features\n",
      "\n",
      "DEBUG:root:\t\t\t}  // END of iteration 3/4\n",
      "\n",
      "DEBUG:root:\n",
      "\t\t\t{\n",
      "DEBUG:root:\t\t\t# ---------------------------------------------------------------\n",
      "DEBUG:root:\t\t\t# iteration 4/4\n",
      "DEBUG:root:\t\t\t#  4-th stage_spec: StageSpec(index=4, block_count=3, return_features=True)\n",
      "DEBUG:root:\t\t\t# ---------------------------------------------------------------\n",
      "DEBUG:root:\t\t\tname = \"layer\" + str(stage_spec.index)\n",
      "DEBUG:root:\t\t\t// name: layer4\n",
      "\n",
      "DEBUG:root:\t\t\tstage2_relative_factor = 2 ** (stage_spec.index - 1)\n",
      "DEBUG:root:\t\t\t// stage2_relative_factor: 8\n",
      "\n",
      "DEBUG:root:\t\t\tbottleneck_channels = stage2_bottleneck_channels * stage2_relative_factor\n",
      "DEBUG:root:\t\t\t// bottlenec_channels: 512\n",
      "\n",
      "DEBUG:root:\t\t\tout_channels = stage2_out_channels * stage2_relative_factor\n",
      "DEBUG:root:\t\t\t// out_channels: 2048\n",
      "\n",
      "DEBUG:root:\t\t\tstage_with_dcn = cfg.MODEL.RESNETS.STAGE_WITH_DCN[stage_spec.index - 1]\n",
      "DEBUG:root:\t\t\t// stage_with_dcn: False\n",
      "\n",
      "DEBUG:root:\t\t\tmodule = _make_stage(\n",
      "DEBUG:root:\t\t\t\ttransformation_module = <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>,\n",
      "DEBUG:root:\t\t\t\tin_channels = 1024,\n",
      "DEBUG:root:\t\t\t\tbottleneck_channels = 512,\n",
      "DEBUG:root:\t\t\t\tout_channels = 2048,\n",
      "DEBUG:root:\t\t\t\tstage_spec.block_count = 3,\n",
      "DEBUG:root:\t\t\t\tnum_groups = 1,\n",
      "DEBUG:root:\t\t\t\tcfg.MODEL.RESNETS.STRIDE_IN_1X1 : True,\n",
      "DEBUG:root:\t\t\t\tfirst_stride=int(stage_spec.index > 1) + 1: 2,\n",
      "DEBUG:root:\t\t\t\tdcn_config={\n",
      "DEBUG:root:\t\t\t\t\t'stage_with_dcn': False,\n",
      "DEBUG:root:\t\t\t\t\t'with_modulated_dcn': False,\n",
      "DEBUG:root:\t\t\t\t\t'deformable_groups': 1,\n",
      "DEBUG:root:\t\t\t\t\t}\n",
      "DEBUG:root:\t\t\t\t) // CALL\n",
      "DEBUG:root:\t\t\t\t{\n",
      "DEBUG:root:\n",
      "\t_make_stage() { //BEGIN\n",
      "DEBUG:root:\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/resnet.py\n",
      "\n",
      "DEBUG:root:\t\t// Params:\n",
      "DEBUG:root:\t\t\t// transformation_module: <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>\n",
      "DEBUG:root:\t\t\t// in_channels: 1024\n",
      "DEBUG:root:\t\t\t// bottleneck_channels: 512\n",
      "DEBUG:root:\t\t\t// out_channels: 2048\n",
      "DEBUG:root:\t\t\t// block_count: 3\n",
      "DEBUG:root:\t\t\t// num_groups: 3\n",
      "DEBUG:root:\t\t\t// stride_in_1x1: True\n",
      "DEBUG:root:\t\t\t// first_stride: 2\n",
      "DEBUG:root:\t\t\t// dilation: 1\n",
      "DEBUG:root:\t\t\t// dcn_config: {'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}\n",
      "\n",
      "DEBUG:root:\t\tblocks = []\n",
      "\n",
      "DEBUG:root:\t\tstride = first_stride\n",
      "\n",
      "DEBUG:root:\t\tfor _ in range(block_count):  {\n",
      "DEBUG:root:\t\t\t{\n",
      "DEBUG:root:\t\t\t# --------------\n",
      "DEBUG:root:\t\t\t# blocks.append iteration 1/3\n",
      "DEBUG:root:\t\t\t# --------------\n",
      "DEBUG:root:\t\t\tblocks.append(\n",
      "DEBUG:root:\t\t\t    transformation_module(\n",
      "DEBUG:root:\t\t\t        in_channels=1024,\n",
      "DEBUG:root:\t\t\t        bottleneck_channels=512,\n",
      "DEBUG:root:\t\t\t        out_channels=2048,\n",
      "DEBUG:root:\t\t\t        num_groups=1,\n",
      "DEBUG:root:\t\t\t        stride_in_1x1=True,\n",
      "DEBUG:root:\t\t\t        stride=2,\n",
      "DEBUG:root:\t\t\t        dilation=1,\n",
      "DEBUG:root:\t\t\t        dcn_config={'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}\n",
      "DEBUG:root:\t\t\t   )\n",
      "DEBUG:root:\t\t\t)\n",
      "\n",
      "DEBUG:root:\t\t\tblocks[-1]:BottleneckWithFixedBatchNorm(\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): FrozenBatchNorm2d()\n",
      "  )\n",
      "  (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (bn1): FrozenBatchNorm2d()\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): FrozenBatchNorm2d()\n",
      "  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): FrozenBatchNorm2d()\n",
      ")\n",
      "DEBUG:root:\t\t\tstride = 1\n",
      "DEBUG:root:\t\t\tin_channels = out_channels\n",
      "DEBUG:root:\n",
      "\t\t\t}\n",
      "DEBUG:root:\t\t\t{\n",
      "DEBUG:root:\t\t\t# --------------\n",
      "DEBUG:root:\t\t\t# blocks.append iteration 2/3\n",
      "DEBUG:root:\t\t\t# --------------\n",
      "DEBUG:root:\t\t\tblocks.append(\n",
      "DEBUG:root:\t\t\t    transformation_module(\n",
      "DEBUG:root:\t\t\t        in_channels=2048,\n",
      "DEBUG:root:\t\t\t        bottleneck_channels=512,\n",
      "DEBUG:root:\t\t\t        out_channels=2048,\n",
      "DEBUG:root:\t\t\t        num_groups=1,\n",
      "DEBUG:root:\t\t\t        stride_in_1x1=True,\n",
      "DEBUG:root:\t\t\t        stride=1,\n",
      "DEBUG:root:\t\t\t        dilation=1,\n",
      "DEBUG:root:\t\t\t        dcn_config={'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}\n",
      "DEBUG:root:\t\t\t   )\n",
      "DEBUG:root:\t\t\t)\n",
      "\n",
      "DEBUG:root:\t\t\tblocks[-1]:BottleneckWithFixedBatchNorm(\n",
      "  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): FrozenBatchNorm2d()\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): FrozenBatchNorm2d()\n",
      "  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): FrozenBatchNorm2d()\n",
      ")\n",
      "DEBUG:root:\t\t\tstride = 1\n",
      "DEBUG:root:\t\t\tin_channels = out_channels\n",
      "DEBUG:root:\n",
      "\t\t\t}\n",
      "DEBUG:root:\t\t\t{\n",
      "DEBUG:root:\t\t\t# --------------\n",
      "DEBUG:root:\t\t\t# blocks.append iteration 3/3\n",
      "DEBUG:root:\t\t\t# --------------\n",
      "DEBUG:root:\t\t\tblocks.append(\n",
      "DEBUG:root:\t\t\t    transformation_module(\n",
      "DEBUG:root:\t\t\t        in_channels=2048,\n",
      "DEBUG:root:\t\t\t        bottleneck_channels=512,\n",
      "DEBUG:root:\t\t\t        out_channels=2048,\n",
      "DEBUG:root:\t\t\t        num_groups=1,\n",
      "DEBUG:root:\t\t\t        stride_in_1x1=True,\n",
      "DEBUG:root:\t\t\t        stride=1,\n",
      "DEBUG:root:\t\t\t        dilation=1,\n",
      "DEBUG:root:\t\t\t        dcn_config={'stage_with_dcn': False, 'with_modulated_dcn': False, 'deformable_groups': 1}\n",
      "DEBUG:root:\t\t\t   )\n",
      "DEBUG:root:\t\t\t)\n",
      "\n",
      "DEBUG:root:\t\t\tblocks[-1]:BottleneckWithFixedBatchNorm(\n",
      "  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): FrozenBatchNorm2d()\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): FrozenBatchNorm2d()\n",
      "  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): FrozenBatchNorm2d()\n",
      ")\n",
      "DEBUG:root:\t\t\tstride = 1\n",
      "DEBUG:root:\t\t\tin_channels = out_channels\n",
      "DEBUG:root:\n",
      "\t\t\t}\n",
      "DEBUG:root:\t\t}// END for _ in range(block_count):\n",
      "\n",
      "DEBUG:root:\t\treturn nn.Sequential(*blocks)\n",
      "\n",
      "DEBUG:root:\n",
      "\t} // END _make_stage()\n",
      "DEBUG:root:\t\t\t\t}\n",
      "DEBUG:root:\t\t\tmodule = _make_stage(\n",
      "DEBUG:root:\t\t\t\ttransformation_module = <class 'maskrcnn_benchmark.modeling.backbone.resnet.BottleneckWithFixedBatchNorm'>,\n",
      "DEBUG:root:\t\t\t\tin_channels = 1024,\n",
      "DEBUG:root:\t\t\t\tbottleneck_channels = 512,\n",
      "DEBUG:root:\t\t\t\tout_channels = 2048,\n",
      "DEBUG:root:\t\t\t\tstage_spec.block_count = 3,\n",
      "DEBUG:root:\t\t\t\tnum_groups = 1,\n",
      "DEBUG:root:\t\t\t\tcfg.MODEL.RESNETS.STRIDE_IN_1X1 : True,\n",
      "DEBUG:root:\t\t\t\tfirst_stride=int(stage_spec.index > 1) + 1: 2,\n",
      "DEBUG:root:\t\t\t\tdcn_config={\n",
      "DEBUG:root:\t\t\t\t\t'stage_with_dcn': False,\n",
      "DEBUG:root:\t\t\t\t\t'with_modulated_dcn': False,\n",
      "DEBUG:root:\t\t\t\t\t'deformable_groups': 1,\n",
      "DEBUG:root:\t\t\t\t\t}\n",
      "DEBUG:root:\t\t\t\t) // RETURNED\n",
      "\n",
      "DEBUG:root:\t\t\tin_channels = out_channels\n",
      "DEBUG:root:\t\t\t// in_channels: 2048\n",
      "\n",
      "DEBUG:root:\t\t\tself.add_module(name=layer4, module)\n",
      "\n",
      "DEBUG:root:\t\t\tself.stages.append(name=layer4)\n",
      "\n",
      "DEBUG:root:\t\t\t// name: layer4\n",
      "DEBUG:root:\t\t\t// stage_spec.return_features: True\n",
      "DEBUG:root:\t\t\tself.return_features[name] = stage_spec.return_features\n",
      "\n",
      "DEBUG:root:\t\t\t}  // END of iteration 4/4\n",
      "\n",
      "DEBUG:root:} // END for stage_spec in stage_specs:\n",
      "\n",
      "DEBUG:root:\t\t\t// cfg.MODEL.BACKBONE.FREEZE_CONV_BODY_AT: 2)\n",
      "DEBUG:root:\t\t\tself._freeze_backbone(cfg.MODEL.BACKBONE.FREEZE_CONV_BODY_AT)\n",
      "DEBUG:root:\n",
      "\tResnet.__freeze_backbone(self, freeze_at) { // BEGIN\n",
      "DEBUG:root:\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/resnet.py\n",
      "\n",
      "DEBUG:root:\t\t// Params:\n",
      "DEBUG:root:\t\t\t// freeze_at: 2\n",
      "DEBUG:root:\t} // END Resnet.__freeze_backbone(self, freeze_at)\n",
      "\n",
      "DEBUG:root:} // END Resnet.__init__(self, cfg)\n",
      "\n",
      "DEBUG:root:\n",
      "\t\t}\n",
      "DEBUG:root:\t\tbody = resnet.ResNet(cfg) // RETURNED\n",
      "\n",
      "\n",
      "\n",
      "DEBUG:root:\t\t# ================================\n",
      "DEBUG:root:\t\t# 1-1-2 FPN build\n",
      "DEBUG:root:\t\t# ================================\n",
      "\n",
      "DEBUG:root:\t\t# get the channels parameters required by fpn\n",
      "DEBUG:root:\t\t// cfg.MODEL.RESNETS.RES2_OUT_CHANNELS: 256\n",
      "DEBUG:root:\t\tin_channels_stage2 = cfg.MODEL.RESNETS.RES2_OUT_CHANNELS\n",
      "DEBUG:root:\t\t// in_channels_stage2: 256\n",
      "\n",
      "DEBUG:root:\t\t// cfg.MODEL.RESNETS.BACKBONE_OUT_CHANNELS:1024\n",
      "DEBUG:root:\t\tout_channels = cfg.MODEL.RESNETS.BACKBONE_OUT_CHANNELS\n",
      "DEBUG:root:\t\t// out_channels: 1024\n",
      "\n",
      "DEBUG:root:\t\t// in_channels_stage2: 256\n",
      "DEBUG:root:\t\t// out_channels: 1024\n",
      "DEBUG:root:\t\t// cfg.MODEL.RETINANET.USE_C5: True\n",
      "DEBUG:root:\t\tin_channels_p6p7 = in_channels_stage2 * 8 if cfg.MODEL.RETINANET.USE_C5 else out_channels\n",
      "DEBUG:root:\t\t// in_channels_p6p7: 2048\n",
      "\n",
      "DEBUG:root:\n",
      "\t\tfpn = fpn_module.FPN(\n",
      "DEBUG:root:\t\t\t\tin_channels_list = [0, 512, 1024, 2048],\n",
      "DEBUG:root:\t\t\t\tout_channels = 1024,\n",
      "DEBUG:root:\t\t\t\tconv_block=conv_with_kaiming_uniform( cfg.MODEL.FPN.USE_GN =False, cfg.MODEL.FPN.USE_RELU =False ),\n",
      "DEBUG:root:\t\t\t\ttop_blocks=fpn_module.LastLevelP6P7(in_channels_p6p7=2048, out_channels=1024,) // CALL\n",
      "DEBUG:root:\n",
      "\t\t\tconv_with_kaiming_uniform(use_gn=False, use_relut=False) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/make_layers.py\n",
      "DEBUG:root:\t\t\t} // END conv_with_kaiming_uniform(use_gn=False, use_relu=False)\n",
      "\n",
      "DEBUG:root:\t\t# =================================\n",
      "DEBUG:root:\t\t# 1-1-2-1 FPN.LastLevelP6P7 build\n",
      "DEBUG:root:\t\t# =================================\n",
      "\n",
      "DEBUG:root:\t\t\tLastLevelP6P7.__init__(self, in_channels, out_channels) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/fpn.py\n",
      "\n",
      "DEBUG:root:\t\t\t\t> Param:\n",
      "DEBUG:root:\t\t\t\t\t>in_channels: 2048\n",
      "DEBUG:root:\t\t\t\t\t>out_channels: 1024\n",
      "\n",
      "DEBUG:root:\t\t\t\tsuper(LastLevelP6P7, self).__init__()\n",
      "DEBUG:root:\t\t\t\tself.p6 = nn.Conv2d(in_channels=2048, out_channels=1024, 3, 2, 1)\n",
      "DEBUG:root:\t\t\t\t// self.p6: Conv2d(2048, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "\n",
      "DEBUG:root:\t\t\t\tself.p7 = nn.Conv2d(out_channels=1024, out_channels=1024, 3, 2, 1)\n",
      "DEBUG:root:\t\t\t\t// self.p7: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "\n",
      "DEBUG:root:\t\t\t\tfor module in [self.p6, self.p7] {\n",
      "DEBUG:root:\t\t\t\t\tmodule=Conv2d(2048, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "DEBUG:root:\t\t\t\t\tnn.init.kaiming_uniform_(module.weight=module.weight, a=1)\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tnn.init.constant_(module.bias=module.bias, 0)\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tmodule=Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "DEBUG:root:\t\t\t\t\tnn.init.kaiming_uniform_(module.weight=module.weight, a=1)\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tnn.init.constant_(module.bias=module.bias, 0)\n",
      "\n",
      "DEBUG:root:\t\t\t\t} // END for module in [self.p6, self.p7]\n",
      "\n",
      "DEBUG:root:\t\t\t\tself.use_P5 = in_channels == out_channels\n",
      "DEBUG:root:\t\t\t\t\t// self.use_p5: False\n",
      "\n",
      "DEBUG:root:\t\t\t\t} // END LastLevelP6P7.__init__(self, in_channels, out_channels)\n",
      "\n",
      "\n",
      "DEBUG:root:\t\t# =================================\n",
      "DEBUG:root:\t\t# 1-1-2-2 FPN build\n",
      "DEBUG:root:\t\t# =================================\n",
      "\n",
      "DEBUG:root:\n",
      "\n",
      "FPN.__init__ { // BEGIN\n",
      "DEBUG:root:\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/backbone/fpn.py\n",
      "\n",
      "DEBUG:root:\t\t// Params\n",
      "DEBUG:root:\t\t\t// in_channels_list: [0, 512, 1024, 2048]\n",
      "DEBUG:root:\t\t\t// out_channels: 1024\n",
      "DEBUG:root:\t\t\t// conv_block: <function conv_with_kaiming_uniform.<locals>.make_conv at 0x7fb977508e18>\n",
      "DEBUG:root:\t\t\t// top_blocks: LastLevelP6P7(\n",
      "  (p6): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (p7): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      ")\n",
      "\n",
      "DEBUG:root:\t\tsuper(FPN, self).__init__()\n",
      "\n",
      "DEBUG:root:\t\t# create two empty lists\n",
      "DEBUG:root:\t\tself.inner_blocks = []\n",
      "DEBUG:root:\t\tself.layer_block = []\n",
      "DEBUG:root:\t\tfor idx, in_channels in enumerate(in_channels_list, 1) {\n",
      "\n",
      "DEBUG:root:\t\t\t{\n",
      "DEBUG:root:\t\t\t\t# -----------------------------------------------------\n",
      "DEBUG:root:\t\t\t\t# in_channels:0, iteration 1/4 BEGIN\n",
      "DEBUG:root:\t\t\t\t# -----------------------------------------------------\n",
      "DEBUG:root:\t\t\t\tinner_block = \"fpn_inner{}\".format(idx)\n",
      "DEBUG:root:\t\t\t\t// inner_block: {inner_block}\n",
      "\n",
      "DEBUG:root:\t\t\t\tlayer_block = \"fpn_layer{}\".format(idx)\n",
      "DEBUG:root:\t\t\t\t// layer_block: {layer_block}\n",
      "\n",
      "DEBUG:root:\t\t\t\tif in_channels ==0, skip\n",
      "\n",
      "DEBUG:root:\t\t\t}\n",
      "\t\t\t# iteration 1/4 END\n",
      "\n",
      "DEBUG:root:\t\t\t{\n",
      "DEBUG:root:\t\t\t\t# -----------------------------------------------------\n",
      "DEBUG:root:\t\t\t\t# in_channels:512, iteration 2/4 BEGIN\n",
      "DEBUG:root:\t\t\t\t# -----------------------------------------------------\n",
      "DEBUG:root:\t\t\t\tinner_block = \"fpn_inner{}\".format(idx)\n",
      "DEBUG:root:\t\t\t\t// inner_block: {inner_block}\n",
      "\n",
      "DEBUG:root:\t\t\t\tlayer_block = \"fpn_layer{}\".format(idx)\n",
      "DEBUG:root:\t\t\t\t// layer_block: {layer_block}\n",
      "\n",
      "DEBUG:root:\t\t\t\t// inner_block: fpn_inner2\n",
      "DEBUG:root:\t\t\t\t// layer_block: fpn_layer2\n",
      "\n",
      "DEBUG:root:\n",
      "\t\t\t\tmake_conv(in_channels, out_channels, kernel_size, stride=1, dilation=1) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/make_layers.py\n",
      "\n",
      "DEBUG:root:\t\t\t\t// Params:\n",
      "DEBUG:root:\t\t\t\t\t// in_channels: 512\n",
      "DEBUG:root:\t\t\t\t\t// out_channels: 1024\n",
      "DEBUG:root:\t\t\t\t\t// kernel_size: 1\n",
      "DEBUG:root:\t\t\t\t\t// stride: 1\n",
      "DEBUG:root:\t\t\t\t\t// dilation: 1\n",
      "\n",
      "DEBUG:root:\t\t\t\tconv = Conv2d(in_channles=512, out_channels=1024, kernel_size=1, stride=1\n",
      "DEBUG:root:\t\t\t\t       padding=0, dilation=1, bias=True, )\n",
      "DEBUG:root:\t\t\t\t// conv: Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "\n",
      "DEBUG:root:\t\t\t\tnn.init.kaiming_uniform_(conv.weight, a=1)\n",
      "\n",
      "DEBUG:root:\t\t\t\tif not use_gn:\n",
      "DEBUG:root:\t\t\t\t\tnn.init.constant_(conv.bias, 0)\n",
      "\n",
      "DEBUG:root:\t\t\t\tmodule = [conv,]\n",
      "DEBUG:root:\t\t\t\t// module: [Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))]\n",
      "\n",
      "DEBUG:root:\t\t\t\tconv: Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "DEBUG:root:\t\t\t\treturn conv\n",
      "\n",
      "DEBUG:root:\t\t\t\t} // END conv_with_kaiming_uniform().make_conv()\n",
      "\n",
      "DEBUG:root:\t\t\t\tinner_block_module = conv_block(in_channels=512, out_channels=1024, 1)\n",
      "DEBUG:root:\t\t\t\t// inner_block_module: Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "\n",
      "DEBUG:root:\n",
      "\t\t\t\tmake_conv(in_channels, out_channels, kernel_size, stride=1, dilation=1) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/make_layers.py\n",
      "\n",
      "DEBUG:root:\t\t\t\t// Params:\n",
      "DEBUG:root:\t\t\t\t\t// in_channels: 1024\n",
      "DEBUG:root:\t\t\t\t\t// out_channels: 1024\n",
      "DEBUG:root:\t\t\t\t\t// kernel_size: 3\n",
      "DEBUG:root:\t\t\t\t\t// stride: 1\n",
      "DEBUG:root:\t\t\t\t\t// dilation: 1\n",
      "\n",
      "DEBUG:root:\t\t\t\tconv = Conv2d(in_channles=1024, out_channels=1024, kernel_size=3, stride=1\n",
      "DEBUG:root:\t\t\t\t       padding=1, dilation=1, bias=True, )\n",
      "DEBUG:root:\t\t\t\t// conv: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "\n",
      "DEBUG:root:\t\t\t\tnn.init.kaiming_uniform_(conv.weight, a=1)\n",
      "\n",
      "DEBUG:root:\t\t\t\tif not use_gn:\n",
      "DEBUG:root:\t\t\t\t\tnn.init.constant_(conv.bias, 0)\n",
      "\n",
      "DEBUG:root:\t\t\t\tmodule = [conv,]\n",
      "DEBUG:root:\t\t\t\t// module: [Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]\n",
      "\n",
      "DEBUG:root:\t\t\t\tconv: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "DEBUG:root:\t\t\t\treturn conv\n",
      "\n",
      "DEBUG:root:\t\t\t\t} // END conv_with_kaiming_uniform().make_conv()\n",
      "\n",
      "DEBUG:root:\t\t\t\tlayer_block_module = conv_block(out_channels=1024, out_channels=1024, 3,1)\n",
      "DEBUG:root:\t\t\t\t// layer_block_module: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "\n",
      "DEBUG:root:\t\t\t\tself.add_module(inner_block, inner_block_module)\n",
      "\n",
      "DEBUG:root:\t\t\t\tself.add_module(layer_block, layer_block_module)\n",
      "\n",
      "DEBUG:root:\t\t\t\tself.inner_blocks.append(fpn_inner2)\n",
      "\n",
      "DEBUG:root:\t\t\t\tself.layer_blocks.append(fpn_layer2)\n",
      "\n",
      "DEBUG:root:\t\t\t}\n",
      "\t\t\t# iteration 2/4 END\n",
      "\n",
      "DEBUG:root:\t\t\t{\n",
      "DEBUG:root:\t\t\t\t# -----------------------------------------------------\n",
      "DEBUG:root:\t\t\t\t# in_channels:1024, iteration 3/4 BEGIN\n",
      "DEBUG:root:\t\t\t\t# -----------------------------------------------------\n",
      "DEBUG:root:\t\t\t\tinner_block = \"fpn_inner{}\".format(idx)\n",
      "DEBUG:root:\t\t\t\t// inner_block: {inner_block}\n",
      "\n",
      "DEBUG:root:\t\t\t\tlayer_block = \"fpn_layer{}\".format(idx)\n",
      "DEBUG:root:\t\t\t\t// layer_block: {layer_block}\n",
      "\n",
      "DEBUG:root:\t\t\t\t// inner_block: fpn_inner3\n",
      "DEBUG:root:\t\t\t\t// layer_block: fpn_layer3\n",
      "\n",
      "DEBUG:root:\n",
      "\t\t\t\tmake_conv(in_channels, out_channels, kernel_size, stride=1, dilation=1) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/make_layers.py\n",
      "\n",
      "DEBUG:root:\t\t\t\t// Params:\n",
      "DEBUG:root:\t\t\t\t\t// in_channels: 1024\n",
      "DEBUG:root:\t\t\t\t\t// out_channels: 1024\n",
      "DEBUG:root:\t\t\t\t\t// kernel_size: 1\n",
      "DEBUG:root:\t\t\t\t\t// stride: 1\n",
      "DEBUG:root:\t\t\t\t\t// dilation: 1\n",
      "\n",
      "DEBUG:root:\t\t\t\tconv = Conv2d(in_channles=1024, out_channels=1024, kernel_size=1, stride=1\n",
      "DEBUG:root:\t\t\t\t       padding=0, dilation=1, bias=True, )\n",
      "DEBUG:root:\t\t\t\t// conv: Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "\n",
      "DEBUG:root:\t\t\t\tnn.init.kaiming_uniform_(conv.weight, a=1)\n",
      "\n",
      "DEBUG:root:\t\t\t\tif not use_gn:\n",
      "DEBUG:root:\t\t\t\t\tnn.init.constant_(conv.bias, 0)\n",
      "\n",
      "DEBUG:root:\t\t\t\tmodule = [conv,]\n",
      "DEBUG:root:\t\t\t\t// module: [Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))]\n",
      "\n",
      "DEBUG:root:\t\t\t\tconv: Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "DEBUG:root:\t\t\t\treturn conv\n",
      "\n",
      "DEBUG:root:\t\t\t\t} // END conv_with_kaiming_uniform().make_conv()\n",
      "\n",
      "DEBUG:root:\t\t\t\tinner_block_module = conv_block(in_channels=1024, out_channels=1024, 1)\n",
      "DEBUG:root:\t\t\t\t// inner_block_module: Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "\n",
      "DEBUG:root:\n",
      "\t\t\t\tmake_conv(in_channels, out_channels, kernel_size, stride=1, dilation=1) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/make_layers.py\n",
      "\n",
      "DEBUG:root:\t\t\t\t// Params:\n",
      "DEBUG:root:\t\t\t\t\t// in_channels: 1024\n",
      "DEBUG:root:\t\t\t\t\t// out_channels: 1024\n",
      "DEBUG:root:\t\t\t\t\t// kernel_size: 3\n",
      "DEBUG:root:\t\t\t\t\t// stride: 1\n",
      "DEBUG:root:\t\t\t\t\t// dilation: 1\n",
      "\n",
      "DEBUG:root:\t\t\t\tconv = Conv2d(in_channles=1024, out_channels=1024, kernel_size=3, stride=1\n",
      "DEBUG:root:\t\t\t\t       padding=1, dilation=1, bias=True, )\n",
      "DEBUG:root:\t\t\t\t// conv: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "\n",
      "DEBUG:root:\t\t\t\tnn.init.kaiming_uniform_(conv.weight, a=1)\n",
      "\n",
      "DEBUG:root:\t\t\t\tif not use_gn:\n",
      "DEBUG:root:\t\t\t\t\tnn.init.constant_(conv.bias, 0)\n",
      "\n",
      "DEBUG:root:\t\t\t\tmodule = [conv,]\n",
      "DEBUG:root:\t\t\t\t// module: [Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]\n",
      "\n",
      "DEBUG:root:\t\t\t\tconv: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "DEBUG:root:\t\t\t\treturn conv\n",
      "\n",
      "DEBUG:root:\t\t\t\t} // END conv_with_kaiming_uniform().make_conv()\n",
      "\n",
      "DEBUG:root:\t\t\t\tlayer_block_module = conv_block(out_channels=1024, out_channels=1024, 3,1)\n",
      "DEBUG:root:\t\t\t\t// layer_block_module: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "\n",
      "DEBUG:root:\t\t\t\tself.add_module(inner_block, inner_block_module)\n",
      "\n",
      "DEBUG:root:\t\t\t\tself.add_module(layer_block, layer_block_module)\n",
      "\n",
      "DEBUG:root:\t\t\t\tself.inner_blocks.append(fpn_inner3)\n",
      "\n",
      "DEBUG:root:\t\t\t\tself.layer_blocks.append(fpn_layer3)\n",
      "\n",
      "DEBUG:root:\t\t\t}\n",
      "\t\t\t# iteration 3/4 END\n",
      "\n",
      "DEBUG:root:\t\t\t{\n",
      "DEBUG:root:\t\t\t\t# -----------------------------------------------------\n",
      "DEBUG:root:\t\t\t\t# in_channels:2048, iteration 4/4 BEGIN\n",
      "DEBUG:root:\t\t\t\t# -----------------------------------------------------\n",
      "DEBUG:root:\t\t\t\tinner_block = \"fpn_inner{}\".format(idx)\n",
      "DEBUG:root:\t\t\t\t// inner_block: {inner_block}\n",
      "\n",
      "DEBUG:root:\t\t\t\tlayer_block = \"fpn_layer{}\".format(idx)\n",
      "DEBUG:root:\t\t\t\t// layer_block: {layer_block}\n",
      "\n",
      "DEBUG:root:\t\t\t\t// inner_block: fpn_inner4\n",
      "DEBUG:root:\t\t\t\t// layer_block: fpn_layer4\n",
      "\n",
      "DEBUG:root:\n",
      "\t\t\t\tmake_conv(in_channels, out_channels, kernel_size, stride=1, dilation=1) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/make_layers.py\n",
      "\n",
      "DEBUG:root:\t\t\t\t// Params:\n",
      "DEBUG:root:\t\t\t\t\t// in_channels: 2048\n",
      "DEBUG:root:\t\t\t\t\t// out_channels: 1024\n",
      "DEBUG:root:\t\t\t\t\t// kernel_size: 1\n",
      "DEBUG:root:\t\t\t\t\t// stride: 1\n",
      "DEBUG:root:\t\t\t\t\t// dilation: 1\n",
      "\n",
      "DEBUG:root:\t\t\t\tconv = Conv2d(in_channles=2048, out_channels=1024, kernel_size=1, stride=1\n",
      "DEBUG:root:\t\t\t\t       padding=0, dilation=1, bias=True, )\n",
      "DEBUG:root:\t\t\t\t// conv: Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "\n",
      "DEBUG:root:\t\t\t\tnn.init.kaiming_uniform_(conv.weight, a=1)\n",
      "\n",
      "DEBUG:root:\t\t\t\tif not use_gn:\n",
      "DEBUG:root:\t\t\t\t\tnn.init.constant_(conv.bias, 0)\n",
      "\n",
      "DEBUG:root:\t\t\t\tmodule = [conv,]\n",
      "DEBUG:root:\t\t\t\t// module: [Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))]\n",
      "\n",
      "DEBUG:root:\t\t\t\tconv: Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "DEBUG:root:\t\t\t\treturn conv\n",
      "\n",
      "DEBUG:root:\t\t\t\t} // END conv_with_kaiming_uniform().make_conv()\n",
      "\n",
      "DEBUG:root:\t\t\t\tinner_block_module = conv_block(in_channels=2048, out_channels=1024, 1)\n",
      "DEBUG:root:\t\t\t\t// inner_block_module: Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "\n",
      "DEBUG:root:\n",
      "\t\t\t\tmake_conv(in_channels, out_channels, kernel_size, stride=1, dilation=1) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/make_layers.py\n",
      "\n",
      "DEBUG:root:\t\t\t\t// Params:\n",
      "DEBUG:root:\t\t\t\t\t// in_channels: 1024\n",
      "DEBUG:root:\t\t\t\t\t// out_channels: 1024\n",
      "DEBUG:root:\t\t\t\t\t// kernel_size: 3\n",
      "DEBUG:root:\t\t\t\t\t// stride: 1\n",
      "DEBUG:root:\t\t\t\t\t// dilation: 1\n",
      "\n",
      "DEBUG:root:\t\t\t\tconv = Conv2d(in_channles=1024, out_channels=1024, kernel_size=3, stride=1\n",
      "DEBUG:root:\t\t\t\t       padding=1, dilation=1, bias=True, )\n",
      "DEBUG:root:\t\t\t\t// conv: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "\n",
      "DEBUG:root:\t\t\t\tnn.init.kaiming_uniform_(conv.weight, a=1)\n",
      "\n",
      "DEBUG:root:\t\t\t\tif not use_gn:\n",
      "DEBUG:root:\t\t\t\t\tnn.init.constant_(conv.bias, 0)\n",
      "\n",
      "DEBUG:root:\t\t\t\tmodule = [conv,]\n",
      "DEBUG:root:\t\t\t\t// module: [Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]\n",
      "\n",
      "DEBUG:root:\t\t\t\tconv: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "DEBUG:root:\t\t\t\treturn conv\n",
      "\n",
      "DEBUG:root:\t\t\t\t} // END conv_with_kaiming_uniform().make_conv()\n",
      "\n",
      "DEBUG:root:\t\t\t\tlayer_block_module = conv_block(out_channels=1024, out_channels=1024, 3,1)\n",
      "DEBUG:root:\t\t\t\t// layer_block_module: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "\n",
      "DEBUG:root:\t\t\t\tself.add_module(inner_block, inner_block_module)\n",
      "\n",
      "DEBUG:root:\t\t\t\tself.add_module(layer_block, layer_block_module)\n",
      "\n",
      "DEBUG:root:\t\t\t\tself.inner_blocks.append(fpn_inner4)\n",
      "\n",
      "DEBUG:root:\t\t\t\tself.layer_blocks.append(fpn_layer4)\n",
      "\n",
      "DEBUG:root:\t\t\t}\n",
      "\t\t\t# iteration 4/4 END\n",
      "\n",
      "DEBUG:root:\n",
      "\t\t} // END for idx, in_channels in enumerate(in_channels_list, 1)\n",
      "DEBUG:root:\t\tself.top_blocks = top_blocks\n",
      "\n",
      "DEBUG:root:\t\t// self.inner_blocks: ['fpn_inner2', 'fpn_inner3', 'fpn_inner4']\n",
      "DEBUG:root:\t\t// self.fpn_inner2: Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "DEBUG:root:\t\t// self.fpn_inner3: Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "DEBUG:root:\t\t// self.fpn_inner4: Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "DEBUG:root:\n",
      "\t// self.layer_blocks: ['fpn_layer2', 'fpn_layer3', 'fpn_layer4']\n",
      "DEBUG:root:\t\t// self.fpn_layer2: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "DEBUG:root:\t\t// self.fpn_layer3: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "DEBUG:root:\t\t// self.fpn_layer4: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "DEBUG:root:\n",
      "\t// self.top_blocks: LastLevelP6P7(\n",
      "  (p6): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (p7): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      ")\n",
      "DEBUG:root:\n",
      "} // END FPN.__init__\n",
      "\n",
      "\n",
      "DEBUG:root:\n",
      "\t\tfpn = fpn_module.FPN(\n",
      "DEBUG:root:\n",
      "\t\t\t\tin_channels_list = [0, 512, 1024, 2048],\n",
      "DEBUG:root:\n",
      "\t\t\t\tout_channels = 1024,\n",
      "DEBUG:root:\n",
      "\t\t\t\tconv_block=conv_with_kaiming_uniform( cfg.MODEL.FPN.USE_GN =False, cfg.MODEL.FPN.USE_RELU =False ),\n",
      "DEBUG:root:\n",
      "\t\t\t\ttop_blocks=fpn_module.LastLevelP6P7(in_channels_p6p7=2048, out_channels=1024,) // RETURNED\n",
      "DEBUG:root:\n",
      "\t\t\t// fpn: FPN(\n",
      "  (fpn_inner2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (fpn_layer2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fpn_inner3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (fpn_layer3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fpn_inner4): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (fpn_layer4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (top_blocks): LastLevelP6P7(\n",
      "    (p6): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (p7): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "DEBUG:root:\t\tmodel = nn.Sequential(OrderedDict([(\"body\", body), (\"fpn\", fpn)]))\n",
      "\n",
      "DEBUG:root:\t\tmodel.out_channels = out_channels\n",
      "DEBUG:root:\t\t\t// model.out_channels: 1024\n",
      "\n",
      "DEBUG:root:\t\treturn model\n",
      "\n",
      "DEBUG:root:\t} // END build_resnet_fpn_p3p7_backbone(cfg)\n",
      "\n",
      "\n",
      "DEBUG:root:\t} // END build_backbone(cfg)\n",
      "\n",
      "DEBUG:root:\t}\n",
      "DEBUG:root:\tself.backbone = build_backbone(cfg) // RETURNED\n",
      "\n",
      "DEBUG:root:\n",
      "\t} // END of 1.1 \n",
      "\n",
      "DEBUG:root:\t# ===========================================\n",
      "DEBUG:root:\t# 1.2 RPN (Region Proposal Network) build\n",
      "DEBUG:root:\t# ===========================================\n",
      "DEBUG:root:\t{ // BEGIN of 1.2\n",
      "\n",
      "DEBUG:root:\t// self.backbone.out_channels: 1024\n",
      "DEBUG:root:\tself.rpn = build_rpn(cfg, self.backbone.out_channels) // CALL\n",
      "DEBUG:root:\tbuild_retinanet(cfg, in_channels) { // BEGIN\n",
      "DEBUG:root:\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/retinanet/retinanet.py\n",
      "\n",
      "DEBUG:root:\t\t// Param:\n",
      "DEBUG:root:\t\t\t// cfg:\n",
      "DEBUG:root:\t\t\t// in_channels: 1024\n",
      "DEBUG:root:\treturn RetinaNetModule(cfg, in_channels) // CALL\n",
      "DEBUG:root:\t\tRetinaNetModule.__init__(self, cfg, in_channels) { // BEGIN\n",
      "DEBUG:root:\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/retinanet/retinanet.py\n",
      "\n",
      "DEBUG:root:\t\t\t// Params:\n",
      "DEBUG:root:\t\t\t\t// cfg:\n",
      "DEBUG:root:\t\t\t\t// in_channels: 1024\n",
      "\n",
      "DEBUG:root:\tsuper(RetinaNetModule, self).__init__()\n",
      "DEBUG:root:\tself.cfg = cfg.clone()\n",
      "DEBUG:root:\t#============================\n",
      "DEBUG:root:\t# 1.2.1 anchor generator build\n",
      "DEBUG:root:\t#============================\n",
      "DEBUG:root:\tanchor_generator = make_anchor_generator_retinanet(cfg) // CALL\n",
      "\t{\n",
      "DEBUG:root:\n",
      "\t\tmake_anchor_generator_retinanet(config) { // BEGIN\n",
      "DEBUG:root:\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "\n",
      "DEBUG:root:\t\t\t\t// Params\n",
      "DEBUG:root:\t\t\t\t\t// anchor_sizes: (32, 64, 128, 256, 512)\n",
      "DEBUG:root:\t\t\t\t\t// aspect_ratios: (0.5, 1.0, 2.0)\n",
      "DEBUG:root:\t\t\t\t\t// anchor_strides: (8, 16, 32, 64, 128)\n",
      "DEBUG:root:\t\t\t\t\t// straddle_thresh: -1\n",
      "DEBUG:root:\t\t\t\t\t// octave: 2.0\n",
      "DEBUG:root:\t\t\t\t\t// scales_per_octave: 3\n",
      "\n",
      "DEBUG:root:\t\t\t\tnew_anchor_sizes = []\n",
      "\n",
      "DEBUG:root:\n",
      "\t\t\t\tfor size in anchor_sizes {\n",
      "DEBUG:root:\t\t\t\t\t{\n",
      "DEBUG:root:\t\t\t\t\t//------------------------\n",
      "DEBUG:root:\t\t\t\t\t// size: 32\n",
      "DEBUG:root:\t\t\t\t\t//------------------------\n",
      "\n",
      "DEBUG:root:\t\t\tper_layer_anchor_sizes = []\n",
      "DEBUG:root:\n",
      "\t\t\t\t\tfor scale_per_octave in range(scales_per_octave=3) { // BEGIN\n",
      "DEBUG:root:\t\t\t\t\t\t{\n",
      "DEBUG:root:\t\t\t\t\t\t// ------------------------\n",
      "DEBUG:root:\t\t\t\t\t\t// scale_per_octave: 0, octave: 2.0\n",
      "DEBUG:root:\t\t\t\t\t\t// ------------------------\n",
      "DEBUG:root:\t\t\t\t\t\toctave_scale = octave ** (scale_per_octave / float(scales_per_octave))\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t// octave_scale: 1.0\n",
      "DEBUG:root:\t\t\t\t\t\t// size: 32\n",
      "DEBUG:root:\t\t\t\t\t\tper_layer_anchor_sizes.append(octave_scale * size)\n",
      "DEBUG:root:\t\t\t\t\t\t// per_layer_anchor_sizes[-1]: 32.0\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t}\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t{\n",
      "DEBUG:root:\t\t\t\t\t\t// ------------------------\n",
      "DEBUG:root:\t\t\t\t\t\t// scale_per_octave: 1, octave: 2.0\n",
      "DEBUG:root:\t\t\t\t\t\t// ------------------------\n",
      "DEBUG:root:\t\t\t\t\t\toctave_scale = octave ** (scale_per_octave / float(scales_per_octave))\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t// octave_scale: 1.2599210498948732\n",
      "DEBUG:root:\t\t\t\t\t\t// size: 32\n",
      "DEBUG:root:\t\t\t\t\t\tper_layer_anchor_sizes.append(octave_scale * size)\n",
      "DEBUG:root:\t\t\t\t\t\t// per_layer_anchor_sizes[-1]: 40.31747359663594\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t}\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t{\n",
      "DEBUG:root:\t\t\t\t\t\t// ------------------------\n",
      "DEBUG:root:\t\t\t\t\t\t// scale_per_octave: 2, octave: 2.0\n",
      "DEBUG:root:\t\t\t\t\t\t// ------------------------\n",
      "DEBUG:root:\t\t\t\t\t\toctave_scale = octave ** (scale_per_octave / float(scales_per_octave))\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t// octave_scale: 1.5874010519681994\n",
      "DEBUG:root:\t\t\t\t\t\t// size: 32\n",
      "DEBUG:root:\t\t\t\t\t\tper_layer_anchor_sizes.append(octave_scale * size)\n",
      "DEBUG:root:\t\t\t\t\t\t// per_layer_anchor_sizes[-1]: 50.79683366298238\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t}\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t} // END for scale_per_octave in range(scales_per_octave)\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tnew_anchor_sizes.append(tuple(per_layer_anchor_sizes))\n",
      "DEBUG:root:\t\t\t\t\t// new_anchor_sizes[-1]: (32.0, 40.31747359663594, 50.79683366298238)\n",
      "DEBUG:root:\t\t\t\t\t}\n",
      "DEBUG:root:\t\t\t\t\t{\n",
      "DEBUG:root:\t\t\t\t\t//------------------------\n",
      "DEBUG:root:\t\t\t\t\t// size: 64\n",
      "DEBUG:root:\t\t\t\t\t//------------------------\n",
      "\n",
      "DEBUG:root:\t\t\tper_layer_anchor_sizes = []\n",
      "DEBUG:root:\n",
      "\t\t\t\t\tfor scale_per_octave in range(scales_per_octave=3) { // BEGIN\n",
      "DEBUG:root:\t\t\t\t\t\t{\n",
      "DEBUG:root:\t\t\t\t\t\t// ------------------------\n",
      "DEBUG:root:\t\t\t\t\t\t// scale_per_octave: 0, octave: 2.0\n",
      "DEBUG:root:\t\t\t\t\t\t// ------------------------\n",
      "DEBUG:root:\t\t\t\t\t\toctave_scale = octave ** (scale_per_octave / float(scales_per_octave))\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t// octave_scale: 1.0\n",
      "DEBUG:root:\t\t\t\t\t\t// size: 64\n",
      "DEBUG:root:\t\t\t\t\t\tper_layer_anchor_sizes.append(octave_scale * size)\n",
      "DEBUG:root:\t\t\t\t\t\t// per_layer_anchor_sizes[-1]: 64.0\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t}\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t{\n",
      "DEBUG:root:\t\t\t\t\t\t// ------------------------\n",
      "DEBUG:root:\t\t\t\t\t\t// scale_per_octave: 1, octave: 2.0\n",
      "DEBUG:root:\t\t\t\t\t\t// ------------------------\n",
      "DEBUG:root:\t\t\t\t\t\toctave_scale = octave ** (scale_per_octave / float(scales_per_octave))\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t// octave_scale: 1.2599210498948732\n",
      "DEBUG:root:\t\t\t\t\t\t// size: 64\n",
      "DEBUG:root:\t\t\t\t\t\tper_layer_anchor_sizes.append(octave_scale * size)\n",
      "DEBUG:root:\t\t\t\t\t\t// per_layer_anchor_sizes[-1]: 80.63494719327188\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t}\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t{\n",
      "DEBUG:root:\t\t\t\t\t\t// ------------------------\n",
      "DEBUG:root:\t\t\t\t\t\t// scale_per_octave: 2, octave: 2.0\n",
      "DEBUG:root:\t\t\t\t\t\t// ------------------------\n",
      "DEBUG:root:\t\t\t\t\t\toctave_scale = octave ** (scale_per_octave / float(scales_per_octave))\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t// octave_scale: 1.5874010519681994\n",
      "DEBUG:root:\t\t\t\t\t\t// size: 64\n",
      "DEBUG:root:\t\t\t\t\t\tper_layer_anchor_sizes.append(octave_scale * size)\n",
      "DEBUG:root:\t\t\t\t\t\t// per_layer_anchor_sizes[-1]: 101.59366732596476\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t}\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t} // END for scale_per_octave in range(scales_per_octave)\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tnew_anchor_sizes.append(tuple(per_layer_anchor_sizes))\n",
      "DEBUG:root:\t\t\t\t\t// new_anchor_sizes[-1]: (64.0, 80.63494719327188, 101.59366732596476)\n",
      "DEBUG:root:\t\t\t\t\t}\n",
      "DEBUG:root:\t\t\t\t\t{\n",
      "DEBUG:root:\t\t\t\t\t//------------------------\n",
      "DEBUG:root:\t\t\t\t\t// size: 128\n",
      "DEBUG:root:\t\t\t\t\t//------------------------\n",
      "\n",
      "DEBUG:root:\t\t\tper_layer_anchor_sizes = []\n",
      "DEBUG:root:\n",
      "\t\t\t\t\tfor scale_per_octave in range(scales_per_octave=3) { // BEGIN\n",
      "DEBUG:root:\t\t\t\t\t\t{\n",
      "DEBUG:root:\t\t\t\t\t\t// ------------------------\n",
      "DEBUG:root:\t\t\t\t\t\t// scale_per_octave: 0, octave: 2.0\n",
      "DEBUG:root:\t\t\t\t\t\t// ------------------------\n",
      "DEBUG:root:\t\t\t\t\t\toctave_scale = octave ** (scale_per_octave / float(scales_per_octave))\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t// octave_scale: 1.0\n",
      "DEBUG:root:\t\t\t\t\t\t// size: 128\n",
      "DEBUG:root:\t\t\t\t\t\tper_layer_anchor_sizes.append(octave_scale * size)\n",
      "DEBUG:root:\t\t\t\t\t\t// per_layer_anchor_sizes[-1]: 128.0\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t}\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t{\n",
      "DEBUG:root:\t\t\t\t\t\t// ------------------------\n",
      "DEBUG:root:\t\t\t\t\t\t// scale_per_octave: 1, octave: 2.0\n",
      "DEBUG:root:\t\t\t\t\t\t// ------------------------\n",
      "DEBUG:root:\t\t\t\t\t\toctave_scale = octave ** (scale_per_octave / float(scales_per_octave))\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t// octave_scale: 1.2599210498948732\n",
      "DEBUG:root:\t\t\t\t\t\t// size: 128\n",
      "DEBUG:root:\t\t\t\t\t\tper_layer_anchor_sizes.append(octave_scale * size)\n",
      "DEBUG:root:\t\t\t\t\t\t// per_layer_anchor_sizes[-1]: 161.26989438654377\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t}\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t{\n",
      "DEBUG:root:\t\t\t\t\t\t// ------------------------\n",
      "DEBUG:root:\t\t\t\t\t\t// scale_per_octave: 2, octave: 2.0\n",
      "DEBUG:root:\t\t\t\t\t\t// ------------------------\n",
      "DEBUG:root:\t\t\t\t\t\toctave_scale = octave ** (scale_per_octave / float(scales_per_octave))\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t// octave_scale: 1.5874010519681994\n",
      "DEBUG:root:\t\t\t\t\t\t// size: 128\n",
      "DEBUG:root:\t\t\t\t\t\tper_layer_anchor_sizes.append(octave_scale * size)\n",
      "DEBUG:root:\t\t\t\t\t\t// per_layer_anchor_sizes[-1]: 203.18733465192952\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t}\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t} // END for scale_per_octave in range(scales_per_octave)\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tnew_anchor_sizes.append(tuple(per_layer_anchor_sizes))\n",
      "DEBUG:root:\t\t\t\t\t// new_anchor_sizes[-1]: (128.0, 161.26989438654377, 203.18733465192952)\n",
      "DEBUG:root:\t\t\t\t\t}\n",
      "DEBUG:root:\t\t\t\t\t{\n",
      "DEBUG:root:\t\t\t\t\t//------------------------\n",
      "DEBUG:root:\t\t\t\t\t// size: 256\n",
      "DEBUG:root:\t\t\t\t\t//------------------------\n",
      "\n",
      "DEBUG:root:\t\t\tper_layer_anchor_sizes = []\n",
      "DEBUG:root:\n",
      "\t\t\t\t\tfor scale_per_octave in range(scales_per_octave=3) { // BEGIN\n",
      "DEBUG:root:\t\t\t\t\t\t{\n",
      "DEBUG:root:\t\t\t\t\t\t// ------------------------\n",
      "DEBUG:root:\t\t\t\t\t\t// scale_per_octave: 0, octave: 2.0\n",
      "DEBUG:root:\t\t\t\t\t\t// ------------------------\n",
      "DEBUG:root:\t\t\t\t\t\toctave_scale = octave ** (scale_per_octave / float(scales_per_octave))\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t// octave_scale: 1.0\n",
      "DEBUG:root:\t\t\t\t\t\t// size: 256\n",
      "DEBUG:root:\t\t\t\t\t\tper_layer_anchor_sizes.append(octave_scale * size)\n",
      "DEBUG:root:\t\t\t\t\t\t// per_layer_anchor_sizes[-1]: 256.0\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t}\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t{\n",
      "DEBUG:root:\t\t\t\t\t\t// ------------------------\n",
      "DEBUG:root:\t\t\t\t\t\t// scale_per_octave: 1, octave: 2.0\n",
      "DEBUG:root:\t\t\t\t\t\t// ------------------------\n",
      "DEBUG:root:\t\t\t\t\t\toctave_scale = octave ** (scale_per_octave / float(scales_per_octave))\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t// octave_scale: 1.2599210498948732\n",
      "DEBUG:root:\t\t\t\t\t\t// size: 256\n",
      "DEBUG:root:\t\t\t\t\t\tper_layer_anchor_sizes.append(octave_scale * size)\n",
      "DEBUG:root:\t\t\t\t\t\t// per_layer_anchor_sizes[-1]: 322.53978877308754\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t}\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t{\n",
      "DEBUG:root:\t\t\t\t\t\t// ------------------------\n",
      "DEBUG:root:\t\t\t\t\t\t// scale_per_octave: 2, octave: 2.0\n",
      "DEBUG:root:\t\t\t\t\t\t// ------------------------\n",
      "DEBUG:root:\t\t\t\t\t\toctave_scale = octave ** (scale_per_octave / float(scales_per_octave))\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t// octave_scale: 1.5874010519681994\n",
      "DEBUG:root:\t\t\t\t\t\t// size: 256\n",
      "DEBUG:root:\t\t\t\t\t\tper_layer_anchor_sizes.append(octave_scale * size)\n",
      "DEBUG:root:\t\t\t\t\t\t// per_layer_anchor_sizes[-1]: 406.37466930385904\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t}\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t} // END for scale_per_octave in range(scales_per_octave)\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tnew_anchor_sizes.append(tuple(per_layer_anchor_sizes))\n",
      "DEBUG:root:\t\t\t\t\t// new_anchor_sizes[-1]: (256.0, 322.53978877308754, 406.37466930385904)\n",
      "DEBUG:root:\t\t\t\t\t}\n",
      "DEBUG:root:\t\t\t\t\t{\n",
      "DEBUG:root:\t\t\t\t\t//------------------------\n",
      "DEBUG:root:\t\t\t\t\t// size: 512\n",
      "DEBUG:root:\t\t\t\t\t//------------------------\n",
      "\n",
      "DEBUG:root:\t\t\tper_layer_anchor_sizes = []\n",
      "DEBUG:root:\n",
      "\t\t\t\t\tfor scale_per_octave in range(scales_per_octave=3) { // BEGIN\n",
      "DEBUG:root:\t\t\t\t\t\t{\n",
      "DEBUG:root:\t\t\t\t\t\t// ------------------------\n",
      "DEBUG:root:\t\t\t\t\t\t// scale_per_octave: 0, octave: 2.0\n",
      "DEBUG:root:\t\t\t\t\t\t// ------------------------\n",
      "DEBUG:root:\t\t\t\t\t\toctave_scale = octave ** (scale_per_octave / float(scales_per_octave))\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t// octave_scale: 1.0\n",
      "DEBUG:root:\t\t\t\t\t\t// size: 512\n",
      "DEBUG:root:\t\t\t\t\t\tper_layer_anchor_sizes.append(octave_scale * size)\n",
      "DEBUG:root:\t\t\t\t\t\t// per_layer_anchor_sizes[-1]: 512.0\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t}\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t{\n",
      "DEBUG:root:\t\t\t\t\t\t// ------------------------\n",
      "DEBUG:root:\t\t\t\t\t\t// scale_per_octave: 1, octave: 2.0\n",
      "DEBUG:root:\t\t\t\t\t\t// ------------------------\n",
      "DEBUG:root:\t\t\t\t\t\toctave_scale = octave ** (scale_per_octave / float(scales_per_octave))\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t// octave_scale: 1.2599210498948732\n",
      "DEBUG:root:\t\t\t\t\t\t// size: 512\n",
      "DEBUG:root:\t\t\t\t\t\tper_layer_anchor_sizes.append(octave_scale * size)\n",
      "DEBUG:root:\t\t\t\t\t\t// per_layer_anchor_sizes[-1]: 645.0795775461751\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t}\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t{\n",
      "DEBUG:root:\t\t\t\t\t\t// ------------------------\n",
      "DEBUG:root:\t\t\t\t\t\t// scale_per_octave: 2, octave: 2.0\n",
      "DEBUG:root:\t\t\t\t\t\t// ------------------------\n",
      "DEBUG:root:\t\t\t\t\t\toctave_scale = octave ** (scale_per_octave / float(scales_per_octave))\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t// octave_scale: 1.5874010519681994\n",
      "DEBUG:root:\t\t\t\t\t\t// size: 512\n",
      "DEBUG:root:\t\t\t\t\t\tper_layer_anchor_sizes.append(octave_scale * size)\n",
      "DEBUG:root:\t\t\t\t\t\t// per_layer_anchor_sizes[-1]: 812.7493386077181\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t}\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t} // END for scale_per_octave in range(scales_per_octave)\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tnew_anchor_sizes.append(tuple(per_layer_anchor_sizes))\n",
      "DEBUG:root:\t\t\t\t\t// new_anchor_sizes[-1]: (512.0, 645.0795775461751, 812.7493386077181)\n",
      "DEBUG:root:\t\t\t\t\t}\n",
      "DEBUG:root:\n",
      "\t\t\t\t} // END for size in anchor_sizes\n",
      "\n",
      "DEBUG:root:\t\t\t\tnew_anchor_sizes:[(32.0, 40.31747359663594, 50.79683366298238), (64.0, 80.63494719327188, 101.59366732596476), (128.0, 161.26989438654377, 203.18733465192952), (256.0, 322.53978877308754, 406.37466930385904), (512.0, 645.0795775461751, 812.7493386077181)]\n",
      "DEBUG:root:\t\t\t\taspect_ratios:(0.5, 1.0, 2.0)\n",
      "DEBUG:root:\t\t\t\tanchor_strides:(8, 16, 32, 64, 128)\n",
      "DEBUG:root:\t\t\t\tstraddle_thresh:-1\n",
      "DEBUG:root:\t\t\t\tanchor_generator = AnchorGenerator( tuple(new_anchor_sizes), aspect_ratios, anchor_strides, straddle_thresh ) { //CALL\n",
      "DEBUG:root:\t\tAnchorGenerator.__init__(sizes, aspect_ratios, anchor_strides, straddle_thresh) { //BEGIN\n",
      "DEBUG:root:\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "\n",
      "DEBUG:root:\t\t\t// Params\n",
      "DEBUG:root:\t\t\t\t// sizes: ((32.0, 40.31747359663594, 50.79683366298238), (64.0, 80.63494719327188, 101.59366732596476), (128.0, 161.26989438654377, 203.18733465192952), (256.0, 322.53978877308754, 406.37466930385904), (512.0, 645.0795775461751, 812.7493386077181))\n",
      "DEBUG:root:\t\t\t\t// aspect_ratios: (0.5, 1.0, 2.0)\n",
      "DEBUG:root:\t\t\t\t// anchor_strides: (8, 16, 32, 64, 128)\n",
      "DEBUG:root:\t\t\t\t// straddle_thresh: -1\n",
      "\n",
      "DEBUG:root:\t\tif len(anchor_strides) == 1: \n",
      "DEBUG:root:\t\telse: i.e, len(anchor_strides) !=1\n",
      "DEBUG:root:\t\t\tanchor_stride = anchor_strides[0]\n",
      "DEBUG:root:\t\t\tlen(anchor_strides):5, len(size): 5\n",
      "DEBUG:root:\t\telse: i.e, len(anchor_strides) == len(sizes)\n",
      "DEBUG:root:\t\tcell_anchors = [ generate_anchors( anchor_stride,\n",
      "DEBUG:root:\t\t                 size if isinstance(size, (tuple, list)) else (size,), \n",
      "DEBUG:root:\t\t                 aspect_ratios).float()\n",
      "DEBUG:root:\t\tfor anchor_stride, size in zip(anchor_strides, sizes)\n",
      "DEBUG:root:\t\t\t\tgenerate_anchors(stride, sizes, aspect_ratios) { //BEGIN\n",
      "DEBUG:root:\t\t\t//defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t\t// Params:\n",
      "DEBUG:root:\t\t\t\t\t\t// stride: 8\n",
      "DEBUG:root:\t\t\t\t\t\t// sizes: (32.0, 40.31747359663594, 50.79683366298238)\n",
      "DEBUG:root:\t\t\t\t\t\t// aspect_ratios: (0.5, 1.0, 2.0)\n",
      "\n",
      "DEBUG:root:\t\t\t\t\treturn _generate_anchors(stride,\n",
      "DEBUG:root:\t\t\t\t\t\t     np.array(sizes, dtype=np.float) / stride,\n",
      "DEBUG:root:\t\t\t\t\t\t     np.array(aspect_ratios, dtype=np.float),)\n",
      "DEBUG:root:\t\t\t\t\t\t_generate_anchors(base_size, scales, aspect_ratios) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t\t// Params:\n",
      "DEBUG:root:\t\t\t\t\t\t\t\t// base_size: 8\n",
      "DEBUG:root:\t\t\t\t\t\t\t\t// scales: [4.         5.0396842  6.34960421]\n",
      "DEBUG:root:\t\t\t\t\t\t\t\t// aspect_ratios: [0.5 1.  2. ]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\tanchor = np.array([1, 1, base_size, base_size], dtype=np.float) - 1\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [0. 0. 7. 7.]\n",
      "DEBUG:root:\t\t\t\t_ratio_enum(anchor, ratios) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t// Params:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [0. 0. 7. 7.]\n",
      "DEBUG:root:\t\t\t\t\t\t// ratios: [0.5 1.  2. ]\n",
      "\n",
      "DEBUG:root:\t\t\t\t_whctrs(anchors) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [0. 0. 7. 7.]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\tw = anchor[2] - anchor[0] + 1\n",
      "DEBUG:root:\t\t\t\t\t\tw: 8.0\n",
      "DEBUG:root:\t\t\t\t\t\th = anchor[3] - anchor[1] + 1\n",
      "DEBUG:root:\t\t\t\t\t\th: 8.0\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr = anchor[0] + 0.5 * (w - 1)\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr: 3.5\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr = anchor[1] + 0.5 * (h - 1)\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr: 3.5\n",
      "DEBUG:root:\t\t\t\t\t\treturn w, h, x_ctr, y_ctr\n",
      "DEBUG:root:\t\t\t\t\t} // END _whctrs(anchors)\n",
      "DEBUG:root:\t\t\t\t\tw, h, x_ctr, y_ctr = _whctrs(anchor)\n",
      "DEBUG:root:\t\t\t\t\t// w: 8.0, h: 8.0, x_ctr: 3.5, y_ctr: 3.5\n",
      "DEBUG:root:\t\t\t\t\tsize = w * h\n",
      "DEBUG:root:\t\t\t\t\t// size: 64.0\n",
      "DEBUG:root:\t\t\t\t\tsize_ratios = size / ratios\n",
      "DEBUG:root:\t\t\t\t\t// size_ratios: [128.  64.  32.]\n",
      "DEBUG:root:\t\t\t\t\tws = np.round(np.sqrt(size_ratios))\n",
      "DEBUG:root:\t\t\t\t\t// ws: [11.  8.  6.]\n",
      "DEBUG:root:\t\t\t\t\ths = np.round(ws * ratios)\n",
      "DEBUG:root:\t\t\t\t\t// hs: [ 6.  8. 12.]\n",
      "DEBUG:root:\t\t\t_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN\n",
      "DEBUG:root:\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t// ws: [11.  8.  6.]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [ 6.  8. 12.]\n",
      "DEBUG:root:\t\t\t\t\t// x_ctr: 3.5\n",
      "DEBUG:root:\t\t\t\t\t// y_ctr: 3.5\n",
      "\n",
      "DEBUG:root:\t\t\t\tws = ws[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// ws: [[11.]\n",
      " [ 8.]\n",
      " [ 6.]]\n",
      "DEBUG:root:\t\t\t\ths = hs[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [[ 6.]\n",
      " [ 8.]\n",
      " [12.]]\n",
      "DEBUG:root:\t\t\t\tanchors = np.hstack(\n",
      "DEBUG:root:\t\t\t\t    (\n",
      "DEBUG:root:\t\t\t\t        x_ctr - 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr - 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t        x_ctr + 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr + 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t    )\n",
      "DEBUG:root:\t\t\t\t)\n",
      "DEBUG:root:\t\t\t\t// anchors: [[-1.5  1.   8.5  6. ]\n",
      " [ 0.   0.   7.   7. ]\n",
      " [ 1.  -2.   6.   9. ]]\n",
      "\n",
      "DEBUG:root:\t\t\t\treturn anchors\n",
      "DEBUG:root:\t\t\t} // END _mkanchors(ws, hs, x_ctr, y_ctr)\n",
      "DEBUG:root:\t\t\t\t\tanchors = _mkanchors(ws, hs, x_ctr, y_ctr)\n",
      "DEBUG:root:\t\t\t\t\t// anchors: [[-1.5  1.   8.5  6. ]\n",
      " [ 0.   0.   7.   7. ]\n",
      " [ 1.  -2.   6.   9. ]]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\treturn anchors\n",
      "DEBUG:root:\t\t\t\t} // END _ratio_enum(anchor, ratios)\n",
      "DEBUG:root:\t\t\t\t\t\tanchors = _ratio_enum(anchor, aspect_ratios)\n",
      "DEBUG:root:\t\t\t\t\t\t// anchors: [[-1.5  1.   8.5  6. ]\n",
      " [ 0.   0.   7.   7. ]\n",
      " [ 1.  -2.   6.   9. ]]\n",
      "DEBUG:root:\t\t\t\t\t\tanchors = np.vstack(\n",
      "DEBUG:root:\t\t\t\t\t\t[_scale_enum(anchors[i, :], scales) for i in range(anchors.shape[0])]\n",
      "DEBUG:root:\t\t\t\t\t\t)\n",
      "DEBUG:root:\t\t\t\t\t_scale_enum(anchor, scales) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [-1.5  1.   8.5  6. ]\n",
      "DEBUG:root:\t\t\t\t\t\t// scales: [4.         5.0396842  6.34960421]\n",
      "\n",
      "DEBUG:root:\t\t\t\t_whctrs(anchors) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [-1.5  1.   8.5  6. ]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\tw = anchor[2] - anchor[0] + 1\n",
      "DEBUG:root:\t\t\t\t\t\tw: 11.0\n",
      "DEBUG:root:\t\t\t\t\t\th = anchor[3] - anchor[1] + 1\n",
      "DEBUG:root:\t\t\t\t\t\th: 6.0\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr = anchor[0] + 0.5 * (w - 1)\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr: 3.5\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr = anchor[1] + 0.5 * (h - 1)\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr: 3.5\n",
      "DEBUG:root:\t\t\t\t\t\treturn w, h, x_ctr, y_ctr\n",
      "DEBUG:root:\t\t\t\t\t} // END _whctrs(anchors)\n",
      "DEBUG:root:\t\t\t\t\tw, h, x_ctr, y_ctr = _whctrs(anchor)\n",
      "DEBUG:root:\t\t\t\t\t// w: 11.0, h: 6.0, x_ctr: 3.5, y_ctr: 3.5\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tws = w * scales\n",
      "DEBUG:root:\t\t\t\t\t// ws: [44.         55.4365262  69.84564629]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\ths = h * scales\n",
      "DEBUG:root:\t\t\t\t\t// hs: [24.         30.2381052  38.09762525]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tanchors = _mkanchors(ws, hs, x_ctr, y_ctr) { // CALL\n",
      "DEBUG:root:\t\t\t_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN\n",
      "DEBUG:root:\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t// ws: [44.         55.4365262  69.84564629]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [24.         30.2381052  38.09762525]\n",
      "DEBUG:root:\t\t\t\t\t// x_ctr: 3.5\n",
      "DEBUG:root:\t\t\t\t\t// y_ctr: 3.5\n",
      "\n",
      "DEBUG:root:\t\t\t\tws = ws[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// ws: [[44.        ]\n",
      " [55.4365262 ]\n",
      " [69.84564629]]\n",
      "DEBUG:root:\t\t\t\ths = hs[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [[24.        ]\n",
      " [30.2381052 ]\n",
      " [38.09762525]]\n",
      "DEBUG:root:\t\t\t\tanchors = np.hstack(\n",
      "DEBUG:root:\t\t\t\t    (\n",
      "DEBUG:root:\t\t\t\t        x_ctr - 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr - 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t        x_ctr + 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr + 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t    )\n",
      "DEBUG:root:\t\t\t\t)\n",
      "DEBUG:root:\t\t\t\t// anchors: [[-18.          -8.          25.          15.        ]\n",
      " [-23.7182631  -11.1190526   30.7182631   18.1190526 ]\n",
      " [-30.92282314 -15.04881262  37.92282314  22.04881262]]\n",
      "\n",
      "DEBUG:root:\t\t\t\treturn anchors\n",
      "DEBUG:root:\t\t\t} // END _mkanchors(ws, hs, x_ctr, y_ctr)\n",
      "DEBUG:root:\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t}anchors = _mkanchors(ws, hs, x_ctr, y_ctr) // RETURNED\n",
      "DEBUG:root:\t\t\t\t\t// anchors: [[-18.          -8.          25.          15.        ]\n",
      " [-23.7182631  -11.1190526   30.7182631   18.1190526 ]\n",
      " [-30.92282314 -15.04881262  37.92282314  22.04881262]]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\treturn anchors: [[-18.          -8.          25.          15.        ]\n",
      " [-23.7182631  -11.1190526   30.7182631   18.1190526 ]\n",
      " [-30.92282314 -15.04881262  37.92282314  22.04881262]]\n",
      "DEBUG:root:\t\t\t\t} // END _scale_enum(anchor, scales)\n",
      "DEBUG:root:\t\t\t\t\t_scale_enum(anchor, scales) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [0. 0. 7. 7.]\n",
      "DEBUG:root:\t\t\t\t\t\t// scales: [4.         5.0396842  6.34960421]\n",
      "\n",
      "DEBUG:root:\t\t\t\t_whctrs(anchors) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [0. 0. 7. 7.]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\tw = anchor[2] - anchor[0] + 1\n",
      "DEBUG:root:\t\t\t\t\t\tw: 8.0\n",
      "DEBUG:root:\t\t\t\t\t\th = anchor[3] - anchor[1] + 1\n",
      "DEBUG:root:\t\t\t\t\t\th: 8.0\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr = anchor[0] + 0.5 * (w - 1)\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr: 3.5\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr = anchor[1] + 0.5 * (h - 1)\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr: 3.5\n",
      "DEBUG:root:\t\t\t\t\t\treturn w, h, x_ctr, y_ctr\n",
      "DEBUG:root:\t\t\t\t\t} // END _whctrs(anchors)\n",
      "DEBUG:root:\t\t\t\t\tw, h, x_ctr, y_ctr = _whctrs(anchor)\n",
      "DEBUG:root:\t\t\t\t\t// w: 8.0, h: 8.0, x_ctr: 3.5, y_ctr: 3.5\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tws = w * scales\n",
      "DEBUG:root:\t\t\t\t\t// ws: [32.         40.3174736  50.79683366]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\ths = h * scales\n",
      "DEBUG:root:\t\t\t\t\t// hs: [32.         40.3174736  50.79683366]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tanchors = _mkanchors(ws, hs, x_ctr, y_ctr) { // CALL\n",
      "DEBUG:root:\t\t\t_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN\n",
      "DEBUG:root:\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t// ws: [32.         40.3174736  50.79683366]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [32.         40.3174736  50.79683366]\n",
      "DEBUG:root:\t\t\t\t\t// x_ctr: 3.5\n",
      "DEBUG:root:\t\t\t\t\t// y_ctr: 3.5\n",
      "\n",
      "DEBUG:root:\t\t\t\tws = ws[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// ws: [[32.        ]\n",
      " [40.3174736 ]\n",
      " [50.79683366]]\n",
      "DEBUG:root:\t\t\t\ths = hs[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [[32.        ]\n",
      " [40.3174736 ]\n",
      " [50.79683366]]\n",
      "DEBUG:root:\t\t\t\tanchors = np.hstack(\n",
      "DEBUG:root:\t\t\t\t    (\n",
      "DEBUG:root:\t\t\t\t        x_ctr - 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr - 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t        x_ctr + 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr + 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t    )\n",
      "DEBUG:root:\t\t\t\t)\n",
      "DEBUG:root:\t\t\t\t// anchors: [[-12.         -12.          19.          19.        ]\n",
      " [-16.1587368  -16.1587368   23.1587368   23.1587368 ]\n",
      " [-21.39841683 -21.39841683  28.39841683  28.39841683]]\n",
      "\n",
      "DEBUG:root:\t\t\t\treturn anchors\n",
      "DEBUG:root:\t\t\t} // END _mkanchors(ws, hs, x_ctr, y_ctr)\n",
      "DEBUG:root:\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t}anchors = _mkanchors(ws, hs, x_ctr, y_ctr) // RETURNED\n",
      "DEBUG:root:\t\t\t\t\t// anchors: [[-12.         -12.          19.          19.        ]\n",
      " [-16.1587368  -16.1587368   23.1587368   23.1587368 ]\n",
      " [-21.39841683 -21.39841683  28.39841683  28.39841683]]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\treturn anchors: [[-12.         -12.          19.          19.        ]\n",
      " [-16.1587368  -16.1587368   23.1587368   23.1587368 ]\n",
      " [-21.39841683 -21.39841683  28.39841683  28.39841683]]\n",
      "DEBUG:root:\t\t\t\t} // END _scale_enum(anchor, scales)\n",
      "DEBUG:root:\t\t\t\t\t_scale_enum(anchor, scales) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [ 1. -2.  6.  9.]\n",
      "DEBUG:root:\t\t\t\t\t\t// scales: [4.         5.0396842  6.34960421]\n",
      "\n",
      "DEBUG:root:\t\t\t\t_whctrs(anchors) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [ 1. -2.  6.  9.]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\tw = anchor[2] - anchor[0] + 1\n",
      "DEBUG:root:\t\t\t\t\t\tw: 6.0\n",
      "DEBUG:root:\t\t\t\t\t\th = anchor[3] - anchor[1] + 1\n",
      "DEBUG:root:\t\t\t\t\t\th: 12.0\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr = anchor[0] + 0.5 * (w - 1)\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr: 3.5\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr = anchor[1] + 0.5 * (h - 1)\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr: 3.5\n",
      "DEBUG:root:\t\t\t\t\t\treturn w, h, x_ctr, y_ctr\n",
      "DEBUG:root:\t\t\t\t\t} // END _whctrs(anchors)\n",
      "DEBUG:root:\t\t\t\t\tw, h, x_ctr, y_ctr = _whctrs(anchor)\n",
      "DEBUG:root:\t\t\t\t\t// w: 6.0, h: 12.0, x_ctr: 3.5, y_ctr: 3.5\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tws = w * scales\n",
      "DEBUG:root:\t\t\t\t\t// ws: [24.         30.2381052  38.09762525]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\ths = h * scales\n",
      "DEBUG:root:\t\t\t\t\t// hs: [48.         60.47621039 76.19525049]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tanchors = _mkanchors(ws, hs, x_ctr, y_ctr) { // CALL\n",
      "DEBUG:root:\t\t\t_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN\n",
      "DEBUG:root:\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t// ws: [24.         30.2381052  38.09762525]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [48.         60.47621039 76.19525049]\n",
      "DEBUG:root:\t\t\t\t\t// x_ctr: 3.5\n",
      "DEBUG:root:\t\t\t\t\t// y_ctr: 3.5\n",
      "\n",
      "DEBUG:root:\t\t\t\tws = ws[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// ws: [[24.        ]\n",
      " [30.2381052 ]\n",
      " [38.09762525]]\n",
      "DEBUG:root:\t\t\t\ths = hs[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [[48.        ]\n",
      " [60.47621039]\n",
      " [76.19525049]]\n",
      "DEBUG:root:\t\t\t\tanchors = np.hstack(\n",
      "DEBUG:root:\t\t\t\t    (\n",
      "DEBUG:root:\t\t\t\t        x_ctr - 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr - 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t        x_ctr + 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr + 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t    )\n",
      "DEBUG:root:\t\t\t\t)\n",
      "DEBUG:root:\t\t\t\t// anchors: [[ -8.         -20.          15.          27.        ]\n",
      " [-11.1190526  -26.2381052   18.1190526   33.2381052 ]\n",
      " [-15.04881262 -34.09762525  22.04881262  41.09762525]]\n",
      "\n",
      "DEBUG:root:\t\t\t\treturn anchors\n",
      "DEBUG:root:\t\t\t} // END _mkanchors(ws, hs, x_ctr, y_ctr)\n",
      "DEBUG:root:\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t}anchors = _mkanchors(ws, hs, x_ctr, y_ctr) // RETURNED\n",
      "DEBUG:root:\t\t\t\t\t// anchors: [[ -8.         -20.          15.          27.        ]\n",
      " [-11.1190526  -26.2381052   18.1190526   33.2381052 ]\n",
      " [-15.04881262 -34.09762525  22.04881262  41.09762525]]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\treturn anchors: [[ -8.         -20.          15.          27.        ]\n",
      " [-11.1190526  -26.2381052   18.1190526   33.2381052 ]\n",
      " [-15.04881262 -34.09762525  22.04881262  41.09762525]]\n",
      "DEBUG:root:\t\t\t\t} // END _scale_enum(anchor, scales)\n",
      "DEBUG:root:\t\t\t\t\t\t// anchors: [[-18.          -8.          25.          15.        ]\n",
      " [-23.7182631  -11.1190526   30.7182631   18.1190526 ]\n",
      " [-30.92282314 -15.04881262  37.92282314  22.04881262]\n",
      " [-12.         -12.          19.          19.        ]\n",
      " [-16.1587368  -16.1587368   23.1587368   23.1587368 ]\n",
      " [-21.39841683 -21.39841683  28.39841683  28.39841683]\n",
      " [ -8.         -20.          15.          27.        ]\n",
      " [-11.1190526  -26.2381052   18.1190526   33.2381052 ]\n",
      " [-15.04881262 -34.09762525  22.04881262  41.09762525]]\n",
      "DEBUG:root:\t\t\t\t\t\t\treturn torch.from_numpy(anchors)\n",
      "DEBUG:root:\t\t\t\t\t\t} // END _generate_anchors(base_size, scales, apect_ratios) END\n",
      "DEBUG:root:\t\t\t\t\t} // END generate_anchors(stride, sizes, aspect_ratios)\n",
      "DEBUG:root:\t\t\t\tgenerate_anchors(stride, sizes, aspect_ratios) { //BEGIN\n",
      "DEBUG:root:\t\t\t//defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t\t// Params:\n",
      "DEBUG:root:\t\t\t\t\t\t// stride: 16\n",
      "DEBUG:root:\t\t\t\t\t\t// sizes: (64.0, 80.63494719327188, 101.59366732596476)\n",
      "DEBUG:root:\t\t\t\t\t\t// aspect_ratios: (0.5, 1.0, 2.0)\n",
      "\n",
      "DEBUG:root:\t\t\t\t\treturn _generate_anchors(stride,\n",
      "DEBUG:root:\t\t\t\t\t\t     np.array(sizes, dtype=np.float) / stride,\n",
      "DEBUG:root:\t\t\t\t\t\t     np.array(aspect_ratios, dtype=np.float),)\n",
      "DEBUG:root:\t\t\t\t\t\t_generate_anchors(base_size, scales, aspect_ratios) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t\t// Params:\n",
      "DEBUG:root:\t\t\t\t\t\t\t\t// base_size: 16\n",
      "DEBUG:root:\t\t\t\t\t\t\t\t// scales: [4.         5.0396842  6.34960421]\n",
      "DEBUG:root:\t\t\t\t\t\t\t\t// aspect_ratios: [0.5 1.  2. ]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\tanchor = np.array([1, 1, base_size, base_size], dtype=np.float) - 1\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [ 0.  0. 15. 15.]\n",
      "DEBUG:root:\t\t\t\t_ratio_enum(anchor, ratios) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t// Params:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [ 0.  0. 15. 15.]\n",
      "DEBUG:root:\t\t\t\t\t\t// ratios: [0.5 1.  2. ]\n",
      "\n",
      "DEBUG:root:\t\t\t\t_whctrs(anchors) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [ 0.  0. 15. 15.]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\tw = anchor[2] - anchor[0] + 1\n",
      "DEBUG:root:\t\t\t\t\t\tw: 16.0\n",
      "DEBUG:root:\t\t\t\t\t\th = anchor[3] - anchor[1] + 1\n",
      "DEBUG:root:\t\t\t\t\t\th: 16.0\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr = anchor[0] + 0.5 * (w - 1)\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr: 7.5\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr = anchor[1] + 0.5 * (h - 1)\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr: 7.5\n",
      "DEBUG:root:\t\t\t\t\t\treturn w, h, x_ctr, y_ctr\n",
      "DEBUG:root:\t\t\t\t\t} // END _whctrs(anchors)\n",
      "DEBUG:root:\t\t\t\t\tw, h, x_ctr, y_ctr = _whctrs(anchor)\n",
      "DEBUG:root:\t\t\t\t\t// w: 16.0, h: 16.0, x_ctr: 7.5, y_ctr: 7.5\n",
      "DEBUG:root:\t\t\t\t\tsize = w * h\n",
      "DEBUG:root:\t\t\t\t\t// size: 256.0\n",
      "DEBUG:root:\t\t\t\t\tsize_ratios = size / ratios\n",
      "DEBUG:root:\t\t\t\t\t// size_ratios: [512. 256. 128.]\n",
      "DEBUG:root:\t\t\t\t\tws = np.round(np.sqrt(size_ratios))\n",
      "DEBUG:root:\t\t\t\t\t// ws: [23. 16. 11.]\n",
      "DEBUG:root:\t\t\t\t\ths = np.round(ws * ratios)\n",
      "DEBUG:root:\t\t\t\t\t// hs: [12. 16. 22.]\n",
      "DEBUG:root:\t\t\t_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN\n",
      "DEBUG:root:\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t// ws: [23. 16. 11.]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [12. 16. 22.]\n",
      "DEBUG:root:\t\t\t\t\t// x_ctr: 7.5\n",
      "DEBUG:root:\t\t\t\t\t// y_ctr: 7.5\n",
      "\n",
      "DEBUG:root:\t\t\t\tws = ws[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// ws: [[23.]\n",
      " [16.]\n",
      " [11.]]\n",
      "DEBUG:root:\t\t\t\ths = hs[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [[12.]\n",
      " [16.]\n",
      " [22.]]\n",
      "DEBUG:root:\t\t\t\tanchors = np.hstack(\n",
      "DEBUG:root:\t\t\t\t    (\n",
      "DEBUG:root:\t\t\t\t        x_ctr - 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr - 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t        x_ctr + 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr + 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t    )\n",
      "DEBUG:root:\t\t\t\t)\n",
      "DEBUG:root:\t\t\t\t// anchors: [[-3.5  2.  18.5 13. ]\n",
      " [ 0.   0.  15.  15. ]\n",
      " [ 2.5 -3.  12.5 18. ]]\n",
      "\n",
      "DEBUG:root:\t\t\t\treturn anchors\n",
      "DEBUG:root:\t\t\t} // END _mkanchors(ws, hs, x_ctr, y_ctr)\n",
      "DEBUG:root:\t\t\t\t\tanchors = _mkanchors(ws, hs, x_ctr, y_ctr)\n",
      "DEBUG:root:\t\t\t\t\t// anchors: [[-3.5  2.  18.5 13. ]\n",
      " [ 0.   0.  15.  15. ]\n",
      " [ 2.5 -3.  12.5 18. ]]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\treturn anchors\n",
      "DEBUG:root:\t\t\t\t} // END _ratio_enum(anchor, ratios)\n",
      "DEBUG:root:\t\t\t\t\t\tanchors = _ratio_enum(anchor, aspect_ratios)\n",
      "DEBUG:root:\t\t\t\t\t\t// anchors: [[-3.5  2.  18.5 13. ]\n",
      " [ 0.   0.  15.  15. ]\n",
      " [ 2.5 -3.  12.5 18. ]]\n",
      "DEBUG:root:\t\t\t\t\t\tanchors = np.vstack(\n",
      "DEBUG:root:\t\t\t\t\t\t[_scale_enum(anchors[i, :], scales) for i in range(anchors.shape[0])]\n",
      "DEBUG:root:\t\t\t\t\t\t)\n",
      "DEBUG:root:\t\t\t\t\t_scale_enum(anchor, scales) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [-3.5  2.  18.5 13. ]\n",
      "DEBUG:root:\t\t\t\t\t\t// scales: [4.         5.0396842  6.34960421]\n",
      "\n",
      "DEBUG:root:\t\t\t\t_whctrs(anchors) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [-3.5  2.  18.5 13. ]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\tw = anchor[2] - anchor[0] + 1\n",
      "DEBUG:root:\t\t\t\t\t\tw: 23.0\n",
      "DEBUG:root:\t\t\t\t\t\th = anchor[3] - anchor[1] + 1\n",
      "DEBUG:root:\t\t\t\t\t\th: 12.0\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr = anchor[0] + 0.5 * (w - 1)\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr: 7.5\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr = anchor[1] + 0.5 * (h - 1)\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr: 7.5\n",
      "DEBUG:root:\t\t\t\t\t\treturn w, h, x_ctr, y_ctr\n",
      "DEBUG:root:\t\t\t\t\t} // END _whctrs(anchors)\n",
      "DEBUG:root:\t\t\t\t\tw, h, x_ctr, y_ctr = _whctrs(anchor)\n",
      "DEBUG:root:\t\t\t\t\t// w: 23.0, h: 12.0, x_ctr: 7.5, y_ctr: 7.5\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tws = w * scales\n",
      "DEBUG:root:\t\t\t\t\t// ws: [ 92.         115.91273659 146.04089678]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\ths = h * scales\n",
      "DEBUG:root:\t\t\t\t\t// hs: [48.         60.47621039 76.19525049]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tanchors = _mkanchors(ws, hs, x_ctr, y_ctr) { // CALL\n",
      "DEBUG:root:\t\t\t_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN\n",
      "DEBUG:root:\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t// ws: [ 92.         115.91273659 146.04089678]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [48.         60.47621039 76.19525049]\n",
      "DEBUG:root:\t\t\t\t\t// x_ctr: 7.5\n",
      "DEBUG:root:\t\t\t\t\t// y_ctr: 7.5\n",
      "\n",
      "DEBUG:root:\t\t\t\tws = ws[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// ws: [[ 92.        ]\n",
      " [115.91273659]\n",
      " [146.04089678]]\n",
      "DEBUG:root:\t\t\t\ths = hs[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [[48.        ]\n",
      " [60.47621039]\n",
      " [76.19525049]]\n",
      "DEBUG:root:\t\t\t\tanchors = np.hstack(\n",
      "DEBUG:root:\t\t\t\t    (\n",
      "DEBUG:root:\t\t\t\t        x_ctr - 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr - 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t        x_ctr + 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr + 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t    )\n",
      "DEBUG:root:\t\t\t\t)\n",
      "DEBUG:root:\t\t\t\t// anchors: [[-38.         -16.          53.          31.        ]\n",
      " [-49.9563683  -22.2381052   64.9563683   37.2381052 ]\n",
      " [-65.02044839 -30.09762525  80.02044839  45.09762525]]\n",
      "\n",
      "DEBUG:root:\t\t\t\treturn anchors\n",
      "DEBUG:root:\t\t\t} // END _mkanchors(ws, hs, x_ctr, y_ctr)\n",
      "DEBUG:root:\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t}anchors = _mkanchors(ws, hs, x_ctr, y_ctr) // RETURNED\n",
      "DEBUG:root:\t\t\t\t\t// anchors: [[-38.         -16.          53.          31.        ]\n",
      " [-49.9563683  -22.2381052   64.9563683   37.2381052 ]\n",
      " [-65.02044839 -30.09762525  80.02044839  45.09762525]]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\treturn anchors: [[-38.         -16.          53.          31.        ]\n",
      " [-49.9563683  -22.2381052   64.9563683   37.2381052 ]\n",
      " [-65.02044839 -30.09762525  80.02044839  45.09762525]]\n",
      "DEBUG:root:\t\t\t\t} // END _scale_enum(anchor, scales)\n",
      "DEBUG:root:\t\t\t\t\t_scale_enum(anchor, scales) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [ 0.  0. 15. 15.]\n",
      "DEBUG:root:\t\t\t\t\t\t// scales: [4.         5.0396842  6.34960421]\n",
      "\n",
      "DEBUG:root:\t\t\t\t_whctrs(anchors) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [ 0.  0. 15. 15.]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\tw = anchor[2] - anchor[0] + 1\n",
      "DEBUG:root:\t\t\t\t\t\tw: 16.0\n",
      "DEBUG:root:\t\t\t\t\t\th = anchor[3] - anchor[1] + 1\n",
      "DEBUG:root:\t\t\t\t\t\th: 16.0\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr = anchor[0] + 0.5 * (w - 1)\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr: 7.5\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr = anchor[1] + 0.5 * (h - 1)\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr: 7.5\n",
      "DEBUG:root:\t\t\t\t\t\treturn w, h, x_ctr, y_ctr\n",
      "DEBUG:root:\t\t\t\t\t} // END _whctrs(anchors)\n",
      "DEBUG:root:\t\t\t\t\tw, h, x_ctr, y_ctr = _whctrs(anchor)\n",
      "DEBUG:root:\t\t\t\t\t// w: 16.0, h: 16.0, x_ctr: 7.5, y_ctr: 7.5\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tws = w * scales\n",
      "DEBUG:root:\t\t\t\t\t// ws: [ 64.          80.63494719 101.59366733]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\ths = h * scales\n",
      "DEBUG:root:\t\t\t\t\t// hs: [ 64.          80.63494719 101.59366733]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tanchors = _mkanchors(ws, hs, x_ctr, y_ctr) { // CALL\n",
      "DEBUG:root:\t\t\t_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN\n",
      "DEBUG:root:\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t// ws: [ 64.          80.63494719 101.59366733]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [ 64.          80.63494719 101.59366733]\n",
      "DEBUG:root:\t\t\t\t\t// x_ctr: 7.5\n",
      "DEBUG:root:\t\t\t\t\t// y_ctr: 7.5\n",
      "\n",
      "DEBUG:root:\t\t\t\tws = ws[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// ws: [[ 64.        ]\n",
      " [ 80.63494719]\n",
      " [101.59366733]]\n",
      "DEBUG:root:\t\t\t\ths = hs[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [[ 64.        ]\n",
      " [ 80.63494719]\n",
      " [101.59366733]]\n",
      "DEBUG:root:\t\t\t\tanchors = np.hstack(\n",
      "DEBUG:root:\t\t\t\t    (\n",
      "DEBUG:root:\t\t\t\t        x_ctr - 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr - 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t        x_ctr + 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr + 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t    )\n",
      "DEBUG:root:\t\t\t\t)\n",
      "DEBUG:root:\t\t\t\t// anchors: [[-24.         -24.          39.          39.        ]\n",
      " [-32.3174736  -32.3174736   47.3174736   47.3174736 ]\n",
      " [-42.79683366 -42.79683366  57.79683366  57.79683366]]\n",
      "\n",
      "DEBUG:root:\t\t\t\treturn anchors\n",
      "DEBUG:root:\t\t\t} // END _mkanchors(ws, hs, x_ctr, y_ctr)\n",
      "DEBUG:root:\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t}anchors = _mkanchors(ws, hs, x_ctr, y_ctr) // RETURNED\n",
      "DEBUG:root:\t\t\t\t\t// anchors: [[-24.         -24.          39.          39.        ]\n",
      " [-32.3174736  -32.3174736   47.3174736   47.3174736 ]\n",
      " [-42.79683366 -42.79683366  57.79683366  57.79683366]]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\treturn anchors: [[-24.         -24.          39.          39.        ]\n",
      " [-32.3174736  -32.3174736   47.3174736   47.3174736 ]\n",
      " [-42.79683366 -42.79683366  57.79683366  57.79683366]]\n",
      "DEBUG:root:\t\t\t\t} // END _scale_enum(anchor, scales)\n",
      "DEBUG:root:\t\t\t\t\t_scale_enum(anchor, scales) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [ 2.5 -3.  12.5 18. ]\n",
      "DEBUG:root:\t\t\t\t\t\t// scales: [4.         5.0396842  6.34960421]\n",
      "\n",
      "DEBUG:root:\t\t\t\t_whctrs(anchors) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [ 2.5 -3.  12.5 18. ]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\tw = anchor[2] - anchor[0] + 1\n",
      "DEBUG:root:\t\t\t\t\t\tw: 11.0\n",
      "DEBUG:root:\t\t\t\t\t\th = anchor[3] - anchor[1] + 1\n",
      "DEBUG:root:\t\t\t\t\t\th: 22.0\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr = anchor[0] + 0.5 * (w - 1)\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr: 7.5\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr = anchor[1] + 0.5 * (h - 1)\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr: 7.5\n",
      "DEBUG:root:\t\t\t\t\t\treturn w, h, x_ctr, y_ctr\n",
      "DEBUG:root:\t\t\t\t\t} // END _whctrs(anchors)\n",
      "DEBUG:root:\t\t\t\t\tw, h, x_ctr, y_ctr = _whctrs(anchor)\n",
      "DEBUG:root:\t\t\t\t\t// w: 11.0, h: 22.0, x_ctr: 7.5, y_ctr: 7.5\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tws = w * scales\n",
      "DEBUG:root:\t\t\t\t\t// ws: [44.         55.4365262  69.84564629]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\ths = h * scales\n",
      "DEBUG:root:\t\t\t\t\t// hs: [ 88.         110.87305239 139.69129257]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tanchors = _mkanchors(ws, hs, x_ctr, y_ctr) { // CALL\n",
      "DEBUG:root:\t\t\t_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN\n",
      "DEBUG:root:\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t// ws: [44.         55.4365262  69.84564629]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [ 88.         110.87305239 139.69129257]\n",
      "DEBUG:root:\t\t\t\t\t// x_ctr: 7.5\n",
      "DEBUG:root:\t\t\t\t\t// y_ctr: 7.5\n",
      "\n",
      "DEBUG:root:\t\t\t\tws = ws[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// ws: [[44.        ]\n",
      " [55.4365262 ]\n",
      " [69.84564629]]\n",
      "DEBUG:root:\t\t\t\ths = hs[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [[ 88.        ]\n",
      " [110.87305239]\n",
      " [139.69129257]]\n",
      "DEBUG:root:\t\t\t\tanchors = np.hstack(\n",
      "DEBUG:root:\t\t\t\t    (\n",
      "DEBUG:root:\t\t\t\t        x_ctr - 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr - 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t        x_ctr + 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr + 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t    )\n",
      "DEBUG:root:\t\t\t\t)\n",
      "DEBUG:root:\t\t\t\t// anchors: [[-14.         -36.          29.          51.        ]\n",
      " [-19.7182631  -47.4365262   34.7182631   62.4365262 ]\n",
      " [-26.92282314 -61.84564629  41.92282314  76.84564629]]\n",
      "\n",
      "DEBUG:root:\t\t\t\treturn anchors\n",
      "DEBUG:root:\t\t\t} // END _mkanchors(ws, hs, x_ctr, y_ctr)\n",
      "DEBUG:root:\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t}anchors = _mkanchors(ws, hs, x_ctr, y_ctr) // RETURNED\n",
      "DEBUG:root:\t\t\t\t\t// anchors: [[-14.         -36.          29.          51.        ]\n",
      " [-19.7182631  -47.4365262   34.7182631   62.4365262 ]\n",
      " [-26.92282314 -61.84564629  41.92282314  76.84564629]]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\treturn anchors: [[-14.         -36.          29.          51.        ]\n",
      " [-19.7182631  -47.4365262   34.7182631   62.4365262 ]\n",
      " [-26.92282314 -61.84564629  41.92282314  76.84564629]]\n",
      "DEBUG:root:\t\t\t\t} // END _scale_enum(anchor, scales)\n",
      "DEBUG:root:\t\t\t\t\t\t// anchors: [[-38.         -16.          53.          31.        ]\n",
      " [-49.9563683  -22.2381052   64.9563683   37.2381052 ]\n",
      " [-65.02044839 -30.09762525  80.02044839  45.09762525]\n",
      " [-24.         -24.          39.          39.        ]\n",
      " [-32.3174736  -32.3174736   47.3174736   47.3174736 ]\n",
      " [-42.79683366 -42.79683366  57.79683366  57.79683366]\n",
      " [-14.         -36.          29.          51.        ]\n",
      " [-19.7182631  -47.4365262   34.7182631   62.4365262 ]\n",
      " [-26.92282314 -61.84564629  41.92282314  76.84564629]]\n",
      "DEBUG:root:\t\t\t\t\t\t\treturn torch.from_numpy(anchors)\n",
      "DEBUG:root:\t\t\t\t\t\t} // END _generate_anchors(base_size, scales, apect_ratios) END\n",
      "DEBUG:root:\t\t\t\t\t} // END generate_anchors(stride, sizes, aspect_ratios)\n",
      "DEBUG:root:\t\t\t\tgenerate_anchors(stride, sizes, aspect_ratios) { //BEGIN\n",
      "DEBUG:root:\t\t\t//defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t\t// Params:\n",
      "DEBUG:root:\t\t\t\t\t\t// stride: 32\n",
      "DEBUG:root:\t\t\t\t\t\t// sizes: (128.0, 161.26989438654377, 203.18733465192952)\n",
      "DEBUG:root:\t\t\t\t\t\t// aspect_ratios: (0.5, 1.0, 2.0)\n",
      "\n",
      "DEBUG:root:\t\t\t\t\treturn _generate_anchors(stride,\n",
      "DEBUG:root:\t\t\t\t\t\t     np.array(sizes, dtype=np.float) / stride,\n",
      "DEBUG:root:\t\t\t\t\t\t     np.array(aspect_ratios, dtype=np.float),)\n",
      "DEBUG:root:\t\t\t\t\t\t_generate_anchors(base_size, scales, aspect_ratios) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t\t// Params:\n",
      "DEBUG:root:\t\t\t\t\t\t\t\t// base_size: 32\n",
      "DEBUG:root:\t\t\t\t\t\t\t\t// scales: [4.         5.0396842  6.34960421]\n",
      "DEBUG:root:\t\t\t\t\t\t\t\t// aspect_ratios: [0.5 1.  2. ]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\tanchor = np.array([1, 1, base_size, base_size], dtype=np.float) - 1\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [ 0.  0. 31. 31.]\n",
      "DEBUG:root:\t\t\t\t_ratio_enum(anchor, ratios) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t// Params:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [ 0.  0. 31. 31.]\n",
      "DEBUG:root:\t\t\t\t\t\t// ratios: [0.5 1.  2. ]\n",
      "\n",
      "DEBUG:root:\t\t\t\t_whctrs(anchors) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [ 0.  0. 31. 31.]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\tw = anchor[2] - anchor[0] + 1\n",
      "DEBUG:root:\t\t\t\t\t\tw: 32.0\n",
      "DEBUG:root:\t\t\t\t\t\th = anchor[3] - anchor[1] + 1\n",
      "DEBUG:root:\t\t\t\t\t\th: 32.0\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr = anchor[0] + 0.5 * (w - 1)\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr: 15.5\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr = anchor[1] + 0.5 * (h - 1)\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr: 15.5\n",
      "DEBUG:root:\t\t\t\t\t\treturn w, h, x_ctr, y_ctr\n",
      "DEBUG:root:\t\t\t\t\t} // END _whctrs(anchors)\n",
      "DEBUG:root:\t\t\t\t\tw, h, x_ctr, y_ctr = _whctrs(anchor)\n",
      "DEBUG:root:\t\t\t\t\t// w: 32.0, h: 32.0, x_ctr: 15.5, y_ctr: 15.5\n",
      "DEBUG:root:\t\t\t\t\tsize = w * h\n",
      "DEBUG:root:\t\t\t\t\t// size: 1024.0\n",
      "DEBUG:root:\t\t\t\t\tsize_ratios = size / ratios\n",
      "DEBUG:root:\t\t\t\t\t// size_ratios: [2048. 1024.  512.]\n",
      "DEBUG:root:\t\t\t\t\tws = np.round(np.sqrt(size_ratios))\n",
      "DEBUG:root:\t\t\t\t\t// ws: [45. 32. 23.]\n",
      "DEBUG:root:\t\t\t\t\ths = np.round(ws * ratios)\n",
      "DEBUG:root:\t\t\t\t\t// hs: [22. 32. 46.]\n",
      "DEBUG:root:\t\t\t_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN\n",
      "DEBUG:root:\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t// ws: [45. 32. 23.]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [22. 32. 46.]\n",
      "DEBUG:root:\t\t\t\t\t// x_ctr: 15.5\n",
      "DEBUG:root:\t\t\t\t\t// y_ctr: 15.5\n",
      "\n",
      "DEBUG:root:\t\t\t\tws = ws[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// ws: [[45.]\n",
      " [32.]\n",
      " [23.]]\n",
      "DEBUG:root:\t\t\t\ths = hs[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [[22.]\n",
      " [32.]\n",
      " [46.]]\n",
      "DEBUG:root:\t\t\t\tanchors = np.hstack(\n",
      "DEBUG:root:\t\t\t\t    (\n",
      "DEBUG:root:\t\t\t\t        x_ctr - 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr - 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t        x_ctr + 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr + 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t    )\n",
      "DEBUG:root:\t\t\t\t)\n",
      "DEBUG:root:\t\t\t\t// anchors: [[-6.5  5.  37.5 26. ]\n",
      " [ 0.   0.  31.  31. ]\n",
      " [ 4.5 -7.  26.5 38. ]]\n",
      "\n",
      "DEBUG:root:\t\t\t\treturn anchors\n",
      "DEBUG:root:\t\t\t} // END _mkanchors(ws, hs, x_ctr, y_ctr)\n",
      "DEBUG:root:\t\t\t\t\tanchors = _mkanchors(ws, hs, x_ctr, y_ctr)\n",
      "DEBUG:root:\t\t\t\t\t// anchors: [[-6.5  5.  37.5 26. ]\n",
      " [ 0.   0.  31.  31. ]\n",
      " [ 4.5 -7.  26.5 38. ]]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\treturn anchors\n",
      "DEBUG:root:\t\t\t\t} // END _ratio_enum(anchor, ratios)\n",
      "DEBUG:root:\t\t\t\t\t\tanchors = _ratio_enum(anchor, aspect_ratios)\n",
      "DEBUG:root:\t\t\t\t\t\t// anchors: [[-6.5  5.  37.5 26. ]\n",
      " [ 0.   0.  31.  31. ]\n",
      " [ 4.5 -7.  26.5 38. ]]\n",
      "DEBUG:root:\t\t\t\t\t\tanchors = np.vstack(\n",
      "DEBUG:root:\t\t\t\t\t\t[_scale_enum(anchors[i, :], scales) for i in range(anchors.shape[0])]\n",
      "DEBUG:root:\t\t\t\t\t\t)\n",
      "DEBUG:root:\t\t\t\t\t_scale_enum(anchor, scales) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [-6.5  5.  37.5 26. ]\n",
      "DEBUG:root:\t\t\t\t\t\t// scales: [4.         5.0396842  6.34960421]\n",
      "\n",
      "DEBUG:root:\t\t\t\t_whctrs(anchors) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [-6.5  5.  37.5 26. ]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\tw = anchor[2] - anchor[0] + 1\n",
      "DEBUG:root:\t\t\t\t\t\tw: 45.0\n",
      "DEBUG:root:\t\t\t\t\t\th = anchor[3] - anchor[1] + 1\n",
      "DEBUG:root:\t\t\t\t\t\th: 22.0\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr = anchor[0] + 0.5 * (w - 1)\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr: 15.5\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr = anchor[1] + 0.5 * (h - 1)\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr: 15.5\n",
      "DEBUG:root:\t\t\t\t\t\treturn w, h, x_ctr, y_ctr\n",
      "DEBUG:root:\t\t\t\t\t} // END _whctrs(anchors)\n",
      "DEBUG:root:\t\t\t\t\tw, h, x_ctr, y_ctr = _whctrs(anchor)\n",
      "DEBUG:root:\t\t\t\t\t// w: 45.0, h: 22.0, x_ctr: 15.5, y_ctr: 15.5\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tws = w * scales\n",
      "DEBUG:root:\t\t\t\t\t// ws: [180.         226.78578898 285.73218935]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\ths = h * scales\n",
      "DEBUG:root:\t\t\t\t\t// hs: [ 88.         110.87305239 139.69129257]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tanchors = _mkanchors(ws, hs, x_ctr, y_ctr) { // CALL\n",
      "DEBUG:root:\t\t\t_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN\n",
      "DEBUG:root:\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t// ws: [180.         226.78578898 285.73218935]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [ 88.         110.87305239 139.69129257]\n",
      "DEBUG:root:\t\t\t\t\t// x_ctr: 15.5\n",
      "DEBUG:root:\t\t\t\t\t// y_ctr: 15.5\n",
      "\n",
      "DEBUG:root:\t\t\t\tws = ws[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// ws: [[180.        ]\n",
      " [226.78578898]\n",
      " [285.73218935]]\n",
      "DEBUG:root:\t\t\t\ths = hs[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [[ 88.        ]\n",
      " [110.87305239]\n",
      " [139.69129257]]\n",
      "DEBUG:root:\t\t\t\tanchors = np.hstack(\n",
      "DEBUG:root:\t\t\t\t    (\n",
      "DEBUG:root:\t\t\t\t        x_ctr - 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr - 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t        x_ctr + 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr + 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t    )\n",
      "DEBUG:root:\t\t\t\t)\n",
      "DEBUG:root:\t\t\t\t// anchors: [[ -74.          -28.          105.           59.        ]\n",
      " [ -97.39289449  -39.4365262   128.39289449   70.4365262 ]\n",
      " [-126.86609468  -53.84564629  157.86609468   84.84564629]]\n",
      "\n",
      "DEBUG:root:\t\t\t\treturn anchors\n",
      "DEBUG:root:\t\t\t} // END _mkanchors(ws, hs, x_ctr, y_ctr)\n",
      "DEBUG:root:\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t}anchors = _mkanchors(ws, hs, x_ctr, y_ctr) // RETURNED\n",
      "DEBUG:root:\t\t\t\t\t// anchors: [[ -74.          -28.          105.           59.        ]\n",
      " [ -97.39289449  -39.4365262   128.39289449   70.4365262 ]\n",
      " [-126.86609468  -53.84564629  157.86609468   84.84564629]]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\treturn anchors: [[ -74.          -28.          105.           59.        ]\n",
      " [ -97.39289449  -39.4365262   128.39289449   70.4365262 ]\n",
      " [-126.86609468  -53.84564629  157.86609468   84.84564629]]\n",
      "DEBUG:root:\t\t\t\t} // END _scale_enum(anchor, scales)\n",
      "DEBUG:root:\t\t\t\t\t_scale_enum(anchor, scales) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [ 0.  0. 31. 31.]\n",
      "DEBUG:root:\t\t\t\t\t\t// scales: [4.         5.0396842  6.34960421]\n",
      "\n",
      "DEBUG:root:\t\t\t\t_whctrs(anchors) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [ 0.  0. 31. 31.]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\tw = anchor[2] - anchor[0] + 1\n",
      "DEBUG:root:\t\t\t\t\t\tw: 32.0\n",
      "DEBUG:root:\t\t\t\t\t\th = anchor[3] - anchor[1] + 1\n",
      "DEBUG:root:\t\t\t\t\t\th: 32.0\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr = anchor[0] + 0.5 * (w - 1)\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr: 15.5\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr = anchor[1] + 0.5 * (h - 1)\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr: 15.5\n",
      "DEBUG:root:\t\t\t\t\t\treturn w, h, x_ctr, y_ctr\n",
      "DEBUG:root:\t\t\t\t\t} // END _whctrs(anchors)\n",
      "DEBUG:root:\t\t\t\t\tw, h, x_ctr, y_ctr = _whctrs(anchor)\n",
      "DEBUG:root:\t\t\t\t\t// w: 32.0, h: 32.0, x_ctr: 15.5, y_ctr: 15.5\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tws = w * scales\n",
      "DEBUG:root:\t\t\t\t\t// ws: [128.         161.26989439 203.18733465]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\ths = h * scales\n",
      "DEBUG:root:\t\t\t\t\t// hs: [128.         161.26989439 203.18733465]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tanchors = _mkanchors(ws, hs, x_ctr, y_ctr) { // CALL\n",
      "DEBUG:root:\t\t\t_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN\n",
      "DEBUG:root:\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t// ws: [128.         161.26989439 203.18733465]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [128.         161.26989439 203.18733465]\n",
      "DEBUG:root:\t\t\t\t\t// x_ctr: 15.5\n",
      "DEBUG:root:\t\t\t\t\t// y_ctr: 15.5\n",
      "\n",
      "DEBUG:root:\t\t\t\tws = ws[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// ws: [[128.        ]\n",
      " [161.26989439]\n",
      " [203.18733465]]\n",
      "DEBUG:root:\t\t\t\ths = hs[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [[128.        ]\n",
      " [161.26989439]\n",
      " [203.18733465]]\n",
      "DEBUG:root:\t\t\t\tanchors = np.hstack(\n",
      "DEBUG:root:\t\t\t\t    (\n",
      "DEBUG:root:\t\t\t\t        x_ctr - 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr - 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t        x_ctr + 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr + 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t    )\n",
      "DEBUG:root:\t\t\t\t)\n",
      "DEBUG:root:\t\t\t\t// anchors: [[-48.         -48.          79.          79.        ]\n",
      " [-64.63494719 -64.63494719  95.63494719  95.63494719]\n",
      " [-85.59366733 -85.59366733 116.59366733 116.59366733]]\n",
      "\n",
      "DEBUG:root:\t\t\t\treturn anchors\n",
      "DEBUG:root:\t\t\t} // END _mkanchors(ws, hs, x_ctr, y_ctr)\n",
      "DEBUG:root:\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t}anchors = _mkanchors(ws, hs, x_ctr, y_ctr) // RETURNED\n",
      "DEBUG:root:\t\t\t\t\t// anchors: [[-48.         -48.          79.          79.        ]\n",
      " [-64.63494719 -64.63494719  95.63494719  95.63494719]\n",
      " [-85.59366733 -85.59366733 116.59366733 116.59366733]]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\treturn anchors: [[-48.         -48.          79.          79.        ]\n",
      " [-64.63494719 -64.63494719  95.63494719  95.63494719]\n",
      " [-85.59366733 -85.59366733 116.59366733 116.59366733]]\n",
      "DEBUG:root:\t\t\t\t} // END _scale_enum(anchor, scales)\n",
      "DEBUG:root:\t\t\t\t\t_scale_enum(anchor, scales) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [ 4.5 -7.  26.5 38. ]\n",
      "DEBUG:root:\t\t\t\t\t\t// scales: [4.         5.0396842  6.34960421]\n",
      "\n",
      "DEBUG:root:\t\t\t\t_whctrs(anchors) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [ 4.5 -7.  26.5 38. ]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\tw = anchor[2] - anchor[0] + 1\n",
      "DEBUG:root:\t\t\t\t\t\tw: 23.0\n",
      "DEBUG:root:\t\t\t\t\t\th = anchor[3] - anchor[1] + 1\n",
      "DEBUG:root:\t\t\t\t\t\th: 46.0\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr = anchor[0] + 0.5 * (w - 1)\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr: 15.5\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr = anchor[1] + 0.5 * (h - 1)\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr: 15.5\n",
      "DEBUG:root:\t\t\t\t\t\treturn w, h, x_ctr, y_ctr\n",
      "DEBUG:root:\t\t\t\t\t} // END _whctrs(anchors)\n",
      "DEBUG:root:\t\t\t\t\tw, h, x_ctr, y_ctr = _whctrs(anchor)\n",
      "DEBUG:root:\t\t\t\t\t// w: 23.0, h: 46.0, x_ctr: 15.5, y_ctr: 15.5\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tws = w * scales\n",
      "DEBUG:root:\t\t\t\t\t// ws: [ 92.         115.91273659 146.04089678]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\ths = h * scales\n",
      "DEBUG:root:\t\t\t\t\t// hs: [184.         231.82547318 292.08179356]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tanchors = _mkanchors(ws, hs, x_ctr, y_ctr) { // CALL\n",
      "DEBUG:root:\t\t\t_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN\n",
      "DEBUG:root:\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t// ws: [ 92.         115.91273659 146.04089678]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [184.         231.82547318 292.08179356]\n",
      "DEBUG:root:\t\t\t\t\t// x_ctr: 15.5\n",
      "DEBUG:root:\t\t\t\t\t// y_ctr: 15.5\n",
      "\n",
      "DEBUG:root:\t\t\t\tws = ws[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// ws: [[ 92.        ]\n",
      " [115.91273659]\n",
      " [146.04089678]]\n",
      "DEBUG:root:\t\t\t\ths = hs[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [[184.        ]\n",
      " [231.82547318]\n",
      " [292.08179356]]\n",
      "DEBUG:root:\t\t\t\tanchors = np.hstack(\n",
      "DEBUG:root:\t\t\t\t    (\n",
      "DEBUG:root:\t\t\t\t        x_ctr - 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr - 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t        x_ctr + 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr + 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t    )\n",
      "DEBUG:root:\t\t\t\t)\n",
      "DEBUG:root:\t\t\t\t// anchors: [[ -30.          -76.           61.          107.        ]\n",
      " [ -41.9563683   -99.91273659   72.9563683   130.91273659]\n",
      " [ -57.02044839 -130.04089678   88.02044839  161.04089678]]\n",
      "\n",
      "DEBUG:root:\t\t\t\treturn anchors\n",
      "DEBUG:root:\t\t\t} // END _mkanchors(ws, hs, x_ctr, y_ctr)\n",
      "DEBUG:root:\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t}anchors = _mkanchors(ws, hs, x_ctr, y_ctr) // RETURNED\n",
      "DEBUG:root:\t\t\t\t\t// anchors: [[ -30.          -76.           61.          107.        ]\n",
      " [ -41.9563683   -99.91273659   72.9563683   130.91273659]\n",
      " [ -57.02044839 -130.04089678   88.02044839  161.04089678]]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\treturn anchors: [[ -30.          -76.           61.          107.        ]\n",
      " [ -41.9563683   -99.91273659   72.9563683   130.91273659]\n",
      " [ -57.02044839 -130.04089678   88.02044839  161.04089678]]\n",
      "DEBUG:root:\t\t\t\t} // END _scale_enum(anchor, scales)\n",
      "DEBUG:root:\t\t\t\t\t\t// anchors: [[ -74.          -28.          105.           59.        ]\n",
      " [ -97.39289449  -39.4365262   128.39289449   70.4365262 ]\n",
      " [-126.86609468  -53.84564629  157.86609468   84.84564629]\n",
      " [ -48.          -48.           79.           79.        ]\n",
      " [ -64.63494719  -64.63494719   95.63494719   95.63494719]\n",
      " [ -85.59366733  -85.59366733  116.59366733  116.59366733]\n",
      " [ -30.          -76.           61.          107.        ]\n",
      " [ -41.9563683   -99.91273659   72.9563683   130.91273659]\n",
      " [ -57.02044839 -130.04089678   88.02044839  161.04089678]]\n",
      "DEBUG:root:\t\t\t\t\t\t\treturn torch.from_numpy(anchors)\n",
      "DEBUG:root:\t\t\t\t\t\t} // END _generate_anchors(base_size, scales, apect_ratios) END\n",
      "DEBUG:root:\t\t\t\t\t} // END generate_anchors(stride, sizes, aspect_ratios)\n",
      "DEBUG:root:\t\t\t\tgenerate_anchors(stride, sizes, aspect_ratios) { //BEGIN\n",
      "DEBUG:root:\t\t\t//defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t\t// Params:\n",
      "DEBUG:root:\t\t\t\t\t\t// stride: 64\n",
      "DEBUG:root:\t\t\t\t\t\t// sizes: (256.0, 322.53978877308754, 406.37466930385904)\n",
      "DEBUG:root:\t\t\t\t\t\t// aspect_ratios: (0.5, 1.0, 2.0)\n",
      "\n",
      "DEBUG:root:\t\t\t\t\treturn _generate_anchors(stride,\n",
      "DEBUG:root:\t\t\t\t\t\t     np.array(sizes, dtype=np.float) / stride,\n",
      "DEBUG:root:\t\t\t\t\t\t     np.array(aspect_ratios, dtype=np.float),)\n",
      "DEBUG:root:\t\t\t\t\t\t_generate_anchors(base_size, scales, aspect_ratios) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t\t// Params:\n",
      "DEBUG:root:\t\t\t\t\t\t\t\t// base_size: 64\n",
      "DEBUG:root:\t\t\t\t\t\t\t\t// scales: [4.         5.0396842  6.34960421]\n",
      "DEBUG:root:\t\t\t\t\t\t\t\t// aspect_ratios: [0.5 1.  2. ]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\tanchor = np.array([1, 1, base_size, base_size], dtype=np.float) - 1\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [ 0.  0. 63. 63.]\n",
      "DEBUG:root:\t\t\t\t_ratio_enum(anchor, ratios) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t// Params:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [ 0.  0. 63. 63.]\n",
      "DEBUG:root:\t\t\t\t\t\t// ratios: [0.5 1.  2. ]\n",
      "\n",
      "DEBUG:root:\t\t\t\t_whctrs(anchors) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [ 0.  0. 63. 63.]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\tw = anchor[2] - anchor[0] + 1\n",
      "DEBUG:root:\t\t\t\t\t\tw: 64.0\n",
      "DEBUG:root:\t\t\t\t\t\th = anchor[3] - anchor[1] + 1\n",
      "DEBUG:root:\t\t\t\t\t\th: 64.0\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr = anchor[0] + 0.5 * (w - 1)\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr: 31.5\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr = anchor[1] + 0.5 * (h - 1)\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr: 31.5\n",
      "DEBUG:root:\t\t\t\t\t\treturn w, h, x_ctr, y_ctr\n",
      "DEBUG:root:\t\t\t\t\t} // END _whctrs(anchors)\n",
      "DEBUG:root:\t\t\t\t\tw, h, x_ctr, y_ctr = _whctrs(anchor)\n",
      "DEBUG:root:\t\t\t\t\t// w: 64.0, h: 64.0, x_ctr: 31.5, y_ctr: 31.5\n",
      "DEBUG:root:\t\t\t\t\tsize = w * h\n",
      "DEBUG:root:\t\t\t\t\t// size: 4096.0\n",
      "DEBUG:root:\t\t\t\t\tsize_ratios = size / ratios\n",
      "DEBUG:root:\t\t\t\t\t// size_ratios: [8192. 4096. 2048.]\n",
      "DEBUG:root:\t\t\t\t\tws = np.round(np.sqrt(size_ratios))\n",
      "DEBUG:root:\t\t\t\t\t// ws: [91. 64. 45.]\n",
      "DEBUG:root:\t\t\t\t\ths = np.round(ws * ratios)\n",
      "DEBUG:root:\t\t\t\t\t// hs: [46. 64. 90.]\n",
      "DEBUG:root:\t\t\t_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN\n",
      "DEBUG:root:\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t// ws: [91. 64. 45.]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [46. 64. 90.]\n",
      "DEBUG:root:\t\t\t\t\t// x_ctr: 31.5\n",
      "DEBUG:root:\t\t\t\t\t// y_ctr: 31.5\n",
      "\n",
      "DEBUG:root:\t\t\t\tws = ws[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// ws: [[91.]\n",
      " [64.]\n",
      " [45.]]\n",
      "DEBUG:root:\t\t\t\ths = hs[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [[46.]\n",
      " [64.]\n",
      " [90.]]\n",
      "DEBUG:root:\t\t\t\tanchors = np.hstack(\n",
      "DEBUG:root:\t\t\t\t    (\n",
      "DEBUG:root:\t\t\t\t        x_ctr - 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr - 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t        x_ctr + 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr + 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t    )\n",
      "DEBUG:root:\t\t\t\t)\n",
      "DEBUG:root:\t\t\t\t// anchors: [[-13.5   9.   76.5  54. ]\n",
      " [  0.    0.   63.   63. ]\n",
      " [  9.5 -13.   53.5  76. ]]\n",
      "\n",
      "DEBUG:root:\t\t\t\treturn anchors\n",
      "DEBUG:root:\t\t\t} // END _mkanchors(ws, hs, x_ctr, y_ctr)\n",
      "DEBUG:root:\t\t\t\t\tanchors = _mkanchors(ws, hs, x_ctr, y_ctr)\n",
      "DEBUG:root:\t\t\t\t\t// anchors: [[-13.5   9.   76.5  54. ]\n",
      " [  0.    0.   63.   63. ]\n",
      " [  9.5 -13.   53.5  76. ]]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\treturn anchors\n",
      "DEBUG:root:\t\t\t\t} // END _ratio_enum(anchor, ratios)\n",
      "DEBUG:root:\t\t\t\t\t\tanchors = _ratio_enum(anchor, aspect_ratios)\n",
      "DEBUG:root:\t\t\t\t\t\t// anchors: [[-13.5   9.   76.5  54. ]\n",
      " [  0.    0.   63.   63. ]\n",
      " [  9.5 -13.   53.5  76. ]]\n",
      "DEBUG:root:\t\t\t\t\t\tanchors = np.vstack(\n",
      "DEBUG:root:\t\t\t\t\t\t[_scale_enum(anchors[i, :], scales) for i in range(anchors.shape[0])]\n",
      "DEBUG:root:\t\t\t\t\t\t)\n",
      "DEBUG:root:\t\t\t\t\t_scale_enum(anchor, scales) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [-13.5   9.   76.5  54. ]\n",
      "DEBUG:root:\t\t\t\t\t\t// scales: [4.         5.0396842  6.34960421]\n",
      "\n",
      "DEBUG:root:\t\t\t\t_whctrs(anchors) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [-13.5   9.   76.5  54. ]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\tw = anchor[2] - anchor[0] + 1\n",
      "DEBUG:root:\t\t\t\t\t\tw: 91.0\n",
      "DEBUG:root:\t\t\t\t\t\th = anchor[3] - anchor[1] + 1\n",
      "DEBUG:root:\t\t\t\t\t\th: 46.0\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr = anchor[0] + 0.5 * (w - 1)\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr: 31.5\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr = anchor[1] + 0.5 * (h - 1)\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr: 31.5\n",
      "DEBUG:root:\t\t\t\t\t\treturn w, h, x_ctr, y_ctr\n",
      "DEBUG:root:\t\t\t\t\t} // END _whctrs(anchors)\n",
      "DEBUG:root:\t\t\t\t\tw, h, x_ctr, y_ctr = _whctrs(anchor)\n",
      "DEBUG:root:\t\t\t\t\t// w: 91.0, h: 46.0, x_ctr: 31.5, y_ctr: 31.5\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tws = w * scales\n",
      "DEBUG:root:\t\t\t\t\t// ws: [364.         458.61126216 577.81398292]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\ths = h * scales\n",
      "DEBUG:root:\t\t\t\t\t// hs: [184.         231.82547318 292.08179356]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tanchors = _mkanchors(ws, hs, x_ctr, y_ctr) { // CALL\n",
      "DEBUG:root:\t\t\t_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN\n",
      "DEBUG:root:\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t// ws: [364.         458.61126216 577.81398292]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [184.         231.82547318 292.08179356]\n",
      "DEBUG:root:\t\t\t\t\t// x_ctr: 31.5\n",
      "DEBUG:root:\t\t\t\t\t// y_ctr: 31.5\n",
      "\n",
      "DEBUG:root:\t\t\t\tws = ws[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// ws: [[364.        ]\n",
      " [458.61126216]\n",
      " [577.81398292]]\n",
      "DEBUG:root:\t\t\t\ths = hs[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [[184.        ]\n",
      " [231.82547318]\n",
      " [292.08179356]]\n",
      "DEBUG:root:\t\t\t\tanchors = np.hstack(\n",
      "DEBUG:root:\t\t\t\t    (\n",
      "DEBUG:root:\t\t\t\t        x_ctr - 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr - 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t        x_ctr + 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr + 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t    )\n",
      "DEBUG:root:\t\t\t\t)\n",
      "DEBUG:root:\t\t\t\t// anchors: [[-150.          -60.          213.          123.        ]\n",
      " [-197.30563108  -83.91273659  260.30563108  146.91273659]\n",
      " [-256.90699146 -114.04089678  319.90699146  177.04089678]]\n",
      "\n",
      "DEBUG:root:\t\t\t\treturn anchors\n",
      "DEBUG:root:\t\t\t} // END _mkanchors(ws, hs, x_ctr, y_ctr)\n",
      "DEBUG:root:\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t}anchors = _mkanchors(ws, hs, x_ctr, y_ctr) // RETURNED\n",
      "DEBUG:root:\t\t\t\t\t// anchors: [[-150.          -60.          213.          123.        ]\n",
      " [-197.30563108  -83.91273659  260.30563108  146.91273659]\n",
      " [-256.90699146 -114.04089678  319.90699146  177.04089678]]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\treturn anchors: [[-150.          -60.          213.          123.        ]\n",
      " [-197.30563108  -83.91273659  260.30563108  146.91273659]\n",
      " [-256.90699146 -114.04089678  319.90699146  177.04089678]]\n",
      "DEBUG:root:\t\t\t\t} // END _scale_enum(anchor, scales)\n",
      "DEBUG:root:\t\t\t\t\t_scale_enum(anchor, scales) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [ 0.  0. 63. 63.]\n",
      "DEBUG:root:\t\t\t\t\t\t// scales: [4.         5.0396842  6.34960421]\n",
      "\n",
      "DEBUG:root:\t\t\t\t_whctrs(anchors) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [ 0.  0. 63. 63.]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\tw = anchor[2] - anchor[0] + 1\n",
      "DEBUG:root:\t\t\t\t\t\tw: 64.0\n",
      "DEBUG:root:\t\t\t\t\t\th = anchor[3] - anchor[1] + 1\n",
      "DEBUG:root:\t\t\t\t\t\th: 64.0\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr = anchor[0] + 0.5 * (w - 1)\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr: 31.5\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr = anchor[1] + 0.5 * (h - 1)\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr: 31.5\n",
      "DEBUG:root:\t\t\t\t\t\treturn w, h, x_ctr, y_ctr\n",
      "DEBUG:root:\t\t\t\t\t} // END _whctrs(anchors)\n",
      "DEBUG:root:\t\t\t\t\tw, h, x_ctr, y_ctr = _whctrs(anchor)\n",
      "DEBUG:root:\t\t\t\t\t// w: 64.0, h: 64.0, x_ctr: 31.5, y_ctr: 31.5\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tws = w * scales\n",
      "DEBUG:root:\t\t\t\t\t// ws: [256.         322.53978877 406.3746693 ]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\ths = h * scales\n",
      "DEBUG:root:\t\t\t\t\t// hs: [256.         322.53978877 406.3746693 ]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tanchors = _mkanchors(ws, hs, x_ctr, y_ctr) { // CALL\n",
      "DEBUG:root:\t\t\t_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN\n",
      "DEBUG:root:\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t// ws: [256.         322.53978877 406.3746693 ]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [256.         322.53978877 406.3746693 ]\n",
      "DEBUG:root:\t\t\t\t\t// x_ctr: 31.5\n",
      "DEBUG:root:\t\t\t\t\t// y_ctr: 31.5\n",
      "\n",
      "DEBUG:root:\t\t\t\tws = ws[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// ws: [[256.        ]\n",
      " [322.53978877]\n",
      " [406.3746693 ]]\n",
      "DEBUG:root:\t\t\t\ths = hs[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [[256.        ]\n",
      " [322.53978877]\n",
      " [406.3746693 ]]\n",
      "DEBUG:root:\t\t\t\tanchors = np.hstack(\n",
      "DEBUG:root:\t\t\t\t    (\n",
      "DEBUG:root:\t\t\t\t        x_ctr - 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr - 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t        x_ctr + 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr + 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t    )\n",
      "DEBUG:root:\t\t\t\t)\n",
      "DEBUG:root:\t\t\t\t// anchors: [[ -96.          -96.          159.          159.        ]\n",
      " [-129.26989439 -129.26989439  192.26989439  192.26989439]\n",
      " [-171.18733465 -171.18733465  234.18733465  234.18733465]]\n",
      "\n",
      "DEBUG:root:\t\t\t\treturn anchors\n",
      "DEBUG:root:\t\t\t} // END _mkanchors(ws, hs, x_ctr, y_ctr)\n",
      "DEBUG:root:\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t}anchors = _mkanchors(ws, hs, x_ctr, y_ctr) // RETURNED\n",
      "DEBUG:root:\t\t\t\t\t// anchors: [[ -96.          -96.          159.          159.        ]\n",
      " [-129.26989439 -129.26989439  192.26989439  192.26989439]\n",
      " [-171.18733465 -171.18733465  234.18733465  234.18733465]]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\treturn anchors: [[ -96.          -96.          159.          159.        ]\n",
      " [-129.26989439 -129.26989439  192.26989439  192.26989439]\n",
      " [-171.18733465 -171.18733465  234.18733465  234.18733465]]\n",
      "DEBUG:root:\t\t\t\t} // END _scale_enum(anchor, scales)\n",
      "DEBUG:root:\t\t\t\t\t_scale_enum(anchor, scales) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [  9.5 -13.   53.5  76. ]\n",
      "DEBUG:root:\t\t\t\t\t\t// scales: [4.         5.0396842  6.34960421]\n",
      "\n",
      "DEBUG:root:\t\t\t\t_whctrs(anchors) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [  9.5 -13.   53.5  76. ]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\tw = anchor[2] - anchor[0] + 1\n",
      "DEBUG:root:\t\t\t\t\t\tw: 45.0\n",
      "DEBUG:root:\t\t\t\t\t\th = anchor[3] - anchor[1] + 1\n",
      "DEBUG:root:\t\t\t\t\t\th: 90.0\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr = anchor[0] + 0.5 * (w - 1)\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr: 31.5\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr = anchor[1] + 0.5 * (h - 1)\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr: 31.5\n",
      "DEBUG:root:\t\t\t\t\t\treturn w, h, x_ctr, y_ctr\n",
      "DEBUG:root:\t\t\t\t\t} // END _whctrs(anchors)\n",
      "DEBUG:root:\t\t\t\t\tw, h, x_ctr, y_ctr = _whctrs(anchor)\n",
      "DEBUG:root:\t\t\t\t\t// w: 45.0, h: 90.0, x_ctr: 31.5, y_ctr: 31.5\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tws = w * scales\n",
      "DEBUG:root:\t\t\t\t\t// ws: [180.         226.78578898 285.73218935]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\ths = h * scales\n",
      "DEBUG:root:\t\t\t\t\t// hs: [360.         453.57157796 571.46437871]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tanchors = _mkanchors(ws, hs, x_ctr, y_ctr) { // CALL\n",
      "DEBUG:root:\t\t\t_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN\n",
      "DEBUG:root:\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t// ws: [180.         226.78578898 285.73218935]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [360.         453.57157796 571.46437871]\n",
      "DEBUG:root:\t\t\t\t\t// x_ctr: 31.5\n",
      "DEBUG:root:\t\t\t\t\t// y_ctr: 31.5\n",
      "\n",
      "DEBUG:root:\t\t\t\tws = ws[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// ws: [[180.        ]\n",
      " [226.78578898]\n",
      " [285.73218935]]\n",
      "DEBUG:root:\t\t\t\ths = hs[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [[360.        ]\n",
      " [453.57157796]\n",
      " [571.46437871]]\n",
      "DEBUG:root:\t\t\t\tanchors = np.hstack(\n",
      "DEBUG:root:\t\t\t\t    (\n",
      "DEBUG:root:\t\t\t\t        x_ctr - 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr - 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t        x_ctr + 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr + 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t    )\n",
      "DEBUG:root:\t\t\t\t)\n",
      "DEBUG:root:\t\t\t\t// anchors: [[ -58.         -148.          121.          211.        ]\n",
      " [ -81.39289449 -194.78578898  144.39289449  257.78578898]\n",
      " [-110.86609468 -253.73218935  173.86609468  316.73218935]]\n",
      "\n",
      "DEBUG:root:\t\t\t\treturn anchors\n",
      "DEBUG:root:\t\t\t} // END _mkanchors(ws, hs, x_ctr, y_ctr)\n",
      "DEBUG:root:\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t}anchors = _mkanchors(ws, hs, x_ctr, y_ctr) // RETURNED\n",
      "DEBUG:root:\t\t\t\t\t// anchors: [[ -58.         -148.          121.          211.        ]\n",
      " [ -81.39289449 -194.78578898  144.39289449  257.78578898]\n",
      " [-110.86609468 -253.73218935  173.86609468  316.73218935]]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\treturn anchors: [[ -58.         -148.          121.          211.        ]\n",
      " [ -81.39289449 -194.78578898  144.39289449  257.78578898]\n",
      " [-110.86609468 -253.73218935  173.86609468  316.73218935]]\n",
      "DEBUG:root:\t\t\t\t} // END _scale_enum(anchor, scales)\n",
      "DEBUG:root:\t\t\t\t\t\t// anchors: [[-150.          -60.          213.          123.        ]\n",
      " [-197.30563108  -83.91273659  260.30563108  146.91273659]\n",
      " [-256.90699146 -114.04089678  319.90699146  177.04089678]\n",
      " [ -96.          -96.          159.          159.        ]\n",
      " [-129.26989439 -129.26989439  192.26989439  192.26989439]\n",
      " [-171.18733465 -171.18733465  234.18733465  234.18733465]\n",
      " [ -58.         -148.          121.          211.        ]\n",
      " [ -81.39289449 -194.78578898  144.39289449  257.78578898]\n",
      " [-110.86609468 -253.73218935  173.86609468  316.73218935]]\n",
      "DEBUG:root:\t\t\t\t\t\t\treturn torch.from_numpy(anchors)\n",
      "DEBUG:root:\t\t\t\t\t\t} // END _generate_anchors(base_size, scales, apect_ratios) END\n",
      "DEBUG:root:\t\t\t\t\t} // END generate_anchors(stride, sizes, aspect_ratios)\n",
      "DEBUG:root:\t\t\t\tgenerate_anchors(stride, sizes, aspect_ratios) { //BEGIN\n",
      "DEBUG:root:\t\t\t//defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t\t// Params:\n",
      "DEBUG:root:\t\t\t\t\t\t// stride: 128\n",
      "DEBUG:root:\t\t\t\t\t\t// sizes: (512.0, 645.0795775461751, 812.7493386077181)\n",
      "DEBUG:root:\t\t\t\t\t\t// aspect_ratios: (0.5, 1.0, 2.0)\n",
      "\n",
      "DEBUG:root:\t\t\t\t\treturn _generate_anchors(stride,\n",
      "DEBUG:root:\t\t\t\t\t\t     np.array(sizes, dtype=np.float) / stride,\n",
      "DEBUG:root:\t\t\t\t\t\t     np.array(aspect_ratios, dtype=np.float),)\n",
      "DEBUG:root:\t\t\t\t\t\t_generate_anchors(base_size, scales, aspect_ratios) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\t\t// Params:\n",
      "DEBUG:root:\t\t\t\t\t\t\t\t// base_size: 128\n",
      "DEBUG:root:\t\t\t\t\t\t\t\t// scales: [4.         5.0396842  6.34960421]\n",
      "DEBUG:root:\t\t\t\t\t\t\t\t// aspect_ratios: [0.5 1.  2. ]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\tanchor = np.array([1, 1, base_size, base_size], dtype=np.float) - 1\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [  0.   0. 127. 127.]\n",
      "DEBUG:root:\t\t\t\t_ratio_enum(anchor, ratios) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t// Params:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [  0.   0. 127. 127.]\n",
      "DEBUG:root:\t\t\t\t\t\t// ratios: [0.5 1.  2. ]\n",
      "\n",
      "DEBUG:root:\t\t\t\t_whctrs(anchors) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [  0.   0. 127. 127.]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\tw = anchor[2] - anchor[0] + 1\n",
      "DEBUG:root:\t\t\t\t\t\tw: 128.0\n",
      "DEBUG:root:\t\t\t\t\t\th = anchor[3] - anchor[1] + 1\n",
      "DEBUG:root:\t\t\t\t\t\th: 128.0\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr = anchor[0] + 0.5 * (w - 1)\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr: 63.5\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr = anchor[1] + 0.5 * (h - 1)\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr: 63.5\n",
      "DEBUG:root:\t\t\t\t\t\treturn w, h, x_ctr, y_ctr\n",
      "DEBUG:root:\t\t\t\t\t} // END _whctrs(anchors)\n",
      "DEBUG:root:\t\t\t\t\tw, h, x_ctr, y_ctr = _whctrs(anchor)\n",
      "DEBUG:root:\t\t\t\t\t// w: 128.0, h: 128.0, x_ctr: 63.5, y_ctr: 63.5\n",
      "DEBUG:root:\t\t\t\t\tsize = w * h\n",
      "DEBUG:root:\t\t\t\t\t// size: 16384.0\n",
      "DEBUG:root:\t\t\t\t\tsize_ratios = size / ratios\n",
      "DEBUG:root:\t\t\t\t\t// size_ratios: [32768. 16384.  8192.]\n",
      "DEBUG:root:\t\t\t\t\tws = np.round(np.sqrt(size_ratios))\n",
      "DEBUG:root:\t\t\t\t\t// ws: [181. 128.  91.]\n",
      "DEBUG:root:\t\t\t\t\ths = np.round(ws * ratios)\n",
      "DEBUG:root:\t\t\t\t\t// hs: [ 90. 128. 182.]\n",
      "DEBUG:root:\t\t\t_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN\n",
      "DEBUG:root:\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t// ws: [181. 128.  91.]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [ 90. 128. 182.]\n",
      "DEBUG:root:\t\t\t\t\t// x_ctr: 63.5\n",
      "DEBUG:root:\t\t\t\t\t// y_ctr: 63.5\n",
      "\n",
      "DEBUG:root:\t\t\t\tws = ws[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// ws: [[181.]\n",
      " [128.]\n",
      " [ 91.]]\n",
      "DEBUG:root:\t\t\t\ths = hs[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [[ 90.]\n",
      " [128.]\n",
      " [182.]]\n",
      "DEBUG:root:\t\t\t\tanchors = np.hstack(\n",
      "DEBUG:root:\t\t\t\t    (\n",
      "DEBUG:root:\t\t\t\t        x_ctr - 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr - 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t        x_ctr + 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr + 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t    )\n",
      "DEBUG:root:\t\t\t\t)\n",
      "DEBUG:root:\t\t\t\t// anchors: [[-26.5  19.  153.5 108. ]\n",
      " [  0.    0.  127.  127. ]\n",
      " [ 18.5 -27.  108.5 154. ]]\n",
      "\n",
      "DEBUG:root:\t\t\t\treturn anchors\n",
      "DEBUG:root:\t\t\t} // END _mkanchors(ws, hs, x_ctr, y_ctr)\n",
      "DEBUG:root:\t\t\t\t\tanchors = _mkanchors(ws, hs, x_ctr, y_ctr)\n",
      "DEBUG:root:\t\t\t\t\t// anchors: [[-26.5  19.  153.5 108. ]\n",
      " [  0.    0.  127.  127. ]\n",
      " [ 18.5 -27.  108.5 154. ]]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\treturn anchors\n",
      "DEBUG:root:\t\t\t\t} // END _ratio_enum(anchor, ratios)\n",
      "DEBUG:root:\t\t\t\t\t\tanchors = _ratio_enum(anchor, aspect_ratios)\n",
      "DEBUG:root:\t\t\t\t\t\t// anchors: [[-26.5  19.  153.5 108. ]\n",
      " [  0.    0.  127.  127. ]\n",
      " [ 18.5 -27.  108.5 154. ]]\n",
      "DEBUG:root:\t\t\t\t\t\tanchors = np.vstack(\n",
      "DEBUG:root:\t\t\t\t\t\t[_scale_enum(anchors[i, :], scales) for i in range(anchors.shape[0])]\n",
      "DEBUG:root:\t\t\t\t\t\t)\n",
      "DEBUG:root:\t\t\t\t\t_scale_enum(anchor, scales) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [-26.5  19.  153.5 108. ]\n",
      "DEBUG:root:\t\t\t\t\t\t// scales: [4.         5.0396842  6.34960421]\n",
      "\n",
      "DEBUG:root:\t\t\t\t_whctrs(anchors) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [-26.5  19.  153.5 108. ]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\tw = anchor[2] - anchor[0] + 1\n",
      "DEBUG:root:\t\t\t\t\t\tw: 181.0\n",
      "DEBUG:root:\t\t\t\t\t\th = anchor[3] - anchor[1] + 1\n",
      "DEBUG:root:\t\t\t\t\t\th: 90.0\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr = anchor[0] + 0.5 * (w - 1)\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr: 63.5\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr = anchor[1] + 0.5 * (h - 1)\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr: 63.5\n",
      "DEBUG:root:\t\t\t\t\t\treturn w, h, x_ctr, y_ctr\n",
      "DEBUG:root:\t\t\t\t\t} // END _whctrs(anchors)\n",
      "DEBUG:root:\t\t\t\t\tw, h, x_ctr, y_ctr = _whctrs(anchor)\n",
      "DEBUG:root:\t\t\t\t\t// w: 181.0, h: 90.0, x_ctr: 63.5, y_ctr: 63.5\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tws = w * scales\n",
      "DEBUG:root:\t\t\t\t\t// ws: [ 724.          912.18284012 1149.27836162]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\ths = h * scales\n",
      "DEBUG:root:\t\t\t\t\t// hs: [360.         453.57157796 571.46437871]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tanchors = _mkanchors(ws, hs, x_ctr, y_ctr) { // CALL\n",
      "DEBUG:root:\t\t\t_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN\n",
      "DEBUG:root:\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t// ws: [ 724.          912.18284012 1149.27836162]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [360.         453.57157796 571.46437871]\n",
      "DEBUG:root:\t\t\t\t\t// x_ctr: 63.5\n",
      "DEBUG:root:\t\t\t\t\t// y_ctr: 63.5\n",
      "\n",
      "DEBUG:root:\t\t\t\tws = ws[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// ws: [[ 724.        ]\n",
      " [ 912.18284012]\n",
      " [1149.27836162]]\n",
      "DEBUG:root:\t\t\t\ths = hs[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [[360.        ]\n",
      " [453.57157796]\n",
      " [571.46437871]]\n",
      "DEBUG:root:\t\t\t\tanchors = np.hstack(\n",
      "DEBUG:root:\t\t\t\t    (\n",
      "DEBUG:root:\t\t\t\t        x_ctr - 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr - 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t        x_ctr + 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr + 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t    )\n",
      "DEBUG:root:\t\t\t\t)\n",
      "DEBUG:root:\t\t\t\t// anchors: [[-298.         -116.          425.          243.        ]\n",
      " [-392.09142006 -162.78578898  519.09142006  289.78578898]\n",
      " [-510.63918081 -221.73218935  637.63918081  348.73218935]]\n",
      "\n",
      "DEBUG:root:\t\t\t\treturn anchors\n",
      "DEBUG:root:\t\t\t} // END _mkanchors(ws, hs, x_ctr, y_ctr)\n",
      "DEBUG:root:\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t}anchors = _mkanchors(ws, hs, x_ctr, y_ctr) // RETURNED\n",
      "DEBUG:root:\t\t\t\t\t// anchors: [[-298.         -116.          425.          243.        ]\n",
      " [-392.09142006 -162.78578898  519.09142006  289.78578898]\n",
      " [-510.63918081 -221.73218935  637.63918081  348.73218935]]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\treturn anchors: [[-298.         -116.          425.          243.        ]\n",
      " [-392.09142006 -162.78578898  519.09142006  289.78578898]\n",
      " [-510.63918081 -221.73218935  637.63918081  348.73218935]]\n",
      "DEBUG:root:\t\t\t\t} // END _scale_enum(anchor, scales)\n",
      "DEBUG:root:\t\t\t\t\t_scale_enum(anchor, scales) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [  0.   0. 127. 127.]\n",
      "DEBUG:root:\t\t\t\t\t\t// scales: [4.         5.0396842  6.34960421]\n",
      "\n",
      "DEBUG:root:\t\t\t\t_whctrs(anchors) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [  0.   0. 127. 127.]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\tw = anchor[2] - anchor[0] + 1\n",
      "DEBUG:root:\t\t\t\t\t\tw: 128.0\n",
      "DEBUG:root:\t\t\t\t\t\th = anchor[3] - anchor[1] + 1\n",
      "DEBUG:root:\t\t\t\t\t\th: 128.0\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr = anchor[0] + 0.5 * (w - 1)\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr: 63.5\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr = anchor[1] + 0.5 * (h - 1)\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr: 63.5\n",
      "DEBUG:root:\t\t\t\t\t\treturn w, h, x_ctr, y_ctr\n",
      "DEBUG:root:\t\t\t\t\t} // END _whctrs(anchors)\n",
      "DEBUG:root:\t\t\t\t\tw, h, x_ctr, y_ctr = _whctrs(anchor)\n",
      "DEBUG:root:\t\t\t\t\t// w: 128.0, h: 128.0, x_ctr: 63.5, y_ctr: 63.5\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tws = w * scales\n",
      "DEBUG:root:\t\t\t\t\t// ws: [512.         645.07957755 812.74933861]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\ths = h * scales\n",
      "DEBUG:root:\t\t\t\t\t// hs: [512.         645.07957755 812.74933861]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tanchors = _mkanchors(ws, hs, x_ctr, y_ctr) { // CALL\n",
      "DEBUG:root:\t\t\t_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN\n",
      "DEBUG:root:\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t// ws: [512.         645.07957755 812.74933861]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [512.         645.07957755 812.74933861]\n",
      "DEBUG:root:\t\t\t\t\t// x_ctr: 63.5\n",
      "DEBUG:root:\t\t\t\t\t// y_ctr: 63.5\n",
      "\n",
      "DEBUG:root:\t\t\t\tws = ws[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// ws: [[512.        ]\n",
      " [645.07957755]\n",
      " [812.74933861]]\n",
      "DEBUG:root:\t\t\t\ths = hs[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [[512.        ]\n",
      " [645.07957755]\n",
      " [812.74933861]]\n",
      "DEBUG:root:\t\t\t\tanchors = np.hstack(\n",
      "DEBUG:root:\t\t\t\t    (\n",
      "DEBUG:root:\t\t\t\t        x_ctr - 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr - 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t        x_ctr + 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr + 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t    )\n",
      "DEBUG:root:\t\t\t\t)\n",
      "DEBUG:root:\t\t\t\t// anchors: [[-192.         -192.          319.          319.        ]\n",
      " [-258.53978877 -258.53978877  385.53978877  385.53978877]\n",
      " [-342.3746693  -342.3746693   469.3746693   469.3746693 ]]\n",
      "\n",
      "DEBUG:root:\t\t\t\treturn anchors\n",
      "DEBUG:root:\t\t\t} // END _mkanchors(ws, hs, x_ctr, y_ctr)\n",
      "DEBUG:root:\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t}anchors = _mkanchors(ws, hs, x_ctr, y_ctr) // RETURNED\n",
      "DEBUG:root:\t\t\t\t\t// anchors: [[-192.         -192.          319.          319.        ]\n",
      " [-258.53978877 -258.53978877  385.53978877  385.53978877]\n",
      " [-342.3746693  -342.3746693   469.3746693   469.3746693 ]]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\treturn anchors: [[-192.         -192.          319.          319.        ]\n",
      " [-258.53978877 -258.53978877  385.53978877  385.53978877]\n",
      " [-342.3746693  -342.3746693   469.3746693   469.3746693 ]]\n",
      "DEBUG:root:\t\t\t\t} // END _scale_enum(anchor, scales)\n",
      "DEBUG:root:\t\t\t\t\t_scale_enum(anchor, scales) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [ 18.5 -27.  108.5 154. ]\n",
      "DEBUG:root:\t\t\t\t\t\t// scales: [4.         5.0396842  6.34960421]\n",
      "\n",
      "DEBUG:root:\t\t\t\t_whctrs(anchors) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t\t// anchor: [ 18.5 -27.  108.5 154. ]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t\tw = anchor[2] - anchor[0] + 1\n",
      "DEBUG:root:\t\t\t\t\t\tw: 91.0\n",
      "DEBUG:root:\t\t\t\t\t\th = anchor[3] - anchor[1] + 1\n",
      "DEBUG:root:\t\t\t\t\t\th: 182.0\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr = anchor[0] + 0.5 * (w - 1)\n",
      "DEBUG:root:\t\t\t\t\t\tx_ctr: 63.5\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr = anchor[1] + 0.5 * (h - 1)\n",
      "DEBUG:root:\t\t\t\t\t\ty_ctr: 63.5\n",
      "DEBUG:root:\t\t\t\t\t\treturn w, h, x_ctr, y_ctr\n",
      "DEBUG:root:\t\t\t\t\t} // END _whctrs(anchors)\n",
      "DEBUG:root:\t\t\t\t\tw, h, x_ctr, y_ctr = _whctrs(anchor)\n",
      "DEBUG:root:\t\t\t\t\t// w: 91.0, h: 182.0, x_ctr: 63.5, y_ctr: 63.5\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tws = w * scales\n",
      "DEBUG:root:\t\t\t\t\t// ws: [364.         458.61126216 577.81398292]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\ths = h * scales\n",
      "DEBUG:root:\t\t\t\t\t// hs: [ 728.          917.22252432 1155.62796583]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\tanchors = _mkanchors(ws, hs, x_ctr, y_ctr) { // CALL\n",
      "DEBUG:root:\t\t\t_mkanchors(ws, hs, x_ctr, y_ctr) { // BEGIN\n",
      "DEBUG:root:\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\t\t\t// Param:\n",
      "DEBUG:root:\t\t\t\t\t// ws: [364.         458.61126216 577.81398292]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [ 728.          917.22252432 1155.62796583]\n",
      "DEBUG:root:\t\t\t\t\t// x_ctr: 63.5\n",
      "DEBUG:root:\t\t\t\t\t// y_ctr: 63.5\n",
      "\n",
      "DEBUG:root:\t\t\t\tws = ws[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// ws: [[364.        ]\n",
      " [458.61126216]\n",
      " [577.81398292]]\n",
      "DEBUG:root:\t\t\t\ths = hs[:, np.newaxis]\n",
      "DEBUG:root:\t\t\t\t\t// hs: [[ 728.        ]\n",
      " [ 917.22252432]\n",
      " [1155.62796583]]\n",
      "DEBUG:root:\t\t\t\tanchors = np.hstack(\n",
      "DEBUG:root:\t\t\t\t    (\n",
      "DEBUG:root:\t\t\t\t        x_ctr - 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr - 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t        x_ctr + 0.5 * (ws - 1),\n",
      "DEBUG:root:\t\t\t\t        y_ctr + 0.5 * (hs - 1),\n",
      "DEBUG:root:\t\t\t\t    )\n",
      "DEBUG:root:\t\t\t\t)\n",
      "DEBUG:root:\t\t\t\t// anchors: [[-118.         -300.          245.          427.        ]\n",
      " [-165.30563108 -394.61126216  292.30563108  521.61126216]\n",
      " [-224.90699146 -513.81398292  351.90699146  640.81398292]]\n",
      "\n",
      "DEBUG:root:\t\t\t\treturn anchors\n",
      "DEBUG:root:\t\t\t} // END _mkanchors(ws, hs, x_ctr, y_ctr)\n",
      "DEBUG:root:\n",
      "\n",
      "DEBUG:root:\t\t\t\t\t}anchors = _mkanchors(ws, hs, x_ctr, y_ctr) // RETURNED\n",
      "DEBUG:root:\t\t\t\t\t// anchors: [[-118.         -300.          245.          427.        ]\n",
      " [-165.30563108 -394.61126216  292.30563108  521.61126216]\n",
      " [-224.90699146 -513.81398292  351.90699146  640.81398292]]\n",
      "\n",
      "DEBUG:root:\t\t\t\t\treturn anchors: [[-118.         -300.          245.          427.        ]\n",
      " [-165.30563108 -394.61126216  292.30563108  521.61126216]\n",
      " [-224.90699146 -513.81398292  351.90699146  640.81398292]]\n",
      "DEBUG:root:\t\t\t\t} // END _scale_enum(anchor, scales)\n",
      "DEBUG:root:\t\t\t\t\t\t// anchors: [[-298.         -116.          425.          243.        ]\n",
      " [-392.09142006 -162.78578898  519.09142006  289.78578898]\n",
      " [-510.63918081 -221.73218935  637.63918081  348.73218935]\n",
      " [-192.         -192.          319.          319.        ]\n",
      " [-258.53978877 -258.53978877  385.53978877  385.53978877]\n",
      " [-342.3746693  -342.3746693   469.3746693   469.3746693 ]\n",
      " [-118.         -300.          245.          427.        ]\n",
      " [-165.30563108 -394.61126216  292.30563108  521.61126216]\n",
      " [-224.90699146 -513.81398292  351.90699146  640.81398292]]\n",
      "DEBUG:root:\t\t\t\t\t\t\treturn torch.from_numpy(anchors)\n",
      "DEBUG:root:\t\t\t\t\t\t} // END _generate_anchors(base_size, scales, apect_ratios) END\n",
      "DEBUG:root:\t\t\t\t\t} // END generate_anchors(stride, sizes, aspect_ratios)\n",
      "DEBUG:root:\t\t\tlen(cell_anchors): 5\n",
      "DEBUG:root:\t\t\tcell_anchors[i].shape: torch.Size([9, 4])\n",
      "DEBUG:root:\t\t\tcell_anchors[i].shape: torch.Size([9, 4])\n",
      "DEBUG:root:\t\t\tcell_anchors[i].shape: torch.Size([9, 4])\n",
      "DEBUG:root:\t\t\tcell_anchors[i].shape: torch.Size([9, 4])\n",
      "DEBUG:root:\t\t\tcell_anchors[i].shape: torch.Size([9, 4])\n",
      "DEBUG:root:\tself.strides = anchor_strides\n",
      "DEBUG:root:\t// self.strides: (8, 16, 32, 64, 128)\n",
      "DEBUG:root:\tself.cell_anchors = BufferList(cell_anchors) // CALL\n",
      "DEBUG:root:BufferList.__init__(slef, buffers=None) { // BEGIN\n",
      "DEBUG:root:\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\tParams\n",
      "DEBUG:root:\t\tlen(buffers): 5\n",
      "DEBUG:root:\tsuper(BufferList, self).__init__()\n",
      "DEBUG:root:if buffers is not None:\n",
      "DEBUG:root:BufferList.extend(self, buffers) { // BEGIN\n",
      "DEBUG:root:\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/anchor_generator.py\n",
      "DEBUG:root:\t\tParams\n",
      "DEBUG:root:\t\tlen(buffers): 5\n",
      "\n",
      "DEBUG:root:\toffset = len(self)\n",
      "DEBUG:root:\t// offset: 0\n",
      "\n",
      "DEBUG:root:\tfor i, buffer in enumerate(buffers) { // BEGIN\n",
      "DEBUG:root:\tt{ // BEGIN iteration 0\n",
      "DEBUG:root:\t#--------------------\n",
      "DEBUG:root:buffer.shape: torch.Size([9, 4])\n",
      "DEBUG:root:\t#--------------------\n",
      "DEBUG:root:self.register_buffer(str(offset + i), buffer)\n",
      "DEBUG:root:\t\t} // END iteration 0 \n",
      "DEBUG:root:\tt{ // BEGIN iteration 1\n",
      "DEBUG:root:\t#--------------------\n",
      "DEBUG:root:buffer.shape: torch.Size([9, 4])\n",
      "DEBUG:root:\t#--------------------\n",
      "DEBUG:root:self.register_buffer(str(offset + i), buffer)\n",
      "DEBUG:root:\t\t} // END iteration 1 \n",
      "DEBUG:root:\tt{ // BEGIN iteration 2\n",
      "DEBUG:root:\t#--------------------\n",
      "DEBUG:root:buffer.shape: torch.Size([9, 4])\n",
      "DEBUG:root:\t#--------------------\n",
      "DEBUG:root:self.register_buffer(str(offset + i), buffer)\n",
      "DEBUG:root:\t\t} // END iteration 2 \n",
      "DEBUG:root:\tt{ // BEGIN iteration 3\n",
      "DEBUG:root:\t#--------------------\n",
      "DEBUG:root:buffer.shape: torch.Size([9, 4])\n",
      "DEBUG:root:\t#--------------------\n",
      "DEBUG:root:self.register_buffer(str(offset + i), buffer)\n",
      "DEBUG:root:\t\t} // END iteration 3 \n",
      "DEBUG:root:\tt{ // BEGIN iteration 4\n",
      "DEBUG:root:\t#--------------------\n",
      "DEBUG:root:buffer.shape: torch.Size([9, 4])\n",
      "DEBUG:root:\t#--------------------\n",
      "DEBUG:root:self.register_buffer(str(offset + i), buffer)\n",
      "DEBUG:root:\t\t} // END iteration 4 \n",
      "DEBUG:root:\t} // END for i, buffer in enumerate(buffers)\n",
      "\n",
      "DEBUG:root:\tself: BufferList()\n",
      "DEBUG:root:\treturn self\n",
      "DEBUG:root:} // END BufferList.extend(self, buffers)\n",
      "DEBUG:root:self.extend(buffers)\n",
      "DEBUG:root:\tlen(buffers): 5\n",
      "DEBUG:root:} // END BufferList.__init__(slef, buffers=None)\n",
      "DEBUG:root:\tself.cell_anchors = BufferList(cell_anchors) // RETURNED\n",
      "DEBUG:root:\t// self.cell_anchors: BufferList()\n",
      "DEBUG:root:\tself.straddle_thresh = straddle_thresh\n",
      "DEBUG:root:\t// self.straddle_thresh: -1\n",
      "DEBUG:root:\t\t} // END AnchorGenerator.__init__(sizes, aspect_ratios, anchor_strides, straddle_thresh)\n",
      "DEBUG:root:\t\t\t\t}\n",
      "DEBUG:root:\t\t\t\tanchor_generator = AnchorGenerator( tuple(new_anchor_sizes), aspect_ratios, anchor_strides, straddle_thresh ) // RETURNED\n",
      "DEBUG:root:\t\t\t\t// anchor_generator = AnchorGenerator(\n",
      "  (cell_anchors): BufferList()\n",
      ")\n",
      "\n",
      "DEBUG:root:\n",
      "\t\treturn anchor_generator\n",
      "DEBUG:root:\t\t} // make_anchor_generator_retinanet(config) END\n",
      "\n",
      "DEBUG:root:\t}\n",
      "\tanchor_generator = make_anchor_generator_retinanet(cfg) // RETURNED\n",
      "\n",
      "DEBUG:root:\t// anchor_generator: AnchorGenerator(\n",
      "  (cell_anchors): BufferList()\n",
      ")\n",
      "DEBUG:root:\t#============================\n",
      "DEBUG:root:\t# 1.2.2 RPN head build \n",
      "DEBUG:root:\t#============================\n",
      "DEBUG:root:\thead = RetinaNetHead(cfg, in_channels=1024) // CALL\n",
      "\t{\n",
      "DEBUG:root:\n",
      "\n",
      "\t\t\tRetinaNetHead.__init__(cfg, in_channels) { //BEGIN\n",
      "DEBUG:root:\t\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/retinanet/retinanet.py\n",
      "\n",
      "DEBUG:root:\t\t\t\t// Params:\n",
      "DEBUG:root:\t\t\t\t\t// cfg:\n",
      "DEBUG:root:\t\t\t\t\t//in_channles: 1024\n",
      "\n",
      "DEBUG:root:\t\t\t\tnum_classes = cfg.MODEL.RETINANET.NUM_CLASSES - 1\n",
      "DEBUG:root:\t\t\t\t// num_classes: 1\n",
      "DEBUG:root:\t\t\t\t// cfg.MODEL.RETINANET.ASPECT_RATIOS: (0.5, 1.0, 2.0)\n",
      "DEBUG:root:\t\t\t\t// cfg.MODEL.RETINANET.SCALES_PER_OCTAVE: 3\n",
      "DEBUG:root:\t\t\t\tnum_anchors = len(cfg.MODEL.RETINANET.ASPECT_RATIOS) \\\n",
      "DEBUG:root:\t\t\t\t                * cfg.MODEL.RETINANET.SCALES_PER_OCTAVE\n",
      "DEBUG:root:\t\t\t\t// num_anchors: 9\n",
      "DEBUG:root:\n",
      "\n",
      "} // END RetinaNetHead._init__(cfg, in_channels)\n",
      "DEBUG:root:\t}\n",
      "\thead = RetinaNetHead(cfg, in_channels=1024) // RETURNED\n",
      "DEBUG:root:\t// head: RetinaNetHead(\n",
      "  (cls_tower): Sequential(\n",
      "    (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "  )\n",
      "  (bbox_tower): Sequential(\n",
      "    (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "  )\n",
      "  (cls_logits): Conv2d(1024, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bbox_pred): Conv2d(1024, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "DEBUG:root:\t#============================\n",
      "DEBUG:root:\t# 1.2.3 RPN box_coder build\n",
      "DEBUG:root:\t#============================\n",
      "DEBUG:root:\tbox_coder = BoxCoder(weights=(10., 10., 5., 5.)) // CALL\n",
      "\t{\n",
      "DEBUG:root:\t\tBoxCoder.__init__(self, weights, bbox_xfrom_clip)__ { // BEGIN\n",
      "DEBUG:root:\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/box_coder.py\n",
      "DEBUG:root:\t\t\t// Params:\n",
      "DEBUG:root:\t\t\t\tweights: (10.0, 10.0, 5.0, 5.0)\n",
      "DEBUG:root:\t\t\t\tbbox_xform_clip: 4.135166556742356\n",
      "DEBUG:root:\t\t\t\tself.weights = weights\n",
      "DEBUG:root:\t\t\t\tself.bbox_xform_clip = bbox_xform_clip\n",
      "\n",
      "DEBUG:root:\t\t} // END BoxCoder.__init__(self, weights, bbox_xfrom_clip)__\n",
      "\n",
      "DEBUG:root:\t}\n",
      "\tbox_coder = BoxCoder(weights=(10., 10., 5., 5.)) // RETURNED\n",
      "DEBUG:root:\t// box_coder: <maskrcnn_benchmark.modeling.box_coder.BoxCoder object at 0x7fb964579e80>\n",
      "DEBUG:root:\t#============================\n",
      "DEBUG:root:\t# 1.2.4 RPN box_selector_test build\n",
      "DEBUG:root:\t#============================\n",
      "DEBUG:root:\tbox_selector_test = make_retinanet_postprocessor(cfg, box_coder) // CALL\n",
      "\t{\n",
      "DEBUG:root:make_retinanet_postprocessor() { //BEGIN\n",
      "DEBUG:root:\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/retinanet/inference.py\n",
      "\n",
      "DEBUG:root:\t// Params:\n",
      "DEBUG:root:\t\t> config:\n",
      "DEBUG:root:\t\t> rpn_box_coder:\n",
      "\n",
      "DEBUG:root:RPNPostProcessor.__init__() { //BEGIN\n",
      "DEBUG:root:\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/inference.py\n",
      "DEBUG:root:} // END RPNPostProcessor.__init__()\n",
      "DEBUG:root:RetinaNetPostProcessor.__init__() { //BEGIN\n",
      "DEBUG:root:\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/modeling/rpn/retinanet/inference.py\n",
      "\n",
      "DEBUG:root:\t// Params:\n",
      "DEBUG:root:\t\t> pre_nms_top_n: 1000\n",
      "DEBUG:root:\t\t> post_nms_top_n: 1000\n",
      "DEBUG:root:\t\t> nms_thresh: 0.4\n",
      "DEBUG:root:\t\t> min_size: 0\n",
      "DEBUG:root:\t\t> box_coder: <maskrcnn_benchmark.modeling.box_coder.BoxCoder object at 0x7fb964579e80>\n",
      "DEBUG:root:\t\t> fpn_post_nms_top_n: 100\n",
      "DEBUG:root:\tself.pre_nms_thresh = pre_nms_thresh\n",
      "DEBUG:root:\tself.pre_nms_top_n = pre_nms_top_n\n",
      "DEBUG:root:\tself.nms_thresh = nms_thresh\n",
      "DEBUG:root:\tself.fpn_post_nms_top_n = fpn_post_nms_top_n\n",
      "DEBUG:root:\tself.min_size = min_size\n",
      "DEBUG:root:\tself.num_classes = num_classes\n",
      "DEBUG:root:\tself.box_coder = box_coder\n",
      "\n",
      "DEBUG:root:}// END RetinaNetPostProcessor.__init__()\n",
      "DEBUG:root:} // END make_retinanet_postprocessor()\n",
      "DEBUG:root:\t}\n",
      "\tbox_selector_test = make_retinanet_postprocessor(cfg, box_coder) // RETURNED\n",
      "DEBUG:root:\t// box_selector_test: RetinaNetPostProcessor()\n",
      "DEBUG:root:\tself.anchor_generator = anchor_generator\n",
      "DEBUG:root:\tself.head = head\n",
      "DEBUG:root:\tself.box_selector_test = box_selector_test\n",
      "DEBUG:root:\n",
      "\n",
      "} // RetinaNetModule.__init__(self, cfg, in_channels) END\n",
      "DEBUG:root:\t} // END build_retinanet(cfg, in_channels)\n",
      "DEBUG:root:\tself.rpn = build_rpn(cfg, self.backbone.out_channels) // RETURNED\n",
      "\n",
      "\n",
      "DEBUG:root:\t// self.rpn: RetinaNetModule(\n",
      "  (anchor_generator): AnchorGenerator(\n",
      "    (cell_anchors): BufferList()\n",
      "  )\n",
      "  (head): RetinaNetHead(\n",
      "    (cls_tower): Sequential(\n",
      "      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (bbox_tower): Sequential(\n",
      "      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (cls_logits): Conv2d(1024, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bbox_pred): Conv2d(1024, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (box_selector_test): RetinaNetPostProcessor()\n",
      ")\n",
      "DEBUG:root:\n",
      "\t} // END of 1.2\n",
      "\n",
      "DEBUG:root:} // END GeneralizedRCNN.__init__(self, cfg)\n",
      "INFO:maskrcnn_benchmark.utils.checkpoint:Loading checkpoint from ../model/detection/model_det_v2_200924_002_180k.pth\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.bn1.bias                  loaded from backbone.body.layer1.0.bn1.bias                  of shape (64,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.bn1.running_mean          loaded from backbone.body.layer1.0.bn1.running_mean          of shape (64,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.bn1.running_var           loaded from backbone.body.layer1.0.bn1.running_var           of shape (64,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.bn1.weight                loaded from backbone.body.layer1.0.bn1.weight                of shape (64,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.bn2.bias                  loaded from backbone.body.layer1.0.bn2.bias                  of shape (64,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.bn2.running_mean          loaded from backbone.body.layer1.0.bn2.running_mean          of shape (64,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.bn2.running_var           loaded from backbone.body.layer1.0.bn2.running_var           of shape (64,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.bn2.weight                loaded from backbone.body.layer1.0.bn2.weight                of shape (64,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.bn3.bias                  loaded from backbone.body.layer1.0.bn3.bias                  of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.bn3.running_mean          loaded from backbone.body.layer1.0.bn3.running_mean          of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.bn3.running_var           loaded from backbone.body.layer1.0.bn3.running_var           of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.bn3.weight                loaded from backbone.body.layer1.0.bn3.weight                of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.conv1.weight              loaded from backbone.body.layer1.0.conv1.weight              of shape (64, 64, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.conv2.weight              loaded from backbone.body.layer1.0.conv2.weight              of shape (64, 64, 3, 3)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.conv3.weight              loaded from backbone.body.layer1.0.conv3.weight              of shape (256, 64, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.downsample.0.weight       loaded from backbone.body.layer1.0.downsample.0.weight       of shape (256, 64, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.downsample.1.bias         loaded from backbone.body.layer1.0.downsample.1.bias         of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.downsample.1.running_mean loaded from backbone.body.layer1.0.downsample.1.running_mean of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.downsample.1.running_var  loaded from backbone.body.layer1.0.downsample.1.running_var  of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.0.downsample.1.weight       loaded from backbone.body.layer1.0.downsample.1.weight       of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.bn1.bias                  loaded from backbone.body.layer1.1.bn1.bias                  of shape (64,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.bn1.running_mean          loaded from backbone.body.layer1.1.bn1.running_mean          of shape (64,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.bn1.running_var           loaded from backbone.body.layer1.1.bn1.running_var           of shape (64,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.bn1.weight                loaded from backbone.body.layer1.1.bn1.weight                of shape (64,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.bn2.bias                  loaded from backbone.body.layer1.1.bn2.bias                  of shape (64,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.bn2.running_mean          loaded from backbone.body.layer1.1.bn2.running_mean          of shape (64,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.bn2.running_var           loaded from backbone.body.layer1.1.bn2.running_var           of shape (64,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.bn2.weight                loaded from backbone.body.layer1.1.bn2.weight                of shape (64,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.bn3.bias                  loaded from backbone.body.layer1.1.bn3.bias                  of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.bn3.running_mean          loaded from backbone.body.layer1.1.bn3.running_mean          of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.bn3.running_var           loaded from backbone.body.layer1.1.bn3.running_var           of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.bn3.weight                loaded from backbone.body.layer1.1.bn3.weight                of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.conv1.weight              loaded from backbone.body.layer1.1.conv1.weight              of shape (64, 256, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.conv2.weight              loaded from backbone.body.layer1.1.conv2.weight              of shape (64, 64, 3, 3)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.1.conv3.weight              loaded from backbone.body.layer1.1.conv3.weight              of shape (256, 64, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.bn1.bias                  loaded from backbone.body.layer1.2.bn1.bias                  of shape (64,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.bn1.running_mean          loaded from backbone.body.layer1.2.bn1.running_mean          of shape (64,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.bn1.running_var           loaded from backbone.body.layer1.2.bn1.running_var           of shape (64,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.bn1.weight                loaded from backbone.body.layer1.2.bn1.weight                of shape (64,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.bn2.bias                  loaded from backbone.body.layer1.2.bn2.bias                  of shape (64,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.bn2.running_mean          loaded from backbone.body.layer1.2.bn2.running_mean          of shape (64,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.bn2.running_var           loaded from backbone.body.layer1.2.bn2.running_var           of shape (64,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.bn2.weight                loaded from backbone.body.layer1.2.bn2.weight                of shape (64,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.bn3.bias                  loaded from backbone.body.layer1.2.bn3.bias                  of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.bn3.running_mean          loaded from backbone.body.layer1.2.bn3.running_mean          of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.bn3.running_var           loaded from backbone.body.layer1.2.bn3.running_var           of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.bn3.weight                loaded from backbone.body.layer1.2.bn3.weight                of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.conv1.weight              loaded from backbone.body.layer1.2.conv1.weight              of shape (64, 256, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.conv2.weight              loaded from backbone.body.layer1.2.conv2.weight              of shape (64, 64, 3, 3)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer1.2.conv3.weight              loaded from backbone.body.layer1.2.conv3.weight              of shape (256, 64, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.bn1.bias                  loaded from backbone.body.layer2.0.bn1.bias                  of shape (128,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.bn1.running_mean          loaded from backbone.body.layer2.0.bn1.running_mean          of shape (128,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.bn1.running_var           loaded from backbone.body.layer2.0.bn1.running_var           of shape (128,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.bn1.weight                loaded from backbone.body.layer2.0.bn1.weight                of shape (128,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.bn2.bias                  loaded from backbone.body.layer2.0.bn2.bias                  of shape (128,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.bn2.running_mean          loaded from backbone.body.layer2.0.bn2.running_mean          of shape (128,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.bn2.running_var           loaded from backbone.body.layer2.0.bn2.running_var           of shape (128,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.bn2.weight                loaded from backbone.body.layer2.0.bn2.weight                of shape (128,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.bn3.bias                  loaded from backbone.body.layer2.0.bn3.bias                  of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.bn3.running_mean          loaded from backbone.body.layer2.0.bn3.running_mean          of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.bn3.running_var           loaded from backbone.body.layer2.0.bn3.running_var           of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.bn3.weight                loaded from backbone.body.layer2.0.bn3.weight                of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.conv1.weight              loaded from backbone.body.layer2.0.conv1.weight              of shape (128, 256, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.conv2.weight              loaded from backbone.body.layer2.0.conv2.weight              of shape (128, 128, 3, 3)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.conv3.weight              loaded from backbone.body.layer2.0.conv3.weight              of shape (512, 128, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.downsample.0.weight       loaded from backbone.body.layer2.0.downsample.0.weight       of shape (512, 256, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.downsample.1.bias         loaded from backbone.body.layer2.0.downsample.1.bias         of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.downsample.1.running_mean loaded from backbone.body.layer2.0.downsample.1.running_mean of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.downsample.1.running_var  loaded from backbone.body.layer2.0.downsample.1.running_var  of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.0.downsample.1.weight       loaded from backbone.body.layer2.0.downsample.1.weight       of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.bn1.bias                  loaded from backbone.body.layer2.1.bn1.bias                  of shape (128,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.bn1.running_mean          loaded from backbone.body.layer2.1.bn1.running_mean          of shape (128,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.bn1.running_var           loaded from backbone.body.layer2.1.bn1.running_var           of shape (128,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.bn1.weight                loaded from backbone.body.layer2.1.bn1.weight                of shape (128,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.bn2.bias                  loaded from backbone.body.layer2.1.bn2.bias                  of shape (128,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.bn2.running_mean          loaded from backbone.body.layer2.1.bn2.running_mean          of shape (128,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.bn2.running_var           loaded from backbone.body.layer2.1.bn2.running_var           of shape (128,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.bn2.weight                loaded from backbone.body.layer2.1.bn2.weight                of shape (128,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.bn3.bias                  loaded from backbone.body.layer2.1.bn3.bias                  of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.bn3.running_mean          loaded from backbone.body.layer2.1.bn3.running_mean          of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.bn3.running_var           loaded from backbone.body.layer2.1.bn3.running_var           of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.bn3.weight                loaded from backbone.body.layer2.1.bn3.weight                of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.conv1.weight              loaded from backbone.body.layer2.1.conv1.weight              of shape (128, 512, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.conv2.weight              loaded from backbone.body.layer2.1.conv2.weight              of shape (128, 128, 3, 3)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.1.conv3.weight              loaded from backbone.body.layer2.1.conv3.weight              of shape (512, 128, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.bn1.bias                  loaded from backbone.body.layer2.2.bn1.bias                  of shape (128,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.bn1.running_mean          loaded from backbone.body.layer2.2.bn1.running_mean          of shape (128,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.bn1.running_var           loaded from backbone.body.layer2.2.bn1.running_var           of shape (128,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.bn1.weight                loaded from backbone.body.layer2.2.bn1.weight                of shape (128,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.bn2.bias                  loaded from backbone.body.layer2.2.bn2.bias                  of shape (128,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.bn2.running_mean          loaded from backbone.body.layer2.2.bn2.running_mean          of shape (128,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.bn2.running_var           loaded from backbone.body.layer2.2.bn2.running_var           of shape (128,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.bn2.weight                loaded from backbone.body.layer2.2.bn2.weight                of shape (128,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.bn3.bias                  loaded from backbone.body.layer2.2.bn3.bias                  of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.bn3.running_mean          loaded from backbone.body.layer2.2.bn3.running_mean          of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.bn3.running_var           loaded from backbone.body.layer2.2.bn3.running_var           of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.bn3.weight                loaded from backbone.body.layer2.2.bn3.weight                of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.conv1.weight              loaded from backbone.body.layer2.2.conv1.weight              of shape (128, 512, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.conv2.weight              loaded from backbone.body.layer2.2.conv2.weight              of shape (128, 128, 3, 3)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.2.conv3.weight              loaded from backbone.body.layer2.2.conv3.weight              of shape (512, 128, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.bn1.bias                  loaded from backbone.body.layer2.3.bn1.bias                  of shape (128,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.bn1.running_mean          loaded from backbone.body.layer2.3.bn1.running_mean          of shape (128,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.bn1.running_var           loaded from backbone.body.layer2.3.bn1.running_var           of shape (128,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.bn1.weight                loaded from backbone.body.layer2.3.bn1.weight                of shape (128,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.bn2.bias                  loaded from backbone.body.layer2.3.bn2.bias                  of shape (128,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.bn2.running_mean          loaded from backbone.body.layer2.3.bn2.running_mean          of shape (128,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.bn2.running_var           loaded from backbone.body.layer2.3.bn2.running_var           of shape (128,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.bn2.weight                loaded from backbone.body.layer2.3.bn2.weight                of shape (128,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.bn3.bias                  loaded from backbone.body.layer2.3.bn3.bias                  of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.bn3.running_mean          loaded from backbone.body.layer2.3.bn3.running_mean          of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.bn3.running_var           loaded from backbone.body.layer2.3.bn3.running_var           of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.bn3.weight                loaded from backbone.body.layer2.3.bn3.weight                of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.conv1.weight              loaded from backbone.body.layer2.3.conv1.weight              of shape (128, 512, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.conv2.weight              loaded from backbone.body.layer2.3.conv2.weight              of shape (128, 128, 3, 3)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer2.3.conv3.weight              loaded from backbone.body.layer2.3.conv3.weight              of shape (512, 128, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.bn1.bias                  loaded from backbone.body.layer3.0.bn1.bias                  of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.bn1.running_mean          loaded from backbone.body.layer3.0.bn1.running_mean          of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.bn1.running_var           loaded from backbone.body.layer3.0.bn1.running_var           of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.bn1.weight                loaded from backbone.body.layer3.0.bn1.weight                of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.bn2.bias                  loaded from backbone.body.layer3.0.bn2.bias                  of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.bn2.running_mean          loaded from backbone.body.layer3.0.bn2.running_mean          of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.bn2.running_var           loaded from backbone.body.layer3.0.bn2.running_var           of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.bn2.weight                loaded from backbone.body.layer3.0.bn2.weight                of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.bn3.bias                  loaded from backbone.body.layer3.0.bn3.bias                  of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.bn3.running_mean          loaded from backbone.body.layer3.0.bn3.running_mean          of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.bn3.running_var           loaded from backbone.body.layer3.0.bn3.running_var           of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.bn3.weight                loaded from backbone.body.layer3.0.bn3.weight                of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.conv1.weight              loaded from backbone.body.layer3.0.conv1.weight              of shape (256, 512, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.conv2.weight              loaded from backbone.body.layer3.0.conv2.weight              of shape (256, 256, 3, 3)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.conv3.weight              loaded from backbone.body.layer3.0.conv3.weight              of shape (1024, 256, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.downsample.0.weight       loaded from backbone.body.layer3.0.downsample.0.weight       of shape (1024, 512, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.downsample.1.bias         loaded from backbone.body.layer3.0.downsample.1.bias         of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.downsample.1.running_mean loaded from backbone.body.layer3.0.downsample.1.running_mean of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.downsample.1.running_var  loaded from backbone.body.layer3.0.downsample.1.running_var  of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.0.downsample.1.weight       loaded from backbone.body.layer3.0.downsample.1.weight       of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.bn1.bias                  loaded from backbone.body.layer3.1.bn1.bias                  of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.bn1.running_mean          loaded from backbone.body.layer3.1.bn1.running_mean          of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.bn1.running_var           loaded from backbone.body.layer3.1.bn1.running_var           of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.bn1.weight                loaded from backbone.body.layer3.1.bn1.weight                of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.bn2.bias                  loaded from backbone.body.layer3.1.bn2.bias                  of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.bn2.running_mean          loaded from backbone.body.layer3.1.bn2.running_mean          of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.bn2.running_var           loaded from backbone.body.layer3.1.bn2.running_var           of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.bn2.weight                loaded from backbone.body.layer3.1.bn2.weight                of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.bn3.bias                  loaded from backbone.body.layer3.1.bn3.bias                  of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.bn3.running_mean          loaded from backbone.body.layer3.1.bn3.running_mean          of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.bn3.running_var           loaded from backbone.body.layer3.1.bn3.running_var           of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.bn3.weight                loaded from backbone.body.layer3.1.bn3.weight                of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.conv1.weight              loaded from backbone.body.layer3.1.conv1.weight              of shape (256, 1024, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.conv2.weight              loaded from backbone.body.layer3.1.conv2.weight              of shape (256, 256, 3, 3)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.1.conv3.weight              loaded from backbone.body.layer3.1.conv3.weight              of shape (1024, 256, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.bn1.bias                  loaded from backbone.body.layer3.2.bn1.bias                  of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.bn1.running_mean          loaded from backbone.body.layer3.2.bn1.running_mean          of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.bn1.running_var           loaded from backbone.body.layer3.2.bn1.running_var           of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.bn1.weight                loaded from backbone.body.layer3.2.bn1.weight                of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.bn2.bias                  loaded from backbone.body.layer3.2.bn2.bias                  of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.bn2.running_mean          loaded from backbone.body.layer3.2.bn2.running_mean          of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.bn2.running_var           loaded from backbone.body.layer3.2.bn2.running_var           of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.bn2.weight                loaded from backbone.body.layer3.2.bn2.weight                of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.bn3.bias                  loaded from backbone.body.layer3.2.bn3.bias                  of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.bn3.running_mean          loaded from backbone.body.layer3.2.bn3.running_mean          of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.bn3.running_var           loaded from backbone.body.layer3.2.bn3.running_var           of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.bn3.weight                loaded from backbone.body.layer3.2.bn3.weight                of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.conv1.weight              loaded from backbone.body.layer3.2.conv1.weight              of shape (256, 1024, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.conv2.weight              loaded from backbone.body.layer3.2.conv2.weight              of shape (256, 256, 3, 3)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.2.conv3.weight              loaded from backbone.body.layer3.2.conv3.weight              of shape (1024, 256, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.bn1.bias                  loaded from backbone.body.layer3.3.bn1.bias                  of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.bn1.running_mean          loaded from backbone.body.layer3.3.bn1.running_mean          of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.bn1.running_var           loaded from backbone.body.layer3.3.bn1.running_var           of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.bn1.weight                loaded from backbone.body.layer3.3.bn1.weight                of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.bn2.bias                  loaded from backbone.body.layer3.3.bn2.bias                  of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.bn2.running_mean          loaded from backbone.body.layer3.3.bn2.running_mean          of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.bn2.running_var           loaded from backbone.body.layer3.3.bn2.running_var           of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.bn2.weight                loaded from backbone.body.layer3.3.bn2.weight                of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.bn3.bias                  loaded from backbone.body.layer3.3.bn3.bias                  of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.bn3.running_mean          loaded from backbone.body.layer3.3.bn3.running_mean          of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.bn3.running_var           loaded from backbone.body.layer3.3.bn3.running_var           of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.bn3.weight                loaded from backbone.body.layer3.3.bn3.weight                of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.conv1.weight              loaded from backbone.body.layer3.3.conv1.weight              of shape (256, 1024, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.conv2.weight              loaded from backbone.body.layer3.3.conv2.weight              of shape (256, 256, 3, 3)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.3.conv3.weight              loaded from backbone.body.layer3.3.conv3.weight              of shape (1024, 256, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.bn1.bias                  loaded from backbone.body.layer3.4.bn1.bias                  of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.bn1.running_mean          loaded from backbone.body.layer3.4.bn1.running_mean          of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.bn1.running_var           loaded from backbone.body.layer3.4.bn1.running_var           of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.bn1.weight                loaded from backbone.body.layer3.4.bn1.weight                of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.bn2.bias                  loaded from backbone.body.layer3.4.bn2.bias                  of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.bn2.running_mean          loaded from backbone.body.layer3.4.bn2.running_mean          of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.bn2.running_var           loaded from backbone.body.layer3.4.bn2.running_var           of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.bn2.weight                loaded from backbone.body.layer3.4.bn2.weight                of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.bn3.bias                  loaded from backbone.body.layer3.4.bn3.bias                  of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.bn3.running_mean          loaded from backbone.body.layer3.4.bn3.running_mean          of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.bn3.running_var           loaded from backbone.body.layer3.4.bn3.running_var           of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.bn3.weight                loaded from backbone.body.layer3.4.bn3.weight                of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.conv1.weight              loaded from backbone.body.layer3.4.conv1.weight              of shape (256, 1024, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.conv2.weight              loaded from backbone.body.layer3.4.conv2.weight              of shape (256, 256, 3, 3)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.4.conv3.weight              loaded from backbone.body.layer3.4.conv3.weight              of shape (1024, 256, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.bn1.bias                  loaded from backbone.body.layer3.5.bn1.bias                  of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.bn1.running_mean          loaded from backbone.body.layer3.5.bn1.running_mean          of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.bn1.running_var           loaded from backbone.body.layer3.5.bn1.running_var           of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.bn1.weight                loaded from backbone.body.layer3.5.bn1.weight                of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.bn2.bias                  loaded from backbone.body.layer3.5.bn2.bias                  of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.bn2.running_mean          loaded from backbone.body.layer3.5.bn2.running_mean          of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.bn2.running_var           loaded from backbone.body.layer3.5.bn2.running_var           of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.bn2.weight                loaded from backbone.body.layer3.5.bn2.weight                of shape (256,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.bn3.bias                  loaded from backbone.body.layer3.5.bn3.bias                  of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.bn3.running_mean          loaded from backbone.body.layer3.5.bn3.running_mean          of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.bn3.running_var           loaded from backbone.body.layer3.5.bn3.running_var           of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.bn3.weight                loaded from backbone.body.layer3.5.bn3.weight                of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.conv1.weight              loaded from backbone.body.layer3.5.conv1.weight              of shape (256, 1024, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.conv2.weight              loaded from backbone.body.layer3.5.conv2.weight              of shape (256, 256, 3, 3)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer3.5.conv3.weight              loaded from backbone.body.layer3.5.conv3.weight              of shape (1024, 256, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.bn1.bias                  loaded from backbone.body.layer4.0.bn1.bias                  of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.bn1.running_mean          loaded from backbone.body.layer4.0.bn1.running_mean          of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.bn1.running_var           loaded from backbone.body.layer4.0.bn1.running_var           of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.bn1.weight                loaded from backbone.body.layer4.0.bn1.weight                of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.bn2.bias                  loaded from backbone.body.layer4.0.bn2.bias                  of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.bn2.running_mean          loaded from backbone.body.layer4.0.bn2.running_mean          of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.bn2.running_var           loaded from backbone.body.layer4.0.bn2.running_var           of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.bn2.weight                loaded from backbone.body.layer4.0.bn2.weight                of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.bn3.bias                  loaded from backbone.body.layer4.0.bn3.bias                  of shape (2048,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.bn3.running_mean          loaded from backbone.body.layer4.0.bn3.running_mean          of shape (2048,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.bn3.running_var           loaded from backbone.body.layer4.0.bn3.running_var           of shape (2048,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.bn3.weight                loaded from backbone.body.layer4.0.bn3.weight                of shape (2048,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.conv1.weight              loaded from backbone.body.layer4.0.conv1.weight              of shape (512, 1024, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.conv2.weight              loaded from backbone.body.layer4.0.conv2.weight              of shape (512, 512, 3, 3)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.conv3.weight              loaded from backbone.body.layer4.0.conv3.weight              of shape (2048, 512, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.downsample.0.weight       loaded from backbone.body.layer4.0.downsample.0.weight       of shape (2048, 1024, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.downsample.1.bias         loaded from backbone.body.layer4.0.downsample.1.bias         of shape (2048,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.downsample.1.running_mean loaded from backbone.body.layer4.0.downsample.1.running_mean of shape (2048,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.downsample.1.running_var  loaded from backbone.body.layer4.0.downsample.1.running_var  of shape (2048,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.0.downsample.1.weight       loaded from backbone.body.layer4.0.downsample.1.weight       of shape (2048,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.bn1.bias                  loaded from backbone.body.layer4.1.bn1.bias                  of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.bn1.running_mean          loaded from backbone.body.layer4.1.bn1.running_mean          of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.bn1.running_var           loaded from backbone.body.layer4.1.bn1.running_var           of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.bn1.weight                loaded from backbone.body.layer4.1.bn1.weight                of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.bn2.bias                  loaded from backbone.body.layer4.1.bn2.bias                  of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.bn2.running_mean          loaded from backbone.body.layer4.1.bn2.running_mean          of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.bn2.running_var           loaded from backbone.body.layer4.1.bn2.running_var           of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.bn2.weight                loaded from backbone.body.layer4.1.bn2.weight                of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.bn3.bias                  loaded from backbone.body.layer4.1.bn3.bias                  of shape (2048,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.bn3.running_mean          loaded from backbone.body.layer4.1.bn3.running_mean          of shape (2048,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.bn3.running_var           loaded from backbone.body.layer4.1.bn3.running_var           of shape (2048,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.bn3.weight                loaded from backbone.body.layer4.1.bn3.weight                of shape (2048,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.conv1.weight              loaded from backbone.body.layer4.1.conv1.weight              of shape (512, 2048, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.conv2.weight              loaded from backbone.body.layer4.1.conv2.weight              of shape (512, 512, 3, 3)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.1.conv3.weight              loaded from backbone.body.layer4.1.conv3.weight              of shape (2048, 512, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.bn1.bias                  loaded from backbone.body.layer4.2.bn1.bias                  of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.bn1.running_mean          loaded from backbone.body.layer4.2.bn1.running_mean          of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.bn1.running_var           loaded from backbone.body.layer4.2.bn1.running_var           of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.bn1.weight                loaded from backbone.body.layer4.2.bn1.weight                of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.bn2.bias                  loaded from backbone.body.layer4.2.bn2.bias                  of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.bn2.running_mean          loaded from backbone.body.layer4.2.bn2.running_mean          of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.bn2.running_var           loaded from backbone.body.layer4.2.bn2.running_var           of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.bn2.weight                loaded from backbone.body.layer4.2.bn2.weight                of shape (512,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.bn3.bias                  loaded from backbone.body.layer4.2.bn3.bias                  of shape (2048,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.bn3.running_mean          loaded from backbone.body.layer4.2.bn3.running_mean          of shape (2048,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.bn3.running_var           loaded from backbone.body.layer4.2.bn3.running_var           of shape (2048,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.bn3.weight                loaded from backbone.body.layer4.2.bn3.weight                of shape (2048,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.conv1.weight              loaded from backbone.body.layer4.2.conv1.weight              of shape (512, 2048, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.conv2.weight              loaded from backbone.body.layer4.2.conv2.weight              of shape (512, 512, 3, 3)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.layer4.2.conv3.weight              loaded from backbone.body.layer4.2.conv3.weight              of shape (2048, 512, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.stem.bn1.bias                      loaded from backbone.body.stem.bn1.bias                      of shape (64,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.stem.bn1.running_mean              loaded from backbone.body.stem.bn1.running_mean              of shape (64,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.stem.bn1.running_var               loaded from backbone.body.stem.bn1.running_var               of shape (64,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.stem.bn1.weight                    loaded from backbone.body.stem.bn1.weight                    of shape (64,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.body.stem.conv1.weight                  loaded from backbone.body.stem.conv1.weight                  of shape (64, 3, 7, 7)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.fpn_inner2.bias                     loaded from backbone.fpn.fpn_inner2.bias                     of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.fpn_inner2.weight                   loaded from backbone.fpn.fpn_inner2.weight                   of shape (1024, 512, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.fpn_inner3.bias                     loaded from backbone.fpn.fpn_inner3.bias                     of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.fpn_inner3.weight                   loaded from backbone.fpn.fpn_inner3.weight                   of shape (1024, 1024, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.fpn_inner4.bias                     loaded from backbone.fpn.fpn_inner4.bias                     of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.fpn_inner4.weight                   loaded from backbone.fpn.fpn_inner4.weight                   of shape (1024, 2048, 1, 1)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.fpn_layer2.bias                     loaded from backbone.fpn.fpn_layer2.bias                     of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.fpn_layer2.weight                   loaded from backbone.fpn.fpn_layer2.weight                   of shape (1024, 1024, 3, 3)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.fpn_layer3.bias                     loaded from backbone.fpn.fpn_layer3.bias                     of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.fpn_layer3.weight                   loaded from backbone.fpn.fpn_layer3.weight                   of shape (1024, 1024, 3, 3)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.fpn_layer4.bias                     loaded from backbone.fpn.fpn_layer4.bias                     of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.fpn_layer4.weight                   loaded from backbone.fpn.fpn_layer4.weight                   of shape (1024, 1024, 3, 3)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.top_blocks.p6.bias                  loaded from backbone.fpn.top_blocks.p6.bias                  of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.top_blocks.p6.weight                loaded from backbone.fpn.top_blocks.p6.weight                of shape (1024, 2048, 3, 3)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.top_blocks.p7.bias                  loaded from backbone.fpn.top_blocks.p7.bias                  of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:backbone.fpn.top_blocks.p7.weight                loaded from backbone.fpn.top_blocks.p7.weight                of shape (1024, 1024, 3, 3)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:rpn.anchor_generator.cell_anchors.0              loaded from rpn.anchor_generator.cell_anchors.0              of shape (9, 4)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:rpn.anchor_generator.cell_anchors.1              loaded from rpn.anchor_generator.cell_anchors.1              of shape (9, 4)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:rpn.anchor_generator.cell_anchors.2              loaded from rpn.anchor_generator.cell_anchors.2              of shape (9, 4)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:rpn.anchor_generator.cell_anchors.3              loaded from rpn.anchor_generator.cell_anchors.3              of shape (9, 4)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:rpn.anchor_generator.cell_anchors.4              loaded from rpn.anchor_generator.cell_anchors.4              of shape (9, 4)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.bbox_pred.bias                          loaded from rpn.head.bbox_pred.bias                          of shape (36,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.bbox_pred.weight                        loaded from rpn.head.bbox_pred.weight                        of shape (36, 1024, 3, 3)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.bbox_tower.0.bias                       loaded from rpn.head.bbox_tower.0.bias                       of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.bbox_tower.0.weight                     loaded from rpn.head.bbox_tower.0.weight                     of shape (1024, 1024, 3, 3)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.bbox_tower.2.bias                       loaded from rpn.head.bbox_tower.2.bias                       of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.bbox_tower.2.weight                     loaded from rpn.head.bbox_tower.2.weight                     of shape (1024, 1024, 3, 3)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.bbox_tower.4.bias                       loaded from rpn.head.bbox_tower.4.bias                       of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.bbox_tower.4.weight                     loaded from rpn.head.bbox_tower.4.weight                     of shape (1024, 1024, 3, 3)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.bbox_tower.6.bias                       loaded from rpn.head.bbox_tower.6.bias                       of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.bbox_tower.6.weight                     loaded from rpn.head.bbox_tower.6.weight                     of shape (1024, 1024, 3, 3)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.cls_logits.bias                         loaded from rpn.head.cls_logits.bias                         of shape (9,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.cls_logits.weight                       loaded from rpn.head.cls_logits.weight                       of shape (9, 1024, 3, 3)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.cls_tower.0.bias                        loaded from rpn.head.cls_tower.0.bias                        of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.cls_tower.0.weight                      loaded from rpn.head.cls_tower.0.weight                      of shape (1024, 1024, 3, 3)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.cls_tower.2.bias                        loaded from rpn.head.cls_tower.2.bias                        of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.cls_tower.2.weight                      loaded from rpn.head.cls_tower.2.weight                      of shape (1024, 1024, 3, 3)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.cls_tower.4.bias                        loaded from rpn.head.cls_tower.4.bias                        of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.cls_tower.4.weight                      loaded from rpn.head.cls_tower.4.weight                      of shape (1024, 1024, 3, 3)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.cls_tower.6.bias                        loaded from rpn.head.cls_tower.6.bias                        of shape (1024,)\n",
      "INFO:maskrcnn_benchmark.utils.model_serialization:rpn.head.cls_tower.6.weight                      loaded from rpn.head.cls_tower.6.weight                      of shape (1024, 1024, 3, 3)\n",
      "DEBUG:root:\n",
      "\t\tCompose.__init__(self, transforms { // BEGIN\n",
      "DEBUG:root:\t\t\t// defined in /home/kimkk/work/lomin/maskrcnn_benchmark/data/transforms/transforms.py\n",
      "DEBUG:root:\n",
      "\t\t\t// Params:\n",
      "DEBUG:root:\t\t\t\ttransforms: [<maskrcnn_benchmark.data.transforms.transforms.Resize object at 0x7fb9774532b0>, <maskrcnn_benchmark.data.transforms.transforms.ToTensor object at 0x7fb977453080>, <maskrcnn_benchmark.data.transforms.transforms.Normalize object at 0x7fb9774532e8>]\n",
      "DEBUG:root:\n",
      "\t\t\tself.transforms = transforms\n",
      "DEBUG:root:\t\t\t// self.transforms: [<maskrcnn_benchmark.data.transforms.transforms.Resize object at 0x7fb9774532b0>, <maskrcnn_benchmark.data.transforms.transforms.ToTensor object at 0x7fb977453080>, <maskrcnn_benchmark.data.transforms.transforms.Normalize object at 0x7fb9774532e8>]\n",
      "DEBUG:root:\n",
      "\t\tCompose.__init__(self, transforms } // END\n"
     ]
    }
   ],
   "source": [
    "detection_model, _ = pytorch_model_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b0d297a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "saving learnalbe parameters of layers in detection v2 model\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './npy_save/backbone_body_stem_conv1_weight.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-f2623933f348>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_pytorch_model_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetection_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-2c66cbca3526>\u001b[0m in \u001b[0;36msave_pytorch_model_parameters\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# save Conv2d parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msave_pytorch_model_learnable_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# save FrozenBatchNora2d parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-8241f67a5fdb>\u001b[0m in \u001b[0;36msave_pytorch_model_learnable_parameters\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{param_name} of {arr.shape}\\n\\t\\tsaved in {file_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msave\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lomin/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m         \u001b[0mfile_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_ctx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './npy_save/backbone_body_stem_conv1_weight.npy'"
     ]
    }
   ],
   "source": [
    "save_pytorch_model_parameters(detection_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6656e0c",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# Caffe detection model v2 parameter loading\n",
    "\n",
    "Reference\n",
    "* [How do I load a caffe model and convert to a numpy array?](https://stackoverflow.com/questions/45199643/how-do-i-load-a-caffe-model-and-convert-to-a-numpy-array/45208380#45208380)\n",
    "* [Detection Model V2 structure](http://echo.etri.re.kr:8090/display/~kimkk/detection+model+v2+structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564312b7",
   "metadata": {},
   "source": [
    "## Function for loading backbone body (resnet50) parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b285d232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_backbone_body_params(network, log_to_file=False):\n",
    "    \n",
    "    # 로그 파일 ./tmp/load_backbone_body_parms_log.txt에 로그 기록\n",
    "    if log_to_file:\n",
    "        # get current function name\n",
    "        # https://stackoverflow.com/questions/5067604/determine-function-name-from-within-that-function-without-using-traceback\n",
    "        my_name =  inspect.currentframe().f_code.co_name\n",
    "        log_file_path = f\"./tmp/{my_name}_log.txt\"\n",
    "        original_std_out = sys.stdout\n",
    "        f = open(log_file_path, 'w')\n",
    "        sys.stdout = f \n",
    "\n",
    "    # backbone body (resnet50) 파라메터는 'backbone_body_' 접두사로 시작\n",
    "    k_list = [ k for k in network.params.keys() if k.startswith('backbone_body_') ]\n",
    "    total_num_of_params = len(k_list)\n",
    "    num_processing = 1\n",
    "        \n",
    "    # weight 및 bias의 경우, 접미사로 각각 'weight', 'bias'사용\n",
    "    suffix = [\"weight\", \"bias\"]\n",
    "    # num_layers = len(network.layer_dict)\n",
    "    \n",
    "    \n",
    "    for idx, layer_name in enumerate(network.layer_dict):\n",
    "                 \n",
    "        if layer_name in k_list:\n",
    "            print(f\"\\n-----------------------------\")\n",
    "            # print(f\"layer index: {idx}/{num_layers}\")\n",
    "            print(f\"Processing {num_processing}/{total_num_of_params}\")\n",
    "            print(f\"layer name: '{layer_name}''\")\n",
    "            print(f\"layer type: '{network.layers[idx].type}'\")\n",
    "        \n",
    "            params = network.params[layer_name]\n",
    "            print(f\"{len(params)} learnable parameters in '{network.layers[idx].type}' type\")\n",
    "            \n",
    "            for i, p in enumerate(params):\n",
    "                #print(f\"\\tparams[{i}]: {p}\")\n",
    "                #print(f\"\\tparams[{i}] CxHxW: {p.channels}x{p.height}x{p.width}\")\n",
    "                print(f\"\\tp[{i}]: {p.data.shape} of {p.data.dtype}\")                              \n",
    "                                \n",
    "                param_file_path = f\"../npy_save/{layer_name}_{suffix[i]}.npy\"\n",
    "                \n",
    "                param_file = Path(param_file_path)\n",
    "                if param_file.exists():\n",
    "                    print(f\"\\tload {param_file_path}\")\n",
    "                    arr = np.load(param_file_path, allow_pickle=True)\n",
    "                                        \n",
    "                    if p.data.shape == arr.shape:\n",
    "                        print(f\"\\tset {layer_name}_{suffix[i]} with arr:shape {arr.shape}, type {arr.dtype}\")\n",
    "                                                \n",
    "                        p.data[...] = arr                       \n",
    "                        \n",
    "                        if not (np.allclose(p.data, arr)):\n",
    "                            print(f\"\\t>>>>>> p.data is not euqal to arr\")\n",
    "                            print(f\"\\tp.data: {p.data}\")\n",
    "                            print(f\"\\tarr: {arr}\")\n",
    "                            \n",
    "                            if log_to_file:\n",
    "                                sys.stdout = original_std_out\n",
    "                                f.close()\n",
    "                                \n",
    "                            return False                              \n",
    "                    else:\n",
    "                        print(f\">>>>>> p.data.shape: {p.data.shape} is not equal to arr.shape: {arr.shape}\")\n",
    "                        if log_to_file:\n",
    "                            sys.stdout = original_std_out\n",
    "                            f.close()\n",
    "                            \n",
    "                        return False\n",
    "                else:\n",
    "                    print(f\">>>>>> {param_file_path} is not exits!!\")\n",
    "                    if log_to_file:\n",
    "                        sys.stdout = original_std_out\n",
    "                        f.close()\n",
    "                        \n",
    "                    return False                     \n",
    "            # END for i, pin in enumerate(params):\n",
    "            \n",
    "            num_processing +=1\n",
    "                    \n",
    "        #else:\n",
    "        #    print(f\"no learnable parameters in '{layer_name}' of '{network.layers[idx].type}' type'\")\n",
    "        \n",
    "    # END for idx, layer_name in enumerate(network.layer_dict):    \n",
    "    \n",
    "    print(f\"success!!\")\n",
    "    if log_to_file:\n",
    "        sys.stdout = original_std_out\n",
    "        f.close()\n",
    "    \n",
    "    print(f\"before return True\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251be859",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### Note on Update of parameter Blob in Caffe\n",
    "\n",
    "Refrence\n",
    "* [Why does assigning an ndarray to an ndarray in PyCaffe raise an Attribute Error?](https://stackoverflow.com/questions/32080017/why-does-assigning-an-ndarray-to-an-ndarray-in-pycaffe-raise-an-attribute-error/37271679#37271679) - stackoverflow\n",
    "* [copying layer weights and biases between networks](https://groups.google.com/g/caffe-users/c/1TqHBsfj1Zc) - caffe-users@googlegroups.com\n",
    "* [Improve python wrapper #311](https://github.com/BVLC/caffe/pull/311#issuecomment-40047852) - github.com/BVLC/caffe/pull/311\n",
    "\n",
    "Blob update should be done with `...` as follows\n",
    "```python\n",
    "stem_conv1_weight = detection_nw.params['backbone_body_stem_conv1'][0]\n",
    "# stem_conv1_weight.data= arr_stem_conv1_weight  # method 1\n",
    "stem_conv1_weight.data[...]= arr_stem_conv1_weight    # method 2\n",
    "```\n",
    "\n",
    "> The problem with the first method(`net.blobs['data'].data = z4`) is that 'data' is an attribute of net.blobs['data'](which is Caffe Blob object) which can not be assigned. If you assign numpy array to the data attribute, you mean \"instead of using the memory allocated for data, use the memory of the numpy array\", which is **not acceptable**.\n",
    "> \n",
    "> But if you use `net.blobs['data'].data[...] = z4`, you mean \"copy the data from the numpy array to the memory allocated for the data attribute\", which is **acceptable**.\n",
    "\n",
    "> Copying blobs in pycaffe works in the usual numpy way. Evan elided the \".data\" accessor in his assignment; the important difference is between attribute assignment and numpy slice assignment.   \n",
    ">> If you write   \n",
    ">> `blob.data = some_array`   \n",
    ">>> you are doing attribute assignment; you are saying \"hey net, instead of using the memory you were using before for that blob, use this other memory I have here\". This is not allowed (with certain exceptions).    \n",
    "\n",
    ">> If you write   \n",
    ">> `blob.data[...] = some_array`   \n",
    ">>> you are doing numpy slice assignment; you are saying \"hey net, copy the memory I have here into the memory you've already allocated for that blob\". That is what you want.\n",
    "(If you don't include \".data\" at all, you assigning an ndarray to a Blob, which doesn't make sense; a Blob holds two different ndarrays.)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304fe338",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## backbone_body_only network parameter loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3311ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bockbone body (resnet50) parameter load\n",
    "# 로그는 ./tmp/load_backbone_body_params_log.txt에 기록\n",
    "if (load_backbone_body_params(backbone_body_nw, log_to_file=True)):\n",
    "    print(\"backbone parameter loading success\")\n",
    "else:\n",
    "    print(\"backbone parameter loading fail\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cde2653",
   "metadata": {},
   "source": [
    "## Detection v2 Network's backbone body subnet parameter loading - tempoary disabling for testing backbone_body only network"
   ]
  },
  {
   "cell_type": "raw",
   "id": "839fd5ff",
   "metadata": {},
   "source": [
    "# bockbone body (resnet50) parameter load\n",
    "# 로그는 ./tmp/load_backbone_body_params_log.txt에 기록\n",
    "if (load_backbone_body_params(detection_nw, log_to_file=True)):\n",
    "    print(\"backbone parameter loading success\")\n",
    "else:\n",
    "    print(\"backbone parameter loading fail\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2d7fb189",
   "metadata": {},
   "source": [
    "# bockbon body (resnet50) parameter load\n",
    "# 로그는 화면에 출력\n",
    "if (load_backbone_body_params(detection_nw, log_to_file=False)):\n",
    "    print(\"backbone parameter loading success\")\n",
    "else:\n",
    "    print(\"backbone parameter loading fail\")\n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "id": "dfd29b9b",
   "metadata": {},
   "source": [
    "k_list = [ k for k in detection_nw.params.keys() if k.startswith('backbone_body_') ]\n",
    "k_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b0d692",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "#### check with some layer's weight and bias with `np.allclsoe()`"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9feba89d",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "-----------------------------\n",
    "Processing 15/106\n",
    "layer name: 'backbone_body_layer1_1_conv3''\n",
    "layer type: 'Convolution'\n",
    "1 learnable parameters in 'Convolution' type\n",
    "\tp[0]: (256, 64, 1, 1) of float32\n",
    "\tload ./npy_save/backbone_body_layer1_1_conv3_weight.npy\n",
    "\tset backbone_body_layer1_1_conv3_weight with arr:shape (256, 64, 1, 1), type float32\n",
    "\n",
    "\"\"\"\n",
    "caffe_backbone_body_layer1_1_conv3_weight = detection_nw.params['backbone_body_layer1_1_conv3'][0]\n",
    "torch_backbone_body_layer1_1_conv3_weight = np.load('./npy_save/backbone_body_layer1_1_conv3_weight.npy')\n",
    "np.allclose(torch_backbone_body_layer1_1_conv3_weight, caffe_backbone_body_layer1_1_conv3_weight.data)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7d0c2a4d",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "\n",
    "-----------------------------\n",
    "Processing 75/106\n",
    "layer name: 'backbone_body_layer3_4_conv1''\n",
    "layer type: 'Convolution'\n",
    "1 learnable parameters in 'Convolution' type\n",
    "\tp[0]: (256, 1024, 1, 1) of float32\n",
    "\tload ./npy_save/backbone_body_layer3_4_conv1_weight.npy\n",
    "\tset backbone_body_layer3_4_conv1_weight with arr:shape (256, 1024, 1, 1), type float32\n",
    "\"\"\"\n",
    "caffe_backbone_body_layer3_4_conv1_weight = detection_nw.params['backbone_body_layer3_4_conv1'][0]\n",
    "torch_backbone_body_layer3_4_conv1_weight = np.load('./npy_save/backbone_body_layer3_4_conv1_weight.npy')\n",
    "np.allclose(torch_backbone_body_layer3_4_conv1_weight, caffe_backbone_body_layer3_4_conv1_weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d173ccc5",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### Function for Loading backbone FPN  parameters\n",
    "\n",
    "Referece:\n",
    "* [how to understand caffe's bilinear upsampling](https://stackoverflow.com/questions/38431002/how-to-understand-caffes-bilinear-upsampling)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef6fab6",
   "metadata": {},
   "source": [
    "```java\n",
    "  fpn \"model.backbone.fpn\"\n",
    "    ├── fpn_inner2   \"model.backbone.fpn.fpn_inner2\",   // def: Conv2d(in_channels=512,  out_channels=1024, kernel_size=(1, 1), stride=(1, 1))\n",
    "    ├── fpn_layer2   \"model.backbone.fpn.fpn_layer2\",   // def: Conv2d(in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    │\n",
    "    ├── fpn_inner3   \"model.backbone.fpn.fpn_inner3\",   // def: Conv2d(in_channels=1024, out_channels=1024, kernel_size=(1, 1), stride=(1, 1))\n",
    "    ├── fpn_layer3   \"model.backbone.fpn.fpn_layer3\",   // def: Conv2d(in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    │\n",
    "    ├── fpn_inner4   \"model.backbone.fpn.fpn_inner4\",   // def: Conv2d(in_channels=2048, out_channels=1024, kernel_size=(1, 1), stride=(1, 1))\n",
    "    ├── fpn_layer4   \"model.backbone.fpn.fpn_layer4\",   // def: Conv2d(in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    │\n",
    "    └── top_blocks \"model.backbone.fpn.top_blocks\"\n",
    "           │\n",
    "           ├─── p6   \"model.backbone.fpn.top_blocks.p6\", // def: Conv2d(in_channels=2048, out_channels=1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "           └─── p7   \"model.backbone.fpn.top_blocks.p7\", // def: Conv2d(in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297f16c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_backbone_fpn_params(network, log_to_file=False):\n",
    "    \n",
    "    if log_to_file:\n",
    "        # get current function name\n",
    "        # https://stackoverflow.com/questions/5067604/determine-function-name-from-within-that-function-without-using-traceback\n",
    "        #my_name =  inspect.stack()[0][3]  \n",
    "        my_name =  inspect.currentframe().f_code.co_name\n",
    "        log_file_path = f\"./tmp/{my_name}_log.txt\"\n",
    "        original_std_out = sys.stdout\n",
    "        f = open(log_file_path, 'w')\n",
    "        sys.stdout = f \n",
    "    else:\n",
    "        sys.stdout = sys.stdout\n",
    "        \n",
    "    k_list = [ k for k in network.params.keys() if k.startswith('backbone_fpn') and \"upsample\" not in k ]\n",
    "    total_num_of_params = len(k_list)\n",
    "    num_processing = 1\n",
    "    \n",
    "    suffix = [\"weight\", \"bias\"]\n",
    "    num_layers = len(network.layer_dict)\n",
    "    \n",
    "    \n",
    "    for idx, layer_name in enumerate(network.layer_dict):\n",
    "                 \n",
    "        if layer_name in k_list:\n",
    "            print(f\"\\n-----------------------------\")\n",
    "            # print(f\"layer index: {idx}/{num_layers}\")\n",
    "            print(f\"Processing {num_processing}/{total_num_of_params}\")            \n",
    "            print(f\"layer name: '{layer_name}''\")\n",
    "            print(f\"layer type: '{network.layers[idx].type}'\")\n",
    "           \n",
    "            params = network.params[layer_name]\n",
    "            print(f\"{len(params)} learnable parameters in '{network.layers[idx].type}' type\")        \n",
    "            \n",
    "            for i, p in enumerate(params):\n",
    "                #print(f\"\\tparams[{i}]: {p}\")\n",
    "                #print(f\"\\tparams[{i}] CxHxW: {p.channels}x{p.height}x{p.width}\")\n",
    "                print(f\"\\tp[{i}]: {p.data.shape} of {p.data.dtype}\")\n",
    "                \n",
    "                                \n",
    "                param_file_path = f\"../npy_save/{layer_name}_{suffix[i]}.npy\"\n",
    "                \n",
    "                param_file = Path(param_file_path)\n",
    "                if param_file.exists():\n",
    "                    print(f\"\\tload {param_file_path}\")\n",
    "                    arr = np.load(param_file_path, allow_pickle=True)\n",
    "                    \n",
    "                    if p.data.shape == arr.shape:\n",
    "                        print(f\"\\tset {layer_name}_{suffix[i]} with arr:shape {arr.shape}, type {arr.dtype}\")\n",
    "                                                \n",
    "                        p.data[...] = arr\n",
    "                        if not (np.allclose(p.data, arr)):\n",
    "                            print(f\"\\t>>>>>> p.data is not euqal to arr\")\n",
    "                            print(f\"\\tp.data: {p.data}\")\n",
    "                            print(f\"\\tarr: {arr}\")\n",
    "                            \n",
    "                            if log_to_file:\n",
    "                                sys.stdout = original_std_out\n",
    "                                f.close()\n",
    "                            return False\n",
    "                        \n",
    "                    else:\n",
    "                        print(f\">>>>>> p.data.shape: {p.data.shape} is not equal to arr.shape: {arr.shape}\")\n",
    "                        if log_to_file:\n",
    "                            sys.stdout = original_std_out\n",
    "                            f.close()\n",
    "                            \n",
    "                        return False\n",
    "                else:\n",
    "                    print(f\">>>>>> {param_file_path} is not exits!!\")\n",
    "                    if log_to_file:\n",
    "                        sys.stdout = original_std_out\n",
    "                        f.close()\n",
    "                        \n",
    "                    return False                      \n",
    "            # END for i, p in enumearte(params)            \n",
    "            num_processing +=1\n",
    "        \n",
    "        #else:\n",
    "        #    print(f\"no learnable parameters in '{layer_name}' of '{network.layers[idx].type}' type'\")\n",
    "    \n",
    "    # END for idx, layer_name in enumerate(network.layer_dict):\n",
    "    if log_to_file:\n",
    "        sys.stdout = original_std_out\n",
    "        f.close()\n",
    "        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c54444ee",
   "metadata": {},
   "source": [
    "k_list = [ k for k in detection_nw.params.keys() if k.startswith('backbone_fpn') and \"upsample\" not in k ]\n",
    "k_list"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5478c30b",
   "metadata": {},
   "source": [
    "# bockbone fpn (feature pyramid network) parameter load\n",
    "# 로그는 ./tmp/load_backbone_fpn_params_log.txt에 기록\n",
    "if (load_backbone_fpn_params(detection_nw, log_to_file=True)):\n",
    "    print(\"backbone fpn parameter loading success\")\n",
    "else:\n",
    "    print(\"backbone fpn parameter loading fail\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee8ae4be",
   "metadata": {},
   "source": [
    "# bockbone fpn (feature pyramid network) parameter load\n",
    "# 로그는 화면에 출력\n",
    "if (load_backbone_fpn_params(detection_nw, log_to_file=False)):\n",
    "    print(\"backbone fpn parameter loading success\")\n",
    "else:\n",
    "    print(\"backbone fpn parameter loading fail\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad2798f",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "#### check with some layer's weight and bias with `np.allclsoe()`"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1e5282bb",
   "metadata": {},
   "source": [
    "caffe_backbone_fpn_fpn_inner3_weight = detection_nw.params['backbone_fpn_fpn_inner3'][0]\n",
    "torch_backbone_fpn_fpn_inner3_weight = np.load('./npy_save/backbone_fpn_fpn_inner3_weight.npy')\n",
    "np.allclose(torch_backbone_fpn_fpn_inner3_weight, caffe_backbone_fpn_fpn_inner3_weight.data)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "118c7d38",
   "metadata": {},
   "source": [
    "caffe_backbone_fpn_top_blocks_p6_weight = detection_nw.params['backbone_fpn_top_blocks_p6'][0]\n",
    "torch_backbone_fpn_top_blocks_p6_weight = np.load('./npy_save/backbone_fpn_top_blocks_p6_weight.npy')\n",
    "np.allclose(torch_backbone_fpn_top_blocks_p6_weight, caffe_backbone_fpn_top_blocks_p6_weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901220f0",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### Function for Loading RPN (Region Proposal Network) parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5343ef8e",
   "metadata": {},
   "source": [
    "#### Notes on RPN \n",
    "\n",
    "PyTorch Detection V2 model에서 RPN은 다음과 같은 구조로 이루어져 있으며,\n",
    "\n",
    "* class prediction: cls_tower -> cls_logits  \n",
    "  > **cls_tower.0**: Conv2d(in=1024, out=1024, kernel=(3,3), stride=(1,1), padding(1,1)   \n",
    "  > **cls_tower.1**: ReLu()  \n",
    "  > **cls_tower.2**: Conv2d(in=1024, out=1024, kernel=(3,3), stride=(1,1), padding(1,1)  \n",
    "  > **cls_tower.3**: ReLu()  \n",
    "  > **cls_tower.4**: Conv2d(in=1024, out=1024, kernel=(3,3), stride=(1,1), padding(1,1)  \n",
    "  > **cls_tower.5**: ReLu()  \n",
    "  > **cls_tower.6**: Conv2d(in=1024, out=1024, kernel=(3,3), stride=(1,1), padding(1,1)  \n",
    "  > **cls_tower.7**: ReLu()  \n",
    "  > **cls_logits** : Conv2d(in=1024, out=**9**, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  // note out_channels=9  \n",
    "  \n",
    "* bounding box predction: bbox_tower -> bbox_pred   \n",
    "  > **bbox_tower.0**: Conv2d(in=1024, out=1024, kernel=(3,3), stride=(1,1), padding(1,1)    \n",
    "  > **bbox_tower.1**: ReLu()  \n",
    "  > **bbox_tower.2**: Conv2d(in=1024, out=1024, kernel=(3,3), stride=(1,1), padding(1,1)  \n",
    "  > **bbox_tower.3**: ReLu()  \n",
    "  > **bbox_tower.4**: Conv2d(in=1024, out=1024, kernel=(3,3), stride=(1,1), padding(1,1)  \n",
    "  > **bbox_tower.5**: ReLu()  \n",
    "  > **bbox_tower.6**: Conv2d(in=1024, out=1024, kernel=(3,3), stride=(1,1), padding(1,1)  \n",
    "  > **bbox_tower.7**: ReLu()  \n",
    "  > **bbox_pred** : Conv2d(in=1024, out=**36**, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))   // note out_channels=36  \n",
    "  \n",
    "위와 같은 2개의 요소로 이루어진 서브네트워크에 대하여 backbone_fpn 네트워크에서의 출력인 [P2, P3, P4, P6, P7] 각각에 대하여 for 문을 통하여 looping을 하는 방식을 사용한다.\n",
    "Caffe에서는 서브네트워크에 대하여 looping이 불가능하므로, loop unrolling 방식으로 서브네트워크를 5개로 replication하여 각각 P2, P3, P4, P6, P7를 처리하고\n",
    "bbox_pred 5개, cls_logits 5개를 만들어내도록 네트워크를 구성하였다.\n",
    "\n",
    "```java\n",
    " rpn          \"model.rpn\"\n",
    "   ├─── head  \"model.rpn.head\"\n",
    "   │           │\n",
    "   │           ├─── cls_tower      \"model.rpn.head.cls_tower\",\n",
    "   │           │     ├─── 0        \"model.rpn.head.cls_tower.0\",   // def: Conv2d(in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "   │           │     ├─── 1        \"model.rpn.head.cls_tower.1\",   // def: ReLU()\n",
    "   │           │     ├─── 2        \"model.rpn.head.cls_tower.2\",   // def: Conv2d(in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "   │           │     ├─── 3        \"model.rpn.head.cls_tower.3\",   // def: ReLU()\n",
    "   │           │     ├─── 4        \"model.rpn.head.cls_tower.4\",   // def: Conv2d(in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "   │           │     ├─── 5        \"model.rpn.head.cls_tower.5\",   // def: ReLU()\n",
    "   │           │     ├─── 6        \"model.rpn.head.cls_tower.6\",   // def: Conv2d(in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "   │           │     └─── 7        \"model.rpn.head.cls_tower.7\",   // def: ReLU()\n",
    "   │           │\n",
    "   │           ├─── bbox_tower     \"model.rpn.head.bbox_tower\"\n",
    "   │           │     ├─── 0        \"model.rpn.head.bbox_tower.0\",  // def: Conv2d(in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "   │           │     ├─── 1        \"model.rpn.head.bbox_tower.1\",  // def: ReLU()\n",
    "   │           │     ├─── 2        \"model.rpn.head.bbox_tower.2\",  // def: Conv2d(in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "   │           │     ├─── 3        \"model.rpn.head.bbox_tower.3\",  // def: ReLU()\n",
    "   │           │     ├─── 4        \"model.rpn.head.bbox_tower.4\",  // def: Conv2d(in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "   │           │     ├─── 5        \"model.rpn.head.bbox_tower.5\",  // def: ReLU()\n",
    "   │           │     ├─── 6        \"model.rpn.head.bbox_tower.6\",  // def: Conv2d(in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "   │           │     └─── 7        \"model.rpn.head.bbox_tower.7\",  // def: ReLU()\n",
    "   │           │\n",
    "   │           ├─── cls_logits     \"model.rpn.head.cls_logits\",    // def: Conv2d(in_channels=1024, out_channels=9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "   │           │\n",
    "   │           └─── bbox_pred      \"model.rpn.head.bbox_pred\",      // def: Conv2d(in_channels=1024, out_channels=36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "   │\n",
    "   ├─── anchor_generator \"model.rpn.anchor_generator\"\n",
    "   │           │ \n",
    "   │           └─── cell_anchors   \"model.rpn.anchor_generator.cell_achors\",     // def: BufferList()\n",
    "   │\n",
    "   └─── box_selector_test \"model.rpn.box_selector_test\",                         // def: RetinaNetPostProcessor()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bdc83f02",
   "metadata": {},
   "source": [
    "k_list = [ k for k in detection_nw.params.keys() if k.startswith('rpn_head')]\n",
    "k_list\n",
    "len(k_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f4bb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rpn_params(network, log_to_file=False):\n",
    "    \n",
    "    if log_to_file:\n",
    "        # get current function name\n",
    "        # https://stackoverflow.com/questions/5067604/determine-function-name-from-within-that-function-without-using-traceback\n",
    "        #my_name =  inspect.stack()[0][3]  \n",
    "        my_name =  inspect.currentframe().f_code.co_name\n",
    "        log_file_path = f\"./tmp/{my_name}_log.txt\"\n",
    "        original_std_out = sys.stdout\n",
    "        f = open(log_file_path, 'w')\n",
    "        sys.stdout = f \n",
    "    else:\n",
    "        sys.stdout = sys.stdout\n",
    "        \n",
    "    k_list = [ k for k in network.params.keys() if k.startswith('rpn_head') ]\n",
    "    total_num_of_params = len(k_list)\n",
    "    num_processing = 1\n",
    "    \n",
    "    suffix = [\"weight\", \"bias\"]\n",
    "    #num_layers = len(network.layer_dict)\n",
    "    \n",
    "    \n",
    "    for idx, layer_name in enumerate(network.layer_dict):\n",
    "                 \n",
    "        if layer_name in k_list:\n",
    "            print(f\"\\n-----------------------------\")\n",
    "            # print(f\"layer index: {idx}/{num_layers}\")\n",
    "            print(f\"Processing {num_processing}/{total_num_of_params}\")            \n",
    "            print(f\"layer name: '{layer_name}''\")\n",
    "            print(f\"layer type: '{network.layers[idx].type}'\")\n",
    "           \n",
    "            params = network.params[layer_name]\n",
    "            print(f\"{len(params)} learnable parameters in '{network.layers[idx].type}' type\")        \n",
    "            \n",
    "            for i, p in enumerate(params):\n",
    "                #print(f\"\\tparams[{i}]: {p}\")\n",
    "                #print(f\"\\tparams[{i}] CxHxW: {p.channels}x{p.height}x{p.width}\")\n",
    "                print(f\"\\tp[{i}]: {p.data.shape} of {p.data.dtype}\")                \n",
    "                                \n",
    "                # note remove '_for_pn' suffix from layer name\n",
    "                param_file_path = f\"../npy_save/{layer_name[:-7]}_{suffix[i]}.npy\"\n",
    "                \n",
    "                param_file = Path(param_file_path)\n",
    "                if param_file.exists():\n",
    "                    print(f\"\\tload {param_file_path}\")\n",
    "                    arr = np.load(param_file_path, allow_pickle=True)\n",
    "                    \n",
    "                    if p.data.shape == arr.shape:\n",
    "                        print(f\"\\tset {layer_name}_{suffix[i]} with arr:shape {arr.shape}, type {arr.dtype}\")\n",
    "                                                \n",
    "                        p.data[...] = arr\n",
    "                        if not (np.allclose(p.data, arr)):\n",
    "                            print(f\"\\t>>>>>> p.data is not euqal to arr\")\n",
    "                            print(f\"\\tp.data: {p.data}\")\n",
    "                            print(f\"\\tarr: {arr}\")\n",
    "                            \n",
    "                            if log_to_file:\n",
    "                                sys.stdout = original_std_out\n",
    "                                f.close()\n",
    "                                \n",
    "                            return False\n",
    "                        \n",
    "                    else:\n",
    "                        print(f\">>>>>> p.data.shape: {p.data.shape} is not equal to arr.shape: {arr.shape}\")\n",
    "                        if log_to_file:\n",
    "                            sys.stdout = original_std_out\n",
    "                            f.close()\n",
    "                            \n",
    "                        return False\n",
    "                else:\n",
    "                    print(f\">>>>>> {param_file_path} is not exits!!\")\n",
    "                    if log_to_file:\n",
    "                        sys.stdout = original_std_out\n",
    "                        f.close()\n",
    "                        \n",
    "                    return False                    \n",
    "            # END for i, p in enumearte(params)            \n",
    "            num_processing +=1\n",
    "        \n",
    "        #else:\n",
    "        #    print(f\"no learnable parameters in '{layer_name}' of '{network.layers[idx].type}' type'\")\n",
    "    \n",
    "    # END for idx, layer_name in enumerate(network.layer_dict):\n",
    "    if log_to_file:\n",
    "        sys.stdout = original_std_out\n",
    "        f.close()\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d076ebfa",
   "metadata": {},
   "source": [
    "# rpn (region proposal network) parameter load\n",
    "# 로그는 ./tmp/load_rpn_params_log.txt에 기록\n",
    "if (load_rpn_params(detection_nw, log_to_file=True)):\n",
    "    print(\"rpn parameter loading success\")\n",
    "else:\n",
    "    print(\"rpn parameter loading fail\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea2469d7",
   "metadata": {},
   "source": [
    "# rpn (region proposal network) parameter load\n",
    "# 로그는 화면에 출력\n",
    "if (load_rpn_params(detection_nw, log_to_file=False)):\n",
    "    print(\"backbone fpn parameter loading success\")\n",
    "else:\n",
    "    print(\"backbone fpn parameter loading fail\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5444566",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "#### check with some layer's weight and bias with `np.allclsoe()`"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ff337d3f",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "-----------------------------\n",
    "Processing 39/50\n",
    "layer name: 'rpn_head_bbox_tower_6_for_p6''\n",
    "layer type: 'Convolution'\n",
    "2 learnable parameters in 'Convolution' type\n",
    "\tp[0]: (1024, 1024, 3, 3) of float32\n",
    "\tload ./npy_save/rpn_head_bbox_tower_6_weight.npy\n",
    "\tset rpn_head_bbox_tower_6_for_p6_weight with arr:shape (1024, 1024, 3, 3), type float32\n",
    "\tp[1]: (1024,) of float32\n",
    "\tload ./npy_save/rpn_head_bbox_tower_6_bias.npy\n",
    "\tset rpn_head_bbox_tower_6_for_p6_bias with arr:shape (1024,), type float32\n",
    "\"\"\"\n",
    "\n",
    "caffe_rpn_head_bbox_tower_6_for_p6_weight = detection_nw.params['rpn_head_bbox_tower_6_for_p6'][0]\n",
    "torch_rpn_head_bbox_tower_6_for_p6_weight = np.load('./npy_save/rpn_head_bbox_tower_6_weight.npy')\n",
    "np.allclose(torch_rpn_head_bbox_tower_6_for_p6_weight, caffe_rpn_head_bbox_tower_6_for_p6_weight.data)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "38f37cc7",
   "metadata": {},
   "source": [
    "caffe_rpn_head_bbox_tower_6_for_p6_bias = detection_nw.params['rpn_head_bbox_tower_6_for_p6'][1]\n",
    "torch_rpn_head_bbox_tower_6_for_p6_bias = np.load('./npy_save/rpn_head_bbox_tower_6_bias.npy')\n",
    "np.allclose(torch_rpn_head_bbox_tower_6_for_p6_bias, caffe_rpn_head_bbox_tower_6_for_p6_bias.data)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "276a17a4",
   "metadata": {},
   "source": [
    "help(caffe._caffe.Blob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d46fa5c",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# Saving Layer Paramters Update into `.caffemodel` file\n",
    "\n",
    "Reference:\n",
    "* [Save the weights for a specific layer, not only visualize on Caffe](https://stackoverflow.com/questions/57517000/save-the-weights-for-a-specific-layer-not-only-visualize-on-caffe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6b1d2f",
   "metadata": {},
   "source": [
    "## Saving backbone_body newtork parameter into caffemodel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ba1f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_body_network_caffemodel_file_path = './backbone_body.caffemodel'\n",
    "backbone_body_nw.save(backbone_body_network_caffemodel_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d7c083",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh ./backbone_body.caffemodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e496fdb",
   "metadata": {},
   "source": [
    "## Saving detection v2 newtork parameter  - tempoary disable for tesing backbone_body network"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bebcac8d",
   "metadata": {},
   "source": [
    "detection_v2_network_caffemodel_file_path = './detection_model_v2.caffemodel'\n",
    "detection_nw.save(detection_v2_network_caffemodel_file_path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6194aaf4",
   "metadata": {},
   "source": [
    "!ls -lh ./detection_model_v2.caffemodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2319922e",
   "metadata": {},
   "source": [
    "\n",
    "`caffe.Net.save(path_to_caffemodel)`을 사용하여 현재 Network의 파라메터들을 `.caffemodel` 형식으로 저장할 수 있다. \n",
    "* 네트워크의 구조를 저장하는 `.prototxt` 파일과 달리, 네트워크의 파라메터를 저장하는 `.caffemodel` 파일은 binary형식이므로 에디터로 바로 내용을 확인할 수는 없다.\n",
    "\n",
    "다음과 같이 `protoc` (protobuf compiler)의 `--decode` 옵션을 통하여 human readable text로 변환할 수 있다.\n",
    "* Reference : Export and Import ONNX model](http://echo.etri.re.kr:8090/display/~kimkk/Export+and+Import+ONNX+model) - kimkk confluence page\n",
    "\n",
    "```bash\n",
    "# for all network archtecture information\n",
    "$ protoc --decode=caffe.NetParameter caffe.proto < ./detection_model_v2.caffemodel > detection_model_v2_params.prototxt\n",
    "\n",
    "# for all network layer information\n",
    "$ protoc --decode=caffe.LayerParameter caffe.proto < ./detection_model_v2.caffemodel > detection_model_v2_layer_params.prototxt\n",
    "```\n",
    "* caffe source distribution에 포함된 `caffe.proto` 파일을 복사해놓고 위의 명령을 실행한다.  \n",
    "* `protoc`의 `--decode` 옵션에 디코딩할 최상위 레벨 메시지 타입을 지정하고, protobuf 정의 파일을 지정하고 표준 입력 재지정으로 바이너리로 저장한 파일을 지정해주면\n",
    "디코딩을 통하여 텍스트 포맷으로 저장된 내용을 보여준다.  \n",
    "* 디버깅시에 유용한 옵션이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0edbb6",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## How to access the specific layer output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edb3365",
   "metadata": {},
   "source": [
    "Access layer output in PyCaffe\n",
    "* Reference: \n",
    "  * [Convert Caffe CNN to Feature Extractor](https://stackoverflow.com/questions/49377891/convert-caffe-cnn-to-feature-extractor)\n",
    "\n",
    "`caffe.Net.blobs` (odered dict)는 입력 데이타와 입력 데이타가 레이어들을 따라 계산된 결과를 저장하는 텐서들에 대한 딕셔너리로 다음과 같이 `.prototxt` 파일에서 해당 레이어의 top 필드에 사용한 이름을 key로 사용하여 텐서를 접근할 수 있다.\n",
    "* net.blobs['data'] : shape가 (1, 1, 100, 100)인 입력 데이타 텐서\n",
    "* net.blobs['conv']: ‘conv’ (1, 3, 96, 96)를 통하여 계산된 결과 텐서로 0으로 초기화된다.\n",
    "\n",
    "아래와 같은 코드를 통하여 전체 입력 텐서로부터 각 레이어들에서 계산된 결과를 저장한 텐서들의 전체 sahpe 정보를 확인할 수 있다.\n",
    "```python\n",
    "[(k, v.data.shape) for k, v in net.blobs.items()]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687ef975",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(k, v.data.shape) for k, v in backbone_body_nw.blobs.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d257fc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_output_dict = {}\n",
    "for k, v in backbone_body_nw.blobs.items():\n",
    "    layer_output_dict[k] = v\n",
    "    \n",
    "for k in layer_output_dict.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35453185",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_output_dict['backbone_body_stem_maxpool'].data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cba3ffe",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### check for stem layer output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e00a39a",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# Inference with caffe detection model v2\n",
    "\n",
    "References:\n",
    "* [net_surgery.ipynb](https://github.com/BVLC/caffe/blob/master/examples/net_surgery.ipynb)\n",
    "* [Pycaffe Net forward_all() function not working](https://stackoverflow.com/questions/40181752/pycaffe-net-forward-all-function-not-working)\n",
    "* [Python caffe.TEST Examples](https://www.programcreek.com/python/example/82811/caffe.TEST) - www.programcreek.com\n",
    "* [Prediction in Caffe - Exception: Input blob arguments do not match net inputs](https://stackoverflow.com/questions/29124840/prediction-in-caffe-exception-input-blob-arguments-do-not-match-net-inputs)\n",
    "* [caffe dist example: Classification: Instant Recognition with Caffe](https://github.com/BVLC/caffe/blob/master/examples/00-classification.ipynbhttps://github.com/BVLC/caffe/blob/master/examples/00-classification.ipynb)\n",
    "* [Caffe C++ set data in input layer](https://stackoverflow.com/questions/45457351/caffe-c-set-data-in-input-layer)* [Caffe C++ set data in input layer](https://stackoverflow.com/questions/45457351/caffe-c-set-data-in-input-layer)\n",
    "\n",
    "> You have to pass the data you want to forward to the `forward_all()` function:\n",
    "\n",
    "----\n",
    "\n",
    "```python\n",
    "pred_net = caffe.Net(pred_net_proto_file, 'kg_trained.caffemodel', caffe.TEST)\n",
    "pred_net.forward_all(data=data_samples)\n",
    "```\n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532c2ec0",
   "metadata": {},
   "source": [
    "## Prediction Net instantiation with prototxt and caffemodel files"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8b15fbde",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "help(caffe.Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e475b5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_body_nw = caffe.Net( './backbone_body_network.prototxt', './backbone_body.caffemodel',caffe.TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41826e86",
   "metadata": {},
   "source": [
    "### check for weight in stem layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c61c681",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_body_nw.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519e7c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "caffe_backbone_body_stem_conv1_weight = backbone_body_nw.params['backbone_body_stem_conv1'][0]\n",
    "torch_backbone_body_stem_conv1_weight = np.load('../npy_save/backbone_body_stem_conv1_weight.npy')\n",
    "np.allclose(torch_backbone_body_stem_conv1_weight, caffe_backbone_body_stem_conv1_weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5eb584",
   "metadata": {},
   "outputs": [],
   "source": [
    "caffe_backbone_body_stem_conv1_weight.data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a338a52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "caffe_backbone_body_stem_conv1_weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d900bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "caffe_backbone_body_stem_bn1_weight = backbone_body_nw.params['backbone_body_stem_bn1'][0]\n",
    "torch_backbone_body_stem_bn1_weight = np.load('../npy_save/backbone_body_stem_bn1_weight.npy')\n",
    "np.allclose(torch_backbone_body_stem_bn1_weight, caffe_backbone_body_stem_bn1_weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d28b27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bd0ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "caffe_backbone_body_stem_bn1_bias = backbone_body_nw.params['backbone_body_stem_bn1'][1]\n",
    "torch_backbone_body_stem_bn1_bias = np.load('../npy_save/backbone_body_stem_bn1_bias.npy')\n",
    "np.allclose(torch_backbone_body_stem_bn1_bias, caffe_backbone_body_stem_bn1_bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2096066",
   "metadata": {},
   "outputs": [],
   "source": [
    "caffe_backbone_body_stem_bn1_weight.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206f8bc2",
   "metadata": {},
   "source": [
    "## Net.forward_all() vs. Net.forward()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e4600789",
   "metadata": {},
   "source": [
    "help(caffe.Net.forward_all)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "17dfa652",
   "metadata": {},
   "source": [
    "help(caffe.Net.forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a3cca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batched_arr defined in 5.2.4. Zero Padding\n",
    "batched_arr.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caf1da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_output_dict['data'].data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5579f110",
   "metadata": {},
   "source": [
    "## Set network input \n",
    "\n",
    "Reference: \n",
    "* [Prediction in Caffe - Exception: Input blob arguments do not match net inputs](https://stackoverflow.com/questions/29124840/prediction-in-caffe-exception-input-blob-arguments-do-not-match-net-inputs)\n",
    "* [Caffe C++ set data in input layer](https://stackoverflow.com/questions/45457351/caffe-c-set-data-in-input-layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd97d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_body_nw.blobs['data'].data[...] = batched_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b717d4",
   "metadata": {},
   "source": [
    "**Meaning of the three dots in `net.blobs['data'].data[...]`**\n",
    "> ref: [Cheat sheet for caffe / pycaffe?](https://stackoverflow.com/questions/32379878/cheat-sheet-for-caffe-pycaffe?rq=1)\n",
    "\n",
    "it is a short form of addressing all elements in the matrix which would normally be written as [:,:,:]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9befc859",
   "metadata": {},
   "source": [
    "## Run forward() for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ea6e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT WORKING\n",
    "# backbone_body_nw.forward_all()\n",
    "# backbone_body_nw.forward_all(data=batched_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2296f0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = backbone_body_nw.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92af49e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67effa8",
   "metadata": {},
   "source": [
    "### layer_output_dict reinit\n",
    "\n",
    "**주의 사항**  \n",
    "\n",
    "forward() 호출을 통하여 layer별 출력 결과가 새로 계산되므로, layer_output_dict를 사용하려면 다시 구축해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125e006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(backbone_body_nw.blobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0a2458",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_body_nw.blobs['backbone_body_stem_maxpool'].data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7509f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backbone_body_stem_bn1 scale\n",
    "backbone_body_nw.params['backbone_body_stem_bn1'][0].data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c09d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_body_nw.params['backbone_body_stem_bn1'][0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3478c909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backbone_body_stem_bn1 bias\n",
    "backbone_body_nw.params['backbone_body_stem_bn1'][1].data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44b3155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backbone_body_stem_bn1 bias\n",
    "backbone_body_nw.params['backbone_body_stem_bn1'][1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafd60a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backbone_body_stem_conv1' output\n",
    "backbone_body_nw.blobs['backbone_body_stem_conv1'].data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f99cfa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67b6fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_output_dict = {}\n",
    "for k, v in backbone_body_nw.blobs.items():\n",
    "    layer_output_dict[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1db50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_output_dict['backbone_body_stem_maxpool'].data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40208f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_output_dict['backbone_body_stem_maxpool_backbone_body_stem_maxpool_0_split_0'].data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14817aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_output_dict['backbone_body_stem_maxpool_backbone_body_stem_maxpool_0_split_1'].data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a284f476",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(layer_output_dict['backbone_body_stem_maxpool_backbone_body_stem_maxpool_0_split_0'].data, \\\n",
    "            layer_output_dict['backbone_body_stem_maxpool_backbone_body_stem_maxpool_0_split_1'].data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce90ed8",
   "metadata": {},
   "source": [
    "### stem conv1 ouput check\n",
    "\n",
    "References:  \n",
    "* [The implementation of ResNet is different from official implementation in Caffe #191](https://github.com/pytorch/vision/issues/191)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab6eb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path =f\"../npy_save/backbone_body_stem_conv1_output.npy\"\n",
    "output_file = Path(output_file_path)\n",
    "if output_file.exists():\n",
    "    pytorch_stem_conv1_output = np.load(output_file_path, allow_pickle=True)  \n",
    "    caffe_stem_conv1_output=layer_output_dict['backbone_body_stem_conv1'].data\n",
    "    \n",
    "np.allclose(caffe_stem_conv1_output, pytorch_stem_conv1_output, rtol=1e-03, atol=1e-4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dfed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "caffe_stem_conv1_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189f662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_stem_conv1_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a191a7c",
   "metadata": {},
   "source": [
    "### stem bn1 ouput check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badaa53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path =f\"../npy_save/backbone_body_stem_bn1_output.npy\"\n",
    "output_file = Path(output_file_path)\n",
    "if output_file.exists():\n",
    "    pytorch_stem_bn1_output = np.load(output_file_path, allow_pickle=True)  \n",
    "    caffe_stem_bn1_output=layer_output_dict['backbone_body_stem_bn1'].data\n",
    "    \n",
    "np.allclose(caffe_stem_bn1_output, pytorch_stem_bn1_output, rtol=1e-03, atol=1e-3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a016f07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "caffe_stem_bn1_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329c3bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_stem_bn1_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6239309a",
   "metadata": {},
   "source": [
    "### stem relu ouput check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fedbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path =f\"../npy_save/backbone_body_stem_relu_output.npy\"\n",
    "output_file = Path(output_file_path)\n",
    "if output_file.exists():\n",
    "    pytorch_stem_relu_output = np.load(output_file_path, allow_pickle=True)  \n",
    "    caffe_stem_relu_output=layer_output_dict['backbone_body_stem_relu'].data\n",
    "    \n",
    "np.allclose(caffe_stem_relu_output, pytorch_stem_relu_output, rtol=1e-03, atol=1e-3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778926c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "caffe_stem_relu_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b0fe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_stem_relu_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f717bc",
   "metadata": {},
   "source": [
    "### stem maxpool output check - difference happens here!!\n",
    "\n",
    "References:\n",
    "* [the diff of resnet18 between caffe and pytorch model is large #16 ](https://github.com/xxradon/PytorchToCaffe/issues/16)\n",
    "* [Inconsistency between caffe and pytorch for max-pooling](https://discuss.pytorch.org/t/inconsistency-between-caffe-and-pytorch-for-max-pooling/35553)\n",
    "\n",
    "> the main reason is the difference of pooling layer, **caffe** default mode is **ceil** and **pytorc**h is **floor** ,  \n",
    "> so we need add a para in caffe's pooling layer in PoolingParameter like below :   \n",
    "`round_mode = FLOOR`\n",
    "\n",
    "해결 상황\n",
    "- PyTorch version의 코드에서 `max_pool2d()` 호출 코드를 아래와 같이 `padding=1` 옵션대신 `ceil_mode=True`로 변경하여, caffe 버전의 Resnet50 Stem layer의 conv1, bn1, relu, maxpool 결과와 동일함을 확인하고, 최종 추론 결과는 차이점이 없음을 확인함.\n",
    "\n",
    "수정전: `maskrcnn_benchmark/modeling/backbonemaskrcnn_benchmark/modeling/backbone/resnet.py`\n",
    "```python\n",
    "    x = F.max_pool2d(x, kernel_size=3, stride=2, padding=1)\n",
    "        logger.debug(f\"\\t\\tx = F.max_pool2d(x, kernel_size=3, stride=2, padding=1)\")\n",
    "        logger.debug(f\"\\t\\t// x.shape: {x.shape}\\n\")\n",
    "```\n",
    "\n",
    "수정후: `maskrcnn_benchmark/modeling/backbonemaskrcnn_benchmark/modeling/backbone/resnet.py`\n",
    "```python\n",
    "        #x = F.max_pool2d(x, kernel_size=3, stride=2, padding=1)\n",
    "        x = F.max_pool2d(x, kernel_size=3, stride=2, ceil_mode=True)\n",
    "        logger.debug(f\"\\t\\tx = F.max_pool2d(x, kernel_size=3, stride=2, ceil_mode=True)\")\n",
    "        logger.debug(f\"\\t\\t// x.shape: {x.shape}\\n\")\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cf3392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84148fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path =f\"../npy_save/backbone_body_stem_maxpool_output.npy\"\n",
    "output_file = Path(output_file_path)\n",
    "if output_file.exists():\n",
    "    pytorch_stem_maxpool_output = np.load(output_file_path, allow_pickle=True)  \n",
    "    caffe_stem_maxpool_output=layer_output_dict['backbone_body_stem_maxpool'].data\n",
    "else:\n",
    "    print(f\"{output_file_path} is not exist!!\")\n",
    "    \n",
    "np.allclose(caffe_stem_maxpool_output, pytorch_stem_maxpool_output, rtol=1e-03, atol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad84ee48",
   "metadata": {},
   "outputs": [],
   "source": [
    "caffe_stem_maxpool_output.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a857cd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_stem_maxpool_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f85190",
   "metadata": {},
   "outputs": [],
   "source": [
    "caffe_stem_maxpool_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00df2947",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_stem_maxpool_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9411e74e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 for PyTorch and caffe",
   "language": "python",
   "name": "lomin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
