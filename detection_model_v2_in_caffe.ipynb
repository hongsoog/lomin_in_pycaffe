{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "466f770e",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "* [Mask RCNN Benchmark: model definitions and skeleton networks](http://echo.etri.re.kr:8090/display/~kimkk/Mask+RCNN+Benchmark%3A+model+definitions+and+skeleton+networks) - code by code analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f447fc",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# import caffe layers and params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b77f84f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import caffe\n",
    "from caffe import layers as L, params as P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f99f80e",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### helper to build a conv -> BN -> relu block\n",
    "\n",
    "mask rcnn에서 사용하는 FrozenBatchNorm2d 방식으로 구현할 것.\n",
    "* [Why FrozenBatchNorm2d in ResNet?](http://echo.etri.re.kr:8090/pages/viewpage.action?pageId=78088692)\n",
    "* https://github.com/facebookresearch/maskrcnn-benchmark/issues/267\n",
    "* [Batch Normalization 설명 및 구현](http://echo.etri.re.kr:8090/pages/viewpage.action?pageId=78088844)\n",
    "\n",
    "Caffe BatchNorm vs Torch BatchNorm2d  \n",
    "* [During test phase, the output of Batch Normalization layer is not equal to (input-mean)/sqrt(var + eps)?](https://github.com/BVLC/caffe/issues/4885)\n",
    "> `net.params['bn_1'][0].data` : mean  \n",
    "> `net.params['bn_1'][1].data` : variance   \n",
    "> `net.params['bn_1'][2].data` : scores a scale factor, which I should divide from each mean and variance at this layer.    \n",
    "\n",
    "So in Caffe, the output of BN layer calculated by: \n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "\\frac{\\frac{ \\text{input} - \\text{mean} }{ \\text{scale_factor} }}{\\sqrt { \\frac{ \\text{var }}{ \\text{scale_factor } } + \\epsilon}}\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "batchnorm 없이 scale 레이어로만해도  될듯...\n",
    "\n",
    "**Batch Norm Layer:**  \n",
    "* gamma --> Var (1)   \n",
    "* beta  --> mean (0)   \n",
    "* mean  --> moving average fraction (=1)   \n",
    "\n",
    "**Scale Layer:**\n",
    "* scale --> 논문에서의 gamma   \n",
    "* bias  --> 논문에서의 beta   \n",
    "\n",
    "\n",
    "```python\n",
    "# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.\n",
    "import torch\n",
    "from torch import nn\n",
    " \n",
    " \n",
    "class FrozenBatchNorm2d(nn.Module):\n",
    "    \"\"\"\n",
    "    BatchNorm2d where the batch statistics and the affine parameters\n",
    "    are fixed\n",
    "    \"\"\"\n",
    " \n",
    "    def __init__(self, n):\n",
    "        super(FrozenBatchNorm2d, self).__init__()\n",
    "        self.register_buffer(\"weight\", torch.ones(n))\n",
    "        self.register_buffer(\"bias\", torch.zeros(n))\n",
    "        self.register_buffer(\"running_mean\", torch.zeros(n))\n",
    "        self.register_buffer(\"running_var\", torch.ones(n))\n",
    " \n",
    "    def forward(self, x):\n",
    "        # Cast all fixed parameters to half() if necessary\n",
    "        if x.dtype == torch.float16:\n",
    "            self.weight = self.weight.half()\n",
    "            self.bias = self.bias.half()\n",
    "            self.running_mean = self.running_mean.half()\n",
    "            self.running_var = self.running_var.half()\n",
    " \n",
    "        scale = self.weight * self.running_var.rsqrt()\n",
    "        bias = self.bias - self.running_mean * scale\n",
    "        scale = scale.reshape(1, -1, 1, 1)\n",
    "        bias = bias.reshape(1, -1, 1, 1)\n",
    "        return x * scale + bias\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "480ff31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv_bn_scale(bottom, nout, bias_term=False, **kwargs):\n",
    "    '''Helper to build a conv -> BN -> relu block.\n",
    "    '''\n",
    "    conv = L.Convolution(bottom, num_output=nout, bias_term=bias_term,\n",
    "                         **kwargs)\n",
    "    \n",
    "    # https://github.com/facebookresearch/maskrcnn-benchmark/blob/master/maskrcnn_benchmark/layers/batch_norm.py\n",
    "    bn = L.BatchNorm(conv, use_global_stats=True, in_place=True)\n",
    "    scale = L.Scale(bn, bias_term=True, in_place=True)\n",
    "    return conv, bn, scale\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bd2346",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### helper to build basic resnet block \n",
    "\n",
    "Original Code Source\n",
    "* [https://gist.github.com/kyamagu/80c343a14ae4564ef79b53f0b01cd57e](https://gist.github.com/kyamagu/80c343a14ae4564ef79b53f0b01cd57e)\n",
    "* [https://gist.github.com/rezoo/a1c8d1459b222fc5658f](https://gist.github.com/rezoo/a1c8d1459b222fc5658f)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4eab7afb",
   "metadata": {},
   "source": [
    "def _resnet_block(name, n, bottom, nout, branch1=False, initial_stride=2):\n",
    "    '''function for building Basic Resnet Block\n",
    "    \n",
    "    Arguments:\n",
    "       name    : residual block name\n",
    "       n       : NetSpec object\n",
    "       bottom  : input to this residual block\n",
    "       nout    : num. of out ch.\n",
    "       branch1 : inclusion of subsample at beginning of this residula block? \n",
    "                 if BottleNeck architecutre used, set True (default: False)\n",
    "                  \n",
    "       initial_stride: stride used in branch2a and branc2b. note that branch3b stride is always 1.\n",
    "       \n",
    "       \n",
    "    Overview diagram:\n",
    "    \n",
    "             +------> [ res{}_branch1 -- bn{}_branch1 --- scale{}_branch1 ] -------------------------------------+\n",
    "             |                                                                                                   |\n",
    "    bottom --+---------> [ res{}_branch2a -- bn{}_branc2a --- slcale{}_branch2a - res{}_brach2a_relu ] --+       |\n",
    "             |                                                                                           |       |\n",
    "             |     +-------------------------------------------------------------------------------------+       | \n",
    "             |     |                                                                                             |\n",
    "             |     +---> [ res{}_branch2b -- bn{}_branc2b --- slcale{}_branch2b - res{}_brach2b_relu ] --+       |\n",
    "             |                                                                                           |       | if branch1 == True\n",
    "             |     +-------------------------------------------------------------------------------------+       | \n",
    "             |     |                                                                                             V\n",
    "             |     +---> [ res{}_branch2c -- bn{}_branc2c --- slcale{}_branch2c ] --------------------------> [ res{}: Eltwise ] ----> res{}_relut :ReLu\n",
    "             |                                                                                                   ^\n",
    "             |                                                                                                   | \n",
    "             |                                                                                                   | if branch1 == False\n",
    "             +---------------------------------------------------------------------------------------------------+\n",
    "    '''\n",
    "    \n",
    "    # branch1\n",
    "    if branch1:\n",
    "        res_b1 = 'res{}_branch1'.format(name)\n",
    "        bn_b1 = 'bn{}_branch1'.format(name)\n",
    "        scale_b1 = 'scale{}_branch1'.format(name)\n",
    "        n[res_b1], n[bn_b1], n[scale_b1] = _conv_bn_scale(\n",
    "            bottom, 4 * nout, kernel_size=1, stride=initial_stride, pad=0)\n",
    "    else:\n",
    "        initial_stride = 1\n",
    "\n",
    "    # branch2a\n",
    "    res = 'res{}_branch2a'.format(name)\n",
    "    bn = 'bn{}_branch2a'.format(name)\n",
    "    scale = 'scale{}_branch2a'.format(name)\n",
    "    n[res], n[bn], n[scale] = _conv_bn_scale(\n",
    "        bottom, nout, kernel_size=1, stride=initial_stride, pad=0)\n",
    "    relu2a = 'res{}_branch2a_relu'.format(name)\n",
    "    n[relu2a] = L.ReLU(n[scale], in_place=True)\n",
    "    \n",
    "    # branch2b\n",
    "    res = 'res{}_branch2b'.format(name)\n",
    "    bn = 'bn{}_branch2b'.format(name)\n",
    "    scale = 'scale{}_branch2b'.format(name)\n",
    "    n[res], n[bn], n[scale] = _conv_bn_scale(\n",
    "        n[relu2a], nout, kernel_size=3, stride=1, pad=1)\n",
    "    relu2b = 'res{}_branch2b_relu'.format(name)\n",
    "    n[relu2b] = L.ReLU(n[scale], in_place=True)\n",
    "    \n",
    "    # branch2c\n",
    "    res = 'res{}_branch2c'.format(name)\n",
    "    bn = 'bn{}_branch2c'.format(name)\n",
    "    scale = 'scale{}_branch2c'.format(name)\n",
    "    n[res], n[bn], n[scale] = _conv_bn_scale(\n",
    "        n[relu2b], 4 * nout, kernel_size=1, stride=1, pad=0)\n",
    "    \n",
    "    # res{}\n",
    "    res = 'res{}'.format(name)\n",
    "    if branch1:\n",
    "        n[res] = L.Eltwise(n[scale_b1], n[scale])\n",
    "    else:\n",
    "        n[res] = L.Eltwise(bottom, n[scale])\n",
    "    relu = 'res{}_relu'.format(name)\n",
    "    n[relu] = L.ReLU(n[res], in_place=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "646a9b9a",
   "metadata": {},
   "source": [
    "def resnet_block(stage_name, sublayer_num, n, bottom, nout, downsample_branch=False, initial_stride=2):\n",
    "    '''function for building Basic Resnet Block\n",
    "    \n",
    "    Prameters:\n",
    "       layer_num  : layer number as ? in \"backbone_body_layer?\"\n",
    "       sub_num    : sublayer number as # in \"backbone_body_layer?_#\"\n",
    "       n          : NetSpec object\n",
    "       bottom     : input to this residual block\n",
    "       nout       : num. of out ch.\n",
    "       downsample :  inclusion of subsample at beginning of this residula block? \n",
    "                     if BottleNeck architecutre used, set True (default: False)\\\n",
    "                  \n",
    "       initial_stride: stride used in branch2a and branc2b. note that branch3b stride is always 1.\n",
    "       \n",
    "       \n",
    "    Overview diagram:\n",
    "    \n",
    "             +------> [ *_downsample_0 -- *_downsample_1 --- *_downsample_scale ] -----------+\n",
    "             |                                                                               |\n",
    "    bottom --+---------> [ *_conv1 --- *_bn1 --- *_scale1 --- *_relu1 ] ----+                |\n",
    "             |                                                              |                | \n",
    "             |     +--------------------------------------------------------+                |\n",
    "             |     |                                                                         |\n",
    "             |     +---> [ *_conv2 --- *_bn2 --- *_scale2 --- *_relu2 ] ----+                |\n",
    "             |                                                              |                | if downsample == True\n",
    "             |     +--------------------------------------------------------+                | \n",
    "             |     |                                                                         V\n",
    "             |     +---> [ *_conv3 --- *_bn3 --- *_scale3 -------------------------> [ *_res: Eltwise ] ----> *__res_relu :ReLu\n",
    "             |                                                                                ^\n",
    "             |                                                                                | \n",
    "             |                                                                                | if downsample == False\n",
    "             +--------------------------------------------------------------------------------+\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    prefix =f'backbone_body_layer{stage_name}_{sublayer_num}'\n",
    "    \n",
    "    #-----------------------------------------------------------------\n",
    "    # input downsampling layer at the begining of every layer[0-4]\n",
    "    #------------------------------------------------------------------\n",
    "    # In pytorch model,\n",
    "    # backbone.body.laye{layer_num}.{sublayer_num}.downsample_0\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.downsample_1\n",
    "    #------------------------------------------------------------------\n",
    "    if downsample_branch:\n",
    "        # downsample at first layer in resnet block\n",
    "        downsample_0 = f'{prefix}_downsample_0'\n",
    "        downsample_1 =  f'{prefix}_downsample_1'\n",
    "        downsample_scale = f'{prefix}_downsample_scale'\n",
    "        n[downsample_0], n[downsample_1], n[downsample_scale] = _conv_bn_scale(\n",
    "            bottom, 4 * nout, kernel_size=1, stride=initial_stride, pad=0)\n",
    "    else:\n",
    "        initial_stride = 1\n",
    "\n",
    "    #------------------------------------------------------------------\n",
    "    # In pytorch model,\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.conv1 \n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.bn1\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.scale1\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.relu1\n",
    "    #------------------------------------------------------------------\n",
    "    conv1 = f'{prefix}_conv1'\n",
    "    bn1 = f'{prefix}_bn1'\n",
    "    scale1 = f'{prefix}_scale1'\n",
    "    \n",
    "    n[conv1], n[bn1], n[scale1] = _conv_bn_scale(\n",
    "        bottom, nout, kernel_size=1, stride=initial_stride, pad=0)\n",
    "    \n",
    "    relu1 = f'{prefix}_relu1'\n",
    "    n[relu1] = L.ReLU(n[scale1], in_place=True)\n",
    "    \n",
    "    #------------------------------------------------------------------\n",
    "    # In pytorch model,\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.conv2 \n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.bn2\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.scale2\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.relu2\n",
    "    #------------------------------------------------------------------\n",
    "    conv2 = f'{prefix}_conv2'\n",
    "    bn2 = f'{prefix}_bn2'\n",
    "    scale2 = f'{prefix}_scale2'\n",
    "    \n",
    "    n[conv2], n[bn2], n[scale2] = _conv_bn_scale(\n",
    "        n[relu1], nout, kernel_size=3, stride=1, pad=1)\n",
    "    \n",
    "    relu2 = f'{prefix}_relu2'\n",
    "    n[relu2] = L.ReLU(n[scale2], in_place=True)\n",
    "        \n",
    "    #------------------------------------------------------------------\n",
    "    # In pytorch model,\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.conv3 \n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.bn3\n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.scale3\n",
    "    #------------------------------------------------------------------\n",
    "    con3 = f'{prefix}_conv3'\n",
    "    bn3 = f'{prefix}_bn3'\n",
    "    scale3 = f'{prefix}_scale3'\n",
    "    \n",
    "    n[conv3], n[bn3], n[scale3] = _conv_bn_scale(\n",
    "        n[relu22], 4 * nout, kernel_size=1, stride=1, pad=0)\n",
    "    \n",
    "    #---------------------------------------\n",
    "    # skip connection processing\n",
    "    #---------------------------------------\n",
    "    eltwise = f'{prefix}_eltwise'\n",
    "    \n",
    "    if downsample_branch:\n",
    "        n[eltwise] = L.Eltwise(n[downsample_scale], n[scale3])\n",
    "    else:\n",
    "        n[eltwise] = L.Eltwise(bottom, n[scale3])\n",
    "    \n",
    "    #---------------------------------------\n",
    "    # last relu \n",
    "    # backbone.body.layer{layer_num}.{sublayer_num}.relu\n",
    "    #---------------------------------------\n",
    "    relu = f'{prefix}_relu'.format(name)\n",
    "    n[relu] = L.ReLU(n[res], in_place=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099a89a3",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### why downsample?\n",
    "\n",
    "When the input and output channels of the bottleneck are not equal, a certain strategy needs to be adopted.\n",
    "\n",
    "In the original paper, there are three strategies A, B, and C. Here we use strategy B (also recommended by the original paper)\n",
    "\n",
    "That is, **projection shortcuts** are used only when the number of input and output channels are not equal, \n",
    "\n",
    "- the parameter matrix mapping is used to make the input and output channels equal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45ca9bd",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### helper to build resnet50 \n",
    "\n",
    "* [resnet50 overall](https://i.stack.imgur.com/gI4zT.png)\n",
    "* [resnet50 layers in table](https://i.stack.imgur.com/FoH7Z.jpg)\n",
    "* [resnet50 structure](https://www.researchgate.net/publication/331364877/figure/fig3/AS:741856270901252@1553883726825/Left-ResNet50-architecture-Blocks-with-dotted-line-represents-modules-that-might-be.png)\n",
    "* [resnet50_structure1](https://www.mdpi.com/plants/plants-10-00031/article_deploy/html/images/plants-10-00031-g010.png)\n",
    "* [FrozenBatchNorm2d 소스 코드](https://github.com/facebookresearch/maskrcnn-benchmark/blob/master/maskrcnn_benchmark/layers/batch_norm.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d66b612",
   "metadata": {},
   "source": [
    "### lomin detection model structure\n",
    "\n",
    "\n",
    "**Note**  \n",
    "> This is just structure of detection model v2, its structure does not imply any order of layers.  \n",
    "> In this structure analysis, some layers those not include learnable parameters, such as ReLU or maxpool are hidden.\n",
    "* source : [detection model v2 structure](http://echo.etri.re.kr:8090/display/~kimkk/detection+model+v2+structure)\n",
    "\n",
    "```java\n",
    "(lomin) kimkk@alpha ~/lomin $ vi model_structure.txt\n",
    " \n",
    "GenerallizedRCNN  //model\n",
    "  │\n",
    "  ├─── backbone // model.backbone\n",
    "  │     │\n",
    "  │     ├─── body // model.backbone.body\n",
    "  │     │     ├── stem // model.backbone.body.stem\n",
    "  │     │     │    │\n",
    "  │     │     │    ├── conv1  // model.backbone.body.stem.conv1, def: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "  │     │     │    └── bn1    // model.backbone.body.stem.conv1, def: FrozenBatchNorm2d()\n",
    "  │     │     │\n",
    "  │     │     ├── layer1 //model.backbone.body.layer1\n",
    "  │     │     │    │\n",
    "  │     │     │    ├─── 0     // model.backbone.body.layer1.0\n",
    "  │     │     │    │    ├── downsample // model.backbone.body.layer1.0.downsample\n",
    "  │     │     │    │    │    │\n",
    "  │     │     │    │    │    ├── 0     // model.backbone.body.layer1.0.downsample.0,  def: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) x\n",
    "  │     │     │    │    │    └── 1     // model.backbone.body.layer1.0.downsample.1,  def: FrozenBatchNorm2d()\n",
    "  │     │     │    │    ├── conv1      // model.backbone.body.layer1.0.conv1,         def: Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │    │    ├── bn1        // model.backbone.body.layer1.0.bn1,           def: FrozenBatchNorm2d()\n",
    "  │     │     │    │    ├── conv2      // model.backbone.body.layer1.0.conv2,         def: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  │     │     │    │    ├── bn2        // model.backbone.body.layer1.0.bn2,           def: FrozenBatchNorm2d()\n",
    "  │     │     │    │    ├── conv3      // model.backbone.body.layer1.0.conv3,         def: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │    │    └── bn3        // model.backbone.body.layer1.0.bn3,           def: FrozenBatchNorm2d()\n",
    "  │     │     │    │\n",
    "  │     │     │    ├─── 1 // model.backbone.body.layer1.1\n",
    "  │     │     │    │    ├── conv1      // model.backbone.body.layer1.1.conv1,         def: Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │    │    ├── bn1        // model.backbone.body.layer1.1.bn1,           def: FrozenBatchNorm2d()\n",
    "  │     │     │    │    ├── conv2      // model.backbone.body.layer1.1.conv2,         def: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  │     │     │    │    ├── bn2        // model.backbone.body.layer1.1.bn1,           def: FrozenBatchNorm2d()\n",
    "  │     │     │    │    ├── conv3      // model.backbone.body.layer1.1.conv3,         def: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │    │    └── bn3        // model.backbone.body.layer1.1.bn3,           def: FrozenBatchNorm2d()\n",
    "  │     │     │    │\n",
    "  │     │     │    └─── 2 // model.backbone.body.layer1.2\n",
    "  │     │     │         ├── conv1       // model.backbone.body.layer1.2.conv1,         def: Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │         ├── bn1         // model.backbone.body.layer1.2.bn1,           def: FrozenBatchNorm2d()\n",
    "  │     │     │         ├── conv2       // model.backbone.body.layer1.2.conv2,         def: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  │     │     │         ├── bn2         // model.backbone.body.layer1.2.bn2,           def: FrozenBatchNorm2d()\n",
    "  │     │     │         ├── conv3       // model.backbone.body.layer1.2.conv3,         def: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │         └── bn3         // model.backbone.body.layer1.2.conv2,         def: FrozenBatchNorm2d()\n",
    "  │     │     │\n",
    "  │     │     ├── layer2 // model.backbone.body.layer2\n",
    "  │     │     │    │\n",
    "  │     │     │    ├─── 0 // model.backbone.body.layer2.0)\n",
    "  │     │     │    │    ├── downsample  // model.backbone.body.layer2.0.downsample)\n",
    "  │     │     │    │    │    │\n",
    "  │     │     │    │    │    ├── 0      // model.backbone.body.layer2.0.downsample.0 , def: Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "  │     │     │    │    │    └── 1      // model.backbone.body.layer2.0.downsample.1,  def: FrozenBatchNorm2d()\n",
    "  │     │     │    │    ├── conv1       // model.backbone.body.layer2.0.conv1,         def: Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "  │     │     │    │    ├── bn1         // model.backbone.body.layer2.0.bn1,           def: FrozenBatchNorm2d()\n",
    "  │     │     │    │    ├── conv2       // model.backbone.body.layer2.0.conv2,         def: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  │     │     │    │    ├── bn2         // model.backbone.body.layer2.0.bn2,           def: FrozenBatchNorm2d()\n",
    "  │     │     │    │    ├── conv3       // model.backbone.body.layer2.0.conv3,         def: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │    │    └── bn3         // model.backbone.body.layer2.0.bn3,           def: FrozenBatchNorm2d()\n",
    "  │     │     │    │\n",
    "  │     │     │    ├─── 1 // model.backbone.body.layer2.1\n",
    "  │     │     │    │    ├── conv1       // model.backbone.body.layer2.1.conv1,         def: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │    │    ├── bn1         // model.backbone.body.layer2.1.bn1,           def: FrozenBatchNorm2d()\n",
    "  │     │     │    │    ├── conv2       // model.backbone.body.layer2.1.conv2,         def: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  │     │     │    │    ├── bn2         // model.backbone.body.layer2.1.bn2,           def: FrozenBatchNorm2d()\n",
    "  │     │     │    │    ├── conv3       // model.backbone.body.layer2.1.conv3,         def: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │    │    └── bn3         // model.backbone.body.layer2.1.bn3,           def:# FrozenBatchNorm2d()\n",
    "  │     │     │    │\n",
    "  │     │     │    ├─── 2 // model.backbone.body.layer2.2\n",
    "  │     │     │    │    ├── conv1       // model.backbone.body.layer2.2.conv1,         def: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │    │    ├── bn1         // model.backbone.body.layer2.2.bn1,           def: FrozenBatchNorm2d()\n",
    "  │     │     │    │    ├── conv2       // model.backbone.body.layer2.2.conv2,         def: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  │     │     │    │    ├── bn2         // model.backbone.body.layer2.2.bn2,           def: FrozenBatchNorm2d()\n",
    "  │     │     │    │    ├── conv3       // model.backbone.body.layer2.2.conv3,         def: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │    │    └── bn3         // model.backbone.body.layer2.2.bn3,           def: FrozenBatchNorm2d()\n",
    "  │     │     │    │\n",
    "  │     │     │    └─── 3 // model.backbone.body.layer2.3\n",
    "  │     │     │         ├── conv1       // model.backbone.body.layer2.3.conv1,         def: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │         ├── bn1         // model.backbone.body.layer2.3.bn1,           def: FrozenBatchNorm2d()\n",
    "  │     │     │         ├── conv2       // model.backbone.body.layer2.3.conv2,         def: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  │     │     │         ├── bn2         // model.backbone.body.layer2.3.bn2,           def: FrozenBatchNorm2d()\n",
    "  │     │     │         ├── conv3       // model.backbone.body.layer2.3.conv3,         def: # Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │         └── bn3         // model.backbone.body.layer2.3.bn3,           def: # FrozenBatchNorm2d()\n",
    "  │     │     │\n",
    "  │     │     ├── layer3 // model.backbone.body.layer3\n",
    "  │     │     │    │\n",
    "  │     │     │    ├─── 0 // model.backbone.body.layer3.0\n",
    "  │     │     │    │    ├── downsample // model.backbone.body.layer3.0.downsamples\n",
    "  │     │     │    │    │    │\n",
    "  │     │     │    │    │    ├── 0     // model.backbone.body.layer3.0.downsamples.0, def: Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "  │     │     │    │    │    └── 1     // model.backbone.body.layer3.0.downsamples.0, def: FrozenBatchNorm2d()\n",
    "  │     │     │    │    ├── conv1      // model.backbone.body.layer3.0.conv1,         def: Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "  │     │     │    │    ├── bn1        // model.backbone.body.layer3.0.bn1,           def: # FrozenBatchNorm2d()\n",
    "  │     │     │    │    ├── conv2      // model.backbone.body.layer3.0.conv2,         def: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  │     │     │    │    ├── bn2        // model.backbone.body.layer3.0.bn2,           def: FrozenBatchNorm2d()\n",
    "  │     │     │    │    ├── conv3      // model.backbone.body.layer3.0.conv3,         def: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │    │    └── bn3        // model.backbone.body.layer3.0.bn3,           def: FrozenBatchNorm2d()\n",
    "  │     │     │    │\n",
    "  │     │     │    ├─── 1 // model.backbone.body.layer3.1\n",
    "  │     │     │    │    ├── conv1      // model.backbone.body.layer3.1.conv1,         def: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │    │    ├── bn1        // model.backbone.body.layer3.1.bn1,           def: FrozenBatchNorm2d()\n",
    "  │     │     │    │    ├── conv2      // model.backbone.body.layer3.1.conv2,         def: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  │     │     │    │    ├── bn2        // model.backbone.body.layer3.1.bn2,           def: FrozenBatchNorm2d()\n",
    "  │     │     │    │    ├── conv3      // model.backbone.body.layer3.1.conv3,         def: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │    │    └── bn3        // model.backbone.body.layer3.1.bn3,           def: FrozenBatchNorm2d()\n",
    "  │     │     │    │\n",
    "  │     │     │    ├─── 2 // model.backbone.body.layer3.2\n",
    "  │     │     │    │    ├── conv1      // model.backbone.body.layer3.2.conv1,         def: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │    │    ├── bn1        // model.backbone.body.layer3.2.bn1,           def: FrozenBatchNorm2d()\n",
    "  │     │     │    │    ├── conv2      // model.backbone.body.layer3.2.conv2,         def: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  │     │     │    │    ├── bn2        // model.backbone.body.layer3.2.bn2,           def: FrozenBatchNorm2d()\n",
    "  │     │     │    │    ├── conv3      // model.backbone.body.layer3.2.conv3,         def: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │    │    └── bn3        // model.backbone.body.layer3.2.bn3,           def: FrozenBatchNorm2d()\n",
    "  │     │     │    │\n",
    "  │     │     │    ├─── 3 // model.backbone.body.layer3.3\n",
    "  │     │     │    │    ├── conv1      // model.backbone.body.layer3.3.conv1,         def: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │    │    ├── bn1        // model.backbone.body.layer3.3.bn1,           def: FrozenBatchNorm2d()\n",
    "  │     │     │    │    ├── conv2      // model.backbone.body.layer3.3.conv2,         def: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  │     │     │    │    ├── bn2        // model.backbone.body.layer3.3.bn2,           def: FrozenBatchNorm2d()\n",
    "  │     │     │    │    ├── conv3      // model.backbone.body.layer3.3.conv3,         def: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │    │    └── bn3        // model.backbone.body.layer3.3.bn3,           def: FrozenBatchNorm2d()\n",
    "  │     │     │    │\n",
    "  │     │     │    ├─── 4 (model.backbone.body.layer3.4)\n",
    "  │     │     │    │    ├── conv1      // model.backbone.body.layer3.4.conv1,         def: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │    │    ├── bn1        // model.backbone.body.layer3.4.bn1,           def: FrozenBatchNorm2d()\n",
    "  │     │     │    │    ├── conv2      // model.backbone.body.layer3.4.conv2,         def: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  │     │     │    │    ├── bn2        // model.backbone.body.layer3.4.bn2,           def: FrozenBatchNorm2d()\n",
    "  │     │     │    │    ├── conv3      // model.backbone.body.layer3.4.conv3,         def: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │    │    └── bn3        // model.backbone.body.layer3.4.bn3,           def: FrozenBatchNorm2d()\n",
    "  │     │     │    │\n",
    "  │     │     │    └─── 5 // model.backbone.body.layer3.5\n",
    "  │     │     │         ├── conv1       // model.backbone.body.layer3.5.conv1,         def: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │         ├── bn1         // model.backbone.body.layer3.5.bn1,           def: FrozenBatchNorm2d()\n",
    "  │     │     │         ├── conv2       // model.backbone.body.layer3.5.conv2,         def: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  │     │     │         ├── bn2         // model.backbone.body.layer3.5.bn2,           def: FrozenBatchNorm2d()\n",
    "  │     │     │         ├── conv3       // model.backbone.body.layer3.5.conv3,         def: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │     │         └── bn3         // model.backbone.body.layer3.5.bn3,           def: FrozenBatchNorm2d()\n",
    "  │     │     │\n",
    "  │     │     └── layer4 // model.backbone.body.layer4\n",
    "  │     │          │\n",
    "  │     │          ├─── 0 // model.backbone.body.layer4.0\n",
    "  │     │          │    ├── downsample  // model.backbone.body.layer4.0.downsample\n",
    "  │     │          │    │   │\n",
    "  │     │          │    │   ├── 0       // model.backbone.body.layer4.0.downsample.0,  def: conv1 Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "  │     │          │    │   └── 1       // model.backbone.body.layer4.0.downsample.1,  def: FrozenBatchNorm2d()\n",
    "  │     │          │    ├── conv1       // model.backbone.body.layer4.0.conv1,         def: Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "  │     │          │    ├── bn1         // model.backbone.body.layer4.0.bn1,           def: FrozenBatchNorm2d()\n",
    "  │     │          │    ├── conv2       // model.backbone.body.layer4.0.conv2,         def: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  │     │          │    ├── bn2         // model.backbone.body.layer4.0.bn2,           def: FrozenBatchNorm2d()\n",
    "  │     │          │    ├── conv3       // model.backbone.body.layer4.0.conv3,         def: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │          │    └── bn3         // model.backbone.body.layer4.0.bn3,           def: FrozenBatchNorm2d()\n",
    "  │     │          │\n",
    "  │     │          ├─── 1 // model.backbone.body.layer4.1\n",
    "  │     │          │    ├── conv1       // model.backbone.body.layer4.1.conv1,         def: Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │          │    ├── bn1         // model.backbone.body.layer4.1.bn1,           def: FrozenBatchNorm2d()\n",
    "  │     │          │    ├── conv2       // model.backbone.body.layer4.1.conv2,         def: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  │     │          │    ├── bn2         // model.backbone.body.layer4.1.bn2,           def: FrozenBatchNorm2d()\n",
    "  │     │          │    ├── conv3       // model.backbone.body.layer4.1.conv3,         def: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │          │    └── bn3         // model.backbone.body.layer4.1.bn3,           def: FrozenBatchNorm2d()\n",
    "  │     │          │\n",
    "  │     │          └─── 2 // model.backbone.body.layer4.2\n",
    "  │     │               ├── conv1       // model.backbone.body.layer4.2.conv1,         def: Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │               ├── bn1         // model.backbone.body.layer4.2.bn1,           def: FrozenBatchNorm2d()\n",
    "  │     │               ├── conv2       // model.backbone.body.layer4.2.conv2,         def: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  │     │               ├── bn2         // model.backbone.body.layer4.2.bn2,           def: FrozenBatchNorm2d()\n",
    "  │     │               ├── conv3       // model.backbone.body.layer4.2.conv3,         def: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  │     │               └── bn3         // model.backbone.body.layer4.2.bn3,           def: FrozenBatchNorm2d()\n",
    "  │     │\n",
    "  │     └─── fpn // model.backbone.fpn\n",
    "  │           ├── fpn_inner2            // model.backbone.fpn.fpn_inner2,              def: Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
    "  │           ├── fpn_layer2            // model.backbone.fpn.fpn_layer2,              def: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  │           ├── fpn_inner3            // model.backbone.fpn.fpn_inner3,              def: Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
    "  │           ├── fpn_layer3            // model.backbone.fpn.fpn_layer3,              def: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  │           ├── fpn_inner4            // model.backbone.fpn.fpn_inner4,              def: Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
    "  │           ├── fpn_layer4            // model.backbone.fpn.fpn_layer4,              def: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  │           └── top_blocks // model.backbone.fpn.topblocks\n",
    "  │                 │\n",
    "  │                 ├─── p6             // model.backbone.fpn.topblocks.p6,            def: Conv2d(2048, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "  │                 └─── p7             // model.backbone.fpn.topblocks.p7,            def: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "  │\n",
    "  └─── rpn //  model.rpn\n",
    "        │\n",
    "        ├─── anchor_generator // model.rpn.anchor_generator\n",
    "        │           └─── cell_anchors  // model.rpn.anchor_generator.cell_achors,      def: BufferList()\n",
    "        │\n",
    "        ├─── head // model.rpn.head\n",
    "        │           ├─── cls_tower    // model.rpn.head.cls_tower\n",
    "        │           │     ├─── 0      // model.rpn.head.cls_tower.0,                   def: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        │           │     ├─── 1      // model.rpn.head.cls_tower.1,                   def: ReLU()\n",
    "        │           │     ├─── 2      // model.rpn.head.cls_tower.2,                   def: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        │           │     ├─── 3      // model.rpn.head.cls_tower.3,                   def: ReLU()\n",
    "        │           │     ├─── 4      // model.rpn.head.cls_tower.4,                   def: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ReLU()\n",
    "        │           │     ├─── 5      // model.rpn.head.cls_tower.5,                   def: ReLU()\n",
    "        │           │     ├─── 6      // model.rpn.head.cls_tower.6,                   def: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        │           │     └─── 7      // model.rpn.head.cls_tower.7,                   def: ReLU()\n",
    "        │           │\n",
    "        │           ├─── bbox_tower   // model.rpn.head.bbox_tower\n",
    "        │           │     ├─── 0      // model.rpn.head.bbox_tower.0,                  def: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        │           │     ├─── 1      // model.rpn.head.bbox_tower.1,                  def: ReLU()\n",
    "        │           │     ├─── 2      // model.rpn.head.bbox_tower.2,                  def: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        │           │     ├─── 3      // model.rpn.head.bbox_tower.3,                  def: ReLU()\n",
    "        │           │     ├─── 4      // model.rpn.head.bbox_tower.4,                  def: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ReLU()\n",
    "        │           │     ├─── 5      // model.rpn.head.bbox_tower.5,                  def: ReLU()\n",
    "        │           │     ├─── 6      // model.rpn.head.bbox_tower.6,                  def: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        │           │     └─── 7      // model.rpn.head.bbox_tower.7,                  def: ReLU()\n",
    "        │           │\n",
    "        │           ├─── cls_logits   // model.rpn.head.cls_logits,                    def: Conv2d(1024, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        │           └─── bbox_pred    // model.rpn.head.bbox_pre,                      def: Conv2d(1024, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        │\n",
    "        └─── box_selector_test        // model.rpn.box_selector_test,                  def: RetinaNetPostProcessor()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4032b88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet50(n, bottom):\n",
    "    '''ResNet 50 layers.\n",
    "    '''\n",
    "    \n",
    "    stage_prefix = \"backbone_body\"\n",
    "    \n",
    "    #-------------------------------------\n",
    "    # model.backbone.body.stem (stage 0)\n",
    "    #-------------------------------------\n",
    "    stage_name = \"stem\"\n",
    "    stage = f'{stage_prefix}_{stage_name}_'\n",
    "    \n",
    "    n[stage + 'conv1'], n[stage + 'bn1'], n[stage + 'scale'] =_conv_bn_scale( bottom, 64, bias_term=False, kernel_size=7, pad=3, stride=2)\n",
    "    n[stage + 'relu'] = L.ReLU(n[stage + 'scale'])\n",
    "    n[stage + 'maxpool'] = L.Pooling( n[stage + 'relu'], kernel_size=3, stride=2, pool=P.Pooling.MAX)\n",
    "    \n",
    "    #-------------------------------------\n",
    "    # model.backbone.layer1 (stage 1)\n",
    "    #-------------------------------------\n",
    "    pre_stage = stage\n",
    "    stage_name = \"layer1\"\n",
    "    stage = f'{stage_prefix}_{stage_name}'\n",
    "        \n",
    "    resnet_block(stage, '0', n, n[pre_stage + 'maxpool'], 64, downsample_branch=True, initial_stride=1)\n",
    "    resnet_block(stage, '1', n, n[stage + '_0_downsample_0_relu'], 64)\n",
    "    resnet_block(stage, '2', n, n[stage + '_1_relu'], 64)\n",
    "    \n",
    "    #-------------------------------------\n",
    "    # model.backbone.layer2 (stage 2)\n",
    "    #-------------------------------------\n",
    "    pre_stage = stage\n",
    "    stage_name = \"layer2\"\n",
    "    stage = f'{stage_prefix}_{stage_name}'\n",
    "    \n",
    "    resnet_block(state, '0', n, n[pre_stage + 'relu'], 128, downsample_branch=True)\n",
    "    resnet_block(stage, '1', n, n[stage + '_0_downsample_0_relu'], 128)\n",
    "    resnet_block(stage, '2', n, n[stage + '_1_relu'], 128)\n",
    "    resnet_block(stage, '3', n, n[stage + '_2_relu'], 128)\n",
    "    \n",
    "    #_resnet_block(prefix, '0', n, n.res2c_relu, 128, branch1=True)\n",
    "    #_resnet_block(prefix, '1', n, n.res3a_relu, 128)\n",
    "    #_resnet_block(prefix, '2', n, n.res3b_relu, 128)\n",
    "    #_resnet_block(prefix, '3', n, n.res3c_relu, 128)\n",
    "\n",
    "     #-------------------------------------\n",
    "    # model.backbone.layer3 (stage 3)\n",
    "    #-------------------------------------\n",
    "    pre_stage = stage\n",
    "    stage_name = \"layer3\"\n",
    "    stage = f'{stage_prefix}_{stage_name}'\n",
    "    \n",
    "    resnet_block(prefix, '0', n, n[pre_stage + 'relu'], 256, downsample_branch=True)\n",
    "    resnet_block(prefix, '1', n, n[stage + '0_downsample_0_relu'], 256)\n",
    "    resnet_block(prefix, '2', n, n[stage + '_1_relu'], 256)\n",
    "    resnet_block(prefix, '3', n, n[stage + '_2_relu'], 256)\n",
    "    resnet_block(prefix, '4', n, n[stage + '_3_relu'], 256)\n",
    "    resnet_block(prefix, '5', n, n[stage + '_4_relu'], 256)\n",
    "\n",
    "    #-------------------------------------\n",
    "    # model.backbone.layer4 (stage 4)\n",
    "    #-------------------------------------\n",
    "    pre_stage = stage\n",
    "    stage_name = \"layer4\"\n",
    "    stage = f'{stage_prefix}_{stage_name}'\n",
    "    \n",
    "    stage= f\"backbone_body_layer4\"  \n",
    "    resnet_block(prefix, '0', n, n[pre_stage + 'relu'], 512, downsample_branch=True)\n",
    "    resnet_block(prefix, '1', n, n[stage + '_0_downsample_0_relu'], 512)\n",
    "    resnet_block(prefix, '2', n, n[stage + '_1_relu'], 512)\n",
    "\n",
    "    #-------------------------------------\n",
    "    # Polling after stage 4\n",
    "    #-------------------------------------\n",
    "    pre_stage = stage\n",
    "    stage_name = \"pool\"\n",
    "    stage = f'{stage_prefix}_{stage_name}'    \n",
    "    \n",
    "    n[stage] = L.Pooling(n[pre_stage + 'relu'], kernel_size=7, stride=1, pool=P.Pooling.AVE)\n",
    "\n",
    "    return n.to_proto()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66916994",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'relu22' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-6067b2851860>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDummyData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mres50_proto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#print(str(res50_proto))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-1579242939df>\u001b[0m in \u001b[0;36mresnet50\u001b[0;34m(n, bottom)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mstage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{stage_prefix}_{stage_name}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mresnet_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpre_stage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'maxpool'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownsample_branch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_stride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mresnet_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_0_downsample_0_relu'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mresnet_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_1_relu'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-5ffc470f12da>\u001b[0m in \u001b[0;36mresnet_block\u001b[0;34m(stage_name, sublayer_num, n, bottom, nout, downsample_branch, initial_stride)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     n[conv3], n[bn3], n[scale3] = _conv_bn_scale(\n\u001b[0;32m--> 100\u001b[0;31m         n[relu22], 4 * nout, kernel_size=1, stride=1, pad=0)\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;31m#---------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'relu22' is not defined"
     ]
    }
   ],
   "source": [
    "n = caffe.NetSpec()\n",
    "n.data = L.DummyData(shape=[dict(dim=[1, 3, 224, 224])])\n",
    "\n",
    "res50_proto = resnet50(n, n.data)\n",
    "\n",
    "#print(str(res50_proto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cb9f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25acd87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521faf37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 for PyTorch and caffe",
   "language": "python",
   "name": "lomin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
